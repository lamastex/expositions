
\documentclass{amsart}

\usepackage[applemac]{inputenc}

\addtolength{\hoffset}{-5mm}
\addtolength{\textwidth}{22mm}
\addtolength{\voffset}{-3mm}
\addtolength{\textheight}{20mm}

\def\uuu{_}

\def\vvv{-}

\begin{document}

\centerline{\bf\large{Operator theory}}

\newpage




\centerline {\bf \large {1. Bounded self-adjoint operators.}}

\bigskip

\noindent
Let $\mathcal H$ be a complex Hilbert space.
A bounded linear operator $S$ on $\mathcal H$ is 
self-adjoint if $S=S^*$, or equivalently
\[ 
\langle x,Sy \rangle=\text{the complex conjugate of}\,\, 
\langle Sx, y\rangle\quad\colon\quad x,y\in \mathcal H\tag{*}
\]
If $S$ is self-adjoint we have the equality of operator norms:
\[ 
||S||^2=||S^2||\tag{i}
\]
To see this we notice that if $x\in\mathcal H$ has norm one then
\[
\langle Sx,Sx\rangle=
\langle x,S^*Sx\rangle=
\langle x,S^2x\rangle\tag{ii}
\]
By the Cauchy-Schwarz inequality the last term
is $\leq ||x|\cdot ||S^2||$. Since (ii) holds for
every $x$ of norm one we conclude that
\[
||S||^2\leq ||S^2||
\]
Now (i) follows
from the multiplicative inequality for operator norms.
Next, by induction over $n$ we get the
equalities
\[
||S||^{2n}=||S^n||^2\quad\,\colon\,\,n\geq 1
\]
Taking the $n$:th root and passing to the limit the spectral
radius formula gives
\[
||S||=\max_{z\in\sigma(S)}\, |z|\tag{*}
\]


\noindent
Next, we
consider the spectrum of self-adjoint operators.

\medskip

\noindent
{\bf{1.1 Theorem.}}
\emph{The spectrum of a bounded self-adjoint operator
is a compact real interval.}
\medskip

\noindent
\emph{Proof.}
Let $\lambda$ be a complex number 
and for a given $x$ we set
$y=\lambda x-Sx$.
It follows that
\[ 
||y||^2=|\lambda|^2\cdot ||x||^2+||Sx|^2+
\lambda\cdot \langle x,Sx\rangle+
\bar \lambda\cdot \langle Sx,x\rangle
\]
Since $S$ is self-adjoint
we get
\[
\lambda\cdot \langle x,Sx\rangle+
\bar \lambda\cdot \langle Sx,x\rangle=2\cdot \mathfrak{Re}(\lambda)\cdot
\langle Sx,x\rangle
\]
Now $|\langle Sx,x\rangle|\leq ||Sx||\cdot ||x||$
so the triangle inequality gives
\[
||y||^2\geq |\lambda|^2\cdot ||x||^2+||Sx|^2-2|\mathfrak{Re}(\lambda)||\cdot
||Sx||\cdot ||x||\tag{i}
\]
With $\lambda=a+ib$
the right hand side becomes
\[ 
b^2||x||^2+a^2||x||^2+||Sx||^2-2a\cdot ||Sx||\cdot ||x||\geq b^2||x||^2
\]
Hence we have proved that
\[ 
||\lambda x-Sx||^2\geq( \mathfrak{Im}\,\lambda)^2\cdot ||x||^2\tag{ii}
\]
This implies that
$\lambda E-S$ is invertible for every non-real $\lambda$
which proves Theorem 1.1. Notioce that the proof also gives 
\[
||(\lambda E-S)^{-1}||\leq \frac{1}{|\mathfrak{Im}\,\lambda|}\tag{iii}
\]





\medskip



\noindent
Theorem 1.1 together with
general results about uniform algebras in ¤ XX
 give the following:
\medskip


\noindent
{\bf{1.2 Theorem.}}
\emph{Denote by ${\bf{S}}$  the closed subalgebra of
$L(\mathcal H,\mathcal H)$ generated by $S$ and the identity
operator. Then ${\bf{S}}$ is 
a sup-norm algebra which is isomorphic to
the sup-norm algebra
$C^0(\sigma(S))$.}


\medskip


\noindent
{\bf{Exercise.}}
Let $T$ be an arbitary bounded opertor
on $\mathcal H$. Show that
the operator $A=T^*T$ is self-adjoint and that $\sigma(A)$
is a compact subset of $[0,+\infty)$,  i.e. every point in its spectrum os
real and non-negative.
A hint is to use the biduality formula $T= T^{**}$
and if $s$ is real the reader should verify that
\[
||sx+T^*T x||^2=s^2||x||^2+2s\cdot ||Tx||^2+||T^*T x||^2
\]

\newpage

\centerline{\bf{1.3 Normal operators.}}
\bigskip

\noindent
A bounded linear operator $A$ is normal if it commutes with its
adjoint $A^*$.
Let $A$ be normal and put $S=A^*A$ which yields a self-adjoint by  Exercise 1.2.
Hence (*) above Theorem  1.1  gives
\[
||S||^2= ||S^2||=||A^2\cdot A(^*)^2||\leq
||A^2||\cdot ||(A^*)^2||\tag{i}
\]
where we used the multiplicative inequality for operator norms.
Now $(A^*)^2$ is the adjoint of $A^2$
and we recall from ¤ xx that
the norms of an operator and its adjoint are equal. Hence
the right hand side in (1) is equal to $||A^2||^2$.
At the same time
\[
||S||= ||A^*A||= ||A||^2
\] 
and we conclude that (i) gives
\[
||A||^2\leq ||A^2||\tag{ii}
\]
Exactly as in the self-adjoint case we can take higher powers
and obtain
the equality
\[
||A||=\max_{z\in\sigma(A)}\,|z|\tag{1.3.1}
\]
Since every polynomial in $A$ again is a normal operator
for which (1.3.1) holds we have proved the following:
\medskip

\noindent
{\bf{1.4 Theorem}}
\emph{Let $A$ be a normal operator.
Then the closed subalgebra ${\bf{A}}$ generated by
$A$ in  $L(\mathcal H,\mathcal H)$
is a sup-norm algebra.}
\medskip

\noindent
{\bf{Remark.}}
The spectrum $\sigma(A)$ is 
some compact subset of  ${\bf{C}}$ and in general analytic polynomials
restricted to $\sigma(A)$ do not generate a dense subalgebra of
$C^0(\sigma(A))$.
To get a more extensive algebra
we
consider the closed subalgebra $\mathcal B$
of
$L(\mathcal H,\mathcal H)$ which is generated by $A$ and $A^*$.
Since every  polynomial in $A$ and $A^*$ again is a normal operator
it follows that 
$\mathcal B$ is a sup-norm algebra and here 
the following holds:

\medskip
\noindent
{\bf{1.5 Theorem.}}
\emph{The sup-norm algebra $\mathcal B$ is via the Gelfand
transform isomorphic with $C^0(\sigma(A))$.}
\medskip

\noindent
\emph{Proof.}
Let $Q\in\mathcal B$
be arbitrary. Now $S=Q+Q^*$  is self-adjoint and 
Theorem 1.1 entails that its
Gelfand transform is real-valued, i.e. the function 
$\widehat Q(p)+\hat Q^*(p)$ is real. So if  
with $\widehat Q(p)= a+ib$ we must have $\hat Q^*=a_1-ib$ for some 
real number $a_1$. Next,  $QQ^*$ is also self-adjoint and hence
$(a+ib)(a_1-ib)$ is real. This gives $a=a_1$ and which shows that  
the Gelfand transform of $Q^*$ is the complex conjugate function of
$\widehat Q$. Hence the Gelfand transforms of $\mathcal B$-elements is 
a self-adjoint algebra and 
the Stone-Weierstrass theorem implies that
the Glefand transforms of $\mathcal B$-elements is 
equal to the whole algebra 
$C^0(\mathfrak{M}_\mathcal B$.
Finally, since $\widehat A^*$ is the complex conjugate function of 
$\widehat A$ it follows that the Gelfand transform
$\widehat A$  separates points on $\mathfrak{M}_\mathcal B$
which means that this maximal ideal space can be identified with
$\sigma(A)$.


\bigskip


\centerline {\bf{1.6 Spectral measures.}}
\bigskip


\noindent
Let $A$ be a normal operator and  $\mathcal B$ is the
Banach algebra above.
Each   pair of vectors $x,y$
in
$\mathcal H$ yields
a linear functional on
$\mathcal B$ defined by 
\[ 
T\mapsto \langle Tx,y\rangle
\]
Identifying
$\mathcal B$ with $C^0(\sigma(A))$,
the Riesz representation formula gives 
a unique Riesz measure 
$\mu_{x,y}$ on $\sigma(A)$ such that
\[
\langle Tx,y\rangle=\int_{\sigma(A)}\, \widehat T(z)\cdot d\mu_{x,y}(z)\tag{1.6.1}
\] 
hold for every $T\in \mathcal B$.
Since $\widehat A(z)=z$ we have 
\[
\langle Ax,y\rangle=\int\, z\cdot d\mu_{x,y}(z)
\]
Similarly one has
\[
\langle A^*x,y\rangle=\int\, \bar z\cdot d\mu_{x,y}(z)
\]
\medskip

\noindent
{\bf{1.7 The operators $E(\delta)$}}.
Notice  that (1.6.1) implies that the map
from $\mathcal H\times\mathcal H$ into
the space of Riesz measures on $\sigma(A)$ is bi-linear.
We have for example:
\[
\mu_{x_1+x_2,y}=\mu_{x_1,y}+\mu_{x_2,y}
\]



\noindent
Moreover, since
$\mathcal B$ is the sup-norm algebra $C^0(\sigma(A))$
the total variations of the $\mu$-measures
satisfy the equations:
\[
||\mu_{x,y}||\leq\max_{T\in \mathcal B_*}|\langle Tx,y\rangle|\tag{1.7.1}
\]
where $\mathcal B_*$ is the unit ball in
$\mathcal B$. From this we obtain
\[
|| \mu_{x,y}||\leq ||x||\cdot ||y||\tag{1.7.2}
\]


\noindent
Next, let $\delta$ be a Borel subset of
$\sigma(A)$. Keeping $y$ fixed in $\mathcal H$
we obtain a linear functional on $\mathcal H$ defined by
\[ 
x\mapsto 
\int_\delta \,  d\mu_{x,y}(z)=\mu_{x,y}(\delta)
\]
By (1.7.2) it has norm $\leq ||y||$ and is represented by
a vector $E(\delta)x$ in $\mathcal H$. More precisely 
\[
\langle E(\delta)x,y\rangle= 
\int_\delta \,  d\mu_{x,y}(z)=\mu_{x,y}(\delta)\tag{1.7.3}
\]
\medskip

\noindent
{\bf{1.7.4 Exercise.}}
Show that $x\mapsto E(\delta)x$ is linear and that
the resulting linear operator
$E(\delta)$
commutes with all operators in $\mathcal B$. Moreover, show that 
it is a self-adjoint projection, i.e.
\[ 
E(\delta)^2=E(\delta)\quad\text{and}\quad
E(\delta)^*=E(\delta)
\]
Finally, show that
\[
E(\delta_1\cap\delta_2)=E(\delta_1)E(\delta_2)
\] 
holds for every pair of Borel subsets and with
$\delta=\sigma(A)$ one gets the identity operator.

\bigskip
\noindent
{\bf{1.7.5 Resolution of the identity.}}
If $\delta_1,\ldots,\delta_N$ is any finite family of disjoint 
Borel sets whose union is
$\sigma(A)$ then
\[
1= E(\delta_1)+\ldots +E(\delta_N)
\]
At the same tine we get a decomposition of the operator $A$:
\[
A=A_1+\ldots+A_N\quad\text{where}\quad
A_k=E(\delta_k)\cdot A
\]
For each $k$ the spectrum $\sigma(A_k)$ is equal to  the closure of
$\delta_k$. So the normal operator is represented by a sum of normal operators
where the individual operators have  small spectra when the
$\delta$-partition is fine.


\newpage

\centerline{\bf{2. Unbounded operators on Hilbert spaces}}
\bigskip


\noindent
Let $T$ be a densely
defined
linear operator on a complex Hilbert space $\mathcal H$.
We  suppose that 
$T$ is unbounded so that:
\[ 
\max_{x\in\mathcal D_*(T)}\, ||Tx||=+\infty
\quad \mathcal D_*(T)=\text{ the set of unit vectors in}\quad 
\mathcal D(T)
\]

\medskip

\noindent{\bf{2.1 The adjoint $T^*$.}}
If $y\in\mathcal H$  we get a linear functional on
$\mathcal D(T)$ defined by
\[
 x\mapsto \langle Tx,y\rangle\tag{i}
\]
If there exists a constant $C(y)$ such that
the absolute value of (i) is $\leq C(y)\cdot ||x||$ for every
$x\in\mathcal D(T)$, then  (i) extends to a continuous linear
functional on
$\mathcal H$.
The extension is unique because 
$\mathcal D(T)$ is dense and since   $\mathcal H$ 
is self-dual there exists 
a
unique vector
$T^*y$ such that
\[
\langle Tx,y\rangle=
\langle x,T^*y\rangle\quad\colon\quad x\in\mathcal D(T)
\tag{2.1.1}
\]
This gives  a linear operator $T^*$
where $\mathcal D(T^*)$ is characterised  as above.
Now we shall  describe the
graph of $T^*$. For this purpose 
we consider  the Hilbert space  $\mathcal H\times\mathcal H$
equipped with the  inner product
\[
\langle (x,y),(x_1,y_1)\rangle= 
\langle x,x_1\rangle+\langle y,y_1\rangle
\]
On $\mathcal H\times\mathcal H$ we define the linear operator
\[ 
J(x,y)= (-y,x)
\]


\noindent
{\bf{2.2 Proposition.}}
\emph{For every densely defined operator $T$
one has the equality}
\[ 
\Gamma(T^*)= J(\Gamma(T))^\perp
\]


\noindent
\emph{Proof.}
Let $(y,T^*y)$ be a vector in
$\Gamma(T^*)$. If $x\in\mathcal D(T)$  the equality (2.1.1)
and the construction of $J$ give
\[
\langle (y,-Tx\rangle + \langle  T^*y,x\rangle =0
\]
This proves  that $\Gamma(T^)*\perp
J(\Gamma(T))$. Conversely,  if 
$(y,z)\perp J(\Gamma(T))$
we have
\[
\langle y,-Tx\rangle + \langle  z,x\rangle=0
\quad\colon x\in\mathcal D(T)\tag{i}
\]
This shows that
$y\in\mathcal D(T^*)$ and  $z=T^*y$ which proves Proposition 2.2.
\medskip

\noindent
{\bf{2.3 Consequences.}}
The   orthogonal complement of
a subspace in a Hilbert space is  always
closed. Hence   Proposition 2.2 entails  that
$T^*$ has a closed graph. Passing to the closure of
$\Gamma(T)$
the decompostion of a Hilbert space
into a direct sum of a closed subpace and its orthogonal complement gives
\[
\mathcal H\times\mathcal H=
\overline{J(\Gamma(T))}\oplus \Gamma(T^*)
\tag{2.3.1}
\]


\noindent
Notice also that 
\[
\Gamma(T^*)^\perp=\overline{J(\Gamma(T))}\tag{2.3.2}
\]
\medskip

\noindent
{\bf{2.4 Closed extensions of operators.}}
A closed operator $S$ 
is called a
closed extension of $T$ if
\[
\Gamma(T)\subset\Gamma(S)
\]

\medskip

\noindent
{\bf{2.4.1 Exercise.}}
Show that 
if $S$ is a  closed extension of $T$ then
\[
S^*=T^*
\]



\noindent
{\bf{2.4.2 Theorem.}}
\emph{A densely defined operator $T$  has a closed extension if and only if
$\mathcal D(T^*)$ is dense.
Moreover, if $T$ is closed one has the biduality formula
$T=T^{**}$.}
\medskip

\noindent
\emph{Proof.}
Suppose first that $T$ has a closed extension. 
If $\mathcal D(T^*)$ is not dense 
there
exists a non-zero vector $0\neq h\perp \mathcal D(T^*)$ and
(2.3.2) gives
\[
(h,0)\in\Gamma(T^*)^\perp=J(\Gamma(T))\tag{ii}
\]
By the construction of $J$ this would give
$x\in\mathcal D(T)$ such that
$(h,0)=(-Tx,x)$ which cannot hold since
this equation first gives $x=0$ and then
$h=T(0)=0$.
Hence  closedness of $T$ implies that
$\mathcal D(T^*)$ is dense.
Conversely, assume that
$\mathcal D(T^*)$ is  dense. 
Starting from $T^*$  we 
construct its adjoint  $T^{**}$ and 
Proposition 2.3.2 applied with $T^*$  gives
\[
\Gamma(T^{**})= J(\Gamma(T^*)^\perp\tag{i}
\]
At the same time 
$J(\Gamma(T^*)^\perp$ is equal to the closure of
 $\Gamma(T)$ so (i) gives
\[
\overline{\Gamma(T)}=
\Gamma(T^{**})\tag{ii}
\]
which proves that $T^{**}$ is a closed extension of $T$.
\medskip

\noindent
{\bf{2.4.3 The biduality formula.}}
Let  $T$ be  closed. and  densely defined operator. from the above 
$T^*$ also is densely defined and closed. Hence its
dual exists. It 
is denoted by
$T^{**}$ and called the bi-dual of $T$. With these notations one has:
\[
T=T^{**}\tag{*}
\]
\medskip

\noindent
{\bf{2.4.4 Exercise.}} Prove the equality (*). 

\bigskip


\centerline {\bf{2.5 Inverse operators.}}.
\medskip

\noindent
Denote by
$\mathfrak I(\mathcal H)$ the set of
closed and densely defined operators $T$ such that
$T$ is injective on $\mathcal D(T)$ and the range $T(\mathcal D(T))$Êis dense in
$\mathcal H$.
If $T\in\mathfrak I(\mathcal H)$
there exists the densely defined operator $S$ where
$\mathcal D(S)$ is the range of  $T$ and
\[
S(Tx)= x\quad\colon\quad x\in\mathcal D(T)
\]
By this construction the range of $S$ is equal to
$\mathcal D(T)$. Next, 
 on $\mathcal H\times\mathcal H$
we have the isometry defined by
$I(x,y)= (y,x)$,  i.e we  interchange the pair of vectors.
The construction of $S$ gives 
\[ 
\Gamma(S)= I(\Gamma(T))\tag{i}
\]
Since $\Gamma(T)$ by hypothesis is closed it follows that
$S$ has a closed graph and we conclude that $S\in\mathfrak I(\mathcal H)$.
Moreover, since $I^2$ is the identity on
$\mathcal H\times \mathcal H$ we have
\[ 
\Gamma(T)= I(\Gamma(S))\tag{ii}
\]
We refer to $S$ is as the inverse of
$T$. It is denoted by $T^{-1}$
and  (ii) entails  that
$T$ is the inverse of $T^{-1}$, i.e. one has
\[ 
T=(T^ {-1})^{-1}\tag{*}
\]

\medskip

\noindent
{\bf{2.5.1 Exercise.}}
Let $T$ belong to
$\mathfrak I(\mathcal H)$.
Use the description of $\Gamma(T^*)$
in Proposition 2.3   to show that $T^*$  belongs to 
$\mathfrak I(\mathcal H)$  and the equality  
\[
(T^{-1})^*= (T^*)^{-1}\tag{**}
\]

\medskip


\centerline {\bf{2.6 The operator $T^*T$}}.
\medskip

\noindent
Each 
$h\in\mathcal H$ gives  the vector $(h,0)$ in
$\mathcal H\times\mathcal H$ and  (2.3.1) gives
a  pair  $x\in\mathcal D(T)$ and $y\in\mathcal D(T^*)$.
such that
\[
(h,0)= (x,Tx)+(-T^*y,y)=(x-T^*y, Tx+y)
\]
With $u=-y$ we get $Tx=u$ and obtain
\[
 h=x+T^*(Tx)\tag{2.6.1}
\]


\medskip

\noindent
{\bf{2.6.2  Proposition.}}
\emph{ The vector $x$ in (2.6.1) is uniquely determined by $h$.}

\medskip

\noindent
\emph{Proof.}
Uniqueness follows if we show that
\[
x+T^*(Tx)\implies x=0
\]
But this is clear since the construction
of $T^*$ gives
\[
0=\langle x,x)\rangle+ \langle x,T^*(Tx)\rangle=
\langle x,x)\rangle+ \langle Tx,Tx)\rangle\implies x=0
\] 
\medskip

\noindent
{\bf{2.7 The density of $\mathcal D(T^*T)$}}.
This is the subspace of $\mathcal D(T)$ where the extra
 condition for a vector $x\in\mathcal D(T)$ is that
$Tx\in\mathcal D(T^*)$.
To prove that
$\mathcal D(T^*T)$ is dense we consider some orthogonal vector $h$.
Proposition 2.6 gives some $x\in\mathcal D(T)$ such that
$h=x+T^*(Tx)$ and 
for every $g\in \mathcal D(T^*T)$ we have
\[
0=\langle x,g\rangle+\langle T^*Tx,g\rangle=
\langle x,g\rangle+\langle Tx,Tg\rangle=
\langle x,g\rangle+\langle x,T^*Tg\rangle
\tag{i}
\]
Here (i) hold for every $g\in\mathcal D(T^*T)$ and
by another application of Proposition 2.6 we  find $g$ so that
$x= g+T^*Tg$ and then (i) gives $\langle x,x\rangle =0$ so that
$x=0$.
But then we also have $h=0$ and the requested density follows.
\medskip

\noindent
{\bf{2.8 Conclusion.}}
Set $A=T^*T$.
From the above it is densely defined and
(2.6.1) entails that
the densely defined operator $E+A$ is injective. Moreover,   its range is
equal to $\mathcal H$.
Notice  that
\[
\langle x+Ax,x+Ax\rangle = c+ 
\langle x,Ax\rangle+\langle Ax,x\rangle
\]
Here
\[
\langle x,Ax\rangle=\langle x,T^*Tx\rangle=
\langle Tx,Tx\rangle= ||Tx||^2
\]
and from this
the reader can conclude that
\[
||x+Ax||^2= ||x||^2+||Ax||^2+2\cdot ||Tx||^2\quad\colon x\in \mathcal D(A)
\]
The right hand side is $\geq ||x||^2$ which
implies that
$E+A$ is invertible in Neumann's sense.

\medskip




\noindent
{\bf{2.9 The equality  $A^*=A$}}.
Recall the biduality
formula
$T= T^{**}$ and apply Proposition 2.6.2 starting with
$T^*$. It follows 
that
$\mathcal D(TT^*)$ also is dense and 
exactly as in (2.6.1) every $h\in\mathcal H$ has a unique
representation
\[ 
h= y+T(T^*y)
\]
\medskip

\noindent
{\bf{2.10. Exercise.}}
Verify from the above that $A$ is self-adjoint, i.e one has the equality $A=A^*$.



\bigskip




\centerline{\bf{¤ 2.B Unbounded self-adjoint operators.}}
\bigskip

\noindent
A densely defined operator $A$ 
on the Hilbert space $\mathcal H$
for which $A=A^*$ is called self-adjoint. 


\medskip

\noindent
{\bf{2.B.1  Proposition}}
\emph{The spectrum of a self-adjoint operator
$A$ is contained in
the real line, and if
$\lambda$ is non-real  the resolvent
satisfies the norm inequality}
\[ 
||R_A(\lambda)||\leq \frac{1}{|\mathfrak{Im}\,\lambda|}
\]


\noindent
\emph{Proof.}
Set $\lambda=a+ib$ where $b\neq 0$.
If $x\in\mathcal D(A)$ and $y=\lambda x-Ax$ we have
\[
||y||^2=|\lambda|^2\cdot ||x||^2+||Ax||^2-2\cdot \mathfrak{Re}(\lambda)\cdot \langle x,Ax\rangle
\]

\noindent
The Cauchy-Schwarz inequality gives
\[
||y||^2\geq b^2||x||^2+ a^2||x||^2+||Ax||^2-2|a|\cdot ||Ax||\cdot ||x||
\geq
b^2||x||^2\tag{i}
\]

\noindent
This proves that  $x\to \lambda x-Ax$ is injective and
since
$A$ is closed  the range of
$\lambda\cdot E-A$ is closed.
Next, if $y$ is $\perp$ to this range we have
\[
0=\lambda \langle x,y\rangle -\langle Ax,y\rangle\quad\colon
x\in\mathcal D(A)
\]
From this we see that $y$ belongs to $\mathcal D(A^*)$ and since
$A$ is self-adjoint we get
\[
0=\lambda \langle x,y\rangle -\langle x,Ay\rangle
\]
This holds for all $x$ in the dense subspace $\mathcal D(A)$ which gives
$\lambda\cdot y=Ay$
Since $\lambda$ is non-real we have already seen that this entails that
$y=0$.
Hence the range of $\lambda\cdot E-A$ is equal to $\mathcal H$ and the inequality
(i) entails $R_A(\lambda)$
has norm
$\leq\frac{1}{|\mathfrak{Im}\lambda|}$.


\medskip

\noindent{\bf{2.B.2 A conjugation  formula.}}
Let $A$ be self-adjoint. For each complex number
$\lambda$  the hermitiain inner product on
$\mathcal H$ gives the equation
\[
\bar\lambda-A= (\lambda\cdot E-A)^*
\]
So when we take the complex conjugate of $\lambda$ it follows that
¤ 2.5 that 
\[
R_A(\lambda)^*= R_A(\bar\lambda)\tag{2.5.1}
\]

\noindent


\medskip

\noindent{\bf{2.B.3 Properties of resolvents.}}
Let $A$ be self-adjoint.
By Neumann's resolvent calculus 
the family $\{(R_A(\lambda)\}$ 
consists of pairwise commuting bounded operators
outside the spectrum of $A$. Since $\sigma(A)$ is real 
there exist  operator-valued analytic functions $\lambda\mapsto R_A(\lambda)$Ê
in the upper- respectively the lower half-plane.
Moreover, since Neumann's  resolvents  commute, it follows
from (2.5.1) that
$R_A(\lambda)$ commutes with its adjoint. Hence
every resolvent is a bounded normal operator.


\bigskip

\noindent
{\bf{2.B.4 A special resolvent operator.}}
Take $\lambda=i$ and set
$R=R_A(i)$. So here
\[ 
R(iE-A)(x)= x\quad\colon\quad x\in\mathcal D(A)
\]

\medskip

\noindent
{\bf{2.B.5 Theorem.}}
\emph{The spectrum $\sigma(R)$ is contained in the circle}
\[
C_*=\{|\lambda+i/2|= 1/2\}
\]


\noindent
\emph{Proof.}
Since $\sigma(A)$ is confined to the real line, it follows from
¤ 0.0. XX  that
points in $\sigma(R)$ have the form
\[
\lambda=\frac{1}{i-a}\quad\colon a\in {\bf{R}}
\]
This gives
\[
\lambda+i/2=\frac{1}{i-a}+i/2=
\frac{1}{2(i-a)}(2+i^2-ia)=
\frac{1-ia}{2i(1+ia)}
\]
and the last term has absolute value $1/2$ for every real $a$.




\newpage



\centerline{\bf{2.C. The spectral theorem for unbounded 
self-adjoint operators.}}
\bigskip

\noindent
 The operational calculus in ¤ 1.3-1.6
applies to the bounded
normal operator $R$ in ¤ 2.14.
If $N$ is a positive integer we
set
\[
C_*(N)=\{\lambda\in C_*\,\colon\,\mathfrak {Im}(\lambda)
\leq - \frac{1}{N}\}\quad\text{and}\quad 
\Gamma_N=C_*(N)\cap \sigma(R)
\]
Let $\chi_{\Gamma_N}$ be the characterstic function of $\Gamma_N$.
Now
\[ 
g_N(\lambda)=\frac{1-i\lambda}{\lambda}\cdot \chi_{\Gamma_N}
\] 
is  Borel functionon
$\sigma(R)$ which by 
operational calculus in ¤ 1.xx 
gives a bounded and normal linear operator denoted by $G_N$.
On $\Gamma_N$ we have
 $\lambda=-i/2+\zeta$ where
$|\zeta|= 1/2$. This
gives
\[
\frac{1-i\lambda}{\lambda}=
\frac{1/2-i\zeta}{-i/2+\zeta}
=\frac{(1/2-i\zeta)(i/2+\bar\zeta)}{|\zeta-i/2|^2}
=\frac{\mathfrak{Re}\,\zeta}{|\zeta-i/2|^2}\tag{1}
\]
By  ¤ 1.x the spectrum of
$G_N$ is the range of the $g$-function on $\Gamma_N$ and  (1) 
entails that
$\sigma(G_N)$ is real. Since  $G_N$ also is normal it follows 
that it is self-adjoint.
Next, notice that
\[ 
\lambda\cdot (\frac{1-i\lambda}{\lambda}+i)=1\tag{2}
\]
holds on $\Gamma_N$.
Hence
operational calculus  gives the  equation
\[
R(G_N+i)=E(\Gamma_N)\tag{3}
\]
where $E(\Gamma_N)$
is a self-adjoint projection.
Notice also that
\[
R\cdot G_N=(E-iR)\cdot E(\Gamma_N)\tag{4}
\]
Hence (3-4) entail that
\[
E(\Gamma_N)-iRE(\Gamma_N)=(E-iR)\cdot E(\Gamma_N)\tag{5}
\]


\medskip

\noindent
Next, the equation $RA=E-iR$ gives
\[
RAE(\Gamma_N)=(E-iR)E(\Gamma_N)=R\cdot G_N\tag{*}
\]
\medskip

\noindent
{\bf{2.C.1 Exercise.}}
Conclude from the above that
\[
AE(\Gamma_N)= G_N\tag{*}
\] 
Show also that:
\[ 
\lim_{N\to\infty}\, AE(\Gamma_N)(x)= A(x)\quad
\text{for each}\quad x\in\mathcal D(A)\tag{**}
\]
\medskip

\noindent
{\bf{2.C.2 A general construction.}}
For  each bounded
Borel set $e$
 on the real line
we get a  Borel set 
$e_*\subset \sigma(R)$ 
given
by
\[ 
e_*=\sigma(R)\,\cap\, \{\frac{1}{i-a}\, a\in e\}
\]
The operational calculus  gives
the self-adjoint operator $G_e$ constructed via
$g\cdot \chi_{e_*}$.
We have also the operstor $E(e)$ given by
$ \chi_{e_*}$ and exactly as above we get
\[
AE(e)=G_e
\]
The bounded self-adjoint operators
$E(e)$ and $G_e$ commute with
$A$
and  $\sigma(G_e)$ is contained in the closure of 
the bounded Borel set $e$.
Moreover each $E(e)$ is a self-adjoint projection
and for each pair of bounded Borel sets we have
\[
E(e_1)E(e_2)= E(e_1\cap E(e_1)
\]
In particular the composed operators 
\[
E(e_1)\circ E(e_2)=0
\]
when the Borel  sets are disjoint.
\medskip


\noindent
{\bf{2.C.3 The spectral measure.}}
Exactly as for bounded
self-adjoint operators the results above give
rise to a map from
$\mathcal H\times\mathcal H$ into the space of
Riesz measures:
\[ 
(x,y)\mapsto \mu_{x,y}
\]
For each real-valued
and bounded Borel function $\phi(t)$ on the real line with compact support
there exists a bounded self-adjoint operator
$\phi$ such that
\[
\langle \Phi(x),y\rangle=
\int\, g(t)\cdot  d\mu_{x,y}(t)
\]
All these $\Phi$ operators commute with
$A$.
If $x\in\mathcal D(A)$ and $y$ is a vector in
$\mathcal H$ one has
\[
\langle A(x),y\rangle=\lim_{M\to \infty}\,\int_{-M}^M\,
t\cdot d\mu_{x,y}(t)
\]









\newpage


\centerline{\bf{¤ 3.  Symmetric operators}}

\bigskip


\noindent
A densely defined and closed operator
$T$ on a Hilbert space $\mathcal H$
is  symmetric if
\[
\langle Tx,y\rangle=
\langle x,Ty\rangle\quad\text{hold for all pairs }\quad x,y\in\mathcal D(T)\tag{*}
\]


\noindent
The symmetry means  that
the adjoint 
$T^*$   extends $T$, i.e. 
\[
\Gamma(T)\subset \Gamma(T^*)
\]
Recall that adjoints always are closed operators.
Hence $\Gamma(T^*)$
is a closed subspace of $\mathcal H\times\mathcal H$ and  becomes
a Hilbert space equipped with
the inner product
\[
\{x,y\}=
\langle x,y\rangle+
\langle T^*x,T^*y\rangle
\]
Moreover, since
$T$  is closed. it follows that
$\Gamma(T)$ appears as a closed subspace of this Hilbert space.
Consider 
the  eigenspaces:
\[
\mathcal D_+=\{ x\in\mathcal D(T^*)\quad\colon T^*(x)=ix\}
\quad\text{and}\quad 
\mathcal D_-=\{ x\in\mathcal D(T^*)\quad\colon T^*(x)=-ix\}
\]


\medskip

\noindent {\bf{3.1 Proposition.}}
\emph{The following  orthogonal decomposition exists in
the Hilbert space $\Gamma(T^*)$:}
\[
\Gamma(T^*)=\Gamma(T)\oplus \mathcal D_+ \oplus\mathcal D_-
\tag{*}\]


\noindent
\emph{Proof.}
The verification that the three subspaces are pairwise orthogonal is
left to the reader.
To show  that the direct sum above
is equal to
$\Gamma(T^*)$ we use duality and  there remains only  to
prove that
\[ 
\Gamma(T)^\perp=
\mathcal D_+\oplus \mathcal D_-\tag{1}
\]

\noindent
To show (1) we pick a vector 
$y\in \Gamma(T)^\perp$. Here $(y,T^*y)\in\Gamma(T^*)$
and the definition of orthogonal complements gives:
\[
\langle x,y\rangle+ \langle Tx,T^*y\rangle=0
\quad\colon\quad x\in\mathcal D(T)
\]
From this we see that $T^*y\in\mathcal D(T^*)$ and obtain
\[
\langle x,y\rangle+ \langle x,T^*T^*y\rangle=0
\]
The density of $\mathcal D(T)$ entails that
\[ 
0=y+T^*T^*y=(T^*+iE)(T^*-iE)(y)\implies
\]
\[
\xi=T^*y-iy\in \mathcal D_-\quad\text{and}\quad
\eta=T^*y+iy\in \mathcal D_+\implies
\]
\[ 
y=\frac{1}{2i}(\eta-\xi)
\in \mathcal D_-\oplus \mathcal D_+
\]
which proves (1).


\medskip

\noindent
{\bf{3.2 The case 
$\dim(\mathcal D_+)= \dim(\mathcal D_-)$.}}
Suppose that $\mathcal D_+$ and $\mathcal D_-$  are finite dimensional
with equal  dimension $n\geq 1$. Then
self-adjoint extensions of $T$  are found as follows:
Let   $e_1,\ldots,e_n$ be an orthonormal  basis in $\mathcal D_+$ and
$f_1,\ldots,f_n$ a similar basis in $\mathcal D_-$.
For each $n$-tuple $e^{i\theta_1},\ldots, e^{i\theta_n}$
of complex numbers with absolute value one
we have  the subspace of $\mathcal H$
generated by $\mathcal D(T)$ and
the vectors
\[ 
\xi_k= e_k+ e^{i\theta_k}\cdot f_k\quad\colon\quad 1\leq k\leq n
\]

\medskip

\noindent
On this  subspace we define a linear operator $A_\theta $ where
$A_\theta =T$ on $\mathcal D(T)$
while
\[ 
A_\theta (\xi_k)=ie_k-i e^{i\theta_k}\cdot f_k
\]

\medskip

\noindent
{\bf{3.3 Exercise.}}
Verify 
that
$A_\theta $ is self-adjoint and  prove the converse, i.e. if
$A$ is an arbitrary self-adjoint operator such that
\[
\Gamma(T)\subset
\Gamma(A)\subset\Gamma(T^*)
\]
then there exists a unique $n$-tuple $\{e^{i\theta_\nu}\}$
such that
\[
A=A_\theta
\]







\bigskip
\noindent{\bf{3.4  Example.}}
Let $\mathcal H$ be the Hilbert space
$L^2[0,1]$ of  square-integrable functions 
on the unit interval $[0,1]$ with  the coordinate $t$.
A dense subspace $\mathcal H_*$ consists of  functions
$f(t)\in C^1[0,1]$
such that $f(0)=f(1)=0$.  On $\mathcal H_*$
we define the operator 
$T$ by
\[ 
T(f)=if'(t)
\]
A partial integration gives
\[ 
\langle T (f),g\rangle=
 i\int_0^1\, f'(t)\cdot\bar g(t)\cdot dt=\int_0^1\, \bar g'(t)\cdot f(t)dt=
 \langle f,T(g)\rangle
\] 
Hence $T$ is symmetric.
Next, an $L^2$-function $h$  belongs to $\mathcal D(T^*)$ if and only if there exists a constant $C(h)$ such that
\[
\bigl|\int_0^1\, if'(t)\cdot\bar h(t)dt\bigr|\leq
C(h)\cdot ||f||_2\quad\colon f\in \mathcal H_*
\] 
This means that
$\mathcal D(T^*)$ consists of all $L^2$-functions $h$ such that
the distribution derivative $\frac{dh}{dt}$ again belongs to $L^2$.
\medskip

\noindent
{\bf{Exercise.}}
Show that 
\[ 
\mathfrak{D}_+=\{h\in L^2\quad\colon\frac{dh}{dt}=ih\}
\] 
is a 1-dimensional vector space
generated by the $L^2$-function $e^{ix}$.
Similarly, $\mathcal D_-$ is 1-dimensional and generated
by $e^{-ix}$.
\medskip

\noindent
\emph {Self-adjoint extensions of $T$}.
For each  complex number
$e^{i\theta}$  we get the linear  space  
$\mathcal D_\theta$
of functions
$f(t)\in\mathcal D(T^*)$ such that
\[ 
f(1)= e^{i\theta}f(0)
\]


\noindent
{\bf{Exercise.}}
Verify
that one gets a  self-adjoint operator $T_\theta$
which extends $T$ where 
is   $\mathcal D(T_\theta)= \mathcal D_\theta$.
Conversely, show every  self-adjoint extension of
$T$ is equal to $T_\theta$
for some
$\theta$. Hence the family $\{T_\theta\}$
give all self-adjoint extensions of $T$ with their  graphs 
contained in  $\Gamma(T^*)$.


\bigskip

 
\centerline {\bf{3.5 Semi-bounded symmetric operators.}}
\bigskip

\noindent 
Let $T$ be  closed, densely defined and symmetric.
It is said to be bounded
below 
if there exists some positive constant $k$ such that
\[ 
\langle Tx,x\rangle \geq k\cdot ||x||^2\quad\colon\quad x\in\mathcal D(T)\tag{*}
\]

\medskip

\noindent
On $\mathcal D(T)$ we have the Hermitian bilinear form:
\[
\{x,y\}= \langle Tx,y\rangle \quad\text{where (*) entails that}\quad 
\{x,x\}\geq k\cdot ||x||^2\tag{1}
\]
In particular a Cauchy sequence with respect to this inner product is a
Caichy sequence in the given Hilbert space
$\mathcal H$. So if $\mathcal D_*$ is the completion of
$\mathcal D(T)$ with respect to the inner product above, then
it appears as a subspace of
$\mathcal H$.
Put
\[ 
\mathcal D_0=\mathcal D(T^*)\,\cap\, \mathcal D_*
\]

\noindent
{\bf{3.5.1 Proposition}}. \emph{One has the equality}
\[ 
T^*(\mathcal D_0)=\mathcal H\tag{*}
\]
\emph{Proof.}
A  vector $x\in\mathcal H$  gives
a  linear functional on $\mathcal D_*$ 
defined by
\[ 
y\mapsto \langle y,x\rangle
\]
We have
\[
|\langle y,x\rangle|\leq
||x|\cdot ||y||\leq ||x|||\cdot \frac{1}{\sqrt{k}}\cdot\sqrt{\{y,y\}}\tag{i}
\]
where we used (1) above.
The Hilbert space
$\mathcal D_*$
is self-dual. This   gives a  vector
$z\in\mathcal D_*$ such that
\[
\langle y,x\rangle=\{y,z\}=\langle Ty,z\rangle\tag{iii}
\]
Since $\mathcal D(T)\subset \mathcal D_*$
we have (iii)
for every vector 
$y\in\mathcal D(T)$, and  the construction of $T^*$
entails that  
$z\in  \mathcal D(T^*)$ so that  (iii) gives
\[
\langle y,x\rangle=\langle y,T^*(z)\rangle\tag{iv}
\]
The density of $\mathcal D_*$ in $\mathcal H$
implies that 
$x=T^*(z)$ and since $x\in\mathcal H$ was arbitrary we get
(*) in the proposition.
\bigskip


\noindent
{\bf{3.5.2 A self-adjoint extension.}}
Let $T_1$ be the restriction of $T^*$ to
$\mathcal D_0$. We leqve it to the reader to check that
$T_1$ is symmetric and 
has a closed graph.
Moroever, since $\mathcal D(T)\subset \mathcal D_0$ and 
$T^*$ is an extension of 
$T$ we have
\[ 
\Gamma(T)\subset \Gamma(T_1)
\]
Next, Proposition 4.2.1 gives
\[
 T_1(\mathcal D(T_1)= \mathcal H
\]
 i.e. the $T_1$Êis surjective.
But then $T_1$ is self-adjoint by   the general result below.

\bigskip
 
\noindent{\bf{3.5.3 Theorem }}.
\emph{Let $S$
be a  densely defined, closed and symmetric operator such that}
\[
S(\mathcal D(S))=\mathcal H\tag{*}
\]
\emph{Then $S$ is self-adjoint.}
\medskip



\noindent
\emph{Proof.}
Let $S^*$ be the adjoint of $S$.
When 
$y\in\mathcal D(S^*)$ we have by definition
\[
\langle Sx,y\rangle =\langle x,S^*y\rangle\quad\colon\quad x\in\mathcal D(S)
\]
If $S^*y=0$ this entails that
$\langle Sx,y\rangle=0$ for all $x\in\mathcal D(S)$ so 
the assumption that
$S(\mathcal D(S))=\mathcal H$ 
gives $y=0$ and hence  $S^*$ is injective.
Finally, if $x\in\mathcal D(S^*)$
the hypothesis (*) gives $\xi\in\mathcal D(S)$ such that
\[
S(\xi) =S^*(x)\tag{i}
\] 
Since $S$ is symmetric,
$S^*$ extends $S$ so that 
(i) gives  $S^*(x-\xi)=0$. Since we already proved that
$S^*$ is injective  we have
$x=\xi$. This proves that 
$\mathcal D(S)=\mathcal D(S^*)$ which means that   $S$ is self-adjoint.







\newpage














\centerline{\bf{¤ 4. Contractions and the Nagy-Szeg theorem}}
\bigskip


\noindent
A linear operator $A$ on the Hilbert space $\mathcal H$ is  a contraction if
its operator norm is $\leq 1$, i.e.
\[
 ||Ax||\leq ||x||\quad\colon\quad x\in\mathcal H\tag{1}
\] 
Let $E$ be the identity operator on $\mathcal H$.
Now $E-A^*A$ is a bounded self-adjoint operator and  (1) gives:
\[
\langle x-A^*Ax,x\rangle=||x||^2-||Ax||^2\geq 0
\]
From the result in ¤ 1.xx it follows that
this  non-negative self-adjoint operator has a square root:
\[ 
B_1=\sqrt{E-A^*A}
\]
Next,  the operator norms of $A$ and  $A^*$ are equal so
$A^*$ is  also a  contraction and the equation
$A^{**}=A$ gives the
self-adjoint operator
\[
B_2=\sqrt{E-AA^*}
\]
Since  $AA^*=A^*A$ is not assumed
the  self-adjoint operators
$B_1,B_2$ need not be equal.
However, the following hold:

\medskip

\noindent
{\bf{4.3.1 Propostion.}}
\emph{One has the equations}
\[ 
AB_1=B_2A\quad\text{and}\quad A^*B_2= B_1A^*
\]



\noindent
\emph{Proof.}
If $n$ is a positive integer we notice that
\[
A(A^*A)^n=(AA^*)^nA\tag{i}
\]
Now $A^*A$ is a self-adjoint operator whose compact spectrum is confined to
the closed unit interval $[0,1]$.
If $f\in C^0[0,1]$
is a real-valued continuous function it can be approximated uniformly
by a sequence of polynomials $\{p_n\}$
and the operational calculus from ¤ XX yields an operator
$f(A^*A)$ where
\[
\lim_{n\to\infty}\, ||p_n(A^*A)-f(A^*A)||=0
\]
Since the spectrum of $AA^*$ also is confined to $[0,1]$,
the same polynomial sequence
$\{p_n\}$ gives 
an operator $f(AA^*)$ where
\[
\lim\, ||p_n(AA^*)-f(AA^*)||=0
\]
Now (i) and the two limit formulas above give:
\[
A\circ f(A^*A)= f(AA^*)\circ A\tag{ii}
\]
In particular we can take 
$f(t)= \sqrt{1-t}$
and  Proposition 4.3.1 follows.
\bigskip

\noindent{\bf{4.2 The unitary operator $U_A$}}.
On the Hilbert space $\mathcal H\times \mathcal H$
we define a linear operator $U_A$ represented by the block matrix
\[
U_A=
\begin{pmatrix} A& B_2\\
B_1&-A^*
\end{pmatrix}\tag{*}
\]


\noindent
{\bf{4.3 Proposition.}}
\emph{$U_A$ is a unitary operator on
 $\mathcal H\times \mathcal H$}.
 
 \medskip
 
 \noindent
 \emph{Proof.}
 For a pair of vectors $x,y$ in $\mathcal H$
 we must prove the equality
\[
|| U_A(x\oplus y)||^2=||x||^2+||y||^2\tag{i}
\]
To get (i)  we notice that for every vector $h\in\mathcal H$ 
the self-adjointness of $B_1$ gives
\[
||B_1h||^2=\langle B_1h,B_1h\rangle=
\langle B_1^2h,h\rangle=\langle h-A^*Ah,h\rangle=
||h||^2-||Ah||^2\tag{ii}
\]
where  the last equality holds since we have
$\langle A^*Ah,h\rangle =\langle Ah,A^{**}h\rangle =||Ah||^2$
and the biduality formula $A=A^{**}$.
In the same way one has:
\[
||B_2h||^2=||h||^2-||A^*h||^2\tag{iii}
\]


\noindent
Next, by the construction of $U_A$ the left hand side in (i) becomes
\[
||Ax+B_2y||^2+||B_1x-A^*y||^2\tag{iv}
\]
Using (iii) we have
\[
||Ax+B_2y||^2=||Ax||^2+||y||^2-||A^*y||^2+
\langle Ax,B_2y\rangle+ \langle B_2 y,Ax\rangle
\]
Similarly,  (ii) gives
\[
||B_1x-A^*y||^2=||x||^2-||Ax||^2+||A^*y||^2-
\langle B_1x,A^*y\rangle- \langle A^*y,B_ x\rangle
\]
Adding these two equations  we 
conclude that (i) follows from the equality
\[
\langle Ax,B_2y\rangle+ 
\langle B_2 y,Ax\rangle=
\langle B_1x,A^*y\rangle+ \langle A^*y,B_ x\rangle\tag{v}
\]
To get (v) we use Proposition 4.5.1 which  gives
\[
\langle Ax,B_2y\rangle=
\langle x,A^*B_2y\rangle=
\langle x,B_1A^*y\rangle=
\langle B_1x,A^*y\rangle
\]
where the last equality used that $B_1$ is self-adjoint. In the same way one verifies that
\[
\langle B_2 y,Ax\rangle=
 \langle A^*y,B_ x\rangle
\]
and (v) follows.

\bigskip



\centerline{\bf{4.4 The Nagy-Szeg theorem.}}
\bigskip


\noindent
The constructions above were applied 
by 
Nagy and Szeg to give:
\medskip

\noindent
{\bf{4.4.1 Theorem}}
\emph{For every bounded linear operator $A$ on a Hilbert space
$\mathcal H$ there exists a Hilbert space
$\mathcal H^*$ which contains $\mathcal H$ and a unitary operator $U_A$
on $\mathcal H^*$ such that}
\[
A^n=\mathcal P\cdot U_A^n\quad\colon\quad n=1,2,\ldots
\]
\emph{where $\mathcal P\colon\mathcal H^* \to \mathcal H$
is the orthogonal  projection.}
\medskip


\noindent
\emph{Proof.}
On the product  $\mathcal H_1=\mathcal H\times\mathcal H$ we have the unitary
operator $U_A$ from (*) in 4.3.2. Let
$\mathcal P(x,y)= x$ be the projection onto the first
factor.
Then  (*) in (4.3.2) gives 
$A=\mathcal PU_A$ and  
the constructions from the proof of Propostion 4.3.4
imply that
$A^n=\mathcal P\cdot U^n$ hold for every $n\geq 1$ which finishes the proof.
\bigskip

\noindent
The Nagy-Szeg result has
an interesting consequence. 
Let $A$  be a contraction. If
$p(z)=
c_0+c_1<+\ldots+c_nz^n$ is an arbitrary polynomial with
complex coefficients
we get the 
operator $p(A)=\sum\,c_\nu A^\nu$ and 
with these notations one has:

\medskip

\noindent
{\bf{4.4.2 Theorem}}
\emph{For every pair $A,p(z)$ as above one has}
\[
||p(A)||\leq \max_{z\in D}\, |p(z)|
\] 
\emph{where the the maximum in the right hand side is taken on the unit disc.}
\medskip

\noindent
\emph{Proof.} Theorem 4.4.1  gives $p(A)= \mathcal P\cdot p(U_A)$.
Since the orthogonal $\mathcal P$-projection is norm decreasing we get
\[
||p(A)(\xi)||^2\leq ||p(U_A)(\xi,0)||^2
\]
Let $\xi$ be a unit vector such that
$||p(A)(\xi)||= ||p(A)||$.
The operational calculus in ¤ 7 XX  applied to the unitary operator
$U_A$  yields a
probablity measure $\mu_\xi$ on
the unit circle such that
\[
 ||p(U_A)(\xi,0)||^2=
 \int_0^{2\pi}\, |p(e^{i\theta})|^2\cdot d\mu_\xi(\theta)
 \]
The right hand side is majorized by $|p|_D^2$ and Theorem 4.4.2 follows.

\bigskip

\noindent
{\bf{4.4.3 An application.}}
Let $A(D)$ be the disc algebra. Since each $f\in A(D)$ can be 
uniformly approximated by analytic 
polynomials, Theorem 4.4.2  entails that if a linear operator $A$ 
on the Hilbert space $\mathcal H$ is a contraction
then each $f\in A(D)$
gives a 
bounded linear operator $f(A)$, i.e. we have norm-preserving map  from
the supnorm algebra $A(D)$ into the space of bounded linear operators on
$\mathcal H$.


\newpage

\centerline
{\bf{¤ 5 Miscellanous results}}
\bigskip


\noindent
Before Theorem 5.x is announced
we recall that the product formula for matrices in ¤ X  asserts the following.
Let $N\geq 2$  and $T$  is some $N\times N$-matrix whose
elements are complex numbers
which as usual is regarded as a linear operator on
the Hermitian space ${\bf{C}}^N$.
Then there 
exists the 
self-adjoint matrix $\sqrt{T^*T}$ whose eigenvalues are non-negative.
Notice that for every vector $x$ one has 
\[
||T^*T(x)||^||Tx||^2\implies ||\sqrt{T^*T}(x)||= ||Tx||\tag{i}
\] 


\noindent
and since
$\sqrt{T^*T}$ is self-adjoint
we have an orthogonal decomposition 
\[
\sqrt{T^*T}({\bf{C}}^N)\oplus
\text{Ker}(\sqrt{T^*T})= {\bf{C}}^N\tag{ii}
\]
where the self-adjointness gives the equality
\[
\text{Ker}(\sqrt{T^*T})=\sqrt{T^*T}({\bf{C}}^N)^\perp\tag{iii}
\]
\medskip

\noindent
{\bf{The partial isometry operator.}}
Show that 
there exists a unique linear operator $P$ such that
\[ 
T= P\cdot \sqrt{T^*T}\tag{*}
\]
where the $P$-kernel is
the orthogonal complement of the range of  $\sqrt{T^*T}$.
Moreover, from  (i) it follows that
\[
||P(y)||=||y||
\] 
for each vector in the range of
$\sqrt{T^*T}$.
One  refers to $P$ as a partial isometry attached to $T$.
\bigskip

\noindent
{\bf{Extension to operators on
Hilbert spaces.}}.
Let $T$ be a bounded opertor on
the Hilbert space
$\mathcal H$.
The spectral theorem for bounded
and self-adjoint operators
gives a similar equation as in (*) above
using
the non-negative and self-adjoint
operator $\sqrt{T^*T}$. More generally,
let $T$ be densely defined and closed.
From  ¤ XX  there exists the
densely defined self-adjoint operator $T^*T$
and we can also take its square root.

\medskip

\noindent
{\bf{5.1 Theorem.}}
\emph{There exists  a bounded partial isometry
$P$ such that}
\[ 
T= P\cdot \sqrt{T^*T}
\]



\medskip


\noindent
\emph{Proof.}
Since $T$ has closed graph we have the Hilbert space
$\Gamma(T)$.
For each $x\in\mathcal D(T)$ we get the vector
$x_*=(x,Tx)$ in $\Gamma(T)$.
Now
\[
(x_*.y_*)\mapsto \langle x,y\rangle
\] 
is a bounded Hermitiain bi-linear form on
the Hilbert space $\Gamma(T)$.
The self-duality of Hilbert spaces
gives  bounded and self-adjoint operator
$A$ on
$\Gamma(T)$ such that
\[
\langle x,y\rangle=\{ Ax_*,y_*\}
\]
where the right hand side is the inner product between vectors in
$\Gamma(T)$.
Let 
\[ 
j\colon (x,Tx)\mapsto x
\]
be  the projection from
$\Gamma(T)$ onto $\mathcal D(T)$ and for each
$x\in\mathcal D(T)$ we put
\[ 
Bx= j(Ax_*)
\]
Then $B$ is a linear operator from
$\mathcal D(T)$ into itself where
\[
\langle Bx,y\rangle =\{Ax_*,y_*\}= \{ x_*,Ay_*\}
=\langle x,By\rangle
\quad\colon\quad x,y\in
\mathcal D(T)
\tag{i}
\]
We have also
\[
\langle Bx,x\rangle=\{A^2x_*,x_*\}=\{Ax_*,Ax_*\}=
\langle Bx,Bx\rangle+\langle TBx,TBx\rangle\implies
\]
\[
||Bx||^2= \langle Bx,Bx\rangle\leq \langle Bx,x\rangle
\leq||Bx||\cdot ||x||
\] 

\noindent
where the Cauchy-Schwarz inequality was used in the last step.
Hence
\[
||Bx||\leq ||x||\quad\colon\quad x\in
\mathcal D(T)
\] 
This entails that that the densey defined operator $B$ 
extends uniquely to
$\mathcal H$ as  a bounded operator
of norm $\leq 1$.
 Moreover, since
(i) hold for pairs $x,y$ in the dense subspace
$\mathcal D(T)$, it follows that
$B$  is self-adjoint.
Next, consider a pair $x,y$ in $\mathcal D(T)$ which gives
\[ 
\langle x,y\rangle= \{Ax_*,y_*\}=
\{x_*,Ay_*\}=\langle x, By\rangle+\langle Tx,TBy\rangle
\]
Keeping $y$ fixed the linear functiional
\[ 
x\mapsto \langle Tx,TBy\rangle=\langle x,y\rangle-\langle x, By\rangle
\]
is bounded on $\mathcal D(T)$. By the construction of
$T^*$  it follows that
$TBy\in \mathcal D(T^*)$
and we also get the equality
\[
\langle x,y\rangle=
\langle x, By\rangle+\langle x,T^*TBy\rangle\tag{ii}
\]
\medskip


\noindent
Since (ii)  holds for all $x$ in the dense subspace $\mathcal D(T)$ we conclude that
\[
y=By+T^*TBy= (E+T^*T)(By)\quad\colon\quad y\in \mathcal D(T)\tag{iii}
\]
\medskip

\noindent
{\bf{Conclusion.}}
From the above we have 
the inclusion
\[ 
TB(\mathcal D(T))\subset
\mathcal D(T^*)
\]
Hence   $\mathcal D(T^*T)$
 contains
$B(\mathcal D(T))$ and (iii) 
means that
$B$ is a right inverse of $E+T^*T$
provided that the $y$-vectors are restricted to
$\mathcal D(T)$.
\bigskip


FINISH ..



\bigskip





\centerline{\bf{5.2 Positive operators on $C^0(S)$}}

\bigskip

\noindent
Let $S$ be a compact Hausdorff
space and $X$  the Banach space of continuous and
complex-valued functions on $S$.
A linear operator $T$ on $X$ is  positive if
it sends every non-negative and real-valued function $f$ to another  real-valued and
non-negative function.
Denote by $\mathcal F^+$ the family of positive operators
$T$ which satisfy the following: First
\[
\lim_{n\to\infty}\, \frac{1}{n}\cdot x^*(T^nx)=0\tag{1}
\] 
hold for all pairs $x\in X$ and $x^*\in X^*$.
The second condition is that
$\sigma(T)$ is the union of a compact set in a disc
$\{|\lambda|\leq r$ for some $r<1 $, and a 
finite set of points on the unit circle. 
The  final  condition is that
$R_T(\lambda)$
is meromorphic in the exterior disc
$\{|\lambda>r\}$, i.e. it has poles at
the spectral points on the unit circle.








\medskip

\noindent
{\bf{5.2.1. Theorem.}}
\emph{If $T\in\mathcal F^+$ 
then
each spectral value $e^{i\theta}\in \sigma(T)$ is a root of unity.}

\medskip


\noindent
\emph{Proof.}
First we prove that $R_T(\lambda)$  has a simple pole at
each  $e^{i\theta}\in \sigma(T)$.
Replacing 
$T$ by  $e^{-i\theta}\cdot T$
it suffices to prove this when
$e^{i\theta}=1$.
If $R_T(\lambda)$ has a pole of order $\geq 2$
at $\lambda=1 $ we know from ¤ XX that there exists $x\in X$ such that
\[ 
Tx\neq  x\quad\text{and}\quad
(E-T)^2\,x=0\tag{i}
\]
This gives  $T^2+x=2Tx$ and by an induction
\[
\frac{1}{n} \cdot T^n x=\frac{1}{n}\cdot x+(E-T)x\quad\colon n=1,2,\ldots\tag{ii}
\]
Condition (1) and (ii) give for each $x^*\in X^*$:
\[ 
0=\lim_{n\to\infty}\, \frac{1}{n}\cdot x^*( T^n x)=\lim_{n\to\infty}\,
x^*(\frac{1}{n}\cdot x+(E-T)x)
\] 
It follows that $x^*(E-T)(x)=0$ and since 
$x^*$ is arbitrary we get   $Tx=x$ which contradicts (i).
Hence
the pole must be simple.
\medskip


\noindent
Next, with $e^{i\theta}\in\sigma(T) $
we have seen that
$R_T$  has a simple pole.
By the general result in ¤ xx there exists
some    $f\in C^0(S)$ which is not identically zero and
\[ 
T(f)=e^{i\theta}\cdot f
\]
Multiplying $f$ with a complex scalar we may assume that
its  maximum norm on $S$ is one and there exists a point $s_0\in S$ such that
\[ 
f(s_0)=1
\]
For each $n\geq 1$ we have a linear functional on
$X$ defined by $g\mapsto T^n(g)(s_0)$ which gives a
Riesz measure $\mu_n$ such that
\[
\int_S\, g\cdot d\mu_n=T^n g(s_0)\quad\colon g\in C^0(S)
\]
Since $T^n$ by the hypothesis is positive,
the integrals in the left hand side are
$\geq 0$ when $g$ are real-valued and non-negative. This entails that
the measures $\{\mu_n\}$ are real-valued and non-negative.
For each $n\geq 1 $ we put
\[ 
A_n=\{x\,\colon\, e^{-in\theta}\cdot f(x)\neq 1\}
\]
Since the sup-norm of $f$ is one we notice that
\[ 
A_n=
\{x\,\colon\, \mathfrak{Re}(e^{-in\theta}f(x))<1\}\tag{iii}
\]
Now
\[
0=f(s_0)- e^{-in\theta}\cdot T^n f(s_0)
=\int_S\,[1-e^{-in\theta}f(s)]\cdot  d\mu_n(s)\tag{iv}
\]
Taking real parts we get
\[
0=\int_S\,[1-\mathfrak{Re}(e^{-in\theta}f(s))]\cdot  d\mu_n(s)\tag{v}
\]
By (iii)  the integrand in (v)
is non-negative and since the whole 
integral is zero it follows that
\[
\mu_n(A_n)= \mu_n(\{\mathfrak{Re}(e^{-in\theta}<1\}=0\tag{vi}
\]
Suppose now that
there exists a pair $n\neq m$ such that
\[
(S\setminus A_n)\cap (S_m\setminus A_m)\neq \emptyset\tag{vii}
\] 
A point $s_*$ in this non-empty intersection
gives
\[
1=e^{in\theta}f(s_*)=e^{im\theta}\cdot f(s_*)\implies
e^{in\theta}=e^{im\theta}
\] 
and hence  $e^{i\theta}$ is a root of unity.
$m-n\neq 0$.
So the proof of Theorem 5.2.1  is finished if we have established the following

\medskip

\noindent
\emph{Sublemma.}
\emph{The sets $\{S\setminus A_n\}$ cannot be pairwise disjoint.}
\medskip

\noindent
\emph{Proof.}
First,  $f$ has maximum norm
and by the above:
\[ 
\int_S\, f\cdot d\mu_n=e^{in\theta}
\]
Hence the total mass $\mu_n(S)$ is at least one.
Next, 
for each $n\geq 2$ we set
\[
\pi_n=\frac{1}{n}\cdot (\mu_1+\ldots+\mu_n)
\]
Since 
$\mu_n(S)\geq 1$  for each $n$ we get 
$\pi_n(S)\geq 1$. Put
\[
\mathcal A=\bigcap\, A_n
\]
Above we proved that $\mu_n(A_n)=0$ hold for every $n$ which gives
\[ 
\pi_n(\mathcal A)=0\quad\colon\, n=1,2,\ldots\tag{*}
\]
Next, when
the sets $\{S\setminus A_k\}$ 
are pairwise disjoint one has 
the inclusions
\[
S\setminus A_k\subset A_\nu\quad\forall\,\nu\neq k
\]
Keeping $k$ fixed it follows that
$\pi_\nu(S\setminus A_k)=0$ for every $\nu\geq 0$.
So when $n$ is large while $k$ is kept fixed we obtain
\[ 
\pi_n(S\setminus A_k))= \frac{1}{n}\cdot \mu_k(S\setminus A_k))\implies
\lim_{n\to\infty}\, \pi_n(S\setminus A_k))=0
\quad\colon k=1,2,\ldots\tag{**}
\]
next, recall that we already proved
that
$R_T(\lambda)$ has at most a simple pole at $\lambda=1$.
With $\epsilon>0$
the Neumann series expansion gives
\[
E+\sum_{k=1}^\infty\,
\frac {T^k}{(1+\epsilon)^k}=
R_T(1+\epsilon))
=\frac{1}{\epsilon} \cdot Q+W(1+\epsilon))
\]
where $W(\lambda)$ is an operator-valued analytic function
in an open disc centered at $\lambda=1$ while $Q$ is a bounded
linear operator on $C^0(S)$.
Keeping $\epsilon>0$ fixed we apply both sides to the identity function
$1_S$ on $S$ and the construction of
the measures $\{\mu_n\}$ gives
\[
1+
\sum_{k=1}^\infty\,
\frac {\mu_k(S)}{(1+\epsilon)^k}=\frac{1}{\epsilon} \cdot Q(1_S)(s_0)+
W(1+\epsilon))(1_S)(s_0)
\]
If $n\geq 2$ is an integer and $\epsilon=\frac{1}{n}$
one gets the inequality
\[
\sum_{k=1}^{k=n}\,
\frac {\mu_k(S)}{(1+\frac{1}{n})^k}\leq
n\cdot |Q(1_S)(s_0)|+|W(1+1/n))(1_S)(s_0)|\leq
n\dot ||Q||+ ||W(1+1/n)||\implies
\]
\[
\frac{1}{n}\cdot\sum_{k=1}^{k=n}\,\mu_k(S)\leq
(1+\frac{1}{n})^n\cdot (||Q||+\frac{ ||W(1+1/n)||}{n}
\]
Since
Neper's constant $e\geq (1+\frac{1}{n})^n$ for every $n$
we find
a constant $C$ which is
independent of $n$ such that
\[
\frac{1}{n}\cdot\sum_{k=1}^{k=n}\,\mu_k(S)\leq C
\]
Hence the sequence $\{\pi_n(S)\}$ is  bounded
and we can pass to a subsequence
which converges weakly to a limit measure $\mu_*$.
For this $\sigma$-additive measure the limit formula in (**) above entails that
\[ 
\mu_*(S\setminus A_k)=0\quad\colon\, k=1,2,\ldots\tag{i}
\]
Moreover, by (*) we also have
\[
\pi_*(\mathcal A)=0\tag{ii}
\]
Now
$S= \mathcal A\cup\, A_k$ so (i-ii) give:
\[ 
\mu_*(S)=0
\]
But this is impossible for at the same time
we have already seen that
$\pi_n(S)\geq 1$ for each $n$ and hence also $\mu_*(S)\geq 1$.
This finishes the proof of Theorem 5.2.1.











\bigskip




\noindent
{\bf{5.2.2 The family  $\mathcal F(X)$.}} 
if $X$ is a banach space this family consists
of bounded liner operators  $T$ on $X$  
such that
\[ 
\lim_{n\to\infty}\, \frac{1}{n}\cdot x^*(T^nx)=0\tag{*}
\] 
hold for all pairs $x\in X$ and $x^*\in X^*$.
The Banach-Steinhaus theorem implies that 
if $T\in\mathcal F(X)$, then
there exists a constant $M$ such that the operator norms satisfy
\[ 
||T^n||\leq M\cdot n\quad\colon\, n=1,2,\ldots
\]


\noindent
Since the $n$:th root of $M\cdot n$ tends to one as $n\to+\infty$, 
the spectral radius formula entails that
the spectrum $\sigma(T)$ is contained in the closed unit disc.
\bigskip


\noindent{\bf{5.2.3 The class $\mathcal F_*$}}.
It consists of those $T$ in $\mathcal F(X)$
for which there exists
some $\alpha<1$ such that
$R_T(\lambda)$ extends to a meromorphic function in
the exterior disc
$\{|\lambda|>\alpha\}$.
Since $\sigma(T)\subset
\{|\lambda|\leq 1\}$
it follows that when
$T\in\mathcal F_*$ then
the set of points in $\sigma(T)$ which belongs to the unit circle
in the complex $\lambda$-plane is empty or finite and
after we can always choose $\alpha<1$ such that
\[ 
\sigma(T)\cap \{\alpha<|\lambda|<1\}= \emptyset
\]

\medskip

\noindent
Exactly as in the beginning of the proof of
Theorem 5.2.1 one has
\medskip

\noindent
{\bf{5.2.4 Proposition.}}
\emph{If $T\in \mathcal F_*$ andÊ$e^{i\theta}\in \sigma(T)$
for some $\theta$, then Neumann's resolvent
$R_T(\lambda)$ 
has a simple pole at $e^{i\theta}$.}
 \medskip
\medskip

\noindent
{\bf{5.2.5.Theorem.}}
\emph{Let $T\in \mathcal F(X)$ be such that   there exists a compact
operator $K$ where 
$||T+K||<1$. Then $T\in \mathcal F_*$ and
for every $e^{i\theta}\in\sigma(T)$
the eigenspace
$E_T(\theta)= \{ x\in X\,\colon\, Tx= e^{i\theta} x\}$ is finite dimensional.}

\medskip

\noindent
\emph{Proof.}
Set $S=T+K$ and for a complex number
$\lambda$ we write 
$\lambda\cdot E-T= \lambda\cdot E-T-K+K$. Outside $\sigma(S)$ we get
\[
R_S(\lambda)(\lambda\cdot E-T)=
E+R_S(\lambda)\cdot K\tag{i}
\]
The Neumann series for large absolute values
$|\lambda|$
applied to $R_S(\lambda)$ gives some $\rho>0$ and
\[
( E+R_S(\lambda)\cdot K)^{-1}= E+R_S(\lambda)\cdot K\dot
( E+R_S(\lambda)\cdot K)^{-1}\quad\colon\,|\lambda|>\rho\tag{ii}
\]

\noindent
Next, when
$|\lambda|$ is large
we notice that
(i) gives
\[
R_T(\lambda)=  ( E+R_S(\lambda)\cdot K)^{-1}\cdot R_S(\lambda)\tag{iii}
\]
Together with (ii) we obtain
\[
R_T(\lambda)=R_S(\lambda)+ 
R_S(\lambda)\cdot 
( E+R_S(\lambda)\cdot K)^{-1}\cdot R_S(\lambda)\tag{iv}
\]
Set $\alpha=||S||$ which by assumption is $<1$.
Now
$R_S(\lambda)$ is analytic in the exterior disc
$\{\lambda|>\alpha\}$ so in this exterior disc
$R_\lambda(T)$ differs from  the analytic function $R_\lambda(S)$ by
\[
\lambda\mapsto R_S(\lambda)\cdot 
( E+R_S(\lambda)\cdot K)^{-1}\cdot R_S(\lambda)\tag{v}
\]
Here $K$ is a compact operator so 
the
result in ¤ XX entails that this function extends to
be meromorphic  in $\{|\lambda|>\alpha\}$.
There remains to prove that
eigenspaces at spectral points on the unit circle are finite dimensional.
To prove this we use (iv). 
Let $e^{i\theta}\in\sigma(T)$. By Proposition 5.2.3 it is a simple pole
so we have a Laurent series expansion
\[
R_T(e^{i\theta}+z)= \frac{A_{-1}}{z}+ A_0+ A_1z+\ldots
\]
By the general results from ¤¤ there remains to show that 
$A_{-1}$ has finite dimensional range.
To see this we apply (iv) which gives the equation
\[
R_S(e^{i\theta}+z)+
R_S(e^{i\theta}+z)\cdot(E+
R_S(e^{i\theta}+z)\cdot K)^{-1}\cdot R_S(e^{i\theta}+z)
\]
To simplify notations we set $B(z)=R_S(e^{i\theta}+z)$
which by assumption is analytic in a neighborhood of $z=0$.
Moreover, the operator $B(0)$ is invertible.
So now one has
\[
 \frac{A_{-1}}{z}+ A_0+ A_1z+\ldots=
 B(z)+B(z)(E+B(z)\cdot K)^{-1}B(z)
 \]
Since $B(0)$ is invertible  we  have a Laurent series expansion
\[
(E+B(z)\cdot K)^{-1}= \frac{A^*_{-1}}{z}+A_0^*+A_1^*z+\ldots
\]
and identying the coefficient of $z^{-1}$ gives
\[
A_{-1}= B(0)A^*_{-1}B(0)
\]
Next, from (xx) one has

\[
E=(E+B(z)\cdot K)(\frac{A^*_{-1}}{z}+A_0^*+A_1^*z+\ldots)\implies
(E +B(0)\cdot K)A^*_{-1}=0
\]
Here $B(0)\cdot K$ is a compact operator and hence  Fredholm theory 
implies that $A^*_{-1}$ has a finite dimensional range. Since
$B(0)$ is invertible the same is true for $A_{-1}$ which finishes the proof
of 
Theorem 5.2.4.




\bigskip

\noindent
We finish with noyther result which is used to establish Kakutani's theorem in ¤ xx.

\medskip

\noindent
{\bf{5.2.5 Proposition}}.
\emph{
If
$T\in\mathcal F$ is  such that
$T^N\in\mathcal F_*$ for some integer $N\geq 2$.
Then 
$T\in\mathcal F_*$.}
\medskip

\noindent
\emph{Proof.}
We have the algebraic equation
\[ 
\lambda^N\cdot E -T^N=(\lambda\cdot E-T)(
\lambda^{N-1}\cdot E+
\lambda^{N-2}\cdot T+\ldots+T^{N_1})
\]
It follows that
\[ R_T(\lambda)=
(\lambda^{N-1}\cdot E+
\lambda^{N-2}\cdot T+\ldots+T^{N_1})\cdot R_{T^N}(\lambda^N)
\]
Since $T^NB\in\mathcal F_*$ there exists
$\alpha<1$ such that
\[
\lambda\mapsto  R_{T^N}(\lambda^N)
\]
extends to be meromorphic in
$\{|\lambda|>\alpha\}$. At the same time
$(\lambda^{N-1}\cdot E+
\lambda^{N-2}\cdot T+\ldots+T^{N_1})$
is  a polynomial
and hence
$R_T(\lambda)$ also extends to be meromorphic
in this
exterior disc so that 
$T\in\mathcal F_*$.




\newpage




\centerline{\bf{5.3 Factorizations of non-symmetric kernels.}}


\bigskip

\noindent
Recall that
the Neumann-Poincar kernel $K(p,q)$ of  a
plane $C^1$-curve $\mathcal C$
is given by
\[ 
K(p,q)= \frac{\langle p-q,{\bf{n}}_i(p)\rangle}{|p-q|}
\]
This kernel function gives the integral operator $\mathcal K$
defined on $C^0(\mathcal C)$ by
\[
\mathcal K_g(p)=\int_C\, K(p,q)\cdot g(q)\, ds(q)
\]
where $ds$ is the arc-length measure on $C$.
Let $M$ be a positive number which exceeds the diameter of 
$\mathcal C$
so that
$|p-q|<M\,\colon\, p,q\in\mathcal C$.
Set
\[
N(p,q)= \int_\mathcal C\, 
K(p,\xi )\cdot \log\,\frac{M}{|q-\xi|}\cdot ds(\xi)
\]



\noindent
{\bf{Exercise.}} Verify that
$N$ is symmetric, i.e. $N(p,q)= N(q,p)$
hold for all pairs $p,q$ in $\mathcal C$.
Moreover, 
\[ 
S(p,q)=\log\, \frac{M}{|p-q|}
\] 
is a symmetric and positive kernel function
and since $\mathcal C$ is of class $C^1$ the reader should verify that it gives a
Hilbert-Schmidt kernel, i.e.
\[ 
\iint_{\mathcal C\times\mathcal C}\,
S(p,q)^2\, ds(p)ds(q)<\infty
\]



\noindent
Hence the
Neuman-Poincar operator  $\mathcal K$ appears in an
equation
\[ 
\mathcal N= \mathcal K\circ \mathcal S\tag{*}
\] 
where $\mathcal S$ is defined via a positive  symmetric Hilbert-Schmidt kernel and
$\mathcal N$ is symmetric.
Following  
[Carleman: ¤ 4 ] we give a procedure to determine 
the spectrum of $\mathcal K$.


\medskip

\centerline{\bf{5.3.1 Spectral properties of  non-symmetric kernels.}}
\bigskip


\noindent
In general,let  $K(x,y)$ be a continuous real-valued function on the closed unit square
$\square=\{0\leq x,y\leq 1\}$. We do not assume that  
$K$ is symmetric but 
there exists a positive definite
Hilbert-Schmidt kernel $S(x,y)$ such that
\[ 
N(x,y)=\int_0^1\, S(x,t) K(t,y)\, dy
\] 
yields a symmetric kernel function.
The Hilbert-Schmidt theory
gives
an orthonormal basis $\{\phi_n\}$ in
$L^2[0,1]$ formed by eigenfunctions to $\mathcal S$ where
\[ 
\mathcal S\phi_n=\kappa_n \phi_n\tag{1}
\] 
where the positive $\kappa$-numbers  tend to zero.
Moreover, each $u\in L^2[0,1]$
has a Fourier-Hilbert  expansion
\[ 
 u= \sum\,\alpha_n\cdot \phi_n\tag{2}
\]
We  seek 
eigenfunctions of  the integral operator $\mathcal K$.
Let  $u$ be  a function in $L^2[0,1]$
such that:
\[ 
u=\lambda\cdot \mathcal Ku\tag{3}
\]
where
$\lambda$ in general is a complex number. It follows that
\[
\lambda\cdot \int\, N(x,y)u(y)\, dy
=
\lambda\iint SA(x,t)K(t,y)u(y)\, dtdy=
\int S(x,t)u(t)\,dt\tag{4}
\]
Multiplying  with $\phi_p(x)$ an integration gives
\[
\lambda\cdot \int\, \phi_p(x)N(x,y)u(y)\, dx dy=
\iint \phi_p(x) S(x,t)u(t)\,dxdt=
\kappa_p\int \phi_p(t)u(t) \, dt\tag{5}
\]
Next, using  the expansion of $u$ from (2) we get
the equations:
\[
\sum_{q=1}^\infty \alpha_q\cdot 
\iint  \phi_q(x)\phi_p(x)N(x,y)\, dx dy=\kappa_p\alpha_p
\quad\colon\, p=1,2,\ldots\tag{6}
\]
Set
\[
c_{qp}=\iint  \phi_q(x)\phi_p(x)N(x,y)\, dx dy
\]
It follows that $\{\alpha_p\}$ satisfies the system
\[
\kappa_p\alpha_p=
\lambda\cdot \sum_{q=1}^\infty \, c_{qp}\alpha_q\tag{7}
\]
Since $N(x,y)= N(y,x)$ the
doubly indexed $c$-sequence is symmetric. Set
\[ 
\beta_p= \sqrt{\kappa_p}\cdot \alpha_p
\implies
\beta_p=\lambda\cdot \sum_{q=1}^\infty
\frac{c_{pq}}{\sqrt{\kappa_p}\cdot \sqrt{\kappa_q}}
\cdot \beta_q\tag{1}
\]



\noindent
Next, 
put
\[
k_{p,q}=\iint K(x,y)\phi_p(x)\phi_q(y)\, dxdy\tag{2}
\]
From  the above  the following hold for each pair $p,q$:

\[ c_{pq}= \iiint\,
\phi_q(x)\phi_p(y) S(x,t)K(t,y)\, dxdydt=
\kappa_qk_{p,q}=\kappa_pk_{q,p}\implies
\]
\[ 
\frac{c_{p,q}^2}{ \kappa_p\cdot \kappa_q}\leq
|k_{p,q}\cdot  k_{q,p}|
\leq \frac{1}{2}(k_{p,q}^2+k_{q,p}^2)\tag{3}
\]
Here $\{k_{p,q}\}$ are the Fourier-Hilbert coefficients of $K(x,y)$
which entails that
\[ 
\sum\sum\, k_{p,q}^2\leq
\iint K(x,y)^2\, dxdy
\]
Hence the symmetric and doubly indexed sequence
\[
\frac{c_{p,q}}{\sqrt{\kappa_p\cdot \kappa_q}}\tag{4}
\] 
is of Hilbert-Schmidt type.
\bigskip

\noindent
{\bf{5.3.2 Conclusion.}}
The eigenfunctions $u$ in $L^2[0,1]$
associated to the $\mathcal K$-kernel have Fourier-Hilbert expansions via
the $\{\phi_n\}$-basis  which are  determined by 
$\alpha$-sequences  satisfying the system (7)


\medskip

\noindent
{\bf{5.3.3 Remark.}}
When a plane curve
$\mathcal C$ has corner points the
Neumann-Poincar kernel is
unbounded. Here
the reduction to the symmetric case is  more involved  and leads 
to
quite intricate results which appear in Part II from
[Carleman].
The interplay  between singularities
on boundaries in 
the Neumann-Poincar equation
and the corresponding unbounded kernel functions 
illustrates  the 
general theory
densely defined self-adjoint operators.
Much analysis remains to be done and
open problems about
the Neumann-Poincar equation 
remains to be settled in dimension three. So far  it appears that
only the 2-dimensional case 
is properly understood via 
results  in [Car:516].
See also ¤ xx for a studiy of Neumann's boundary value problem
both in the plane and  ${\bf{R}}^3$.






\end{document}



