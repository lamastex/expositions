\documentclass{amsart}


\usepackage[applemac]{inputenc}

\addtolength{\hoffset}{-12mm}
\addtolength{\voffset}{-10mm}
\addtolength{\textheight}{20mm}

\def\uuu{_}

\def\vvv{-}

\begin{document}

\centerline{\bf\large  1. Distributions and boundary values of analytic functions}

\bigskip


\centerline {\emph{Contents}}

\bigskip



\noindent
\emph{0. Introduction}
\medskip





\noindent
A. The origin of distributions
\medskip





\noindent
B. A bird's view on distributions on the real line
\medskip

\noindent
0. Examples related to distribution theory.

\medskip


\noindent
1. Tempered distributions on the real line
\medskip

\noindent
2. Boundary values of analytic functions
\medskip

\noindent
3. Fourier-Carleman  transforms
\medskip

\noindent
4. The Paley-Wiener theorem
\medskip

\noindent
5. Runge's theorem

\medskip


\noindent
6. The generalised Fourier transform 

\medskip
\noindent
7. Carleman's inequality for differentiable functions 

\medskip
\noindent
8. Carleman's inequality for the inverse Fourier transform
in $L^2({\bf{R}}^*$.

\medskip



\noindent
9. An integral equation.

\medskip
\noindent
10. Spectral synthesis

\medskip



\noindent
11. On  inhomogeneous $\bar\partial$-equations.



\medskip



\noindent
12. Integral equations of Planck and Laplace


\medskip



\noindent
13. The Carleman-Hardy theorem

\medskip

\noindent
14. The log-potential and Abel's inversion formula

\medskip

\noindent
15. An $L^1$\vvv inequality for inverse Fourier transforms.
\medskip

\noindent
16. On functions with a spectral gap.

\medskip

\noindent
17. A result by Beurling



\medskip

\noindent
18. Lindeberg's central limit theorem

\medskip

\noindent
19. Poisson's summation formula

\medskip

\noindent
20. Positive definite functions
\medskip

\noindent
21. Calculations of some Fourer transforms


\medskip


\noindent
22. Boundary values in two variables

\medskip

\noindent
23. The Radon transform

\medskip

\noindent
24. Fundamental solutions to ODE:s with constant coefficients



\newpage


\centerline {\bf {Introduction.}}
\bigskip

\noindent 
Distributions
and their basic properties were announced  by Laurent Schwartz
in 1945 and  
presented in his book 
\emph{ThŽorie des distributions} from 1951.
As pointed out by Lars GŒrding in
Chapter 12 from [History], 
Schwartz' broad attack, his radical use of infinitely differentiable functions
and his conviction that distributions would be useful
almost everywhere made the difference  compared to earlier work
where special cases had adopted the idea of distributions
but never in  full generality.
In a broad sense distribution theory is  a
minor extension of the Lebegue-Riesz theory 
since  a distribution in ${\bf{R}}^n$ is 
locally a finite sum of derivatives of Riesz measures.
However, the notion and the calculus with distributions clarifies
many constructions and is essential in the theory of differential operators.
Already the case of an ordinary differential
operator $P(D)$ with constant coefficients in one
variable illustrates the  new phenomena which arise when
one extends to equation  of
smooth solutions to
distributions and already  for   differential operators
$P(x,D)$ whose coefficients are polynomials in a single variable
$x$
the study of solutions in the space of disttibutions becomes
quite involved.
We give  some comments about this in ¤ XX.

\medskip

\noindent
The reader may now pass directly to the
headline entitled \emph{The origin of distributions}
which togehter with ¤ B and the two sections 1-2
provides
basic material about distrubtions on the realoine and the plane.
Since we are foremost concerened with applications in analytic function theory of
one complex variable we have not tried to expose distribution theory in
full generality.
But we insert some material of a more advanced nature in
¤ xx which includes a discussion about curtrents on manifolds.
Let us finish this introduction with  some 
examples which illustrate the flavour of distributions.












\bigskip

\noindent{\bf{Stokes Theorem.}}
Let 
$\Omega$ be a bounded open set
in
${\bf{R}}^n$ whose boundary satisfies 
the Federer condition 
in ¤ XX. The characteristic function $\chi_\Omega$ yields a distribution
and Stokes Theorem implies
that 
for each $1\leq k\leq n$
one has the equality of distributions:
\[
\frac{\partial\chi_\Omega}{\partial x_k}=
{\bf{n}}_k\cdot dS
\] 
where $dS$ is the area measure on the regular part of
$\partial\Omega$ and 
${\bf{n}}_k$ is the $k$:th component of the outer normal.
Above the right hand side is a Riesz measure supported by the
compact boundary of $\partial\Omega$.
It is now tempting
to continue and
search higher order derivatives.
The case when
$\Omega$ is a convex polygon in
${\bf{R}}^n$
where $n\geq 3$
leads to
interesting formuas which
one ofgen prefers to express via  currents.
Currents are by definition
linear functionals  defined on
test-forms rather than test-functions.
For example, above one starts with the distribution
$\chi_\Omega$
whose differential is the 1-current which
maps a test-form $\gamma^{n-1}$ of degree $(n-1)$ to
\[ 
\int_{\partial\Omega}\, \gamma^{n-1}
\]
Here one employs the orientation on
the $(n-1)$-dimensional pieces of
$\partial\Omega$ where the integration takes places.
An example where one arrives at a distribution of order one
occurs if $\Omega$ is as above and $H$  a harmonic function
defined in some open neighborhood of
$\bar\Omega$. Now there exists
the distribution $H\cdot \chi_\Omega$.
Applying  the Laplace operator 
Greens' formula gives
\[
\int_\Omega\,  
H\cdot \Delta(f)\, dx=
\int_{\partial\Omega}\, H\cdot 
\frac{\partial f}{\partial {\bf{n}}}\cdot dS-
\int_{\partial\Omega}\, 
\frac{\partial H}{\partial{\bf{n}}}\cdot f\cdot dS\quad\colon\,
 f\in C_0^\infty({\bf{R}}^n)
\]
The right hand side gives an expression for the distribution
$\Delta(H\cdot \chi_\Omega)$.
The first integral corresponds to the distribution defined by
\[ 
f\mapsto 
\int_{\partial\Omega}\, H\cdot 
\frac{\partial f}{\partial {\bf{n}}}\cdot dS\tag{i}
\]
The construction of  normal derivatives  means that
(i) is the distribution given by
\[
H\cdot \sum_{k=1}^{k=n}\, {\bf{n}}_k\cdot  
\frac {\partial dS}{\partial x_k}\tag{ii}
\]
Thus, in the last sum one has taken partial distribution derivatives of
the non-negative Riesz measure $dS$ which from the start has
compact support given by the boundary of $\Omega$.


\medskip

\noindent{\bf{Regularisations.}}
Every  distribution $\mu$ in
${\bf{R}}^n$   can be approximated in the weak topology by
$C^\infty$-densities. To achieve this
one takes a $C^\infty$-function
$\phi(x)$ with a compact support such that
\[
\int_{\bf{R}^n}\, \phi(x)\, dx=1\quad\text{and}\quad \phi(0)=1
\]
For every $\delta>0$ there exists the 
$C^\infty$-function $\mu_\delta$ which for each $a\in{\bf{R}}^n$
takes the value 
\[
\mu_\delta(a)=\mu(\phi_{\delta;a})\quad\text{where}\quad 
\phi_{\delta;a}(x)= \delta^{-n}\cdot \phi(\frac{x-a}{\delta})
\]
One easily verifies the limit formula
\[ 
\lim_{\delta\to 0}\, 
\mu_\delta(f)= \mu(f)\quad\colon\, f\in C_0^\infty{\bf{R}}^n)
\]
These regularisations reveal why  
calculus for differentiable functions extends
to distributions. 
We shall foremost study distributions
on the real line and occasionally also
in 2-dimensional case where
${\bf{R}}^2$ can be  identified with
${\bf{C}}$. For a general account about distributions 
we refer to Hšrmander's text-book [Hšrmander].
Major results in this chapter are due to Beurling, Carleman,
Paley and Wiener. We have also included a proof of Lindeberg's sharp version
of the Central Limit Theorem in ¤ 18
where  the passagr to the limit is more precise as compared
to a "weak limit" in the sense of distributions.
In ¤ 1 we construct the Fourier transform of tempered
distributions and derive Fourier's inversion formula.
The  proof  employs
the Schwartz class $\mathcal S$
of  rapidly decreasing
$C^\infty$-functions which
enable us to
define
the Fourier transform
on a  wider class than integrable functions.




\medskip


\noindent
{\bf{Example.}}
Let $\xi$ be the variable when we pass to the Fourier transform.
If $\epsilon>0$ there exists the integrable function
on the $\xi$-line defined by $e^{-\epsilon\xi}$ when $\xi\geq 0$ and zero on
$(-\infty,0)$.
Its inverse Fourier transform is given by the function
\[ 
J_\epsilon(x)=\frac{1}{2\pi}\cdot
 \int_0^\infty\, 
e^{ix\xi}\cdot e^{-\epsilon\xi}\ d\xi=-\frac{1}{2\pi}\cdot
\frac{1}{ix-\epsilon}=-\frac{1}{2\pi i}\cdot\frac{1}{x+i\epsilon}
\]
When $g(\xi)$
belongs to the Schwarz class on the $\xi$-line
it is obvious that there exists a limit
\[
\lim_{\epsilon\to 0}\, 
 \int_0^\infty\, 
 e^{-\epsilon\xi}\cdot g(\xi)\, d\xi=
  \int_0^\infty\, g(\xi)\, d\xi
\]
From this we shall learn that Fourier's inversion formua entails that for
every $f(x)$ in the Schwartz class on the real $x$-line there exists the limit
\[
 \lim_{\epsilon\to 0}\, 
 \int\,\frac{f(x)}{x+i\epsilon}\, dx=  -2\pi i\cdot 
 \int_0^\infty\, \widehat f(\xi)\, d\xi
 \]
 \medskip
 
 \noindent
Passing to the limit we get 
a distribution on the real $x$-line
denoted  by
\[ 
\mu=\frac{1}{x+i0}\tag{1}
\] 
whose Fourier transform is becomes
\[
-2\pi i\cdot H_+(\xi)\tag{2}
\]
where $H_+$ is the Heaviside distribution
on the
$\xi$-line expressed by the density 1 on $\xi\geq 0$ and zero 
on $\{\xi<0\}$
In a similar way we construct the distribution
$\frac{1}{x-i0}$ and here one finds that
\[
\widehat{\frac{1}{x-i0}}(\xi)=2\pi i\cdot H_-(\xi)\tag{2}
\]
where
$H_-(\xi)=1$ if $\xi\leq 0$ and zero on $(0,+\infty)$.
With
\[
 \mu= \frac{1}{x+i0} - \frac{1}{x+i0}
 \] 
 it follows from the above that $\widehat{\mu}=- 2\pi i\cdot 1_\xi$
 where $1_\xi$ is the identity on the $\xi$-line.
 Fourier's inversion formula entails that
 \[
 \mu=-2\pi i\cdot \delta_0
\] 
 where $\delta_0$ is the Dirac measure at $x=0$.
As we shall see in ¤ XX this reflects Cauchy's residue formula and
 illustrates  how analytic funtion theory intervenes with
distributions.


\bigskip


\centerline{\emph {Boundary 
values of analytic functions}}.
\medskip

\noindent
This is a major issue in this chapter. The
basic constructions appear
in   ¤ 2 and  are  used
to obtain boundary values of analytic functions $f(x+iy)$
with a moderate growth  as $y\to 0$.
Theorem 2.7 gives  a  uniqueness
properties when boundary values of analytic 
functions are taken from the upper, respectively
the lower half plane. 
¤ 3  describes general 
procedure to get Fourier's inversion formula  where we follow
Carleman's      lectures at Institute Mittag Leffler in 1935.
Theorem 3.5   leads to the 
Fourier-Carleman transform which  can be used
to establish    
uniqueness  results  for  distributions whose Fourier transforms
have certain gaps.
¤ 4 is devoted to the
\emph{Paley-Wiener theorem}
and ¤ 5 treats
Runge's approximation theorem and
results about the inhomogeneous $\bar\partial$-equation.
¤ 6 extends Fourier's inversion formula
to non\vvv tempered situations 
which  lead to
hyperfunctions describing 
the   dual to the space of  real\vvv analytic functions.
¤ 7 is devoted to a fundamental inequality for differentiable functions
concerned with an    inequality for $L^2$\vvv norms
of  higher order derivatives
of
differentiable functions which vanish up to a a certain order at 
the end\vvv points of a bounded interval.
The remaining sections  treat  topics
which foremost deal with
problems
related to  analytic functions and Fourier transforms.

\bigskip



\centerline{\bf{The meromorphic family $\xi_+^\lambda$}}
\medskip


\noindent
In the upper half plane of the complex $z$-plane 
there exists for each complex $\lambda$ the analytic function
\[ 
z^\lambda= e^{\lambda\cdot \log z}
\]
where the single-valued branch of $\log z$ is chosen so that its
imaginary part stays in $(0,\pi)$.
We shall learn that
$z^\lambda$ has a boundary value  distribution
which is denoted by $(x+i0)^\lambda$.
Moreover, these distributions are tempered and
their  Fourier transforms are
supported by the half-line $\{\xi\geq 0\}$.
To find the Fourier transforms   one introduces
distributions on the $\xi$-line as follows: If
$\mathfrak{Re}\,\lambda>-1$
the function $\xi^{-\lambda}$ is locally integrable on
$\{\xi\geq 0\}$ and we get a tempered distribution $\xi_+^\lambda$ 
defined by
\[
\xi_+^\lambda(g)=\int_0^\infty\, \xi^\lambda\cdot g(\xi)\, d\xi\tag{i}
\]
where $g$ are Schwartz functions on the real $\xi$-line.
Here  $\lambda\mapsto \xi_+^\lambda$ is a distribution-valued anaytic function
in the half-plane
$\mathfrak{Re}\,\lambda>-1$ whose 
complex derivatives are given by
\[
\frac{d}{d\lambda}\xi_+^\lambda(g)=
\int_0^\infty\, \xi^\lambda\cdot \log\,\xi\cdot g(\xi)\, d\xi
\]
In ¤ xx we shall prove that 
 (i) extends to a meromorphic
function defined in the whole complex plane. More precisely one has
the equation 
\[
\xi_+^\lambda=e^{\lambda+1)\pi i}\cdot \frac{\Gamma(\lambda+1)}{2\pi}\cdot
\widehat{(x+i0)}^{-\lambda-1}\tag{*}
\]
where the last factor is the Fourier transform of
$(x+i0)^{-\lambda-1}$.
Since $\lambda\mapsto (x+i0)^\lambda$ is a distribution-valued  entire function of
$\lambda$ the same holds when we pass to the
Fourier transform. 
The equation (*) therefore entails that
the poles of
$\xi_+^\lambda$ ony occur at poles of the
$\Gamma$-function which 
are simple and occur
at non-positive integers. 
\medskip

\noindent
If $M$ is a positive integer then $\xi_+^\lambda$ has a Laurent series expansion at
$\lambda=-M$:
\[
\xi_+^{-M+\tau}=
\frac{\gamma_M}{\tau}+\mu_M+\sum_{k=1}^\infty\,\mu_{k,M}\cdot \tau^k
\]
 If a test-fiunction $g(\xi)$ has compact support on
an interval $[a,b]$ where $0<a<b$, then
the integrals in the right hand side of (i) are entire functions of
$\lambda$. It follows that 
the polar
distributtion $\gamma_M$  in the  Laurent series expansion
is supported by the singleton set
$\{\xi=0\}$,  i.e.  it is a so called Dirac distribution.
To find these polar $\gamma$-distributions
one regards distribution derivatives.
When
$\mathfrak{Re}(\lambda)$ is a large positive number 
amd $g$ a test-function, then
the construction of distribution derivatives give
\[
\partial(\xi_+^\lambda(g)=-\int_0^\infty\, \xi^\lambda\cdot g'(\xi)\, d\xi=
-\xi^\lambda\cdot g(\xi)|_0^\infty+
\lambda\cdot \int_0^\infty\, \xi^{\lambda-1}\cdot g(\xi)\, d\xi
\tag{i}
\]
By analyticity this gives the equation
\[
\partial(\xi_+^\lambda)=\lambda\cdot \xi_+^{\lambda-1}
\]
which now holds in the space of tempered distributions.
With $\lambda=-M+\tau$ the reader may check that repetated
use of (x) gives the equation
\[
\partial^M(\xi_+^\tau)=\tau(\tau-1)\cdots(\tau-M+1)\cdot \xi_+^{-M+\tau}
\]
Passing to the limit as $\tau\to 0$ this entails that
\[
(-1) \cdots(-M+1)\cdot\gamma_M=\partial^M(\xi_+^0)
\]
Here
$\xi_+^0$ is the Heaviside distribution $H_+$ given by the density 1 on
$\xi\geq 0$. The equality
\[
-\int_0^\infty\, g'(\xi)\, d\xi=g(0)
\]
for test-functions means that
the first order distribution derivative
$\partial(H_+)=\delta_0$.
So if $M\geq 1$ we obtain
the equation
\[
\gamma_M=\frac{(-1)^{M-1}}{(M_1)!}\cdot \partial^{M-1}(\delta_0)
\]
To find $\mu_M$ in (*)
we use the
expansion
\[
\xi_+^\tau=H_++\tau\cdot (\log \xi)_++\text{higher order terms}
\]
This gives the equation
\[
\mu_M=\frac{(-1)^{M-1}}{(M-1)!}\cdot \partial^M(\log \xi)_+)
\]
In ¤ xx we  shall compute the right hand side and the result is that
the action by $\mu_M$ is found via
Taylor expansions of test-functions at $\xi=0$. More precisely one has:
\[
\mu_M(g)=
\int_0^1\, [g(\xi)-\xi g'(0)-\ldots-\frac{\xi^{M-1}}{(M-1)!}\cdot g^{(M-1)}(0)]
\cdot \frac{d\xi}{\xi^M}+\int_1^\infty \, \frac{g(\xi)}{\xi^M}\, d\xi\tag{*}
\]
\medskip

\noindent
Thus, one removes a piece of the Taylor expansion of $g$ at
$\xi=0$ to get a denominator which
can be integrated agains $\xi^{-M}$ close to $\xi=0$.
\medskip

\noindent
{\bf{Example.}}
With $M=1$ we see that $\mu_1$ is the distribution defined by
\[
\mu_1(g)=\int_0^1\, g(\xi)\cdot 
\log (\xi)\,  d\xi
\]
At the same time (*) gives
\[
\xi_+^{-1+\tau}=e^{\tau\pi i}\cdot \frac{\Gamma(\tau)}{2\pi}\cdot
\widehat{(x+i0)}^{-\tau}\tag{*}
\]
Since the $\gamma$-function has a simpe pole with residue 1 at
$\tau=0$ a computation gives
\[
\mu_1=\frac{1}{2\pi}\cdot(\pi-\widehat{\log (x+i0)})
\]

\medskip

\noindent
{\bf{Remark.}}
In ¤ xx we give further details about the computations  above.
The  discussion above has been inserted at this early stage
to
illustrate a major issue   in this chapter which demonstrates how
analytic function theory intervenes with distribution theory.







\newpage

\centerline {\bf {A. The origin of distributions.}}
\medskip

\noindent
Here follows 
an excerpt from Jean  Dieudonne's  article \emph{300 years of analyticity} 
presented at
the Symposium  on the Occasion of the \emph{Proof of
Bieberbach's conjecture}. See   [XX].
\bigskip

\noindent
Since Cauchy and Weierstrass, the central fact in complex analysis has been
the one-to-one correspondence
\[
\{c_n\}_{n\geq 0}\mapsto \sum_{n=0}^\infty\, c_n z^n
\]
between sequences of complex numbers which do not increase too fast
and functions holomorphic in a neighborhood of 0.
When you turn to Fourier series, you immediately meet the same kind of correspondence
\[
\{c_n\}_{n\in Z}\mapsto \sum_{-\infty}^\infty\, c_n e^{in\theta}
\]
between families of coefficients and sums of trigonometric series, which has
been one of the most unsatisfactory and thickest jungles of classical analysis.
A situation as satisfactory as in the analytic case has only been achieved
by 
substituting distributions in place of functions. More precisely,
there is a one-to-one correspondence
above when, on the left hand side, only families of \emph{polynomial
growth} are considered, that is, families
such that
\[
|c_n|\leq C(1+|n|)^k \quad\colon\text{for some}\quad k>0\quad \text{and
some constant}\,\,C
\]
and the right hand side is replaced by \emph{any periodic distribution}
$T$Êon $\bf R$. The beauty of this correspondence
is that it is \emph{stable} for derivative, primitive, and convolution; so
Euler was perfectly justified in taking derivatives of
Fourier series and considering them again as
Fourier series !
\medskip

\noindent
Assuming that the sequence $\{c_n\}$ has 
polynomial growth the right hand side
is a distribution $T$ which can be split into
a sum of two periodic distributions $T_1+T_2$, 
corresponding to families $\{c_n\}$ having $c_n=0$ for all $n<0$
(resp. $n\geq 0$), and which have holomorphic extensions
\[ 
f_1(z)=\sum_{n=0}^\infty\quad\text{for}\quad |z|<1
\quad\colon\quad f_2(z)=\sum_{-\infty}^{-1}\quad\text{for}\quad |z|<1
\]
and $f_1(re^{i\theta})$ (resp.  $f_2(r^{-1}e^{i\theta})$), defined for 
$0<r<1$, 
\emph{tends} indeed to $T_1$ (resp. $T_2$) when
$r\to 1$ for the \emph{weak topology} of
distributions.

\bigskip

\noindent {\bf Remark.}
Dieudonne's concise  remarks about distributions
on the unit circle is treated in many text-books and 
easy to grasp. Namely, let $C^\infty(T)$
be the linear space of infinitely differentiable functions on
the unit circle $T$, or equivalently $2\pi$-period functions on
the real line. Partial integration shows that 
Fourier coefficients have rapid decay, i.e. with
\[ 
\widehat f(n)=\int_0^{2\pi}\, e^{-in\theta}f(e^{i\theta})dx\quad\colon
f\in C^\infty(T)\quad\colon\quad
n \,\,\text{any integer}
\]
it follows that 
\[ 
n^k\cdot|\hat f(n)|\leq \max_{0\leq\theta\leq 2\pi}
\, |f^{(k)}(e^{i\theta})|
\quad\colon\quad k=0,1,2,\ldots
\]
The topology on $C^\infty(T)$ is defined by the metric
\[ 
d(f,g)=\sum_{k=0}^\infty\,
2^{-k}\frac{|f-g|_k}{1+|f-g|_k}
\]
In this way $C^\infty(T)$ is a Frechet space and for
every  
continuous linear form $L$  there exists
some integer $k$ and a constant $C$ so that
\[
[L(f)|\leq C\cdot |f|_k\quad\colon\quad f\in C^\infty(T)
\]
From this follows the assertion by DieudonnŽ which
identifies  distributions on $T$ and
sequences $\{c_n\}$ with polynomial growth, i.e. any such sequence yields
a distribution $L$ defined by
\[
L(f)=\sum_{-\infty}^{+\infty}\, c_n\cdot \widehat f(n)
\]


\noindent 
This enable us to define boundary values of analytic functions
$g(z)$ in the open unit disc satisfying the growth condition
\[ 
|g(z)|\leq C\cdot (1-|z|^{-m}\tag{1}
\]
for some $m\geq 2$. Namely, (1)
 implies that the coefficients
$\{c_n\}$ in the series expansion 
$g(z)=\sum c_n\cdot z^n$ have polynomial growth
and  define a distribution $\mathfrak{b}\uuu g$
by the formula
\[ 
\mathfrak{b}\uuu g(f)=\sum\uuu{n=0}^\infty\, c\uuu n\cdot \widehat f(n)\tag{*}
\]


\noindent
Notice that the sum above extends over non\vvv negative integers only.
Let  $\mathcal O\uuu{\text{temp}}(D)$
be the space of analytic functions in $D$ satisfying the
growth (1) where $m$ can be taken as an arbitrary integer.
Then (*) yields an injective map from
$\mathcal O\uuu{\text{temp}}(D)$ 
into a subspace of distributions on $T$.
Using  conformal mappings between the unit disc and the upper, respectively
the lower half-plane we are able to describe
tempered distributions on the real line
via
$\{c_n\}$-sequences as above.
So the periodic case essentially covers
the
study on the real line. We  explain this in ¤ XX.
 






\bigskip


\noindent{\bf{A.1 Poisson's  formula.}}
For every function $f(x)$ in
the Schwartz class $\mathcal S$
on the real $x$-line there
exists a limit of the integrals
\[ 
\lim_{\epsilon\to 0}\, 
\int_{-\infty}^\infty\, \frac{\text{sin}(x+i\epsilon)}{\text{cos}(x+i\epsilon)}
\cdot f(x)\cdot dx\tag{1}
\]
taken as $\epsilon>0$ decrease to zero.
With $z=x+iy$ we consider the analytic function
in the upper half-plane
\[
\frac {\text{sin}(z)}{\text{cos}(z)}=\frac{1}{i}\cdot
\frac{e^{iz}-e^{-iz}}{e^{iz}+e^{-iz}}=
\]
\[
i\cdot\frac{1-e^{2iz}}{1+e^{2iz}}=
i+ 2i\cdot \sum_{k=1}^\infty\, (-1)^k\cdot e^{2ik z}\tag{2}
\]
The last sum converges as long as $z=x+i\epsilon$ with
$\epsilon>0$.
Let $\phi(\xi)$ be the   Schwartz function on the real $\xi$-line such that
\[ 
f(x)=\frac{1}{2\pi}\cdot \int e^{ix\xi}\cdot \phi(\xi)\cdot d\xi
\]
So here $\phi=\widehat f$  by Fourier's inversion formula.
Now (2) implies that the limit in (1) is equal to
\[
i\cdot \phi(0)+ 2i\cdot \sum_{k=1}^\infty\, \phi(-2k)\tag{3}
\]
This means that the distribution on the $\xi$-line expressed by the discrete measure
\[
\mu= i\cdot \delta\uuu 0+\sum_{k=1}^\infty\, \delta\uuu{-2k}
\]
is equal to the Fourier transform of the distribution on the $\xi$-line obtained 
as the boundary value function of  the analytic function in (2).
A special case occurs of $f(x)$ is a test-function with compact support in
$[- \pi/2,\pi/2]$. Then  
the equality between (1) and (3)  gives Poisson's classical formula:
\[
\int_{-\pi/2}^{\pi/2}\, \frac{\text{sin}(x)}{\text{cos}(x)}
\cdot f(x)\cdot dx=
i\cdot \widehat f(0)+2i\cdot \sum_{k=1}^\infty\,\widehat f(\vvv 2k)\tag{*}
\]








\newpage









\centerline{\bf{B. A bird's view upon distributions.}}
\medskip

\noindent
Laurent Schwartz 
defined  the 
class $\mathcal S$ of $C^\infty$-functions on 
the real line which together with all their derivatives
have a rapid decay, i.e. when $f\in\mathcal S$ there exists for
any pair of positive integers $N,M $ a constant $C_{N,M}$ such that
\[
|f^{(N)}(x)|\leq C_{N,M}\cdot(1+|x|^{-M}\quad\colon\quad x\in\bf R
\]

\noindent
In
¤ 1 we explain how $\mathcal S$ is
equipped with a sequence of semi-norms which
gives it a structure as a Frechet space whose dual
is denoted by
$\mathcal S^*$ and consists of 
\emph{tempered distributions}.
 which
Riesz representation formula  entails that
for each $\gamma\in \mathcal S^*$ there exists some integer $N\geq 0$
and a Riesz measure $\mu_N$   such that
\[
\int_{-\infty}^\infty\, (1+|x|)^{-m}\cdot \bigl|d\mu_N(x)\bigr|<\infty\tag{1}
\]
hold for some non-negative integer $m$
and
\[
\gamma(f)=
\int_{-\infty}^\infty\, f^{(N)}(x)\cdot d\mu_N(x)\tag{*}
\]
Let us remark that the given tempered distribution can be represented
by different pairs $(N,\mu_N)$ as $N$ changes. For example, 
the Dirac distribution at $x=0$
is also represented by
\[ 
f\mapsto  \int_{-\infty}^0\,f'(x)\cdot dx
\]


\medskip

\noindent
{\bf{B.0 The Fourier transform.}}
The usefulness of $\mathcal S$   is that the Fourier transform
\[
 f\mapsto \widehat f(\xi)=\int\, e^{-ix\xi}\,f(x)dx
\]
yields a 1-1 map from $\mathcal S$ to the corresponding
$\mathcal S$-class on the real $\xi$-line. 
Moreover one has  
Fourier's inversion formula:
\[
f(x)=\frac{1}{2\pi}\cdot
\int\, e^{ix\xi}\,\widehat f(\xi)d\xi\quad\colon\quad  f\in\mathcal S
\]
\medskip


\noindent
In ¤ XX we explain how
the Fourier transform extends to tempered distributions
and in this
way one gets a bijective mapping between
the $\mathcal S^*$-spaces on the real $x$-line, respectively the
real $\xi$-line.
More precisely, if
$\mu$ is a tempered distribution on the $x$-liner then
$\widehat\mu$
is the distribution on the $\xi$-line for which

\[
\widehat\mu(\phi)=\mu(\phi^*)\quad\colon \phi(\xi)\in\mathcal S_\xi
\]
where
\[
\phi^*(x)=\int\, e^{-ix\xi}\cdot \phi(\xi)\, d\xi
\]
An important  example is when
$\mu$ is the Gaussian density
\[ 
g(x)=\frac{1}{\sqrt{2\pi}}\cdot e^{-x^2/2}
\]
Then we obtain
\[
 \widehat\mu(\phi)=\iint e^{-x^2/2}\cdot e^{-ix\xi}\cdot \phi(\xi)\, dxd\xi=
\int e^{-\xi^2/2}\cdot\phi(\xi)\,d\xi
\]
Thus, apart from
a constant multiple the Fourier transform of $\mu$
is another Gaussian density.

\medskip


\noindent
{\bf{B.1 Boundary
values of analytic functions}}.
Every tempered distribution is
recaptured as a sum of boundary values of analytic functions
defined in the upper, respectively the lower half-plane.
Consider   a Riesz measure $\mu$
on the real $\xi$-line such that
\[
\int_{-\infty}^\infty\, (1+|\xi|)^{-m}\cdot d\bigl|\mu|(\xi)<\infty\tag{1}
\]
holds for some integer $m\geq 0$.
If $z=x+iy$ belongs to the upper half-plane
we set
\[ 
G_+(z)=\int_0^{\infty}\,e^{iz\cdot \xi}\cdot d\mu(\xi)=
\int_0^{\infty}\,e^{i x\cdot \xi-y\cdot\xi}\cdot d\mu(\xi)
\]
This integral is absolutely
convergent since $\xi\to e^{-y\xi}$ tends to zero more rapidly than any power of
$\xi$ as $\xi\to\infty$ when $y>0$ is fixed. Hence
$G_+(z)$ is an analytic function in
$\mathfrak{Im}(z)>0$.
In a similar fashion we get the analytic function
$G_-(z)$in the lower half-plane defined by
\[
G_-(z)=
\int_{-\infty}^0\,e^{iz\cdot \xi}\cdot d\mu(\xi)
\]
In ¤ 2 we prove that
these two $G$-functions have
boundary values on the real $x$-line given by
tempered distributions. More precisely, there exists
$\gamma_+\in\mathcal S^*$ defined by
\[
\gamma_+(f)=
\lim_{y\to 0}\, 
\int_0^ \infty\,G_+(x+iy)\cdot f(x)\cdot dx\quad\colon\quad
f(x)\in\mathcal S
\]
and in a similar fashion 
the tempered distribution $\gamma_-$ defined by
\[
\gamma_-(f)=\lim_{y\to 0}\, 
\int_0^ \infty\,G_-(x-iy)\cdot f(x)\cdot dx\quad\colon\quad
f(x)\in\mathcal S
\]
Excluding the case when
$\mu$ has
an atom at $x=0$, i.e. its discrete part has no mass
at
$x=0$, it follows via Fourier's inversion formula 
that the tempered distribution defined by $\mu$ is equal to
the sum $\gamma_++\gamma_-$.
Conversely, let $g(z)$ be a
bounded analytic function in the upper half-plane $U_+$.
Then there exists the tempered distribution ${\bf{b}}\uuu g$
defined by
\[
{\bf{b}}\uuu g(f)=\lim_{y\to 0}\, 
\int_0^ \infty\,g(x+iy)\cdot f(x)\cdot dx\quad\colon\quad
f\in\mathcal S
\]
Indeed, this follows since the bounded analytic function $g(z)$ has
Fatou limits almost everywhere on the real $x$-line and
if $g(x)=\lim_{y\to 0}\, g(x+iy)$ is the limit function
then the distribution
${\bf{b}}\uuu g$ is 
the
$L^1_{\text{loc}}$-density $g(x)\cdot dx$.
More generally we shall    prove that
an analytic function $G(z)$ in the upper half-plane has a
boundary value given by a tempered distribution if 
there exists a pair of integers $N,m$ and a constant $C$ such that
\[ 
|G(x+iy)|\leq C \cdot y^{-m}\cdot (1+|z|)^N\tag{B.1 *}
\]
hold for all $z=x+iy$ in the upper half-plane.
denote by  $\mathcal O_{\text{temp}}(U_+)$ the class analytic functions satisfying
(B.1.*for some piar $N,m)$. Then
we shall learn in ¤ xx that one has an injective map:
\[
\mathfrak{bf}_+\colon\,\mathcal O_{\text{temp}}(U_+)\to \mathcal S^*\tag{1}
\]
Moreover, the image under this map consists of
temepred distributions $\mu$ for which
$\widehat\mu$ is supported by the closed half-line
$\xi\geq 0$.
In a similar fashoin we introduce the space
$\mathcal O_{\text{temp}}(U_-)$ of analytic functions in
the lower half-pane satisfying
(B.1.*) with $y$ replaced by $|y|$ since
we now have $y<0$. Here one has an injective mapping
\[
\mathfrak{bf}_-\colon\,\mathcal O_{\text{temp}}(U_-)\to \mathcal S^*\tag{2}
\]
whose image consists of tempered distributions $\mu$ where
$\widehat\mu$ is supported by $\{\xi\leq 0\}$.

\medskip

\noindent{\bf{Remark.}}
The intersection of the two image spaces above
consist of distributions $\mu$ where the support of 
$\widehat\mu$ is reduced to $\{\xi=0\}$ which means that
$\mu$ is 
a polynomial density function.
A notable fact is that
the $\mathfrak{bf}$-maps commute with
derivations. More precisely, if
$g\in \mathcal O_{\text{temp}}(U_+)$ its complex derivative
$\frac{\partial g}{\partial z}$ also belongs to this space and one has
\[
\mathfrak{bf}_+(\frac{\partial g}{\partial z})=
\frac{d}{dx} (\mathfrak{bf}_+(g))
\]
\medskip

\noindent 
Using this one arrives at the following:





\medskip

\noindent
{\bf{B.1.2 Theorem.}} 
\emph{Every tempered distribution on the real $x$-line
can be expressed 
by a sum}
\[ 
p(\frac{d}{dx}){\bf{b}}\uuu{g_+} +q(\frac{d}{dx}){\bf{b}}\uuu{g_-}+P(x)
\]
\emph{where $P(x)$ is a polynomial
and the $g$-functions are bounded analytic functions in 
$U_+$ and $U_-$ while $p$ and $q$ are
differential operators with constant coefficients.}
\bigskip










\noindent{\bf B.2 Parseval's formula.}  
In ¤ XX we show that Fourier's inversion formula gives the equality:
\[ 
\int\,|f(x)|^2\, dx=\frac{1}{2\pi}\,
\int\, |\widehat f(\xi)|^2\,d\xi\quad\colon\, f\in\mathcal S\tag{1}
\]


\noindent
Next, on the real $x$-line we have the Hilbert space
$L^2({\bf{R}})$.
Since $\mathcal S$ is a dense subspace the 
construction of
the Fourier transform for 
tempered distributions
will show that if $f(x)\in L^2({\bf{R}})$, then its
Fourier transform is an $L^2$-function on the $\xi$-line
and the equality (1) holds.
Suppose now that  $f(x)\in L^2$ and that
the Fourier transform $\widehat f(\xi)$
is supported by $\xi\geq 0$. In this case
we can get an inverse transform defined in the upper half-plane by
\[
F(z)=
\frac{1}{2\pi}\cdot
\int_0^\infty\, e^{iz\xi}\cdot\widehat f(\xi)\cdot d\xi\quad\colon\quad y>0\tag{2}
\]


\noindent
Fourier' inversion formula and the existence of Fatou limits
gives the limit formula:
\[
 \lim_{y\to 0}\, F(x+iy)=f(x)\quad\text{for almost every}\quad x
\] 
At this stage we encounter
an example where complex analysis enable us to get a result 
which goes beyond
real variable methods.
Namely,  the $L^2$-function $f(x)$
whose Fourier transform by assumption is supported by $\xi\geq 0$
cannot be too small in average. More precisely,  Carleman's  formula from
[XX] gives:
\[
\int_{-\infty}^\infty\,\log^+\,\frac{1}{|f(x)|}\cdot
\frac{dx}{1+x^2}<\infty\tag{*}
\]
In ¤ 9 we prove a converse  result from  
Carleman's 
article [Car:xx].
\medskip

\noindent
{\bf{B.2.1 Theorem.}}
\emph{Let
$f(x)\in L^2({\bf{R}})$
be such that (*) holds.
Then there exists an $L^2$-function $g(\xi)$
supported by $\xi\geq 0$ such that}
\[ 
|f(x)|=\bigl|\int_0^\infty\, e^{ix\xi}\cdot g(\xi)\, d\xi\,\bigr|
\]
\medskip

\noindent{\bf{B.3 Spectral gaps and Cauchy-Fourier formulas.}}
Let $\gamma$ be a tempered distribution
whose support has gaps,  i.e. 
the complement of $\text{Supp}(\gamma)$
is a union of disjoint
open intervals $\{(a_\nu,b_\nu)\}$. From B.1 we find a pair
$G_+$ and $G_-$ such that
\[
\gamma=
\mathfrak{bf}_+(G_+)-\mathfrak{bf}_-(G_-)
\]
For each open interval $(a_\nu,b_\nu)$ we shall learn 
that $G_+$ and $G_\vvv$ extend each other across this
interval on the real $x$-axis. The conclusion is that there exists
an analytic function $G^*(z)$ defined in the connected
set ${\bf{C}}\setminus\, \cup\, [a_\nu,b_\nu]$
such that $G^*=G_+$ in $U_+$ and $G^*=G_-$ in $U_-$.
Next,  
on the $\xi$-line the space of test-functions is dense in
the Frechet space
$\mathcal S_\xi$. Using
the Fourier transform it follows
that $\mathcal S_x$ contains a dense subspace of those
funtion $f(x)$ for which $\widehat f$ has compact support.
Let us denote this space by $\mathcal S_x(c)$. Notice that
every $f\in\mathcal S_x(c)$
is the restriction to the real $x$-line of the entire function
\[ 
f(z)=\frac{1}{2\pi}\cdot \int \, e^{iz\xi}\, \widehat f(\xi)\, d\xi
\]
\medskip

\noindent
With $\gamma$ as above we
suppose that $R$ is a positive number such  that both
$R$ and $-R$ are outside the support of
$\gamma$ and define
\[ 
\gamma_R(f)= \int_{|z|= R}\,
G^*(z)\cdot f(z)\, dz\quad\colon\, f\in \mathcal S_x(c)
\]
By Cauchy's Theorem the complex line integral above is equal to
\[ 
\lim_{\epsilon\to 0}\,\bigl[\, 
\int_{-R}^R\, G_+(x+i\epsilon)\cdot f(x+i\epsilon)\, dx-
\int_{-R}^R\, G_-(x-i\epsilon)\cdot f(x-i\epsilon)\, dx\,\bigr]
\]
If we there exists  a sequence $\{R_\nu\}$ as above where
$R_\nu\to +\infty$
we get the limit formula:
\[ 
\gamma(f)= \lim_{\nu\to \infty}\gamma_{R_\nu}(f)\,
\quad\colon\, f\in \mathcal S_x(c)\tag{B.3. *}
\]
This limit formula will be applied in ¤ 16 to establish  uniqueness results for
tempered distributions whose support have gaps.

\bigskip



\centerline{\bf{B.4 Derivatives of integrable functions.}}
\bigskip


\noindent
Denote by $C^\infty\uuu 0(0,1)$
the space of test\vvv functions with compact support in
the open interval $(0,1)$ and 
$\psi(x)$ is a real\vvv valued and integrable function on the unit interval.
Suppose there exists a constant $K$ such that
\[
\bigl|\, \int\uuu 0^1\, \phi'(x)\cdot \psi(x)\cdot dx\,\bigr|\leq K\cdot\int\uuu 0^1\, |\phi(x)|\cdot dx\tag{*}
\]
hold for every $\phi\in C^\infty\uuu 0(0,1)$.
Now $C^\infty \uuu 0(0,1)$ is a dense subspace of
$L^1[0,1]$ whose dual is
$L^\infty[0,1]$. Hence (*) gives
a unique
$q(x)\in  L^\infty[0,1]$
such that
\[
 \int\uuu 0^1\, \phi'(x)\cdot \psi(x)\cdot dx=\int\uuu 0^1\, q(x)\cdot \phi(x)\cdot dx
\quad\text{for all}\quad \phi\in C^\infty\uuu *(0,1)\tag{1}
\]
Let $Q(x)=\int\uuu 0^x\, q(s)\cdot ds$ be the primitive function.
A partial integration identifies the right hand side in (1) with
\[
\vvv \int\uuu 0^1\, Q(x)\cdot \phi'(x)\cdot dx\tag{2}
\]
First order derivatives of
$C^\infty \uuu 0$\vvv functions
generate a closed hyperplane in
$L^1[0,1]$
which consists of all integrable functions on
$[0,1]$ with mean\vvv value zero.
Hence  (1) and (2) imply that the $L^1$\vvv function
$\psi\vvv Q$ is reduced to a constant. 
So after
$\psi$ has been changed on a null\vvv set, it is equal to an absolutely continuous function
whose
derivative by Lebegue's theorem
exists almost everywhere 
and  is given by 
the  bounded and measurable function $q(x)$  in (1).
\medskip

\noindent
Up to a constant
the inequality (*) describes the family of 
absolutely continuous $\psi$-functions
whose derivative in Lebesgue's sense is bounded.
This illustrates a typcial flavour of distribution theory where
one can use an operative definition as in (*) to
exhibit regularity conditions on functions.


\newpage




\centerline{\bf{B.5  Logarithmic potentials.}} 
\medskip

\noindent
For each absolutely integrable function
$g$ on the unit interval $0\leq t\leq 1$
we set
\[ 
T\uuu g(x)=\int\uuu 0^1\, \log\,|x\vvv t|\cdot g(t)\, dt
\]
Here $g\mapsto T\uuu g$
is an injective linear operator from
$L^1[0,1]$ into itself.
One easily shows that it has a dense range
but the $T$\vvv operator
is not surjective so one
may ask for a precise description of the range.
To achive this
analytic function theory will be  used.
In ¤ 14 we derive an inversion formula which
shows
that a function $f$ belongs to the range of   $T$ if and only if
its is absolutely continuous
and its $L^1$-derivative $f'$ is such that
\[
\frac{1}{\sqrt{x(1-x)}} \cdot \mathcal P_{f'}\in L^1[0,1]
\]
where
$ \mathcal P_{f'}$ is a principal value
distribution on $(0,1)$ obtained via 
the limit formula
\[
\mathcal P_{f'}(x)=
\lim_{\epsilon\to 0}\, \int_0^1\,
\frac{x-t}{(x-t)^2+\epsilon^2}\, f'(t)\, dt
\]
\medskip


\noindent
{\bf{Remark.}}
The example above ilustrates that in more refined questions
one
must perform
a more delicate analysis, ie. the mere notion of distributions is
helpful but does not provide immediate answers to more involved problems.


\bigskip



\centerline{\bf{B.6 Principal values}} 
\medskip

\noindent
A construction which were carried out
prior to the general notion of distributions 
was introduced is 
the integral operator which sends an $L^2$-function $f$ on the real line to
\[ 
T_f(x)= \frac{1}{\pi}\cdot \text{PV}\, \int_{-\infty}^\infty\, \frac{f(y)\, dy}{x-y}\tag{*}
\]
where one takes a principal value.
It turns out
that $T$ is an isometry on $L^2({\bf{R}})$ and the squared operator
$T^2$ is minus the identity.
The proof of  uses  boundary values of analytic functions
More precisely, the principal value
integral in (*)  can be defined  by
\[
T_f(x)=\frac{1}{\pi}\cdot \lim_{\epsilon\to 0}\, 
\bigl[\, \int_{-\infty}^\infty\, \frac{f(y)\, dy}{x+i\epsilon-y}+
\int_{-\infty}^\infty\, \frac{f(y)\, dy}{x-i\epsilon-y} \,\bigr]\tag{**}
\]
In ¤ xx we shall also learn that the limit of the left hand side
yields an $L^2$-function whose Fourier transform
becomes
\[
i\cdot \text{sign}(\xi)\cdot \widehat f(\xi)
\]
So passing to Fourier transforms  the $T$-operator  corresponds to
multiplication of functions  on the $\xi$-line by
$i\cdot \text{sign}(\xi)$ and   Parseval's
identity for $L^2$-norms implies that
$T$ is an isometry on $L^2{\bf{R}})$.


\bigskip




 \centerline{\bf{{B.7 Distributions in ${\bf{R}}^2$}.}} 
\medskip



\noindent
Consider  a continuous  function 
$f(x,y)$ defined on the square
$\square=\{0\leq x,y\leq 1\}$.
Prior to distribution theory  various conditions were suggested
to express that $f$ is an absolutely continuous function of
the two real variables. See  for example 
[xxx\vvv page xxx] for   conditions 
introduced by by Caratheodory and Tonelli.
Using distributions one can ignore this and
simply 
impose the condition that
the distribution derivatives
$f'\uuu x$ and $f'\uuu y$  are 
$L^1$\vvv densities which means that there exists
a constant $C$  such that for every $C^\infty$\vvv function
$\phi(x,y)$ in ${\bf{R}}^2$ it holds that
\[
\bigl |\iint\uuu\square\, f\cdot \phi'\uuu x\, dxdy\,\bigr |\leq
C\cdot \max\uuu{x,y}\, |\phi(x,y)|
\] 
and a similar inequality with
$\phi'\uuu x$ replaced by
$\phi'\uuu y$. This  \emph{operative
definition}  
was put forward by Laurent Schwartz when he created   distribution theory.
Just as in dimension one we can define tempered distributions in
${\bf{R}}^2$
which by defintion are continuous linear forms on
the Frechet space
$\mathcal S({\bf{R}}^2)$ of Schwartz funtion in two variables.
Fourier's inversion formula in dimension two enable us to construct
Fourier transforms of tempered 
distributions just as in the 1-dimensional case.
For applications in analytic function theory one often
identifies
${\bf{C}}$ with the real $(x,y)$-space.
The complex-valued function $z^{-1}$ is locally integrable in
${\bf{C}}$ 
and defines a tempered distribution
Let us recall from ¤ XX that
$z^{-1}$ yields a fundametnal solution to
the $\bar\partial$-operator which may be expressed by the distribution equation
\[
\frac{1}{2}(\partial_x+i\cdot \partial_y)
(z^{-1})=\pi\cdot \delta_0\tag{i}
\] 
where $\delta_0$ is the Dirac measure at the origin  in
${\bf{C}}$.
Now we emplly interchange rule during the passage to the Fourier
transform
which will
be explained in ¤ XX.
It entails  that
$\partial_x$ corresponds to multiplication with $i\xi$, and similarly
$\partial_y$ corresponds to multiplication
with
$i\eta$.
So if we consider the Fourier transform
$\mu=\widehat{z^{-1}}$ and use that
$\widehat \delta_0$ is the identity function in the $(\xi,\eta)$-space then
(i) gives the equation
\[
\frac{1}{2}(i\xi-\eta)\cdot \mu=\pi
\]
From this one verifies that
$\mu$ is the distribution expressed by the $L^1_{\text{loc}}$-function
$\frac{2\pi}{i\xi-\eta}$.
In the next section we shall give an example where
this fomula  is applied.


\medskip











\centerline{\bf{B.8  The Hilbert transform in two variables.}}
\bigskip


\noindent
Let $E $ be a compact set in ${\bf{C}}$.
The Hilbert transform of the characteristic function
$\chi_E$ is defined by
\[
\mathcal H_E(z)= \iint_E\, \frac{dudv}{(z-w)^2}\tag{1}
\] 
where $w=u+iv$.
Outside $E$ this gives an analytic function
which decays like $|z|^{-2}$.
when $|z|\to +\infty$.
There remains to see if the integral (1) makes sense
when $z\in E$.
For this purpose we  introduce the
functions
\[
H_n(z)= \iint_{\{|w-z|>\frac{1}{n}\}\cap E}\, \frac{dudv}{(z-w)^2}\tag{2}
\]
These functions are defined for all $z$
and one may
ask if there exists an almost everywhere defined limit function
\[
H_*(z)= \lim_{n\to\infty}\, H_n(z)
\]
Outside $E$ it is clear that
the limit exists and here $H_*=\mathcal H_E$.
So if (2) exists almost everywhere then
$H_*$ is the candidate for defining
$\mathcal H_E$  at points in
$E$.
Let us  analyze the eventual existence of a limit when
$z=0$. Suppose that $E$ is contained in the disc
$\{|z|\leq R\}$ and for each $r$ we set $E[r]= E\,\cap \{|z[=r\}$.
In polar coordinates we get
\[
H_n(0)=\int_{\frac{1}{n}}^R\, \bigl[\int_{E[r]}\, e^{-2i\theta} \,d\theta\bigr]
\frac{dr}{r}
\]
The function
$\rho_E(r)=\int_{E[r]}\, e^{-2i\theta} \,d\theta$
is bounded but need not entail that
there exists the limit
\[
\lim_{n\to\infty}\, \int_{\frac{1}{n}}^R\,\frac{ \rho_E(r)}{r}\, dr\tag{3}
\]
\medskip

\noindent
\emph{Convergence in $L^2$}.
To avoid the subtle question about existence of
point-wise limits we 
consider convergence in
$L^2$ where
one has:


\medskip

\noindent
{\bf{B.8.1 Theorem.}}
\emph{The sequence $\{H_n\}$ converges in $L^2$ to a limit function
$H_*$ in the $L^2$-norm, i.e.}
\[
\lim_{n\to\infty}\, \iint\, |H_n(z)-H_*(z)|^2\, dxdy=0\quad\text{and}\quad
 \iint\, |H_*(z)|^2\, dxdy=|E|_2
\]
\emph{where the right hand side is the 2-dimensional Lebesgue measure of $E$.}

\medskip


\noindent
{\emph{About the proof.}}
Theorem B.8.1
is a  consequence of
Parseval's  formula
after 
certain Fourier transforms have been computed.
Moreover, one can  replace characteristic functions of compact sets
by
$L^2$-functions in the $(x,y)$-space and
define the Hilbert transform of two variables by
\[ 
\mathcal H_f(z)=\frac{1}{\pi}\cdot \iint\, \frac{f(w)}{(w-z)^2}\, dudv\tag{4}
\]
The conclusive result is that
$f\mapsto \mathcal H_f$ is an isometry on
the Hilbert space
$L^2({\bf{C}})$.
To prove this we must  learn how to compute the
Fourier transform of
the distribution  $z^{-2}$ which is defined via a principal value, i.e.
when $f(x,y)$ is a test-function we set
\[ 
z^{-2}(f)=\lim_{\epsilon\to 0}\,
\iint_{|z|>\epsilon}\, \frac{f(x,y)}{z^2}\, dxdy
\]
Using Stokes formula it follows that one has the distribution equation

\[
\frac{1}{2}(\partial_x-\partial _y)( z^{-1})=
-z^{-2}
\]
Passing to Fourier transforms where the interchange rules are used, it follows that
\[ 
\widehat{z^{-2}}(\xi,\eta)=
\frac{1}{2}\cdot (i\xi+\eta)\cdot  \frac{2\pi}{i\xi-\eta}=
\pi\cdot\frac{i\xi+\eta}{i\xi-\eta}\tag{5}
\]
The last factor has aboslute value one
and  the isometric property the $\mathcal H$-operator in (4) follows from
Parseval's identity.









\bigskip




\noindent
\centerline{\bf{B.9 Weak limits.}}
\medskip




\noindent
In distribution theory  limits are  mostly taken in
a weak sense.
For example, 
consider  the family of 
complex\vvv valued Riesz measures of finite total variation
on the real line.
Let $\{\mu\uuu n\}$ be a sequence of such measures for which
there exists a constant $M$ such that $||\mu\uuu n||\leq M$
hold for every $n$.
The sequence is said to converge weakly to a Riesz measure $\mu$ when
a pointwise limit hold for the  Fourier transforms, i.e. if
\[
\lim\uuu{n\to \infty}\, \widehat \mu\uuu n(\xi)= \widehat \mu(\xi)
\quad\text{holds pointwise}\tag{1}
\] 
The uniform bound on $\{||\mu\uuu n||\}$ implies
that (1) holds if and only if
\[
\lim\uuu{n\to \infty}\int \, f(x)\cdot d\mu\uuu n(x)=
\int \, f(x)\cdot d\mu(x)
\] 
for every continuous function $f(x)$ with a compact support.
Next, let $\phi(x)$ be a bounded and uniformly continuous function on
the real $x$\vvv line. We do not assume that it has compact support but 
the integrals below exist for all $n$: 
\[
\int \, \phi (x)\cdot d\mu\uuu n(x)\tag{2}
\]
The question arises if the pointwise  convergence in (1) entails that
\[
\lim\uuu{n\to\infty}\int\, \phi (x)\cdot d\mu\uuu n(x)
=\int\, \phi (x)\cdot d\mu(x)\tag{*}
\]
Beurling proved that
(*) holds  for every weakly convergent sequence
$\{\mu\uuu n\}$
if and only if
$\phi$  can be uniformly approximated on the whole $x$\vvv line
by functions of the form
\[ 
x\mapsto  \int\, e^{i\xi x}\cdot d\gamma(\xi)
\]
where $\gamma$  is a Riesz measure on the $\xi$\vvv line with a finite total
variation.
This result is  proved  in ¤ 17.
The  proof requires considerable work which relies upon
solutions to  variational problems
so for more subtle problems it is not sufficient to just 
employ the calculus based upon distributions.













\newpage







\centerline
{\bf{0. Examples related to distribution theory.}}
\bigskip

\noindent
Below we give a number of examples
which illustrate how
distributions appear naturally in many 
situations. The reader may return to this material after
the basic theory has been exposed in ¤ XX-XX.
\medskip

\noindent
{\bf{0.1 The Laplace operator.}} 
Let $\Delta=\partial_x^2+\partial_y^2+\partial_z^2$
be the Laplace operator
in ${\bf{R}}^3$ where
$x,y,z$ are the coordinates.
For each $\rho>0$ we define the kernel function:
\[
 A_\rho(p,q)=
 \frac{2}{\rho}-\frac{[p-q|}{\rho^2}-\frac{1}{|p-q|}
\] 
where $p$ and $q$ are points in ${\bf{R}}^3$.
The singularity of the last term is not too bad for if
$p$ is fixed then $q\mapsto \frac{1}{|p-q|}$ is locally square integrable as
a function of $q$.
Let $D$ be a bounded open domain in ${\bf{R}}^3$
and
$\phi$ a 
square integrable function in $D$.
Suppose that $u$ is a continuous function 
on the closure  $\bar D$ such that
for each point   $p\in D$ and every
$\rho<\text{dist}(p,\partial D)$ 
one has the equality

\[ 
u(p)= \int_{B_p(\rho)}\frac{u(q)}{|p-q|}\cdot dq+
 \int_{B_p(\rho)}\, A_\rho(p,q)\cdot \phi(q)\cdot dq\tag{1}
 \] 
Here $dq=dxdydz$ is the Lebesgue measure and
 $B_p(\rho)$ the open ball of radius $\rho$ centered at $p$.
The last integral in (1)
 is defined since
$A_\rho(p,q)\cdot \phi(q)$  belongs to 
$L^1(B_p(\rho))$ by the Cauchy-Schwarz inequality.
If $v$ is a $C^2$-function in $D$ then
Green's formula gives
the equality
\[
v(p)=
\int_{B_p(\rho)}\frac{v(q)}{|p-q|}\cdot dq+
 \int_{B_p(\rho)}\, A_\rho(p,q)\cdot \Delta(v)(q)\cdot dq\tag{2}
\]
It follows that that
(1) gives the equality below in the sense of distributions:
\[ 
\Delta(u)=\phi\tag{3}
\]
Before distributions were introduced, one used the integral formula
(1)  to express a solution $u$ to the inhomogeneous equation (3)
when 
the $\phi$-function is given in  $L^2(D)$.
In other words,
the inhomogeneous equation (3)
is solved via the integral equation (1). 
This device appears in
Ivar Fredholm in  pioneering work   who proved  that 
extensive classes of linear PDE-equations
can be solved via integral equations. So the inhomogeneous
equation (3) is an example from  Fredholm's theory.

\medskip






\noindent
{\bf{0.2 Kernels in analytic function theory.}}
Riemann posed the problem to find an analytic function
$f(z)$ in a bounded domain $\Omega$ whose
real and  imaginary parts  restrict to 
preassigned linearly dependent functions on the boundary.
Hilbert investigated  the more general
 problem
when $\mathcal C(z)=\{ c_{pq}(z)\}$ is an $n\times n$-matrix of continuous complex valued function defined on $\partial\Omega$ and 
asked for
a pair of $n$-tuples $\{f_p(z)\}$ and $\{g_q(z)\}$
where the $f$-functions are meromorphic in $\Omega$ 
with a finite set of poles and the $g$-functions are meromorphic in
the exterior domain with a finite number of poles, such that
\[
 f_p(z)=\sum_{q=1}^{q=n}\, c_{pq}(z)\cdot g_q(z)
\] 
hold on $\partial\Omega$ for every $1\leq p\leq n$.
The system above also appears
in  work by Plemelj  devoted 
to the
problem of finding systems of linear differential equations whose solutions
have a prescribed monodromy.
A more general account was later given by 
Hasemann and one should also mention
work by Uhler who used integral equations to
extend the theory about zeta-functions of Fuchsian type.
Cases where singular kernels appear lead to
equations where  regularisations in the spirit of general distribution theory
are used and we remark that when smoothness of $\partial\Omega$Êis relaxed
many open problems  remain to be analyzed.






\medskip


\noindent
{\bf{0.3 The Pompieu formula.}}
Let $f(z)$ be a continuous complex-valued function 
in a domain $\Omega$ 
which belongs to the class $\mathcal D({\bf{C}}^1)$.
In Chapter III  we established the Pompieu formula under the assumption that
$f$ is a $C^1$-function.
This regularity assumption can be relaxed. Namely,
assume only that $f$ is continuous and that the \emph{distribution derivative}
$\bar\partial(f)$ belongs to $L^1_{\text{loc}}(\Omega)$ which
means that
there exists an $L^1_{\text{loc}}$-function $\phi$ in $\Omega$
such that the following equality  for area integrals hold:
\[
\iint\, \bar\partial(g)\cdot f\cdot dxdy=-\iint\, g\cdot \phi \cdot dxdy\tag{1}
\] 
for each  $g(x,y)\in C\uuu 0^\infty(\Omega)$.
When $z\in\Omega$ is given
we consider test\vvv functions
\[ 
g\uuu \epsilon(\zeta)=\frac{\bar\zeta\vvv \bar z}{|\zeta\vvv z|^2+\epsilon}\cdot \rho
\] 
where $\rho\in C^\infty\uuu 0(\Omega)$
is identical 1 in the compact set of points in
$\Omega$ with distance $\geq \epsilon$ to
$\partial\Omega$.
Passing to the limit as $\epsilon\to 0$ the same reasoning 
as in  Chapter 3: ¤ XX  gives
the equation:

\[ 
f(z)=\frac{1}{\pi}\iint_\Omega\,\frac{f(\zeta)\cdot \bar\partial(\rho)}
{z-\zeta}\cdot d\xi d\eta+
\frac{1}{\pi}\iint_\Omega \frac{\rho(\zeta)\cdot \phi(\zeta)}{z-\zeta}\cdot d\xi d\eta\tag{2}
\]
\medskip

\noindent
The Pompieu formula can
be extended a bit further.
Namely, assume only that $f$ from the start is a \emph{bounded}
Borel function. It can be  identified with an $L^1_{\text{loc}}$-function
which therefore has a distribution derivative
and if we again assume that $\bar\partial(f)=\phi$ for some
$L^1_{\text{loc}}$-function
$\phi$ then (2) still holds.
To be precise, we get a pointwise equality
at every  \emph{Lebesgue point} of $f$.

\medskip


\noindent
{\bf{0.4 The elliptic property of $\bar\partial$}}.
Let $f(x,y)\in L^1_{\text{Loc}}(\Omega)$
where $\Omega$  belongs to $\mathcal D(C^1)$.
Suppose  that
\[ 
\iint\, f\cdot \bar\partial(g)\cdot dxdy=0\tag{*}
\] 
hold for all 
text-functions $g(x,y)$ with compact support in
$\Omega$.
Then  one says that $\bar\partial(f)=0$
holds in the distribution sense. Here $\phi=0$ holds in (2) above
and using 
$\rho$\vvv functions in $C\uuu 0^\infty(\Omega)$
which are identically equal to 1  on arbitrary large compact subsets of
$\Omega$ we see  that
$f$ belongs to $\mathcal O(\Omega)$.
The remarkable fact is  that (*) therefore implies that the
$L^1_{\text{loc}}$-function $f$
\emph{automatically is analytic} in $\Omega$. 
If necessary
one  has only to  change its values on a null-set
which is  harmless since
two 
$L^1_{\text{loc}}$-functions are considered to be equal if they
coincide outside a null set.
A similar result is valid for the Laplacian, i.e. let
$f$ again be in 
$L^1_{\text{loc}}(\Omega)$
and suppose  that
\[ 
\iiint\, f\cdot \Delta(g)\cdot dxdy=0\tag{**}
\] 
holds for every test-function $g$ in $\Omega$. Then $f$
is a harmonic function in $\Omega$ which  entails that
it is a real-analytic function of the two real variables $x$ and $y$.
\medskip

\noindent
{\bf{Remark.}}
In a broader context  the two results
above hold
because 
the  differential operators
$\bar\partial$ and $\Delta$  are \emph{elliptic}.

\newpage


\noindent
{\bf{Exercise.}} Show that
\[
-\iint\,\bar\partial(g)\cdot \frac{1}{z}\cdot dxdxy=\pi\cdot g(0)
\] 
hold for every test function $g(x,y)$ which by the construction
of distribution derivatives
means that
\[
\bar\partial(\frac{1}{z})=\pi\cdot \delta_0\tag{*}
\]
It follows that
the $L^1$-density function $ \frac{1}{\pi\cdot z}$ 
is a \emph{fundamental solution} to the $\bar\partial$-operator.
For the Laplace operator we find a
fundamental solution  via the formula
\[
\Delta(g)(z)=\frac{1}{\pi}\cdot \iint \text{Log}\,|z-\zeta|
\cdot g(z+\zeta)\cdot d\xi d\eta\quad\colon\, g(x,y)\in C_0^\infty({\bf{C}})\tag{**}
\]

\noindent
{\bf{0.5 Riesz measures and positive  harmonic functions.}} 
Let $u(x,y)$ be a non-negative
harmonic function   defined in the open unit disc.
The mean-value property gives
\[
 u(0)=\frac{1}{2\pi}\,\int_0^{2\pi}\,u(re^{i\theta})\cdot d\theta
 \quad\text{for all}\quad 0<r<1
 \]
In general the $u$-function is unbounded and examples show that the radial
limits
$\lim_{r\to 1}\, u(re^{i\theta})$ can be
quite irregular. It may also occur that
these radial limits exist and are zero for all $\theta$-angles outside a null set on the 
periodic interval $[0,2\pi]$.
However, a consistent and unique limit exists in the
distribution sense. Namely,  there exists a unique 
non-negative Riesz measure $\mu$ on the unit circle 
whose total mass is $u(0)$ and

\[
\lim_{r\to 1}\, \frac{1}{2\pi}\,\int_0^{2\pi}\,g(\theta)\cdot u(re^{i\theta})\cdot d\theta
=\int_0^{2\pi}\,g(\theta)\cdot d\mu(\theta)\tag{*}
\] 
hold for every $2\pi$-periodic and continuous $g$-function.
Thus, "boundary values"   of $u$
expressed by
the equation (*).
Moreover,  Herglotz' formula implies that the  map which sends 
a positive harmonic function $u$
to the boundary measure $\mu$ is bijective. 
We can express as follows:
\medskip

\noindent
{\bf{0.5.1 Theorem.}}
\emph{There exists a 
one-to-one 
correspondence between the family of positive 
harmonic functions in $D$ 
and positive  Riesz measures on $T$.}




\bigskip

\noindent
\centerline{\bf{0.6 Cauchy problems.}}
\medskip

\noindent
A basic boundary value  problem for
a second order PDE-equation is to find a function $u(x,y)$
which for $x>0$ satisfies some PDE-equation, and
at $x=0$ the two boundary conditions:
\[ 
u(0,y)=\phi(y)\quad\text{and}\quad
\frac{\partial u}{\partial x}(0,y)=\psi(y) \tag{*}
\]
Here $\phi$ and $\psi$ are given functions of the real $y$-variable and
when $x>0$ the $u$-function solves a
PDE-equation of the  \emph{Riemann type}:

\[  
\frac{\partial^2 u}{\partial x^2}=
F\bigl(\frac{\partial^2 u}{\partial y^2},
\frac{\partial^2 u}{\partial x\partial y},
\frac{\partial u}{\partial x},
\frac{\partial u}{\partial y},u,x,y)\tag{**}
\]
Above $F$ is    a real valued polynomial of
seven variables or more generally some
analytic series. If $\phi$ and $\psi$ both are analytic 
functions of the $y$-variable 
the  Cauchy-Kovalevsky theorem gives
existence and uniqueness
of a solution $u(x,y)$  defined in some open
interval $0\leq x<\delta$ when the analytic Cauchy data is
given on some $y$-interval.
The study of
this boundary value problem when 
$\phi$ and $\psi$ no longer are analytic
leads to a  more involved  situation. This
was  demonstrated by  counter\vvv examples in the
article   [xx] by Sophie Kovalevsky from  1874.
See also the   [HS] by Harold Shapiro 
for an  account about the history of
the Cauchy-Kovalevsky theorem.
\medskip

\noindent
Conditions on non\vvv analytic  pairs $\phi,\psi$ in order that
the Cauchy problem has a solution 
were investigated  by Gevrey, Hadamard and Holmgren.
In his article [XX] from
1902 Hadamard considered  the case when   
$F$ is linear and elliptic. For example, 
let $F$ be  the Laplace operator. So here we
seek a harmonic function $u(x,y)$ defined in some open rectangle 
$\{0<x<\delta\}\,\cap\{a<y<b\}$
which satisfies (*).
Using Schwarz reflection principle and the
fundamental solution of $\Delta$ expressed by 
$\log\,|z|$,
Hadamard proved that the boundary
value problem has a solution
$u$ if and only if the function defined for $a<y<b$ by
\[
y\mapsto \phi(y)+\frac{1}{\pi}\int_a^b\,\text{log}\,\frac{1}{|y-s|}\cdot \psi(s)\cdot ds
\]
is real-analytic on the interval $(a,b)$.
Next,   consider
the
heat equation. So here  $u$ satisfies
\[
\frac{\partial^2u}{\partial x^2}=
\frac{\partial}{\partial y}\quad\colon  x>0
\]
In the  article 
\emph{Sur l'extension de la mŽthode d'integration
de Riemann} from 1904, Holmgren
showed that the boundary
value problem for the heat operator has
solutions if and only if $\phi$ and $\psi$
are related to each other by an equation
\[
\psi(y)=-\frac{1}{\sqrt{\pi}}\cdot\int_0^y\,
\frac{\phi'(u)}{\sqrt{y-u}}\cdot du+g((y)
\]
where the $g$-function
must be $C^\infty$ and   higher order
derivatives
satisfy:
\[
\bigl|g^{(n)}(y)\bigr|\leq M\cdot K^n\cdot (2n+1)!\quad\colon n=1,2,\ldots
\]
for some pair of constants $M$ and $K$.
These estimates on the higher order derivatives
are sufficiently relaxed  in order that
there exists $g$-functions with arbitrary small compact
supports, i.e. the class is not quasi-analytic.


\medskip

\noindent
{\bf{Remark.}}
The discussion above
shows that one should not always
restrict the  attention to
the analytic case. 
It would lead us too
far to discuss results 
concerned with  well-posedness of
boundary value problems in general.
Volume II in Lars Hšrmander's  text-book series
[Hšrmander I-IV]
contains a wealth of  results  together with
an extensive list of
references.
\medskip


\noindent
{\bf{0.6.1 Uniqueness problems.}}
Consider a $C^\infty$-function $u(x,y)$ 
which satisfies the heat equation in a strip domain
\[ 
B=\{ -\infty<x<\infty\}\times \{0<y<A\}
\]
The question arises if the vanishing of $u$ on some line 
$\{y=a\}\,\colon\, 0<a<A$ implies that
$u$ is identically zero in $B$.
It turns out that this is related to growth conditions on $u$.
A sufficient
and "almost necessary" condition for this uniquness
to be valid was proved by Erik Holmgren in the article
[1924:Arkiv]:

\medskip

\noindent
{\bf{0.6.2 Theorem.}}
\emph{Suppose there exists a constant $k$ such that}
\[
|u(x,y]|\leq e^{kx^2\cdot \log(e+|x|)}\quad\colon\, (x,y)\in B
\] 
\emph{Then, if $u(x,a)=0$ holds identically in $x$ for some
$0<a<A$,
it follows that
$u$ is identically zero.}
\medskip

\noindent
{\bf{Remark.}}
This result cannot be proved by
a mere abstract reasoning but relies on analytic function theory.
A complete investigation of the uniqeness problem for the heat equation  was
carried out by TŠcklund
in [TŠcklund].
\medskip

\noindent
{\bf{ 0.6.3 The analytic case.}}
This occurs when
$u$ satisfies an inequality
\[
 |u(x,y]|\leq e^{kx^2}\tag{i}
 \] 
A result due to Hadamard shows that (i) entials
that $u(x,y)$ is an analytic function with
 respect to $y$. Moreover, for each $0<a<A$
 one recovers $u$ from its values on $\{y=a\}$
 via the integral equation
\[ 
u(x,y)=
\frac{1}{2\sqrt{\pi (y-a)}}\int_{-\infty}^\infty\,
u(\xi,a)\cdot U(x-\xi,y-a)\, d\xi\tag{ii}
\]
where $U(x,y)$ is the function which is zero when $y\leq 0$ and 
\[
U(x,y)= e^{-x^2/y}\,\colon\, y>0
\]


\noindent
{\bf{Exercise.}}
Show that (i) implies that
that the integral in the right hand side of (ii) exists
and that the resulting function satisfies 
the heat equation. Moreover, it  coincides with $u$ on the line $\{y=a\}$.
\medskip

\noindent
{\bf{0.6.4 Non-analytic integral formulas.}}
Suppose that $u$ satisfies the heat equation in $B$
and that there exists a function $\epsilon(r)$ which tends to zero as
$r\to+\infty$ such that
\[
u(x,y)|\leq e^{\epsilon(x)\cdot x^2\cdot \log(e+|x|)}\tag{i}
\]
This is a stronger estimate than in  Theorem
0.6.2. Hence   uniquenss holds and
the question arises  if  $u$ 
is recaputred
by an  integral formua.
This time one cannot employ the $U$-kernel because
(i) does  not ensure that
the integral in the right hand side from (0.6.3)
converges.
However,  Beurling has found
such an integral formula 
using another kernel function
than $U$. See  ¤ xx for the   detailed construction.
























\bigskip

\centerline{\bf{0.7 Cauchy transforms and the logarithmic potential }}
\medskip

\noindent
Let $\mu$ be a Riesz measure on the unit interval $\{0\leq t\leq 1\}$.
With $z=x+iy$ 
we 
get the Cauchy transform
\[ 
\mathcal C_\mu(z)=\int_0^1\,\frac{d\mu(t)}{z-t}\tag{*}
\]
We shall learn that there exist the two boundary value distributions
\[ 
\mathcal C_\mu(x+i0)=\lim_{\epsilon\to 0}\, 
\mathcal C_\mu(x+i\epsilon)\quad\text{and}\quad
\mathcal C_\mu(x-i0)=\lim_{\epsilon\to 0}\, 
\mathcal C_\mu(x-i\epsilon)
\tag{1}
\]
For example, when $f(x)$ is a differentiable function
on the real $x$\vvv line with compact support
on some interval $[\vvv a,a]$
then
\[
\mathcal C_\mu(x+i0)(f)=
\lim\uuu{\epsilon\to 0}\,
\int\uuu 0^1\, \,\bigl[\int\uuu{\vvv a}^a\, \frac{f(x)\cdot dx}{x\vvv t+i\epsilon}\,\bigr]
\cdot d\mu(t)\tag{2}
\]
The fact that the limit above
exists will be demonstrated in
¤ 2.
Next, we have the equation 
\[
\mathcal C_\mu(x+i\epsilon)-\mathcal C_\mu(x-i\epsilon)=
-2i\cdot \int_0^1\, \frac{\epsilon}{(x-t)^2+\epsilon^ 2}\cdot d\mu(t)\tag{3}
\]
When $\epsilon>0$
the right hand side is a
function of $x$ which we  denote by
$\rho_\epsilon(x)$. If
$g(x)$ is a test-function on  the real $x$-line we get:
\[
\int\, \rho_\epsilon(x)\cdot g(x)\cdot dx=
2i\cdot \int_0^1\, \bigl[
\int\, \frac{\epsilon}{(x-t)^2+\epsilon^ 2}\cdot g(x) dx\bigr]
\cdot d\mu(t)\tag{4}
\]
The limit of the inner integral is found 
for each $t$ since 
$g$ is a test-function. More precisely the reader can  verify that
\[
\lim_{\epsilon\to 0}\int\, \frac{\epsilon}{(x-t)^2+\epsilon^ 2}\cdot g(x) dx=
\pi\cdot g(t)\tag{5}
\] 
where the convergence even holds uniformly with respect to $t$.
Hence 
\[
\lim\uuu{\epsilon\to 0} \int\, \rho_\epsilon(x)\cdot g(x)\cdot dx=2\pi i\cdot\int \, g(t)\cdot d\mu(t)\tag{6}
\]
In terms of distributions this gives the equality
\[
\mathcal C_\mu(x+i0)-
\mathcal C_\mu(x-i0)=2\pi i\cdot \mu\tag{**}
\]
Hence $\mu$ is expressed as a difference of two distributions
which arise via boundary values of analytic functions.
Next  we consider the sum
\[
\mathcal C_\mu(x+i\epsilon)+\mathcal C_\mu(x-i\epsilon)=
\int_0^1\, \frac{2(x-t)}{(x-t)^2+\epsilon^ 2}\cdot d\mu(t)\tag{7}
\]


\noindent
To get a limit formula  we introduce the function
\[ 
F(z)=\int_0^1\,\log(z-t)\cdot d\mu(t)\tag{8}
\]
Here $F$ is defined outside the real interval $[0,1]$ as 
a multi-valued analytic function. But its complex derivative is
single-valued and is given by
\[
 F'(z)= \mathcal C_\mu(z)\tag{9}
 \]
 At the same time
we
can choose single-valued branches of
$\log(z-t)$ in the the half-planes
$\mathfrak{Im}(z)>0$ and
$\mathfrak{Im}(z)<0$. If $0<t<1$ 
is fixed we get   the limit
formula 
\[
 \lim_{\epsilon\to 0}\, \bigl(\log(x+i\epsilon-t)+\log(x-i\epsilon-t)\bigr )=
 2\cdot \log[x-t|+ \pi\cdot i
\]
This yields   the limit formula:
\[
\lim_{\epsilon\to 0}\,  F(x+i\epsilon)+F(x-i\epsilon)=
2\cdot \int_0^1\, \log|x-t|\cdot d\mu (t)\cdot dt+i\pi\cdot \int_0^1\, d\mu(t)\tag{10}
\] 


\noindent
In XX we shall learn that the passage to boundary
value distributions commute
with
derivations. So (9) and (10) give the following equality of 
distributions on the real $x$\vvv line:
\[ 
\frac{1}{2}\bigl [\mathcal C_\mu(x+i0)+
\mathcal C_\mu(x-i0)\bigr]=\partial_x(f)\tag{***}
\] 
where the right hand side is the distribution derivative of function $f(x)$
defined by:
\[ 
f(x)=\int\uuu 0^1\,\log|x\vvv t|\cdot d\mu(t)\tag{11}
\]











\bigskip



\centerline {\bf{0.8 The Fourier transform.}}
\bigskip


\noindent
The fact that one can define the Fourier transform of a distribution
is very useful.
An example occurs in ¤ 9 where we consider the integral equation
\[ 
f*\phi(x)=\int_0^\infty\, f(x-y)\phi(y)dy=0
\]
Here $f$ is a function in $L^1({\bf{R}})$  and we seek
solutions $\phi$ in the space $L^\infty({\bf{R}})$, i.e.
bounded and Lebesgue measurable 
functions on the real line.
When the zeros of the  Fourier
transform $\widehat f(\xi)$ is a discrete set on the real $\xi$-line
we shall find all $\phi$-solutions. More precisely, every such
solution is the limit of functions
given by finite sums of the exponential functions
$\{ e_\alpha(y)=e^{i\alpha\cdot x}\}$ where $\{\alpha\}$ are the zeros 
of $\widehat f$.
This result is  expected but 
the systematic use of distribution fascilates the proof. One can also reverse
the consideration and start from some $\phi\in L^\infty({\bf{R}})$
and 
seek the set of all $f\in L^1({\bf{R}})$
such that $f*\phi=0$.
This leads to the  problem of \emph{spectral synthesis}
which is treated in ¤ 10, and again the notion of distributions
is helpful to  analyze this problem.
\medskip


\noindent
{\bf{0.8.1 Plancherel's theorem.}}
The construction of Fourier transforms of tempered distributions 
gives  in particular  the existence of  Fourier transforms for functions
in
$L^2({\bf{R}})$. This 
was actually achieved by Plancherel before the general notion of distributions
had appeared. More precisely, for every $A>0$ one defines the
operator $\mathcal P_A$ which sends
a square integrable function $f(x)$ to
\[ 
\mathcal P_A(f)(\xi)=\int_{-A}^A\, e^{-ix\xi}\cdot f(x)\cdot fx\tag{*}
\]
Plancherel proved that there exists
an $L^2$-function $g(\xi)$ on the real $\xi$-line
such that 
\[
\lim_{A\to\infty}\, ||g-\mathcal P_A(f)||_2=0\tag{**}
\]
In the context of distribution theory, $g$ is the Fourier transform of
the tempered distribution on the $x$-line expressed by the
$L^2$-density $f(x)$ and we  set $g=\widehat f$.
\medskip


\noindent
{\bf{0.8.2 Parseval's formula.}}
By $f\mapsto \widehat f$
one gets a linear isomorphism beween the $L^2$-spaces on the real
$x$- respectively the real $\xi$-line.
More precisely, introducing the inner product on these complex
Hilbert spaces one has the equality
\[ 
\langle\, f,g\,\rangle=\frac{1}{2\pi}\cdot \langle \,\widehat f,\widehat g\,\rangle
\quad\text{for all pairs}\quad f,g\in L^2({\bf{R}})\tag{***}
\]



\noindent
{\bf{Remark.}}
In the literature one sometimes normalises the Fourier transform of
$L^2$-functions to attain an isometry, i.e. one employs
$\frac{1}{\sqrt{2\pi}}\cdot \widehat f$ rather than $\widehat f$.
However, to fit everything with  the general construction of
Fourier transforms of tempered distributions we prefer to
define $\widehat f$ without this normalizing factor which entails that
the factor $\frac{1}{2\pi}$ appears in  Parseval's formula.
\medskip


\noindent
{\bf{0.8.3 Comment to Plancherel's theorem.}}
The Fourier transform of the characteristic function for
the interval $[-A,A]$ becomes 
\[ 
\rho_A(\xi)=
2\cdot \frac{\text{sin}(A\xi)}{\xi}\tag{1}
\]
Parseval's formula via a convolution gives
\[
\mathcal P_A(f)(\xi)=\frac{1}{\pi}\cdot
\int\, \rho_A(\eta)\cdot \widehat f(\xi+\eta)\cdot d\eta\tag{2}
\]


\noindent
The  limit in  (**)  with
$g=\widehat f$ can be  established using the
oscillatory behaviour of the $\rho_A$-function as $A\to+\infty$
and the continuity under translations of $L^2$-functions, i.e. one  uses that:
\[
\lim_{\delta\to 0}\, 
\int\, \bigl|\widehat f(\xi+\delta)-\widehat f(\xi)\bigr|^2\cdot d\xi=0\tag{3}
\]
\medskip

\noindent
{\bf{Remark.}}
In  harmonic
analysis one investigates the
rate of convergence in (**) as $A\to+\infty$ via
the behaviour of (3) as $\delta\to 0$. 
Such results are not covered by the mere passage to
weak limits of distributions.
An  example is
the 
\emph{Central Limit Theorem}
in probability theory. Here one can
easily establish
the existence of a  limit  expressed in
a distribution theoretic context. But 
further analysis is needed
to attain a more precise information about rate of convergence.
This occurs
in Lindeberg's 
Central Limit Theorem
where
on allows  "fat tails"  
during the passage to the limit of sums of
independent random variables. 
So the reader should be aware of the fact that
when one refers to  limits in spaces of distributions
they are  often taken
in a weak sense, while more
precise limit formulas   require additional  work.
The next example   illustrates this.

\bigskip

\noindent
{\bf{0.8.4 A pointwise limit formula.}}
Above the Fourier transform was considered on $L^2$-functions
and inversion formulas expressed in terms of
$L^2$-norms. When $f(x)$ from the start is a continuous function
which vanishes outside an interval one gets pointwise limit
formulas provided that the Dini condition 
holds below. Let us recall this classical result. For simplicity we assume
that $f(x)$ is an  even and continuous funtion
which is zero outside $[-1,1]$  and    impose:
\medskip

\noindent
{\bf{Dini's condition.}} \emph{It holds at $x=0$ when}
\[ 
\int_0^1\,\frac{|f(x)|}{x}\cdot dx<\infty\tag{*}
\]
From now on (*) is assumed. Since $f$ is even we have:
\[ 
\widehat f(\xi)=2\cdot\int_0^1\, \text{cos}(x\xi)\cdot f(x)\cdot dx
\]
With $A>0$ we set
\[
\gamma(A)=\frac{1}{2\pi}\int_{-A}^A\, \widehat f(\xi)\cdot d\xi\tag{1}
\]
Our aim is to show that Dini's condition implies that
\[ 
\lim_{A\to\infty}\,\gamma(A)=f(0)\tag{**}
\]

\medskip

\noindent
To prove (**) we first evaluate (1) which gives
\[ 
\gamma(A)=\frac{2}{\pi}\int_0^1\, \frac{\text{sin}(Ax)}{x}\cdot f(x)\cdot dx\tag{2}
\]
Next, we have the limit formula
\[
\lim_{A\to\infty}\frac{2}{\pi}\int_0^1\, \frac{\text{sin}(Ax)}{x}\cdot dx=
\frac{2}{\pi}\int_0^A\, \frac{\text{sin}(t)}{t}\cdot dt=1\tag{3}
\]
So in order to get
$\gamma(A)\to f(0)$ we can replace $f$ by $f(x)-f(0)$, i.e.
it suffices to show that $\gamma(A)\to 0$ when
$f(0)=0$ is assumed. To obtain this
we  fix some $0<\delta<1$
and put
\[
\gamma_\delta(A)=\frac{2}{\pi}\int_0^\delta\, \frac{\text{sin}(Ax)}{x}\cdot f(x)\cdot dx
\tag{4}
\]
\medskip


\noindent
Since $|\text{sin}(Ax)|\leq 1$
the triangle inequality gives
\[
\gamma_\delta(A)\leq\int_0^\delta\,\frac{|f(x)|}{x}\cdot dx<\infty\tag{5}
\] 
for all $A$ and every $\delta>0$. Dini's condition implies that the right
hand side tends to zero as $\delta\to 0$.
Next, we
set
\[ 
\gamma^\delta(A)= \frac{2}{\pi}\int_\delta^1\, \
\frac{\text{sin}(Ax)}{x}\cdot f(x)\cdot dx\tag{6}
\]
Here  $\frac{f(x)}{x}$ 
is continuous on $[\delta,1]$ and has therefore
a finite modulus of continuity, i.e. we get the function
\[
\omega_\delta(r)=\max_{\delta\leq x_1,x_2\leq 1}
\, \bigl|\frac{f(x_1)}{x_1}-\frac{f(x_2)}{x_2}\bigr|
\quad\text{where}\quad |x_1-x_2|\leq r\tag{7}
\]
With these notations one has  the inequality:
\[
\gamma^\delta(A)
\leq\frac{8\pi}{\pi}\cdot 
\omega_\delta(\frac{2\pi}{A})\tag{***}
\]
The verification is left to the reader as an exercise.
We remark only that the extra factor 4 replacing 2 by 8 comes form
$4=\int_0^{2\pi}\, |\text{sin}(t)|\cdot dt$.
Hence we have
\[ 
\gamma(A)\leq \gamma_\delta(A)+\frac{8\pi}{\pi}\cdot 
\omega_\delta(\frac{2\pi}{A})\tag{8}
\]
This holds for all pairs $\delta$ and $A$ and now we conclude
that
Dini's condition indeed gives
the  limit formula in (**).

\medskip

\noindent
{\bf{Remark.}}
Above $x=0$. More generally we can impose 
Dini's condition
for $f$ at an arbitrary point $a$, i.e. for every $a$ we set

\[
D_f(a)=\int\, \frac{|f(x)-f(a)|}{|x-a|}\cdot dx
\]
The results above show that whenever 
$D(a)<\infty$ one has a pointwise limit
\[
f(a)=\lim_{A\to\infty}\, \frac{1}{2\pi}\cdot
\int_{-A}^A\, e^{ia\xi}\cdot \widehat f(\xi)\cdot d\xi\tag{1}
\]
An example when this occurs is when $f(x)$ is Hšlder continuous of some order
$>0$.
\medskip

\noindent
{\bf{0.8.5 Carleson's Theorem.}}
With no other assumption than continuity on $f$
the question about  the pointwise limits in (*) 
was unclear
for more than a century. In 1965
Carleson proved that  pointwise limit in (*) holds almost everywhere
for an arbitrary continuous function $f(x)$ with a compact support.
This famous result from [Carleson] goes far beyond 
the scope of this book.
In the sequel we define  the Fourier transform of distributions where
the resulting inversion formula is taken in
the distribution theoretic sense which
means that  one can \emph{ignore} precise pointwise limits and so on.
In (1) from the Remark above  we are  content to assert that
the right hand side as  functions of $a$ converge to $f$ in the $L^2$-norm on
the real $a$-line.


\bigskip

\noindent
{\bf{0.8.6 A theorem by Carleman and Hardy.}}
A result about the existence of pointwise convergence 
goes as follows:
We are given some  $L^1$-function
$u(x)$ which is even and zero outside $[-1,1]$ and 
of class $C^2$ when $x\neq 0$. Moreover,  assume
that there exists a constant $C$ such that
\[
|u''(x)|\leq \frac{C}{x^2}\quad\colon\quad x\neq 0\tag{*}
\]
Since $u$ is an $L^1$-function we can construct the Fourier
series
\[ 
F_u(x)=\sum_{n=0}^ \infty \, A_n
\cdot \text{cos}\,nx\quad\text{where}\quad A_n=\frac{1}{2\pi}\int_0^{2\pi}\,
\text{cos}(n\xi)\cdot u(\xi)\cdot d\xi
\]
Since $u$ is a $C^2$-function when $x\neq 0$
the series converges uniformly to $u$ on
every interval $[\delta,1]$ when $0<\delta<1$.
There remains to analyze the situation at $x=0$.
The following result is due to Carleman and Hardy and
will be proved in ¤ 13:
  

\medskip

\noindent{\bf{0.8.7 Theorem.}} \emph{The series $\sum\, A_n$ converges
if and only if there exists the limit}

\[
 \lim_{x\to 0}\, u(x)=S_*
\]
\emph{and here  $S_*=\sum\,A_n$.}




\bigskip



\centerline {\bf{0.8.8 The central limit theorem.}}
\medskip


\noindent
Consider  a sequence  of
independent random variables
$\chi_1,\ldots,\chi_N$,
where
each individual variable has mean-value zero and 
a finite variance $\sigma_\nu$. The sum variable 
\[ 
S_N=
\frac{\chi_1+\ldots+\chi_N}{\sqrt{\sigma_1^2+\ldots+\sigma_N^2}}\tag{*}
\] 
has been normalised so that its variance is one.
In 1812
Simon Laplace stated
that
$\{S_N\}$ converges to the normal distribution
whose frequency function is
\[
\frac{1}{\sqrt{2\pi}}\cdot e^{-x^2/2}
\]
under the condition  that each individual variable yields a 
\emph{relatively small contribution}.
This is for example
valid in the sense of Laplace 
if 
there exists a constant $M$ such that
\[
\sigma_\nu\leq M\tag{1}
\]
hold for all $\nu$.
However, one must  assume a bit more than (1)
to get ensure  convergence of $\{S_N\}$ to the normal distribution.
The conclusive result
was established in 1920 by Lindeberg  who proved the convergence with
under an  extra 
hypothesis  that  tails of second order moments 
admit a certain  limit as $n\to\infty$.
 Lindeberg's theorem  is proved in
¤18. 
\medskip

\noindent
A crucial step in
the proof  of Lindeberg's theorem
is the 
inequality  (**) below. To motivate its relevance 
we consider two probability measures
$\mu$ and $\nu$
on the real line
expressing distributions of two random variables.
For a  pair of real numbers $a<b$
and a small $\delta>0$
there exists  a non-negative $C^2$-function $g_\delta(x)$ which is 
identically one on $[a,b]$ and  vanishes outside
$[a-\delta,b+\delta]$.
Elementary calculus shows that
$g_\delta$ can be constructed so that
the maximum norm of its second derivative is
bounded by
$\frac{2}{\delta^2}$. 
At the same time we have the Fourier transforms
$\widehat \mu$ and $\widehat\nu$.
With these notations, Parseval's formula gives
equality
\[ 
2\pi\cdot  \int\, g_\delta(x)\cdot [d\mu(x)-
d\nu(x)]=
\int\,\widehat g_\delta(\xi)\cdot(\widehat\mu(\xi)-\widehat\nu(\xi))\cdot d\xi\tag{2}
\]
Next, if $|\xi|\geq 1$
we have the inequality
\[
|\widehat g_\delta(\xi)|\leq \frac{1}{\xi^2}\cdot \int\, |g''_\delta(x)|\cdot dx\leq
\frac{4}{\delta\cdot \xi^2}
\]
where the last inequality follow since the support of $g''_\delta$ is contained in
a union of two $\delta$-intervals while is maximum norm is $\leq\frac{2}{\delta^2}$.
At the same time the maximum norm of
$\widehat\mu-\widehat\nu$ is bounded by 2. Moreover, the $L^2$-norm of
$\widehat g_\delta$ is $\sqrt{2\pi}$ times the $L^2$-norm of
$g_\delta$ and the latter is bounded by $\sqrt{b-a+2\delta}$.
So if $A\geq 1$ the triangle inequality together with the Cauchy-Schwarz inequality show that
the absolute value of the right hand side in (2) is majorised by
\[
\sqrt{(2\pi(b-a+2\delta)}\cdot
[\int_{-A}^A\,|\widehat\mu(\xi)-\widehat\nu(\xi)|^2\cdot d\xi]^{\frac{1}{2}}
+2\cdot\frac{4}{\delta}\cdot 2\cdot \int_A^\infty\,\frac{d\xi}{\xi^2}\tag{3}
\]



\noindent
Notice that the last term is $\frac{16}{A\cdot\delta}$ which for a given
$\delta>0$ can be made arbitrary small when $A>>1$. From this
one can derive limit formulas when one has an $L^2$-convergence of Fourier transforms of probability measures over
arbitrary large $\xi$-intervals. A variant of (3) is to get rid of
the factor
$\sqrt{(2\pi(b-a+2\delta)}$. Namely,
since the maximum norm of the
$g_\delta$-function is one one has  the majorisation
\[
\int_{-A}^A\,|\widehat\mu(\xi)-\widehat\nu(\xi)|\cdot d\xi+
\frac{16}{\delta\cdot A}\tag{4}
\]


\noindent {\bf{Example.}}
Let 
$\{\mu_N\}$ be the sequence of
probability measures expressing
distributions of the sum variables $\{S_N\}$ in (*) above.
Then (4) yields 
the Central Limit Formula if
if
\[ 
\lim_{N\to\infty}\,\int_{-A}^A\, |\widehat\mu_N(\xi)-e^{-\xi^2/2}|\cdot d\xi=0\tag{i}
\]
holds for every $A\geq 1$.
In 1733 de Moivre in 1733 proved the central limit theorem
when
$S_N$ is the sum of $N$ many Bernoulli variables which
with probability $1/2$ take the values
$+$ or $\vvv \frac{1}{\sqrt{N}}$.
Here
\[
\widehat \mu_N(\xi)=\bigl [\text{cos}(\frac{\xi}{\sqrt{N}})\bigr]^N\tag{ii}
\]
Regarding the Taylor series of the cosine function at
$\xi=0$ we get (i)
from Neper's limit formula
\[
\lim_{N\to\infty}\, (1-\frac{\xi^2}{2N})^N=e^{-\xi^2/2}\tag{3}
\]
\medskip


\noindent
{\bf{Remark.}}
De Moivre proved
actually the central limit theorem
when $S\uuu N$ is the sum of $N$ equally distributed random variables with
some finite probability distribution. The original
proof was based upon  
Stirling's formula and Wallis' formula for products of sine-functions
and has the extra merit that
the rate of convergence is estimated in a quite sharp manner.
The interested reader may  consult 
the literature
for
de Moivre's proof. See for example the elegant account
in
Carleman's text-book [Car: page  278-282]
where the proof gives a  precise upper bound
for the rate of convergence of $\{S_N\}$ to the normal distribution.






 

 






\bigskip







\centerline{\bf   0.9 Dirac's $\delta$-function
and plane waves}

\medskip

\noindent
A basic object in  distribution theory 
is Dirac's 
$\delta$-function which  for  $n\geq 1$
is 
the unit point mass at the origin of ${\bf{R}}^n$.
We restrict  the discussion to  
the case $n=2$ and mention only that similar
results hold more or less verbatim in dimension $\geq 3$.
By definition   $\delta_0$
evaluates  test functions $\phi(x,y)$ in ${\bf{R}}^2$ at the origin:
\[ 
\delta_0(\phi)=\phi(0)
\]
A   far more important 
fact  is   that $\delta_0$
is embedded in an analytic family which leads to 
\emph{plane wave decompositions}.
With $z=x+iy$ we  consider a parametrised 
family of functions:
\[
G_\lambda(z)= \frac{ 2\cdot |z|^\lambda}{2\pi\cdot
\Gamma(\lambda/2+1)}\quad\colon\quad z\in{\bf {C}}\quad\colon\,\,\lambda\in
{\bf{ C}}
\]
\medskip

\noindent
where $\Gamma$ is the usual   Gamma-function.
\medskip

\noindent
{\bf 0.9.1 The analytic continuation of $G_\lambda$.}
If $\mathfrak{Re}\,\lambda>0$ it is clear that $G_\lambda(z)$ is a 
continuous function
in ${\bf {C}}$ which  
yields a distribution on the underlying real $(x,y)$-space.
Moreover, this 
distribution valued  function is analytic as $\lambda$ varies in the right half plane
where the
complex derivative becomes:
\medskip
\[
\frac{d}{d\lambda} \bigl(G_\lambda(z)\bigr)=
\text{Log}\,|z|\cdot G_\lambda(z)-
\frac{ |z|^\lambda\cdot \Gamma'(\lambda/2+1)}
{2\pi\cdot
\Gamma(\lambda/2+1)^2}
\]
\bigskip

\noindent
It turns out that this distribution-valued function
extends to the whole complex $\lambda$-plane. 
\medskip

\noindent {\bf {0.9.2 Theorem}}
\emph{The distribution  valued function $G_\lambda$ extends to an entire function and at 
$\lambda=-2$ one has the equality $G_{-2}=\delta_0$.}
\medskip



\noindent 
We prove this in XXX.
 The fact that $G_\lambda$ is an entire function
becomes  useful
when we write out the integral formula:
\[ 
G_\lambda(x+iy)=
\frac{ 2}{2\pi\cdot
\Gamma(\lambda/2+1)}\cdot
\int_0^{2\pi}\, \bigl |\text{cos}(\theta)\cdot x+
\text{sin}(\theta)\cdot y\bigr|^\lambda\cdot d\theta\tag{*}
\]
Together with  Theorem  0.9.2 this    constitute the plane wave
decomposition of $\delta_0$ in dimension two.
\medskip

\noindent
{\bf{0.9.3 Fundamental solutions.}}
Using  (*) and Theorem 0.9.2 we shall    construct
fundamental solutions to 
elliptic PDE-operators of even order with constant coefficients:
\[ 
L(\partial)=
\sum_{j+k\leq 2m}\, c_{j,k}\cdot\partial_x^j\cdot\partial_y^k
\]
Here $m$ is a positive integers and
the $c$-coefficients  are  complex numbers and the elliptic property means that
the leading polynomial
\[
L^*(\theta)=\sum_{j+k=2m}\,
c_{j,k}
\cdot\text{cos}^j(\theta) \cdot
\text{sin}^k(\theta)\neq 0\quad\text{for all}\quad 0\leq \theta\leq 2\pi
\]


\noindent
To find  
a distribution $\mu_L$ such that
$L(\mu_L)=\delta_0$ we first 
construct  a certain
distribution-valued entire function
\[
\lambda\mapsto \mu_\lambda\tag{1}
\]
where $\mu\uuu L$
will be the constant term $\mu_{-2}$ at $\lambda=-2$.
To get   (1) one proceeds as follows:
Consider for each 
$0\leq\theta\leq 2\pi$
the ordinary differential operator of the single
real variable $s$:
\[
L_\theta(\frac{d}{ds})=
 \sum_{j+k\leq 2m}\, c_{j,k}\cdot
 \text{cos}^j(\theta)\cdot
 \text{sin}^k(\theta)
\cdot \bigl(\frac{d}{ds}\bigr)^{j+k}
\]
It has order $2m$ and  the elliptic property of $L(\partial)$
means that
\[
L_\theta(\frac{d}{ds})=
c_{2m}(\theta)\cdot (\frac{d}{ds})^{2m}+\ldots+c_0(\theta)
\quad\text{where}\quad
c_{2m}(\theta)\neq 0\quad\text{ for all}\quad  \theta
\]
Elementary ODE-theory  gives  for each fixed $0\leq\theta\leq2\pi$ 
and every $\lambda\in{\bf{C}}$ a unique $C^\infty$-function
$v_{\lambda,\theta}(s)$
on the real $s$-line such that
$(\frac{d}{ds})^{2m}(v_{\lambda,\theta})(0)=1$ and
\[
L_\theta(\frac{d}{ds})(v_{\lambda,\theta})=0\quad\text{where}\quad
(\frac{d}{ds})^j(v_{\lambda,\theta})(0)=0\,\,\, \colon\,\,0\leq j\leq 2m-1
\]

\noindent
Moreover, classical    formulas for solutions to 
inhomogeneous ODE-equations imply that the map:
\[
\lambda\mapsto v_{\lambda,\theta}
\]
is an entire function of
$\lambda$ with values in the space of $C^\infty$-functions on the $s$-line, and
at the same time 
$\theta\mapsto v_{\lambda,\theta}(s)$ is a real-analytic 
function of $\theta$ for every pair $(\lambda,s)$.
Define the functions

\[
V_{\lambda,\theta}(z)= v_{\lambda,\theta}\bigl(
\text{cos}(\theta)\cdot x+
\text{sin}(\theta)\cdot y\bigr )
\]

\noindent
In ¤ XX we show that
\[ 
L(\partial)\bigl(V_{\lambda,\theta}\bigr)(z)=
\frac{1}{\Gamma(\lambda/2+1)}\cdot \bigl|
\text{cos}(\theta)\cdot x+
\text{sin}(\theta)\cdot y\bigr |^\lambda\tag{1}
\]
\medskip

\noindent
Next, let us put  
\[ 
u_\lambda(z)=\frac{1}{2\pi}\cdot \int_0^{2\pi}\, 
V_{\lambda,\theta}(z)\cdot d\theta
\]
Now $\lambda\to u_\lambda$ is an entire distribution-valued function.
Using (1)  and the plane wave decomposition (*)
the reader can  verify that when $\lambda=-2$ then
the constant term $u_{-2}$ gives a fundamental solution to $L(\partial)$.






\newpage
















\centerline {\bf  1. Tempered distributions on the real line.}
\bigskip



\noindent
The Schwartz space $\mathcal S$
of rapidly decreasing $C^\infty$-functions on the real line
is equipped with a topology defined by the sequence of  norms
$\{\rho_k\}_0^\infty$ where
\[
\rho_k(f)=\max_{x\in{\bf{R}}}\,\, \, (1+|x|)^k\cdot
\, \sum_{\nu=0}^{\nu=k}\, |f^{(\nu)}(x)|
\]
The distance function on
$\mathcal S$ defined by
\[ 
d(f,g)=\sum_{k=1}^\infty\, 2^{-k}\cdot
\frac{\rho_k(f-g)}{1+\rho_k(f-g)}
\]
One verifies  that this metric above is complete,
i.e. $\mathcal S$ is a Frechet space. 

\medskip

\noindent 
{\bf{1.1 Exercise.}}
Prove that there exists a constant $C$ such that
the following hold for each pair of integers
$0\leq \nu<k$ and every $f\in\mathcal S$.
\[
\max_x\,[1+|x|)^\nu\cdot |f^{(\nu)}(x)|
\leq C^{k-\nu}\cdot 
\max_x\,[1+|x|)^k\cdot |f^{(k)}(x)|
\]
\medskip

\noindent 
{\bf{1.2 An isomorphism.}}
We have the bicontinuous map from the unit circle with the point 1 removed onto the
real $x$-axis defined by
\[
e^{i\theta}\mapsto 
i\cdot\frac{e^{i\theta}+1}{e^{i\theta}-1}
\quad \colon 0<\theta<2\pi
\]
If $f(x)\in\mathcal S$ we define the function
\[ 
f_*(\theta)= f(i\cdot\frac{e^{i\theta}+1}{e^{i\theta}-1})
\]
The rapid decay of $f$ as $|x|\to +\infty$ implies that
$f_*$ extends to a $C^\infty$-function on the whole unit circle
which is flat at 1, i.e. the derivatives
$f^{\nu}(1)=0$ for all $\nu$, or equivalently
\[ 
\lim_{\theta\to 0}\, \frac{f(e^{i\theta})}{(e^{i\theta}-1)^n}=0
\] 
for every positive integer $n$.
Denote by  $C^\infty_*(T)$  the class of $C^\infty$-functions on $T$ which
are flat at $\theta=0$.
The constructions  above gives a bijection 
\[ 
\mathcal S\simeq C^\infty_*(T)
\]
which in addition  is  an isomorphism  of Frechet spaces.
More precisely, here
$C_*^\infty(T)$ is regarded as a closed subspace of
the Frechet space $C^\infty(T)$.





\medskip

\noindent
{\bf{1.3 The dual space $\mathcal S^*$}}.
Exercise 1.1 shows that
to every continuous linear functional 
$\gamma$ on
$\mathcal S$ there exists some pair of  integers $N,M\geq 0$ and a 
Riesz measure $\mu$ such that
\[
\gamma(f)=\int f^{(N)}(x)\cdot d\mu_N(x)
\quad\text{where}\quad \int\, [1+|x|)^{-M}\cdot |d\mu_N(x)|<\infty
\tag{*}
 \] 




\medskip

\noindent{\bf{Remark.}}
The integer $N$ and   the associated Riesz measure $\mu$ are
not uniquely
determined by $\gamma$.
For example, let $\delta_0$ be the Dirac distribution at $x=0$.
It can also be defined by
\[
\delta_0(f)=\int_0^\infty\, f'(x)\, dx
\]
Another  caseis the
distribution $\gamma$ defined by a principal value:

\[ \gamma(f)=\lim_{\epsilon\to 0}\,\text{PV}\, \int_{-\infty}^\infty
\, \frac{f(x)\cdot dx}{x}
\]
Here the reader may verify that
\[ 
\gamma(f)=\int_{-\infty}^\infty\, \text{log}\,|x|\cdot f'(x)\, dx
\]
Thus, with $N=1$ we get the locally integrable function
$\text{log}\,|x|$ and notice that we can take $M=2$ above, i.e. the integral
\[ 
\int\, \bigl|\log|x|\,\bigr |\cdot (1+|x|)^{-2}dx<\infty
\]





\bigskip








\centerline {\bf 1.4 The Fourier transform on $\mathcal S$.}
\medskip

\noindent
If $f\in\mathcal S$ its Fourier transform is defined by
\[ 
\widehat f(\xi)=
\int\, e^{-ix\xi}\cdot f(x)\cdot dx
\]
Since $f(x)$  is rapidly decreasing
we can differentiate with respect to $\xi$
and obtain
\[ 
\partial_\xi^k(\hat f)=
\int\, (-ix)^k\cdot e^{-ix\xi}\cdot f(x)\cdot dx\quad\colon\,\,\, k\geq 1
\]
Next, partial integration with respect to $x$ gives
\[
i\cdot \xi\cdot \hat f(\xi)=\int\, e^{-ix\xi}\cdot f'(x)\cdot dx
\]
Denote by  $\mathcal F$ the Fourier operator from
$\mathcal S$ on the $x$-line to the
corresponding $\mathcal S$-space on the $\xi$-line. Then 
the formulas above can be expressed as  follows:
\medskip

\noindent
{\bf{1.4.1 Proposition.}}
\emph{The following two interchange formulas hold:}
\[ 
-i\partial_\xi\circ\mathcal F=\mathcal F\circ x\quad\colon\quad
i\xi\circ\mathcal F=\mathcal F\circ\partial_x\tag{ii}
\]
\medskip

\noindent 
{\bf{1.4.2 Fourier's inversion formula.}}
\emph{Let $f(x)\in \mathcal S$ and
set}
\[ 
F(x)=\frac{1}{2\pi}\cdot\int\, e^{ix\xi}\cdot \widehat f(\xi)\cdot d\xi
\]
\emph{Then one has the equality}
\[ 
f(x)= F(x)\tag{*}
\]


\noindent
\emph{Proof}.
First we establish the equality  when $x=0$. 
Notice that $f\mapsto F(0)$ is a linear functional on
$\mathcal S$.
Next,  a function $f\in \mathcal S$ such that $f(0)=0$ can be divided by $x$, i.e.
$f=x\cdot\phi(x)$ with
$\phi\in\mathcal S$.
When this holds we have
\[ 
\widehat f= -\partial_\xi(\widehat\phi)\tag{i}
\]
The Fundamental Theorem of Calculus gives
\[ 
\int_{-\infty}^\infty\,
\partial_\xi(g)\cdot d\xi=0
\] 
for all 
$g(\xi)\in\mathcal S$.
Applied to $\widehat\phi$ and using (i) we conclude that
\[ 
f(0)=0\implies F(0)=0
\]
But then the linear functional on the vector space
$\mathcal S$ defined by $f\mapsto f(0)$
must be a constant times
the functional $f\mapsto f(0)$.
Hence there exists   a constant $c$ such that
\[
f(0)=c\cdot \int\, \widehat f(\xi)\cdot d\xi
\]
There remains to determine $c$.
For this purpose we choose the special function
\[ 
f(x)= e^{-x^2/2}
\]
A verification which is left to the reader yields
\[ 
\widehat f(\xi)=
2\pi\cdot e^{-\xi^2/2}
\]
From this we deduce that $c=\frac{1}{2\pi}$.
\medskip

\noindent
\emph{The general case.}
With a fixed real number $a$ 
and $f\in\mathcal S$ we set
\[ 
f_a(x)= f(x+a)
\]
It follows that
\[ 
f(a)= f_a(0)=
\frac{1}{2\pi}\, \int\, \widehat f_a(\xi)\cdot d\xi
\]
Next, notice that a variable substitution gives:

\[
\hat f_a(\xi)=
\int\, f(x+a)\cdot e^{-ix\xi}\cdot dx=
e^{ia\xi}\int\, f(x)\cdot e^{-ix\xi}\cdot dx=
e^{ia\xi}\cdot \hat f(\xi)
\]
From this we get the equality
\[
f(a)=\frac{1}{2\pi}\, \int\, e^{ia\xi}\widehat f_a(\xi)\cdot d\xi
\] 
Since $a$ is an arbitrary real number we have proved
Fourier's inversion formula.
\medskip

\noindent
\bigskip

\noindent
{\bf{Exercise.}}
If $n\geq 2$ we define the Schwarz class of rapidly decreasing
$C^\infty$-functions in
${\bf{R}}^n$.
The Fourier transform is defined by
\[ 
\widehat f(\xi)=\int\, e^{-i\langle \xi,x\rangle}\cdot f(x)dx
\] 
where the integration now is over
${\bf{R}}^n$.
Fourier's inversion formula in dimension 
$n\geq 2$ 
amounts to show that
\[
f(0)=\frac{1}{(2\pi)^n}\cdot
\int\,\widehat f(\xi)\cdot d\xi
\]
This formula can be proved via the fundamental theorem of 
calculus by an induction over $n$.
Let us give the details  when $n=2$ where $(x,y)$ are the coordinates in
${\bf{R}}^2$.
Let $f(x,y)$ be given in $\mathcal S({\bf{R}}^2)$. Define the partial Fourier transform
\[ 
f^*(\xi,y)= \int\, e^{-ix\xi}f(x,y)\,dx
\]
With $\xi$ kept fixed we notice that the Fourier transform of the function 
$y\mapsto f^*(\xi,y)$ is equal to $\hat f(\xi,\eta)$.
The 1-dimensional case applied to the $y$-variable gives 
for every $\xi$:
\[ 
f^*(\xi,0)=\frac{1}{2\pi}\int\, \widehat f(\xi,\eta)\, d\eta\tag{i}
\]
Next, the 1-variable case is also applied to the $x$-variable which gives
\[
f(0,0)=\frac{1}{2\pi}\int f^*(\xi,0)d\xi\tag{ii}
\]
Now (i-ii) give the required formula
\[
f(0,0)=\frac{1}{(2\pi)^2}\iint \widehat f(\xi,\eta)\, d\xi d\eta
\]

\newpage

\centerline{\bf 1.5 The Fourier transform 
of temperate distributions.}
\medskip

\noindent
Let  $\gamma\in\mathcal S^*$ be given. Since the Fourier transform on
$\mathcal S$ is bijective and bi-continuous with respect to the Frechet metric
there exists a unique  tempered distribution $\widehat\gamma$
on the real $\xi$-line defined on functions
$g(\xi)\in\mathcal S$
by:
\[ 
\widehat\gamma(g)=\gamma( g_*)\quad\colon\quad
g_*(x)= \int\, e^{-ix\xi} g(\xi)d\xi\quad\colon\quad
\tag{*}
\]

\medskip

\noindent
{\bf Remark.}
Let 
$f(x)\in \mathcal S$ and denote by 
$\gamma\uuu f$ the  distribution
defined by the density $f(x)dx$. Then  (*) 
gives
\[
\widehat\gamma\uuu f(g)=
\iint\, f(x)\cdot e^{-ix\xi}g(\xi)\, dxd\xi=\int\, \hat f(\xi)\cdot g(\xi)\, d\xi
\]

\medskip

\noindent
Thus, under the inclusion $\mathcal S\cdot dx\subset\mathcal S^*$, the construction
of the Fourier transform of functions in
$\mathcal S$ extend to
temperate distributions via (*).
\medskip


\noindent
{\bf{1.5.1 The Fourier transform of $H\uuu +$.}}
On the real $x$-line we have the Heaviside distribution $H\uuu +$
defined by the density
1 when $x\geq 0$ and zero if $x<0$. To find its Fourier transform
we shall perform certain limits.
To begin with, for every large real number $N$
we have the distribution on the $x$\vvv line defined by
\[
\mu\uuu N(f)= \int\uuu 0^N\, f(x)\cdot dx
\]
Its Fourier transform becomes
\[
\widehat \mu\uuu N(\xi)=\int\uuu 0^N\, e^{\vvv ix\xi}\cdot dx
=\frac{1\vvv e^{\vvv iN\xi}}{i\xi}
\]
It is clear that
\[ \lim\uuu{N\to\infty}\, \mu\uuu N(f)=
H\uuu +(f)
\] 
hold for every $f\in \mathcal S$.
It follows that $\{\widehat\mu\uuu N\}$ converges weakly
to $\widehat H_+$, i.e.
for each $g(\xi)\in\mathcal S$ one has
\[ 
\widehat H_+(g)= \lim\uuu{N\to\infty}
\, \int\uuu{\vvv \infty}^\infty
\frac{1\vvv e^{\vvv iN\xi}}{i\xi}\cdot g(\xi)\cdot d\xi\tag{ii}
\]
We can also find $\widehat H\uuu +$ by other limit
formulas.
Namely, if $\epsilon>0$ we define 
the distribution $\gamma_\epsilon$ on the $x$\vvv line by
\[ 
\gamma_\epsilon(f)= 
\int_0^\infty\,
e^{-\epsilon x}f(x) dx
\]
Here we find that
\[ 
\widehat\gamma_\epsilon(\xi)=
\int_0^\infty\,
e^{-\epsilon x-i\xi x}dx=\frac{1}{\epsilon+i\xi}
\]
This gives the limit formula
\[ 
\widehat H\uuu +(g)=
\lim_{\epsilon\to 0} 
\int\, \frac{g(\xi)\cdot d\xi}{i\xi+\epsilon}\tag{ii}
\]
\medskip

\noindent
Hence  $\widehat H\uuu +$
can be found by different limit formulas.
Both (i) and (ii) are useful.

\bigskip

\noindent
{\bf{1.5.2 A passage to the unit circle.}}
in ¤ X we identfied $\mathcal S$ with
$C_*^\infty(T)$.
The Hahn-bansch theorem implies that
every
$\mu\in \mathcal S^*$ corresponds to a distribution
$\gamma$ on the unit circle whose restriction to
$C_*^\infty(T)$ represents $\mu$ via the topological isomorphism
in (xx).
Here $\gamma$Êis  determined up to
those distributions on $T$
which vanish identically
on $C^\infty_*(T)$.
It is clear that evety such distribution $\gamma$
on $T$ is supported
by the singleton set $\{1\}$ and is therefore a finite sum
of derivatives of the Dirac measure at this point which means that
their periodic Fourier coefficients are finite ${\bf{C}}$-linear
sums 
\[ 
\widehat\gamma(n)=\sum_{\nu=0}^{\nu=k}\,
a_\nu\cdot i^\nu\cdot n^\nu
\]
where $\{a_\nu\}$ are complex numbers.
Thus, if $\text{Temp}({\bf{Z}})$ denotes the 
linear space of all complex sequences $\{c_n\}$ with moderate growth
then one has an isomorphism of vector spaces:
\[ 
\mathcal S^*\simeq\frac{\text{Temp}({\bf{Z}})}{\mathcal P}
\]
where $\mathcal P$ is the subspace of polynomial sequences as
described above.
It leads to some rather interesting constructions.
Consider for example the subspace 
$c_+({\bf{Z}})$
of sequences $\{c_n\}$ where $c_n=0$ for every $n<0$.
It has empty intersection with
$\mathcal P$ and can therefore be identified with
a subspace of $\mathcal S^*$.
Every sequence $\{c_n\}$ in 
$c_+({\bf{Z}})$ gives the analytic function in the unit disc
$\{|w|<1\}$:
\[
g(w)=\sum\,c_nw^n
\]
One has the conformal mapping
where
\[ 
w= \frac{z-i}{z+i}
\]
from the upper half-plane $\mathfrak{Im}\, z>0$ onto the unit $w$-disc.
We find the analytic function $G_+(z)$ in the upper half-plane where
\[
G_+( z)= g(\frac{z-i}{z+i})
\]
Now one verifies that $G_+$ satisfies the growth condition from (XX) 
which yields the tempered
distribution ${\bf{b}}G_+$
on the real $x$-line and  corresponds to
the distributionon $T$ defined by the sequence 
$\{c_n\}$. So in this way it is 
possible to
transform the  study of tempered distributions on the real line
to situations on the unit circle
where the Nevannlina-Jensen class of analytic functions
in the unit disc and the corrspoindfing class in the exterior disc
together
exhibit all termpered distributions on the real line.






 
 



\newpage


\centerline{\bf{1.6   Tempered distributions in
${\bf{R}}^2$}}
\medskip

\noindent
One has 
the Schwartz space $\mathcal S$ of rapidly 
decreasing $C^\infty$-functions $g(x,y)$ of the two real variables 
$x$ and $y$.
The dual $\mathcal S^*$ consists of tempered distributions
and every such distribution $\gamma$ is
represented as a finite sum
\[ 
\gamma(f)=\iint_{{\bf{R}}^2}\,
g^{(\alpha)}(x,y)\cdot d\mu_\alpha(x,y)
\] 
where  $\{\mu_\alpha\}$ is a finite family of Riesz measures and
$\alpha$ are multi-indices which yield higher order 
derivatives of $g$. Finally, there exists an
integer $N$ such that
\[
\iint_{{\bf{R}}^2}\,(1+x^2+y^2)^N\cdot 
|d\mu_\alpha(x,y)|<\infty
\]
hold for every $\alpha$.
Fourier's inversion formula was  established in
¤ 1.4.1 and leads to the construction
of Fourier transform of tempered distributions.
Let us give some examples.
\medskip

\noindent
Identifying ${\bf{R}}^2$ with ${\bf{C}}$
we  have  the first order differential operators
$\partial=\frac{1}{2}[\partial_x-i\partial_y)$ and
$\bar \partial=\frac{1}{2}[\partial_x+i\partial_y)$.
The locally integrable function
$g=\frac{1}{z}$ yields a tempered distribution. 
The interchange rules under  Fourier transforms give
\[
\partial_\xi(\hat g)=-i\cdot \widehat{xg}(\xi,\eta)
\quad\text{and}\quad
\partial_\eta(\hat g)=-i\cdot \widehat{yg}(\xi,\eta)\tag{i}
\]
In the $(\xi,\eta)$-space
we have the complex variable $\zeta=\xi+i\eta$ and 
$\bar\partial_\zeta=\frac{1}{2}(\partial_\xi+i\partial_\eta)$.
We can express (i) by the equation:
\[
i\cdot \bar\partial_\zeta(\hat g)=\text{The Fourier transform of}\quad
(x+iy)g=1\tag{ii}
\]
\medskip


\noindent
Next, the Fourier transform of the identity function 1 in the
$(x,y)$-space becomes 
\[ 
\widehat {1}=\delta_0
\] 
where $\delta_0$ is the Dirac measure at the origin in the
$(\xi,\eta)$-space. 
Hence (ii) means that
\[ 
\bar\partial_\zeta(\widehat{g})= \frac{1}{i}\cdot \delta_0
\]
in particular $\widehat g$ is 
satisfies the Cacuhy\vvv Riemann equation outside
the origin so we expect that it is given
by a holomorphic density in the punctured complex
$\zeta$\vvv plane.
This is indeed true and the precise formula is:
\medskip

\noindent
{\bf{1.6.1 Theorem.}} \emph{The Fourier transform of}
$\frac{1}{x+iy}$ \emph{is equal to}
$\frac{2\pi i}{\zeta}$.
\medskip

\noindent
{\bf{1.6.2 Exercise.}} Prove the formula above. 

















\newpage



\centerline{\bf\large 2. Boundary values of analytic functions}


\bigskip

\noindent
{\bf Introduction.} We shall  construct boundary values of analytic functions
$f(z)$ defined in an open rectangle 
$\{-a<x<a\quad\colon\, 0<y<b\}$.
One says that $f$ has moderate  growth
when the real axis is approached if there exists some integer $N\geq 0$
and a constant $C$ such that
\[ 
|f(x+iy)|\leq C\cdot y^{-N}\tag{*}
\]
When (*) holds we  prove  
that $f$ has a boundary value given by a distribution
${\bf{b}} (f)$ defined on the interval $(a,b)$
of the real $x$-axis.
Moreover,  the map $f\mapsto {\bf{b}}(f)$ commutes
with derivations, i.e.
if $\partial_z=d/dz$ while $\partial_x$ is the derivation on
the real $x$-axis then
\[
{\bf{b}}(\partial_z(f))=\partial_x( {\bf{b}}(f))
\] 


\noindent
where the right hand side is a distribution derivative.
\medskip







\noindent
{\bf{2.1 The  construction.}}
Let $f(z)$ be analytic in a rectangle 
\[ \square=\{(x+iy\colon\quad -A<x<A\quad\colon\,0<y< B\}
\]
where $A,B$ are positive constants and
\medskip
\[ 
|f(x+iy)|\leq C\cdot y^{-N}\quad\colon\quad x+iy\in\square
\] 
where $C$ is a constant and $N$ some non\vvv negative integer.
Under this condition  $f$ has a boundary value
as $y\to 0$  expressed by a distribution acting on test-functions
$g(x)$ with compact support in $(0,A)$.
To achieve this we  extend a test-function $g(x)$ in such a way that 
$\bar\partial$-derivatives are small when $y\to 0$.


\bigskip

\noindent {\bf 2.2 Small $\bar\partial$-extensions}
Given a positive integer $N$ and some $g(x)\in C_0^\infty(-A,A)$
we get  a function $G_N(x+iy)$:
\[
G_N(x+iy)=g(x)+\sum_{\nu=1}^{\nu=N}
\,i^\nu\cdot  \frac{g^{(\nu)}(x)\cdot y^\nu}{\nu\,!} 
\]

\noindent
Since $\bar\partial=\frac{1}{2}[\partial_x+i\partial_y]$
one has the equality
\[ 
2\cdot \bar\partial(G_N)(x+iy)=
\] 
\[
\sum_{\nu=0}^N\, i^\nu\cdot \frac{g^{(\nu+1}(x)\cdot y^\nu}{\nu\,!}
\sum_{\nu=1}^N\, i^{\nu+1}\cdot
 \frac{g^{(\nu}(x)\cdot y^{\nu-1}}{(\nu-1)\,!}=
i^N\cdot \frac{g^{(N+1)}(x)\cdot y^N}{N\,!}\tag{*}
\]
\bigskip

\noindent
{\bf 2.3 The distribution $\mathfrak{b}(f)$.}
Let $f(z)$ satisfy the growth condition  above.
Given $g\in C_0^\infty(-A,A)$
we construct $G_N$. With
$0<\epsilon<b<B$ 
we apply Stokes formula and obtain:
\[
\int_{-A}^A\,G_N(x+i\epsilon)f(x+i\epsilon) dx=
\]
\[
\int_{-A}^A\,G_N(x+ib)f(x+ib) dx+
2i\cdot \int_0^A\int_\epsilon^b \bar\partial(G_N)(x+iy)f(x+iy)dxdy
\]
\medskip

\noindent The growth condition on $f$ and (*) imply
that the absolute value of the double integral is majorized by
\[
\frac{Cb}{N\,!}\cdot\int_0^A\,|g^{(N+1)}(x)|\cdot dx\tag{**}
\]

\noindent 
Since this  holds for any $\epsilon>0$
we can pass to the limit $\epsilon\to 0$ 
while the absolutely integrable double integral 
is computed. Hence we have proved
\medskip


\noindent 
{\bf 2.4 Proposition} \emph{There exists the limit}
\[ \lim_{\epsilon\to 0}\,
\int_{-A}^A\,G_N(x+i\epsilon)f(x+i\epsilon) dx
\] 

\noindent \emph{Moreover, the limit is equal to}
\[
\int_{-A}^A\,G_N(x+ib)f(x+ib) dx+
2i\cdot \int_{-A}^A\int_0^b \bar\partial(G_N)(x+iy)f(x+iy)dxdy
\quad\colon\quad 0<b< B
\] 
\emph{where  the absolute value of the double integral
is majorized by (**) above.}
\bigskip

\noindent {\bf 2.5 Definition.}
\emph{The limit integrals above  yield a distribution
on the open interval $(-A,A)$.
It is denoted by
$\mathfrak{b}(f)$ and called the boundary value distribution of $f$.}
\bigskip

\noindent {\bf 2.6 Use of primitive functions.}
Starting with $f\in\mathcal O(\square)$
we  construct primitive functions which
behave better as we approach the real $x$-axis.
For example, fix a point $p=ia$ with $a>0$ and set
\[ 
F(z)=\int_{ia}^z\, f(\zeta)d\zeta
\]
If $|f(x+iy)|\leq C\cdot y^{-N}$ for some
$N\geq 2$ we get
$|F(i+iy)\leq C_1\cdot y^{-N+1}$
for another constant $C_1$. In the case $N=1$
we get $[F(x+iy)|\leq C_1\cdot\text{Log}\,\frac{1}{|y|}$.
So by choosing $N$ sufficiently large and
taking the $N$:th order primitive $F_N$ of $f$
it has even continuous boundary values and 
$\mathfrak{b}(F_N)$ is just the density function $F_N(x)$.
Then one can take  distribution derivatives on the
real $x$-line and get
\[ 
\mathfrak{b}(f)=
\frac{d^N}{dx^N}(\mathfrak{b}(F_N(x))
\]
\medskip

\noindent 
So this is an alternative procedure to
define $\mathfrak{b}(f)$ without 
small $\bar\partial$-extensions.
Both methods have their advantage
depending on the situation at hand.
\bigskip


\noindent
{\bf{2.7 Example.}} Let $f(z)=\log\,z$ where the single valued branch is chosen 
in $\mathfrak{Im}(z)>0$
so that the argument is between 0 and $\pi$.
Then
$\mathfrak{b}(f)$
is the distribution defined by
the density
$\log\,x$ when $x>0$ and if $x<0$ by
\[ 
\log\,|x|+\pi\cdot i
\]
The complex derivative of $f$ is $\frac{1}{z}$.
Here one finds that
$\mathfrak{b}(\frac{1}{z})$ is the distribution defined
by
\[ 
g\mapsto  \lim_{\epsilon|\to 0}\,
\int\frac{g(x)dx}{x+i\epsilon}=
\int\frac{(g(x)-g(0))\cdot dx}{x}+\pi i\cdot g(0)\tag{1}
\]

\noindent
It is an instructive exercise to
take the distribution derivative of
$\mathfrak{b}(\log\,z)$
and verify that it is equal to the distribution (1).

\medskip




\centerline{\bf { The reflection principle.}}
\medskip



\noindent
Let 
\[ 
\square_-=\{(x+iy\colon\quad 0<x<A\quad\colon\,-B<y< 0\}
\]
be an opposed rectangle in the lower half-plane and
let $h\in\mathcal O( \square_-)$ satisfy the moderate growth
condition. We construct $\mathfrak{b}(h)$ in  the same way
as above.
\bigskip

\noindent {\bf 2.8 Theorem.}
\emph{Let $f\in\mathcal O( \square)$
and $h\in\mathcal O( \square_-)$ be a pair such that
$\mathfrak{b}(f)=\mathfrak{b}(h)$ holds as distributions. Then they
are analytic continuations of each other, i.e. there
exists an analytic function $\Phi$ defined in
$\{-B<y<B\colon\, -A<x<A\}$
such that $\Phi=f$ in $\square$ and $\Phi=h$ in}
$\square_-$.
\bigskip

\noindent 
\emph{Proof.}
We choose a large $N$ so that
th $N$:th order primitive functions
$F\uuu N$ and $H\uuu N$
both extend continuously to the real
$x$\vvv axis.
The equality $\mathfrak{b}(f)=\mathfrak{b}(h)$ entails that
\[
\frac{d^N}{dx^N}( \mathfrak{b}(F\uuu N)\vvv  \mathfrak{b}(H\uuu N)
=0
\]
Now a distribution on the real $x$\vvv line whose $N$:th order derivative is zero is a polynomial $p(x)$ of degree $\leq N\vvv 1$.
So the pair of continuous functions
$F(x)$ and $H(x)$ satisfy
\[
 H(x)= F(x)+p(x)
\]
Hence the analytic functions $F(z)+p(z)$ and $H(z)$ have a common continuous 
boundary
value function so by the Schwarz reflection principle they are analytic continuations
of each other.
Let $G(z)$ be the resulting analytic function defined in
the open  domain where $\vvv B <y<B$ now holds.
Its $N$:th order complex derivative is also analytic in this domain
and  equal to $f$ in $\square \uuu +$ and to $h$ in
$\square\uuu \vvv$. This proves Theorem 2.8 with
$\Phi= G^{(N)}$.



\newpage

\centerline{\bf\large 3. Fourier-Carleman transforms}
\bigskip

\noindent
{\bf Introduction.}
The Fourier transform can be 
obtained from a pair of analytic functions
defined in the upper - resp. the lower half plane.
The idea is that a Fourier transform 
\[ 
\widehat g(\xi)= \int\, e^{-i x\xi}\cdot g(x)\,dx
\]
becomes a sum when we integrate over $(-\infty,0)$ respectively
$(0,+\infty)$.
For each of these  we get
analytic functions
$G_+(\zeta$ and  $G_-(\zeta)$ in the upper,  resp. the lower
half plane of the complex $\zeta$-plane where $\zeta=\xi+i\eta$.
After one can  take their boundary values.
This construction has special interest 
when
the support of the Fourier transform  has gaps, i.e. when its complement consists
of many open intervals and leads to certain uniqueness results which 
are presented  at the end of this section based upon
Beurling's  lectures at Stanford University in 1961. 



\bigskip




\noindent
{\bf 3.1 The functions $G_+$ and $G_-$}.
Consider a continuous complex-valued function 
$g(x)$ defined on the real $x$-line which is   absolutely integrable:
\[
\int_{-\infty}^\infty\,|g(x)|\, dx<\infty
\]
We obtain  analytic functions $G_+(\zeta)$ and $G_-(\zeta)$
defined in the upper,  respectively the lower half-plane of the complex
$\zeta$-plane where $\zeta=\xi+i\eta$.
\[
 G_+(\zeta)=
\int_{-\infty}^0\, g(x)e^{-i\zeta x}\, dx\quad\colon\quad
 G_-(\zeta)=
\int_0^{\infty}\, g(x)e^{-i\zeta x} \,dx\tag{*}
\]
\medskip

\noindent
With $\zeta=\xi+i\eta$ we have $ |e^{-i\zeta x}|=
e^{\eta x}$. This number is  $<1$ when $x<0$ and $\eta>0$, and vice versa.
We conclude  that $G_+(\zeta)$ is analytic in $\mathfrak{Im}(\zeta)>0$
while $G_-(\zeta)$ is analytic in $\mathfrak{Im}(\zeta)<0$.
Since $|g|$ is integrable we see that $G_+$ extends continuously to
the closed upper half
 plane where
\[ 
G_+(\xi)=
\int_{-\infty}^0\, g(x)e^{-i\xi x} dx
\]
Similarly $G_-$ extends to
$\mathfrak{Im}(\zeta)\leq 0$ and we have:
\[
 G_+(\xi)+ G_-(\xi)=
\int_{-\infty}^\infty\, g(x)e^{-i\xi x} dx=\widehat g(\xi)\tag{**}
\]
\bigskip

\noindent
{\bf 3.2 The case when
$\widehat g$ has compact support.}
Then there are  two  intervals 
$(-\infty,a)$ and $(b,+\infty)$ and and  family of bounded
interval $\{(\alpha_\nu,\beta_\nu)\}$
whose union is the open complement of
$\text{Supp}(\widehat g)$.
On each such interval $G_+(\xi)+G_-(\xi)$ is identically zero.
Hence 
we get
\bigskip

\noindent {\bf 3.3 Theorem}
\emph{Put  $\Omega= {\bf{C}}\setminus\text{Supp}(\widehat g)$.
Then there exists a  function $\mathcal G\in\mathcal O(\Omega)$
such that $\mathcal G=G_+$ in the upper half plane and
$\mathcal G=-G_-$ in the lower half plane.}
\bigskip

\noindent Consider some $R>0$ which is chosen so large that
the open disc $D_R$ centered at the origin in the $\zeta$-space contains
the compact set
$\text{Supp}(\widehat g)$.
For each real $x$ the function $e^{ix\zeta}\mathcal G(\zeta)$
is again analytic in $\Omega$. Put
\[ 
J\uuu R(x)=\int_{|\zeta|=R}\,
e^{ix\zeta}\cdot \mathcal G(\zeta)\, d\zeta\tag{i}
\]
\newpage

\noindent
{\bf{Exercise.}} Show that if $[\vvv R,R]$ contains the support of $g$
then  

\[ 
J\uuu R(x)=
\int_{-R}^R\,e^{ix\xi} G_+(\xi)\,d\xi+
\int_{-R}^R\,e^{ix\xi} G_-(\xi)\,d\xi=
\int_{-R}^R\,e^{ix\xi}\cdot  \widehat g(\xi)\, d\xi
\]
\medskip

\noindent The last integral appears in Fourier's inversion formula
which gives:

\medskip

\noindent {\bf 3.4 Theorem} \emph{Let $g(x)\in
L^1({\bf{R}})$ be such that $\widehat g$
has compact support in the interval $[\vvv R\uuu *,R\uuu *]$.
Then}
\[ 
g(x)=\frac{1}{2\pi}\cdot 
\int_{|\zeta|=R}\,
e^{ix\zeta}\cdot \mathcal  G(\zeta)\, d\zeta\quad\colon\quad R>R\uuu *
\] 

\bigskip

\noindent {\bf 3.5 A more general case.} The
condition that $\widehat g$ has compact support is 
restrictive  since it implies that  $g(x)$ extends to an entire function
in the complex $z$-plane. A relaxed condition
is
that
the complement of $\text{Supp}(\widehat g)$  contains some
open  intervals both on positive and the negative real
$\xi$-axis. With  $\Omega= C\setminus\text{Supp}(\widehat g)$ we have
$\mathcal G\in\mathcal O(\Omega)$. So if $R>0$ is a positive number
such that 
$R$ and $-R$ both are outside the support of $\widehat g$
we have the equality
\[
\frac{1}{2\pi}\cdot\int_{|\zeta|=R}\,
e^{ix\zeta}\mathcal G(\zeta)\, d\zeta=
\frac{1}{2\pi}\cdot
\int_{-R}^R\,e^{ix\xi} \cdot \widehat g(\xi)\,d\xi\tag{*}
\]
\medskip

\noindent
If $\widehat g$ is absolutely integrable
Fourier's inversion formula 
gives
\[ 
g(x)=\lim_{R\to\infty}\, 
\frac{1}{2\pi}\cdot
\int_{-R}^R\,e^{ix\xi}\,  \widehat g(\xi)\,d\xi
\]


\noindent 
So when
$\widehat g\in L^1({\bf{R}})$
and  
there exists some
sequence
$\{R_\nu\}$ where $R_\nu$ and $-R_\nu$ both are outside
$\text{Supp}(\widehat g)$, then
\[
g(x)=\lim_{\nu\to\infty}\,
\frac{1}{2\pi}\cdot\int_{|\zeta|=R_\nu}\,
e^{ix\zeta}\cdot \mathcal G(\zeta)\, d\zeta\tag{**}
\]

\bigskip


\centerline {\bf 3.6 Further extensions}
\medskip

\noindent
Above we assumed that $g(x)$ was absolutely integrable which 
implies that $\widehat g$ is a bounded and continuous  function.
Suppose now that $g(x)$ is a continuous function such that
\[ 
\int_{-\infty}^\infty\,
\frac{|g(x)|}{1+|x|^N}\cdot x<\infty
\]
holds for some positive integer $N$.
We can still define the two analytic functions $G_+$ and $G_-$.
Consider the behaviour of $G_+$ as $\zeta$ approaches the real
$\xi$-line. We have by definition
\[
G_+(\xi+i\eta)=
\int_{-\infty}^0\,
g(x)^{-i\xi x}e^{\eta x}dx
\]


\noindent 
Taking absolute values we get for $\eta>0$:
\[
|G_+(\xi+i\eta)|\leq
\int_{-\infty}^0\,
\frac{|g(x)|}{(1+|x|)^N}\cdot
(1+|x|)^N\cdot e^{\eta x}dx
\]
\medskip
Notice
that when  $\alpha>0$, then the function
\[
t\mapsto (1+t)^Ne^{-\alpha t}\,\colon t\geq 0
\]
takes its maximum when $1+t=\frac{N}{\alpha}$
so the maximum value  
over $[0,+\infty)$ is 
$\leq \frac{N^N}{\alpha^N}$.
Apply this with $\eta>0$ and $x<0$ above which gives
a constant $C$ such that
\[
|G_+(\xi+i\eta)|\leq \frac{C}{\eta^N}\cdot 
\int_{-\infty}^\infty\,\frac{|g(x)| \cdot dx}{1+|x|^N}\tag{*}
\]

\medskip

\noindent Hence $G_+$ has temperate growth as $\eta\to 0$ so its boundary
value distribution $\mathfrak{b}(G_+)$
exists.
Similarly we find the boundary value distribution  $\mathfrak{b}(G_-)$.
The Fourier transform of $g(x)$  regarded as a tempered
distribution is equal to  
$\mathfrak{b}(G_+)+\mathfrak{b}(G_-)$.
Again, if $\text{Supp}(\widehat g)$ has gaps
we can proceed as in 3.5
and construct 
the complex line integral
\[
J\uuu R(x)=
\frac{1}{2\pi}\cdot\int_{|\zeta|=R}\,
e^{ix\zeta}\mathcal G(\zeta)\, d\zeta
\]
for those values of $R$ such that $-R$ and $R$ are outside
the support of $\hat g$.

\medskip

\noindent
{\bf{Exercise.}}
Let $g$ be as above and assume that
there exists a sequence $\{R\uuu\nu\}$
where
$-R\uuu\nu $ and $R\uuu\nu$ are outside the support of $g$.
Show that the following hold for
every test\vvv function
$f(x)$ 
\[
\int g(x)\cdot f(\vvv x)\, dx=
\lim\uuu {\nu\to \infty}\, 
\frac{1}{2\pi}\cdot\int_{|\zeta|=R\uuu\nu }\,
\mathcal G(\zeta)\cdot \widehat f(\zeta)\,d\zeta
\]
where $\widehat f(\zeta)$ is the entire Fourier\vvv Laplace transform of $f$.




\bigskip

\centerline{\bf 3.7 Use of Fourier's inversion formula.}

\medskip

\noindent
Consider the following situation:  Let $f(x)$ be a function in the Schwartz
class
and
assume that  $\widehat f(\xi)$ vanishes on some open
interval $a<\xi<b$. 
Set $c=\frac{a+b}{2}$
and $g(x)= e^{ixc}\cdot f(x)$. Then
we get
\[ 
\widehat g(\xi)=\widehat f(\xi+c)
\]
Here $\widehat g$ is zero on an interval centered at $\xi=0$
and we may therefore assume from the start
that $\widehat f$ is zero on some interval $(-A,A)$. Set
\[ 
F_+(x+iy)=
\frac{1}{2\pi}\cdot\int_A^\infty\, e^{(x+iy)i\xi}\,
\widehat f(\xi)\,d\xi\quad\colon\quad
F_-(x+iy)=-\frac{1}{2\pi}\cdot\int_{-\infty}^{-A}\, e^{(x+iy)i\xi}\,
\widehat f(\xi)\, d\xi
\]


\noindent
When $y=0$ we see that
\[ F_+(x)-F_-(x)=\frac{1}{2\pi}\cdot\int_{-\infty}^\infty\, e^{ix\xi}\,
\widehat f(\xi)\, d\xi\tag{*}
\]
By Fourier's inversion formula the last integral is equal to
$f(x)$ since 
$\widehat f=0$ on $(-A,A)$.
Hence $f(x)$ is represented as a difference of
two analytic functions defined in the upper and the lower
half-plane respectively where  one has  the estimates:
\[ 
\bigl|F_+(x+iy)\bigr|\leq
\int_A^\infty\, e^{-y\xi}\cdot |\widehat f(\xi)|\, d\xi\leq
e^{-Ay}\cdot\int_A^\infty\, |\widehat f(\xi)|\,d\xi\tag{1}
\]
\[
|F_-(x+iy)|\leq e^{-A|y|}\cdot\int_{-\infty}^{-A}\, |\widehat f(\xi)|\, d\xi
\tag{2}
\]


\noindent
Suppose now that $f(x)$ also is zero on some
interval, say $a<x<b$. This means that
the two analytic functions
$F_+(z)$ and $F_-(z)$ agree on this interval and  by the Schwarz
reflection principle they are analytic continuations of each other.
Hence, we get the following:
\medskip

\noindent
{\bf 3.8 Proposition.}
\emph{Assume that $\text{Supp}(f)$ is a proper subset
of ${\bf{R}}$ and consider the open complement
\[
U=\,\cup\, (a_\nu,b_\nu)
\] 
where $\{(a_\nu,b_\nu)\}$ is a family of disjoint open
intervals. Then there exists
an analytic function
$\mathcal F(z)$ defined in the connected
set
${\bf{C}}\setminus\text{Supp}(f)$ where}
\[ 
\mathcal F(z)=F_+(z)\quad\colon\,z\in U_+\quad\colon\quad
\mathcal F(z)= F_-(z)\quad\colon\, z\in U_*
\]
\emph{We refer to $\mathcal F$ as the inverse Fourier-Carleman transform of
$\widehat f(\xi)$.}
\medskip

\noindent
{\bf 3.9 A local estimate.}
Consider an open interval $(a_\nu,b_\nu)$ in $U$.
Set 
\[r=\frac{b_\nu-a_\nu}{2}\quad\colon\, 
\quad c=\frac{a_\nu+b_\nu}{2}
\]
Hence the open disc $D_r(c)$ stays in
the open set
$\Omega={\bf{C}}\setminus\text{Supp}(f)$.
Next, when
$0<\phi<\pi$ we have
\[ 
\mathcal F(c+re^{i\phi})=
\frac{1}{2\pi}\cdot
\int_A^\infty\, 
e^{(c+r\text{cos}\phi)i\xi-
r\text{sin}\,\phi\cdot\xi}\cdot
\widehat f(\xi)\cdot d\xi\
\]
Since $\bigl|e^{(c+r\text{cos}\phi)i\xi}\bigr|=1$
the triangle inequality gives
\[
|\mathcal F(c+re^{i\phi})|\leq\frac{1}{2\pi}\cdot
e^{-rA\cdot\text{sin}\,\phi}\cdot 
\int_A^\infty\,
\bigl|\widehat f(\xi)\,\bigr|\cdot d\xi\
\]
\medskip

\noindent 
When $-\pi\leq\phi\leq 0$ we get a similar 
estimate where we now use that
$\mathcal F=F_-$.
Introducing the $L^1$-norm of $\widehat f$
we conclude
\medskip

\noindent
{\bf 3.10 Proposition.} \emph{One has the inequality}
\[
\mathcal F(c+re^{i\phi}\bigr|\leq \frac{||\widehat f||_1}{2\pi}\cdot
e^{-Ar\cdot|\text{sin}\,\phi|}\quad\colon\quad 0\leq\phi\leq 2\pi
\]
\medskip

\noindent
{\bf 3.11 The subharmonic function
$U=\text{Log}\,|\mathcal F|$}.
Replacing $f$ by $c\cdot f$
with some constant $c$
we 
assume that $\frac{||\widehat f||_1}{2\pi}\leq 1$.
Then Proposition 3.10 gives the inequality
\[ 
U(c+re^{i\phi})\leq 
-Ar\cdot|\sin\,\phi\,|\quad\colon\quad -\pi\leq\phi\leq\pi
\]
\medskip
\noindent Since $U$ is subharmonic we can apply Harnack's inequality from
XX and conclude
\medskip

\noindent
{\bf 3.12 Proposition.} \emph{One has the inequality}
\[
U(x)\leq -\frac{Ar}{2\pi}\cdot \quad\colon\quad c-\frac{r}{2}\leq x\leq
c+\frac{r}{2}
\]
\medskip

\noindent
{\bf 3.13 A vanishing theorem.}
In addition to the
inequality in Proposition 3.12 which is valid for 
every open interval  of the $x$-axis outside the support of $f$, we also have
the estimate from Proposition 3.10. This gives
\[
U(x+iy)\leq -A|y|\tag{*}
\]
when 
$||\widehat f||_1\leq 2\pi$.
Now we can apply the general result from XX.
Namely, if  
suppose that there is  a sequence of disjoint intervals
$\{(a\uuu\nu,b\uuu\nu){}$ 
are outside the support of $f$.
Then 
\[
\sum\,(b_\nu-a_\nu)\cdot\int_{a_\nu}^{b_\nu}\,
\frac{dx}{1+x^2}<\infty\tag{**}
\]
must hold unless $f$ is identically zero.
This gives a uniqueness theorem which can be phrased as follows.
Let
$0<c_1<c_2\ldots$ where each $c\uuu\nu$ is the mid\vvv point of an
interval $(a\uuu\nu,b\uuu\nu)$
and these intervals are disjoint. We say that this interval family is thick if
\[
\sum\, \frac {(b\uuu\nu\vvv a\uuu\nu)^2}{c\uuu\nu^2}=+\infty
\]
\medskip

\noindent
{\bf{3.14 Theorem.}} \emph {Let $f(x)$ be a continuous function on
the $x$\vvv line be such its support is disjoint from
a thick union of intervals and 
$\widehat f(\xi)$ is integrable.
Then $\widehat f$ cannot be identically zero on any open subinterval of 
the $\xi$\vvv line unless $f$ is identically zero.}

\medskip


\noindent
{\bf Remark.}
The  proofs above are taken from  i
[Benedicks] and we refer to [loc.cit] 
for further gap-theorems
which are derived using the Fourier-Carleman
transform. 
\newpage


\centerline{\bf 4. The Paley-Wiener theorem}
\bigskip


\noindent
Let $\mu$ be
a distribution on the real-$x$-line whose support is 
contained in an intervall $[-B,B)$.
We consider the complex $\zeta$-space where
$\zeta=\xi+i\eta$.
For each fixed $\zeta$ we have the $C^\infty$-function
$x\mapsto e^{-ix\zeta}$. If $\mu$ is a Riesz measure with compact support we
get the entire function
\[ 
\widehat\mu(\zeta)=\int\, e^{-i\zeta x}\, d\mu(x)
\]
Moreover one has the estimate
\[ 
|\widehat \mu(\xi+i\eta)|\leq e^{B\cdot |\eta|}\cdot ||\mu||
\]
More generally, if the distribution $\mu$  is a sum
of derivatives of Riesz measures up to some order $m$
the entire function $\widehat \mu$  satsfies 
\[
|\widehat {\mu}(\xi+i\eta)|\leq C_m\cdot (1+|\zeta|^m)\cdot
e^{B\cdot |\eta|}
\]
for some constant $C_m$.
The Paley-Wiener theorem gives a converse to this result.

\medskip

\noindent 
{\bf 4.1 Theorem.}
\emph{Let $H(\zeta)$ be an entire function
for which there exist $B$ and some integer $m$
such that}
\[
|H(\zeta)|\leq  (1+|\zeta|)^m\cdot e^{B|\eta|}
\quad\colon\tag{4.1.1}
\]
\emph{Then $H(\zeta)=\widehat\mu(\zeta )$ for a distribution supported by
$[-B,B]$.}
\bigskip

\noindent
The proof has two ingredients. The entire $H$-function is
of exponential type and  has also a polynomial growth on
the real $\xi$-line. By the reeult from ¤¤ there exists for 
a given integer $m$ a constant $C_m$ such that
(4.1.1) above gives
\[
|H(\zeta)|\leq C_m\cdot  (1+|\zeta|)^m\cdot e^{B|\eta|}
\quad\colon\tag{2}
\]


\noindent
Using (2) we shall prove that $H=\widehat\mu$ for a distribution
$\mu$ supported by $[-B,B]$.
To begin with
$H(\xi)$ has a polynomial growth on the $\xi$-line whose inverse
Fourier transform is a tempered distribution $\mu$.
If $g(x)$ is a test-function this means that
\[ 
\mu(g)= \frac{1}{2\pi}\cdot 
\int_{-\infty}^\infty\, \widehat g(-\xi)\cdot H(\xi)\cdot d\xi\tag{i}
\]
\medskip

\noindent
There remains to prove that $\mu$ is supported by $[-B,B]$.
To show this we use that $\widehat g$ extends to an entire function
and from (xx) we find a constant $C$ such that
\[
|\widehat g(\zeta)|\leq C(1+|\zeta|)^{-m-2}\cdot e^{|\mathfrak{Im}\zeta|}\tag{ii}
\]



\noindent
Next, 
consider rectangles in the
$\zeta$-space defined by
\[ 
\square_{R:\rho }=\ -R<\xi<R\}\times
\{ 0<\eta<\rho\}
\]
where $(R,\rho)$ is a pair of positive numbers.
The decay  in (ii) and (2) entail that

\[ 
\lim_{R\to\infty}\, \int_0^\rho \widehat g(-R-is)\cdot H(R+is)\cdot ds=0
\]
and a  similar vanishing of the limit holds for  line integrals along
$\mathfrak{Re}(\zeta)=-R$.
So for each $\rho>0$ Cauchy's integral theorem gives
\[ 
\mu(g)=\frac{1}{2\pi}\cdot \lim_{R\to\infty}\,
\int_{-R}^R\, \widehat g(-\xi-i\rho)\cdot H(\xi+i\rho)\cdot d\xi\tag{iii}
\]
Next, suppose  that the support of $g$ is contained in
$[B^*,+\infty)$ for some $B^*>B$.
By (xx) we have a constant $C$
such that

\[
|\widehat g(\xi+i\rho)|\leq C\cdot (1+|\xi|+\rho)^{-m-2}
\cdot  e^{-B^*\rho}\tag{iv}
\]
hold for all pairs
$\xi$ and $\rho>0$.
Hence (iii) and the triangle inequality give

\[
|\mu(g)|\leq C\cdot \frac{1}{2\pi}
\cdot e^{(B-B^*)\rho}\cdot \int\, (1+|\xi|+\rho)^{-2}\cdot d\xi\tag{v}
\]
The last integral factor is bounded above by
the convergent integral
$\int\, (1+|\xi|)^{-2}\cdot d\xi$.
Since we can choose $\rho$ arbitrary large in (5) it follows that
$\mu(g)=0$.
Here $B^*>B$ was arbitrary so 
$\text{Supp}(\mu)$ is contained in $[B, +\infty)$.
In the same way one proves that the support is contained 
$(-\infty,-B]$ and
hence $\mu$ is supported by $[-B,B]$ which finishes the proof.


 \bigskip

\noindent
{\bf 4.2 A division problem}
Let $\mu$ and $\gamma$ be a pair of distributions with compact support.
Assume that the quotient 
\[
\frac{\widehat\gamma}{\widehat\mu}\in\mathcal O({\bf{C}})
\]
\medskip

\noindent
Since $\widehat\mu$ and $\widehat\gamma$ both are entire functions of
exponential type the  division theorem
by Lindelšf 
in ¤ XX implies that the quotient  is of
exponential type, i.e. there exists some $B$ and a constant $C$ so that

\[
\frac{|\widehat\gamma(\zeta)|}{|\widehat\mu(\zeta)|}\leq Ce^{B|\zeta|}
\]
\medskip

\noindent 
However,  the  polynomial growth which is required in (*) from
4.3
on the real $\xi$-line fails in general. 
To compensate for this failure, A. Beurling and P. Malliavin
made an intensive study of functions in the Carleman class in 
[B-M] to analyze inverse formulas for entuire quotients as above.
In these notes we  refrain from
a further discussion of these more advanced reults.
In addition to [ibid]
the interested reader can also consult
the article
[Malliavin:xx].







\newpage


\centerline{\bf 5. Runge's theorem and the inhomogeneous $\bar\partial$\vvv equation}

\bigskip

\noindent
The main result in this section goes as   follows:
\medskip

\noindent
{\bf 5.1 Theorem.}
\emph{For every open set $\Omega$ in
${\bf{C}}$ and each 
$g\in C^\infty(\Omega)$ there exists
$\phi\in C^\infty(\Omega)$ such that}
\[ 
\bar\partial(\phi)=g\tag{1}
\]


\noindent
The proof relies upon an approximation result of independent interest.
To  each  compact subset $K$ of ${\bf{C}}$
we consider  the algebra
$\mathcal O(K)$ of germs of analytic functions on $K$.
We can   restrict 
every
$f\in\mathcal O(K)$ to $K$. These restrictions yield
a subalgebra of
$C^0(K)$ whose uniform closure is denoted by
$\mathcal H(K)$.
Let us also  consider some open set
$\Omega$ which contains $K$ as a  compact subset.
Each $g\in\mathcal O(\Omega)$ can be restricted to $K$
and these restrictions give a subalgebra of
$C^0(K)$ whose uniform closure is denoted
by
$\mathcal H_\Omega(K)$.
We have the obvious inclusion
\[
\mathcal H_\Omega(K)\subset\mathcal H (K)\tag{0.1}
\]
The question arises when equality holds.
The affirmative answer is as follows:




\medskip

\noindent
{\bf 5.2 Theorem.}
\emph{The equality $\mathcal H_\Omega(K)=\mathcal H (K)$
holds if and only if
$\bar U\cap\,\partial\Omega\neq\emptyset$
for every connected component $U$
of ${\bf{C}}\setminus K$.}
\medskip

\noindent
\emph{Proof.}
Suppose first the inclusion (0.1) is strict.
Riesz representation formula and the Hahn-Banach theorem  give
a  Riesz measure
$\mu$ supported by $K$ such that
\[
\mu\perp
\mathcal H_\Omega(K)\quad\colon\quad\text{and}\quad
\exists\,\,g\in\mathcal H(K)\,\colon\,\int_K g\cdot d\mu\neq 0\tag{1}
\]


\noindent
By density we  find
$f\in\mathcal O(K)$ so that $f|K$ approximates $g$
so close that
$\int\, f\cdot d\mu\neq 0$.
By the result in XXX this gives  some 
$z_*\in{\bf{C}}\setminus K$ such that
\[
\int_K\,\frac{d\mu(\zeta)}{\zeta-z_*}\neq 0\tag {2}
\]
Here  $z_*$  belongs to
a connected component of 
${\bf{C}}\setminus K$ which we denote by $U_*$. Now one has
\[
U\uuu *\subset\Omega\tag{i}
\]
For if (i) fails we  pick a point
\[
a\in U\uuu *\setminus \Omega\tag{ii}
\]
The  functions $\{\frac{1}{(z-a)^m}\}$
belong to $\mathcal O(\Omega)$ for all $m\geq 1$ and since
$\mu\perp \mathcal H\uuu\Omega(K)$ we have:
\[
\int_K\,\frac{d\mu(\zeta)}{(\zeta-a)^m}=0\quad\colon\,
m=1,2,\ldots\tag{iii}
\]

\noindent
In $U_*$  there exists the  analytic function
\[
z\mapsto\int_K\,\frac{d\mu(\zeta)}{(\zeta-z)}=0\tag{iv}
\] 

\medskip
\noindent
Here (iii) means that the series expansion 
at $z=a$ is identically zero and hence (iv) is identically zero in $U\uuu *$
which contradicts (2) and hence (i) must hold.
Next, since 
Since $U_*$ is a connected component of
${\bf{C}}\setminus K$ we have the inclusion
\[ 
\partial U_*\subset K\tag{v}
\]
At the same time $U_*\subset\Omega$ holds by (i) 
and since $K$ is  compact in $\Omega$
it follows that the 
$\partial U_*\cap \partial\Omega\neq \emptyset$.
This proves  the if part  of Theorem 5.2 and there  remains to prove
the implication
\[
\mathcal H_\Omega(K)=\mathcal H(K)\,\implies\,
\bar U\cap\partial\Omega\neq \emptyset \tag{*}
\] 
for every connected component 
$U$ of ${\bf{C}}\setminus K$. To show this we 
argue by a contradiction and suppose that
\[
\bar U\cap \partial\Omega=\emptyset\tag{**}
\]
Now $\partial U\subset K$ and since
$K$ is  compact in $\Omega$ and $U$ is connected
we see that (**) gives the inclusion
\[
\bar U\subset \Omega\tag{vi}
\]
Now we pick $z_0\in U$ which gives
the function
\[ 
f(z)=\frac{1}{z-z_0}\in\mathcal O(K)
\]
The equality
$\mathcal H_\Omega(K)=\mathcal H(K)$ gives  a sequence
$\{g_n\}$ in $\mathcal O(\Omega$
which converges uniformly to $f$ on $K$ so that
\[
\lim_{n\to\infty}\, (z-z_0)(g(z)=1
\quad\,\text{holds uniformly on }\,\,K\tag{vii}
\]
But this gives a contradiction.
For  by (vi)  and the inclusion
$\bar U\subset\Omega$ the
maximum principle for
analytic functions in $U$ gives
\[
|g\uuu n(z\uuu 0)|\leq |g\uuu n|\uuu K\quad\colon n=1,2,\ldots
\]
Since
$g\uuu n\to f$ holds uniformly on $K$
it follows that the sequence $\{g\uuu n(z\uuu 0)\}$ is bounded.
But then it is clear that (vii) cannot hold which gives the
requested contradiction and the proof of Theorem 5.2 is finished.



\bigskip


\centerline {\emph{ 5.3 Proof of Theorem 5.1}} 

\bigskip

\noindent 
\emph{Proof.}
Plane topology 
gives an increasing sequence
of compact subsets
$\{K_\nu\}$ such  that for every $\nu$ one has:
\[
\partial U\cap\partial\Omega\neq\emptyset\quad
\colon\,\,\forall\,\,\text{connected components of}\,\,
U\subset {\bf{C}}\setminus K_\nu\tag{1}
\]



\noindent
Next, Theorem  ¤¤ XX gives for  each
$\nu$  a $C^\infty$-function $\phi_\nu$
and some small open neighborhood $U_\nu$ of $K$
such that
\[
\bar\partial(\phi_\nu)=g\quad\,\text{holds in}\,\, U_\nu\tag{2}
\]


\noindent
It follows that $\phi_{\nu+1}-\phi_\nu\in\mathcal O(K_\nu)$ and
Theorem 5.2  gives  
$h_\nu\in\mathcal O(\Omega)$ such that the maximum norm
\[
|\phi_{\nu+1}-\phi_\nu-h_\nu|_{K_\nu}\leq 2^{-\nu}\tag{3}
\]


\noindent
For every $p\geq 2$ we therefore get a continuous
function defined in $U_p$
by:
\[ 
\psi_p=
\phi_p+\sum_{\nu=p}^\infty\, (\phi_{\nu+1}-\phi_\nu-h_\nu)
-(h_1+\ldots+h_{p-1})\tag {4}
\]


\noindent
A trivial  calculation shows that
$\psi_q=\psi_p$ for all pairs $q>p$ so we get a function 
$\psi_*$ defined in the whole open set
$\Omega$ where $\psi_*|U_p=\psi_p$
for each $p$.
Moreover, for each fixed  $p$ we have 
\[
\phi_{\nu+1}-\phi_\nu-h_\nu|U_p\in\mathcal O(K_p)\quad\colon \nu\geq p
\tag{5}
\]



\noindent
Next, since $\{h_\nu\}$
are analytic in $\Omega$, we conclude that
\[
\psi_*-\phi_p\in\mathcal O(K_p)\quad\colon\, p=1,2,\ldots\tag{6}
\]
Finally, since  the increasing sequence $\{K_p\}$ exhaust $\Omega$
it follows from (6) that
$\psi_*\in C^\infty(\Omega)$ and  (2) gives
$\bar\partial(\psi\uuu *)=g$ in $\Omega$. Hence
$\psi$ 
gives the requested solution in Theorem 5.1.




\newpage


\centerline {\bf \large{6. The generalised Fourier transform.}}
\bigskip

\noindent
{\bf Introduction.}
The book \emph{L'Integrale de Fourier et questions qui
s'y rattachent}  published in 1944 by
Institute Mittag-Leffler  is
based upon Carleman's lectures
at the institute in 1935.
In the introduction he writes:
\emph{C'est avant tous les travaux fondamentaux de M. Wiener
et Paley qui ont attirŽ mon attention}.
The  book \emph{Fourier transforms
on the complex domain} by Raymond Paley and Norbert Wiener was published
the year before.
We  expose material
from Chapter II in [Car]
which 
leads  a generalised 
Fourier transform and goes beyond the ordinary Fourier transform
for tempered distributions on the real line.
This generalised Fourier transform is used when
analytic function theory is applied to study
singular integral equations with non-temperate solutions.
An example is the
Wiener-Hopf equation
where one seeks eigenfunctions
$f(x)$ to 
the integral equation
\medskip
\[ 
f(x)=\int_0^\infty\, K(x-y)f(y)dy\tag{*}
\] 
In many physical applications the kernel $K$ has
exponential decay and one seeks eigenfunctions
$f$ which are  allowed to increase  exponentially.
The major result about solutions (*) appear in
Theorem XVI on page 56 in [Pa-Wi] based upon
the 
article  
[Ho-Wi].
This  
inspired Carleman to 
the constructions  in
¤ 1 below.
Let us  remark that
the generalised inversion formula  in Theorem 6.3 leads to the calculus
of 
hyperfunctions. For  comments about the relation between
Carleman's original constructions and later
studies of
hyperfunctions we refer to 
the article [Kis] by Christer
Kiselman.
\medskip


\noindent
{\bf{6.0 A special construction.}}.
Let $f(z)$ be a bounded analytic in the upper half plane
$\mathfrak{Im}\, z>0$ and suppose it
extends to a continuous function on the closed half-plane and
that the boundary function $f(x)$ is integrable, i.e.
\[
\int_{-\infty}^\infty\, |f(x)|\, dx<\infty
\]
To each $0\leq \theta\leq \pi$
we set
\[ 
G_\theta(\zeta)=
\int_0^\infty\, e^{i\zeta re^{i\theta}}\cdot f(re^{i\theta})
e^{i\theta}\, dr\tag{6.0.1}
\]
With $\zeta= se^{i\phi}$
we have
\[
 |e^{i\zeta re^{i\theta}}|= e^{-sr\sin(\phi+\theta)}
\]
Hence (6.0.1) converges if
$\sin(\phi+\theta)>0$, i.e when
\[
-\theta<\phi<\pi-\theta\tag{ii}
\]
So $G_\theta(z)$ is analytic in a half-space.
In particular $G_0$ is analytic in
$\mathfrak{Im}\,\zeta>0$ while
$G_\pi $ is analytic in the lower half-plane.
Moreover these $G$-functions are glued
as $\theta$-varies.
To see this we notice that (0.1) is the complex line integral
\[
\int_{\ell_+(\theta)}
e^{i\zeta z}\cdot f(z)
\, dz
\] 
where
$\ell_+(\theta)$ is the half-line $\{ re^{i\theta}\,\colon\, r\geq 0\}$.
Hence 
there exists an analytic function $G^*(z)$
in
${\bf{C}}\setminus [0,+\infty)$
which is equal to $G_\theta(z)$ in every half-space
defined via (ii).
Next, with $\zeta=\xi+i\eta$
there exists a limit
\[
\lim_{\epsilon\to 0}
G_0(\xi+i\epsilon)=
\int_0^\infty\, e^{i\xi x}
 f(x) \,dx
\]
Similarly the reader may verify that
\[
\lim_{\epsilon\to 0}
 G_\pi(\xi-i\epsilon )=-\int_0^\infty\, e^{-i\xi r}f(-r)\,dr=
 -\int_{-\infty}^0\,  e^{i\xi r}f(r)\,dr\tag{iii}
 \]
Passing to the usual Fourier transform of $f(x)$ we therefore get the equation
\[
\widehat{f}(-\xi)=
G_0(\xi+i0)-G_\pi(\xi-i0)\tag{iv}
\]
where we have taken boundary values of
the analytic functions $G_0$ and $G_\pi$.
Now
\[ G^*(\xi)=
G_0(\xi+i0)=G_\pi(\xi-i0)\quad\colon \xi<0\tag{v}
\]
Hence (iv) entials that 
$\widehat{f}(-\xi)=0$ 
when $\xi<0$ and reversing signs
we conclude that the support of
$\widehat{f}$ is contained
in the
half-line
$\{\xi\leq 0\}$. This inclusion has been seen before since
the $L^1$-function $f(x)=f(x+i0)$ is the boundary value of an
analytic function in
the upper half-plane.
Moreover (iv) means  that
$\widehat{f}$ on $\{\xi<0\}$
is expressed as the difference of the boundary values
of $G_0$ and $G_\pi$ taken on the positive real $\xi$-line.
Notoce that this difference is expressing obstructions for
the $G^*$-function to extend across intervals
on the positive $\xi$-line.
So in this sense $G^*$ alone
determines $\widehat{f}$.
\medskip

\noindent
The observations above which
were used in work by Plaey and Wiener
led Carelan to perform similar cointructions where
regularity and growth properties are relaxed.

\bigskip


\centerline
{\bf { 6.1 Carleman's constructions}} 
\bigskip

\noindent
Let $U^*$ be  the upper
half-plane.
To each pair of real  numbers
$a,b$ we denote
by
$\mathcal O_{a,b}(U^*)$
the family of  functions $f\in\mathcal O(U^*)$
such that for every $0<\theta_0<\pi/2$ there exists a constant
$A(\theta_0)$ and
\[ 
|f(re^{i\theta})|\leq A(\theta_0)\cdot \bigl( r^a+\frac{1}{r^b}\,\bigr )\quad\colon\quad
\theta_0<\theta<\pi-\theta_0\tag{*}
\]
\medskip

\noindent
{\bf Remark.}
No condition is imposed on the
$A$-function
as $\theta_0\to 0$.
In particular $f(z)$ need not have tempered growth
as one approaches the real line.
In the same way we define the family
$\mathcal O_{a,b}(U_*)$
of analytic functions defined in the lower half-plane $U_*$
satisfying similar estimates as above. 
\medskip

\noindent {\bf Example.} Let $f(z)$ be the ordinary Fourier-Laplace
transform
of a tempered distribution $\mu$ on the real $t$-line supported
by the half-line
$t\leq 0$.  Recall that this gives an integer $N$ and a constant
$C$ such that
\[
|f(x+iy)|\leq C\cdot y^{-N}\quad\colon\quad y>0
\]
Here we can take $a=b=N$ and $A(\theta)=\frac{C}{\text{sin}(\theta)}$
to get $f(z)$ in $\mathcal O_{a,b}(U^*)$.
\bigskip

\noindent
Let us return to the general case. 
Consider some
$f\in\mathcal O_{a,b}(U^*)$. If
$b\geq 1$ we choose a positive integer $m$ so that
$b<1+m$ and when
$0<\theta<\pi$ we consider the half space
\[
U^*_\theta=\{ z=re^{i\phi}\quad\colon
-\pi-\theta<\phi<-\theta\}
\]

\medskip
\noindent
The choice of $m$ and (*) give an analytic function
in  $U^*_\theta(z)$ defined by:
\medskip
\[ 
F_\theta(z)=\frac{i}{\sqrt{2\pi}}\cdot 
\int_0^\infty\,
e^{-iz re^{i\theta}}\cdot r^m\cdot e^{i m\theta}\cdot f(re^{i\theta})e^{i\theta}\cdot dr
\tag{i}
\]
Cauchy's theorem applied to the analytic function
$f(z)$ shows that these  $F_\theta$-functions
are glued together as we rotate the angle $\theta$
in the open interval $(0,\pi)$.
Notice  that
\[ 
\cup_{0<\theta<\pi} \, U^*(\theta)=
{\bf{C}}\setminus [0,+\infty)\tag{ii}
\]
Hence there exists  an analytic function $F^*(z)$
in
${\bf{C}}\setminus [0,+\infty)$ such that
\[
F^*\bigl |\, U^*_\theta=G_\theta\quad\colon\quad 0<\theta<\pi\tag{iii}
\]

\medskip

\noindent
Next, let $U_*$ be the lower half-plane where one defines the family
$\mathcal O_{a,b}(U_*)$.
If 
$g(z)$ belongs to  $\mathcal O_{a,b}(U_*)$
we obtain exactly as above 
analytic functions

\[ 
G_\theta(z)=\frac{i}{\sqrt{2\pi}}\cdot
\int_0^\infty\,
e^{iz re^{i\theta}}\cdot r^m\cdot e^{im\theta}\cdot g(re^{-i\theta})e^{-i\theta}\cdot dr
\quad\colon\quad 0<\theta<\pi
\]
defined in the half-planes
\[ 
U_*(\theta)=\{ z=re^{i\phi}\quad\colon
-\pi+\theta<\phi<\theta\}
\]
These $G_\theta$-functions are again glued together and give 
an analytic function $G_*(z)$   in 
${\bf{C}}\setminus(-\infty,0]$ where
which satisfies:
\[
G_*\bigl|\, U_*(\theta)=G_\theta
\quad\colon\quad 0<\theta<\pi\tag{iii}
\]

\medskip

\noindent
{\bf The $\mathcal{S}$-transform.}
Consider a pair  $f\in\mathcal{O}_{a,b}(U^*)$
and $g\in \mathcal{O}_{a,b}(U_*)$.
We get the functions $F^*$ and $G_*$ and here
$G_*-F^*$
is analytic outside the real axis and 
can be restricted to both the upper and the lower
half-plane. This enable us to give the following:
\medskip

{\noindent
{\bf 6.2 Definition.} \emph{To every pair $f,g$ as above we set}
\[ 
\mathcal{S}^*(z)=G_*( z)-F^*(z)\quad\colon\quad
\mathfrak{Im}(z)>0
\]
\[
\mathcal{S}_*(z)= 
G_*( z)- F^*( z)\quad\colon\quad
\mathfrak{Im}(z)<0
\]
\medskip

\noindent
{\bf Remark.}
The constructions of $F^*$
and $G_*$ entail that
$G_*\vvv F^*$  restricts to a function in
$\mathcal O_{a,b}(U)$ when
$U$ is the upper or the lower half-plane.
Hence $\mathcal S$ is a map from
$ O_{a,b}(U^*)\times \mathcal O_{a,b}(U_*)$ into itself.
\medskip

\noindent
{\bf 6.3 The reflection  operator.}
If $\phi\in\mathcal{O}(U^*)$ 
we get the analytic function in the lower
half-plane defined by
\[ 
T(\phi)(z)=\bar \phi(\bar z)
\]
In the same way $T$ sends an analytic function defined in $U_*$ to an
analytic function defined in $U^*$.
The
composed operator
$T\circ\mathcal{S}$   gives a pair
of analytic functions  defined by
\[
(T\circ\mathcal {S})^*(z)=\mathcal {\bar S}_*(\bar z)
\quad\colon\quad
\mathfrak{Im}(z)>0
\]
\[
(T\circ\mathcal {S})_*(z)=\mathcal {\bar S}^*(\bar z)
\quad\colon\quad
\mathfrak{Im}(z)<0
\]



\bigskip

\noindent
With the notations  above 
the  result below
extends Fourier's  inversion formula for tempered
distributions.
Below $\simeq$ means that two functions
differ by a polynomial in $z$.
\medskip

\noindent
{\bf 6.3 Inversion Theorem.}
\emph{For each pair $(f,g)$
in $\mathcal O_{a,b}(U^*)\times\mathcal O_{a,b}(U^*)$
one has}
\[
T\circ\mathcal{S}\circ T\circ\mathcal{S}(f)\simeq f
\quad\colon\quad
T\circ\mathcal{S}\circ T\circ\mathcal{S}(g)\simeq g
\]
where $\simeq$ means that
the differences are polynomials in $z$.
\medskip

\noindent
{\bf Remark.}
Theorem 6.3 is the assertion from p. 49
in [Car]. For details of the proof we refer to
[loc.cit. p. 50-52]. The proof relies upon
results of  analytic extensions across 
a real interval.
Since these results  have independent  interest 
we proceed to discuss material from  from [ibid]
and once
this has   been done we leave it to the reader
to discover
the proof of Theorem 6.3 or consult Carleman's proof.

\newpage


\centerline {\bf 6.4 Some analytic extensions.}
\medskip

\noindent
Let $D$ be the unit disc centered at
the  origin and set
\[
D^*=D\cap\mathfrak{Im}(z)>0\quad\text{and}\quad
D_*=D\cap\mathfrak{Im}(z)<0
\]

\noindent
{\bf 6.5 Theorem.}
\emph{Let  $f^*\in\mathcal O(D^*)$
and 
$f_*\in\mathcal O(D_*)$ be such that}
\[
\lim_{y\to 0}\, f^*(x+iy)-f_*(x-iy)=0 \tag{*}
\]
\emph{holds uniformly with respect to $x$. 
Then there exists $F\in\mathcal O(D)$
with $F|D^*=f^*$
and
$F|D_*=f_*$.}


\medskip

\noindent
{\bf Remark.}
No special assumptions are imposed on
the two functions except for (*). For example, it is from
the start not assumed that they  have moderate growth as  one approaches
the real $x$-line in (*).
\medskip

\noindent
\emph{Proof.}
In $D^*$ we get the analytic function
\[ 
G(z)=f^*(z)-\bar f_*(\bar z)\tag{i}
\]
Write $G=U+iV$ and notice that
(*) gives
\[ 
\lim_{y\to 0}\, U(x,y)=0\tag{ii}
\]
Hence the harmonic function $U$ in $D^*$
converges uniformly to zero on
the part of $\partial  D^*$
defined by $y=0$.
If $\delta>0$ is small we restrict $U$ to the
upper half-disc $D^*(\delta)$
of radius
$1-\delta$. Now (ii) implies that
when $G$ is expressed by the Poisson kernel of
$D^*(\delta)$ then the boundary integral is only taken over
the upper half-circle.
It follows by the analyticity of the kernel function for
$D^*(\delta)$ that $G(x,y)$ extends to 
a real analytic function across the
the real interval $-1+\delta<x<1-\delta$.
The same holds for the derivatives
$\partial G/\partial x$ and $\partial G/\partial y$.
The Cauchy Riemann equations show that
the complex derivative of $F(z)$ extends analytically across
the real interval and   the reflection principle by
Schwarz finishes the proof.




                                                                                                        
\medskip

\noindent
{\bf 6.6 Another continuation.}
We 
expose  another result from
[ibid]. See 
[Car: p. 40: ThŽorme 3] whose the essential ingredient is 
a subharmonic property for the radius of convergence of analytic functions.
Put  
\[
\square=\{ (x,y)\,\colon\, -1<x<1\quad\text{and}\quad 0<y<1\}
\]
Consider some
$F(z)\in\mathcal  O(\square)$.
With a  small $\ell>0$ we put
\[
D_+(\ell)=\{ |\zeta|<\ell\,\cap \mathfrak{Im}(\zeta)>0\}
\]
With $z_0=x_0+iy_0$ where $-1/2<x_0<1/2$ and $0<y_0<1-\ell$.
we get an analytic function
\[ 
G_\zeta(z)= F(z+\zeta)-F(z)\tag{i}
\]
which is defined in some neighborhood of $z_0$. It has a series expansion:
\[ 
G_\zeta(z)=F(z+\zeta)-F(z)=\sum\, P_\nu(\zeta)(z-z_0)^\nu\quad \text{where}:
\]
\[
P_\nu(\zeta)=
\frac{1}{\nu !}\cdot [F^{(\nu)}(z_0+\zeta)-F^{(\nu)}(z_0)]\tag{*}
\]
\medskip
Let
$\rho(\zeta)$ be the radius of convergence for the series (*).
Hadamard's formula gives:
\[ 
\log\,\frac{1}{\rho(\zeta)}=
\limsup_{\nu\to\infty}\,
\frac{\log\,|P_\nu(\zeta)|}{\nu}\tag{**}
\]


\noindent
Suppose we knew that
\[
\rho(\zeta)\geq y_0\quad\colon\quad
\zeta\in D_+(\ell)\tag{***}
\]
Then we can pick $\zeta=\frac{iy_0}{2}$
and conclude that the function
\[ 
z\mapsto F(z+\frac{iy_0}{2})-F(z)\tag{ii}
\]
is analytic in the disc $|z-z_0|<y_0$.
At the same time
the function $z\mapsto F(z+\frac{iy_0}{2})$ is analytic when
$\mathfrak{Im}(z)>-\frac{y_0}{2}$
and hence  $F(z)$ extends as an analytic function
across a small interval on the real $x$-axis centered at $x_0$.
So if  (***) holds for every
$-1/2<x_0<1/2$. it follows that
$F(z)$ extends analytically across
the real interval $-1(2<x<1/2$.
There remains to find a condition on $F$ in order that
(***)  holds. Notice  that it suffices to get (***)
for sufficiently small $y_0$ if we seek 
some analytic extension of $F$ across the real $x$-line.
To obtain (***) Carleman imposed the following:


\medskip

\noindent
{\bf 6.7 Hypothesis on $F$}. \emph{There exists a pair 
$\ell>0$ and $\delta>0$ such that if $\xi$ is real with
if $|\xi|<\ell$ then $z\mapsto G_\xi(z)$
extends to an analytic function
in the domain where
$|z|<1/2$ and $\mathfrak{Im}(y)>-\delta$.}
\medskip

\noindent
It is clear that this hypothesis implies that
if $y_0$ is sufficiently small then
there exists a constant $k$ such that
\[ 
|P_\nu(\zeta)\leq k^\nu\quad\colon\quad \zeta\in D_+(\ell)\quad\colon \nu=1,2,\ldots\tag{1}
\]


\noindent
Moreover, we see from a figure that the hypothesis also implies that
\[
\rho(\zeta)\geq y_0\quad\colon
\quad |\zeta|=\ell\quad\colon\mathfrak{Im}(\zeta)\geq 0\tag{2}
\]
It is also trivial that
\[
\rho(\zeta)\geq y_0\quad\colon  |\zeta|=\ell\quad\colon\mathfrak{Im}(\zeta)= 0\tag{3}
\]


\medskip
\centerline{\emph{Proof that  (***) holds}}

\medskip
\noindent
The functions
$\zeta\mapsto \log\,|P_\nu(\zeta)|$ are subharmonic in
$D_+(\ell)$ for every $\nu$.
So if $G$ is Green's function for 
$D_+(\ell)$ we have the inequality

\[
\log\, |P_\nu(\zeta)|\leq
\frac{1}{2\pi}\int_{\partial D_*(\ell)}\,
\frac{\partial G(\zeta,w)}{\partial n_w}\cdot 
\frac{\log\, |P_\nu(w)|}{\nu}\cdot |dw|\tag{i}
\]


\noindent
Now (1) above entails that
\[
\frac{\log\, |P_\nu(w)|}{\nu}\leq k\quad\colon
w\in\partial D_+(\ell) \tag{ii}
\]
At the same time (2-3) and Hadamard's formula give
\[
\limsup_{\nu\to\infty}\,
\frac{\log\, |P_\nu(w)|}{\nu}
\leq \log\, \frac{1}{y_0}
\quad\colon w\in\partial D_+(\ell)
\tag{iii}
\]
\medskip

\noindent Thanks to (ii) we can apply Lebesgue's dominated convergence theorem
when we pass to the limes superior  in (i) and hence (iii) gives
\[
\limsup_{\nu\to\infty}\,
\frac{\log\, |P_\nu(\zeta)|}{\nu}
\leq \log\, \frac{1}{y_0}\quad\colon\zeta\in D_+(\ell)\tag{iv}
\]

\noindent
Now we apply  Hadamard's formula for points in
$D_+(\ell)$ and  (***) follows.
\bigskip

\noindent
{\bf Remark.}
The continuation found above can be applied to relax the
assumption in 
Theorem 6.5. For example, there exists
an analytic
extension for a pair $f^*,f_*$
under the less restrictive condition that
\[
\lim_{y\to 0}\, \int_a^b\, \bigl [f^*(x+iy)-f_*(x-iy)\bigr ]\cdot dx=0
\]
\medskip

\noindent
This follows when
6.6  is applied to the primitive functions of the pair.







\newpage







\centerline{\bf\large 7. Carleman's inequality}
\bigskip

\noindent
{\bf Introduction.} In the article
[Ca:1]
from 1923,  Carleman proved a result about
differentiable functions on the real line which confirms the
general philosophy that in order for a polynomial 
$P(x)$ \emph{of any degree} $\geq n$
to  have multiple  roots of
some order $n$ at two points, say 0 and 1, while it does not vanish identically,
the maximum norms of its derivatives up to order $n$
\emph{cannot be too small}.
Theorem 1 below gives a conclusive answer to this  problem.
The crucial
key step in the proof    is to use  \emph{subharmonic majorisations}.
In 1923 this was a pioneering idea which after  has
become
a standard tool in analysis. See ¤ 2 in Chapter 4 in R. Nevanlinna's book
[Nev[ for a further  discussion and 
examples which illustrate 
\emph{Carleman's Prinzip der Gebietserweiterung}.




\medskip



\noindent
Now we begin  to announce  Carleman's theorem.
Let $[0,1]$ be the closed unit interval on the real $t$-line. To each
integer $n\geq 1$ we denote by $S_n$  the class of $n$-times differentiable
functions and non-negative functions on $[0,1]$ satisfying
\[
f^{(\nu)}(0)=f^{(\nu)}(1)=0\quad\colon\,\quad 0\leq\nu\leq n\quad
\colon\quad \int_0^1\,f^2(t)dt=1\quad\colon\,f(t)\geq 0
\]
\medskip

\noindent
Thus, we regard non-negative functions 
which are "flat up to order $n$" at the
end points.
Notice that $S_n$ contains all polynomials of the form
\[ 
t^n(1-t)^n\cdot Q(t)\,\,\,\colon\,Q(t) \,\,\text{any polynomial}\, \geq 0
\,\,\, \text{ where}\,\,\,
 \int_0^1\,t^n(1-t)^nQ(t)dt=1
\]
Since the degree of $Q(t)$ can be arbitrarily large the set of such polynomials
is dense in $S_n$. Next, to each $f\in S_n$ we
introduce the $p$:th roots of the
$L^2$-norms of its derivatives of order $1\leq p\leq n$:
\[ \beta_p(f)=
[\,\int_0^1\, [f^{(p)}(t)]^2dt\,\,]^{\frac{1}{2p}}\quad\colon\quad 1\leq p\leq n
\]
With these notations Carleman's inequality asserts:
\bigskip

\noindent 
{\bf Theorem 1.} \emph{For every $n$ and each $f\in S_n$ one has}

\[ 
\sum_{p=1}^{p=n}\,
\frac{1}{\beta_p(f)}
\leq 2e\pi\cdot  (1+
\frac{1}{4\pi^2 e^2-1})\tag{*}
\]

\bigskip

\noindent {\bf Remark.} The absolute constant in the right hand side
appears as a consequence of the subsequent proof where several majorisations appear.
The best constant $\mathcal C_*$ which would give
\[
\sum_{p=1}^{p=n}\,
\frac{1}{\beta_p(f)}\leq\mathcal C^*\tag{i}
\]
for all $n$ and every $f\in\mathcal S_n$ is not known.
Let us remark that (*)
is sharp in the sense that
there exists a constant $C^*$
such that for every $n$ one can find
$f\in\mathcal S_n$ for which
\[
\sum_{p=1}^{p=n}\,
\frac{1}{\beta_p(f)}\geq C_*\tag{ii}
\]

\noindent
See¤ xx and also  Chapter 1 in [Hš:xx] for the construction of such
functions.
Before we enter the proof if Theorem 1 we 
cite an excerpt from  Emile Borel's comments to
[Ca]:
\medskip

\noindent
\emph{La demonstration donnŽe par M. Carleman de l'noncŽ que
j'avais induit du thŽorme de Denjoy est remarkquable par sa profondeur
et par sa simplicitŽ. Il serait toutefois dŽsirable d'arriver ˆ donner
une demonstration sinon algŽbrique, du moins ne faisant appel qu'aux
variables rŽelles du thŽorme auquel M. Carlemnan vient
d'‡ttacher son nom. Ce thŽorme de Carleman me parait en effet
devoir tre considŽrŽ, avec le thŽorme de
Denjoy, comme l'un des thŽormes fondamentaux de la thŽorie des functions
indŽfiniment dŽrivables de variables rŽelles. Il serait
encore plus intressant de complter les thŽormes de Denjoy et de Carleman
pour une Žtude asymptotique aussi prŽcise que possible
des sŽries de toute terme gŽneral quand $n\to\infty$}.





\bigskip



 
\centerline{\emph{Proof of Theorem 1}.}
\medskip


\noindent
Let $n\geq 1$ and $f\in S_n$.
Keeping $f$ fixed we put $\beta_p=\beta_p(f)$
to simplify notations. The result in ¤ 7.A   shows that the
$\beta$-numbers are non-decreasing. i.e. we have
\[ 
1=\beta_0\leq\beta_1\leq \ldots\leq \beta_{n+1}\tag{*}
\]

Define the complex Laplace transform
\[ 
\Phi(z)=\int_0^1\, e^{-zt}f(t) dt
\]
Since $f$ is $n$-flat at the end-ponts, 
integration by parts $p$ times  gives:

\[
 \Phi(z)=z^{-p}\int_0^1\, e^{-zt}\cdot \partial^p(f^2)(t) dt\quad\colon\quad 1\leq p\leq n+1
\]
where
$\partial^p(f^2)$ is the derivative of order $p$ of $f^2$.
Now we  study the absolute value of $\Phi$ on the vertical
line $\mathfrak{Re}(z)=-1$. 
To each $1\leq p\leq n+1$
we have
\[
\partial^p(f^2)=\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}\cdot
f^{(\nu)}\cdot f^{(p-\nu)}\tag{1}
\]
Since $|e^{t-iyt}|= e^t$
for all $y$, the triangle inequality gives

\[ 
|-1+iy|^p\cdot |\Phi(-1+iy)|\leq
\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}\cdot
\int_0^1\, e^t\cdot |f^{(\nu)}(t)|\cdot |f^{(p-\nu)}(t)|\cdot dt\tag{2}
\]
Now we use that $e^t\leq e$ on $[0,1]$ and apply the 
Cauchy-Schwarz inequality which gives
by the definition of the $\beta$-numbers give:
\[
|-1+iy|^p\cdot |\Phi(-1+iy)|\leq e\cdot 
\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}\cdot
\beta_\nu^\nu\cdot \beta_{p-\nu}^{p-\nu}\tag{3}
\]
From (*) it follows that
$\beta_\nu^\nu\cdot \beta_{p-\nu}^{p-\nu}\leq \beta_p^p$
for each $\nu$ and since
$\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}=2^p$ we obtain
\[
|-1+iy|^p\cdot |\Phi(-1+iy)|\leq e\cdot 2^p\cdot \beta_p^p\tag{4}
\]
Passing to the logarithm we get
\[
\log\, |\Phi(-1+iy)|\leq 1+p\cdot \log\,\frac{2\beta_p}{|-1+iy|}\tag{5}
\]
Here (5) holds when $1\leq p\leq n+1$ and 
the assumption that $\beta_0=1$ also gives
\[
\log\, |\Phi(-1+iy)|\leq 1\tag{6}
\]

\noindent
{\bf{The $\omega$-function}}.
To each $1\leq p\leq n+1$
we find a positve number $y_p$ such that

\[
|-1+iy_p|=2e\beta_p
\]
Now we define a function $\omega(y)$ where
$\omega(y)=0$ when $y<y_1$ and
\[
\omega(y)=p\quad\colon\quad y_p\leq y<y_{p+1}
\]
and finally $\omega(y)=n+1$ when $y\geq y_{n+1}$.
From this  (5-6) give
the inequality
\[
\log\,|\phi(-1+iy)|\leq 1-\omega(y)\tag{7}
\]
for all $-\infty<y<+\infty$.

\medskip

\noindent
\emph { A harmonic majorisation.}
With $1-\omega(y)$ as boundary function in the half-plane
$\mathfrak{Re}(z)>-1$
we construct the harmonic extension $H(z)$
where Poisson's formula in a half-plane  gives:

\[ 
H(0)=
\frac{1}{\pi}\int_{-\infty}^\infty\, \frac{1-\omega(y)}{1+y^2}\cdot dy
\]
Since the function $\log\,|\Phi(z)|$ is subharmonic in this half-plane
it follows from (7) that

\[
0=\log|\Phi(0)|\leq H(0)
\]
We conclude that
\[
\int_{-\infty}^\infty\, \frac{\omega(y)}{1+y^2}\cdot dy
\leq \pi\tag{8}
\]
Now $\omega(y)=0$ when $y\leq y_1$
and hence (8) gives the inequality
\[
\int_{y_1}^\infty\, \frac{\omega(y)}{y^2}\cdot dy
\leq \frac{y_1^2}{1+y_1^2}\cdot \pi\tag{9}
\]
Next, by the construction of the $\omega$-function we have the equality
\[
\int_{y_1}^\infty\, \frac{\omega(y)}{y^2}\cdot dy
=\frac{1}{y_1}+\ldots+\frac{1}{y_{n+1}}\tag{10}
\]
\medskip

\noindent
Next, the construction of the $y_p$-numbers entail that
$y_p\leq 2e\beta_p$ so (9-10) 
give
\[
\frac{1}{\beta_1}+\ldots+\frac{1}{\beta_{n+1}}\leq
2e\pi\cdot  
\frac{1}{1+\frac{1}{y_1^2}}\tag{11}
\]

\noindent
Finally, we have $1+y_1^2=4e^2\beta_1^2$ and by 7:A below
we  have
$\beta_1\geq \pi$ which gives
\[
\frac{1}{1+\frac{1}{y_1^2}}\leq
1+\frac{1}{4\pi^2e^2-1}\tag{12}
\]
Now (11-12) give the requested inequality in Theorem 1.
\bigskip

\noindent {\bf 7.A.}
The proof above used an elementary
result which asserts
that the
$\beta$-sequence increases when $f\in\mathcal S_n$. To see this, 
let $1\leq p\leq n-1$ and  a partial integration gives:
\[ 
\beta_p^2=\int_0^1\, f^{(p-1)}(t)f^{(p+1)}(t)\,dt
\]
The Cauchy-Schwarz inequality gives
\[ 
\beta_p^2\leq \beta_{p-1}\beta_{p+1}
\]
By an induction over $p$ it follows that
$\beta_1\leq\ldots\leq \beta_n$ provided that we prove the inequality
\[
\beta_0^2=
\int_0^1\, f(t)^2\,dt\leq \beta_1^2\tag{*}
\]
Here (*)
follows easily by regarding
Fourier's  development of    $f$  into a sine series
$\sum\, a_\nu\cdot \text{sin}(\nu\pi t)$
and shows that equality in (*) only occurs when
$f(t)= \sin(\nu\pi t)$.

















\newpage

\centerline{\bf  8. Carleman's inequality for
inverse Fourier transforms in $ L^2({\bf{R^+}})$.}
\bigskip

\noindent {\bf Introduction.}
By Parsevel's theorem the Fourier transform sends $L^2$-functions 
on the $\xi$-line to $L^2$-functions on the $x$-line.
We  shall determine the class of non-negative $L^2$-functions $\phi(x)$
such that there exists
an $L^2$-function $F(\xi)$ supported by the half-line  $\xi\geq 0$ and
\[ 
\phi(x)=\bigl|\,\int_0^ \infty\,
e^{ix\xi}\cdot F(\xi)\cdot d\xi\bigr|\tag{*}
\]
\medskip

\noindent
The theorem  below was proved in [Carleman].
Apart from  applications  to 
quasi-analytic functions this result   has several
other consequences which  are put forward by
Paley and Wiener in   [Pe-Wi].
\bigskip

\noindent
{\bf Theorem 8.1.} \emph{An $L^2$-function $\phi(x)$
satisfies (*) if and only if}
\[
\int_{-\infty}^\infty\, \log^+\bigl [\,\frac{1}{\phi(x)}\,\bigr ]
\cdot \frac{dx}{1+x^2}<\infty
\]


\noindent
{\bf 8.2 Remark.}
Theorem 8.1 means that
$\phi(x)$ in the average cannot be too small when (*) holds.
In addition one has the
inequality (ii) below.
Namely, suppose that $F(\xi)$ satisfies the 
weighted mean-value equality
\[ 
\int_0^\infty\, F(\xi)\cdot e^{-\xi}\ d\xi=1\tag{i}
\]
The proof of Theorem 8.1 will show that when $\phi(x)$ is defined by (*)
then 
\[
\int_{-\infty}^\infty\, \log^+\bigl [\,\frac{1}{\phi(x)}\,\bigr ]
\cdot \frac{dx}{1+x^2}\leq 
\int_{-\infty}^\infty\, \frac{\phi(x)^2}{1+x^2}\cdot dx\tag{ii}
\]
\medskip










\centerline
{\emph{Proof of Theorem 8.1}}
\bigskip

\noindent
First we prove the suffiency.
Let  $\phi(x)$ be  a non-negative  $L^2$-function where the  integral  
in Theorem 8.1 is finite. Then
there exists  the harmonic extension of
$\log\,\phi(x)$ to the upper half-plane;
\[
\lambda(x+iy)=\frac{y}{\pi}\cdot 
\int_{-\infty}^\infty\, \frac{\log\,\,\phi(t)}{(x-t)^2+y^2}\cdot dt
\quad\colon\, y>0\tag{1}
\]


\noindent Let $\mu(z)$ be the conjugate harmonic function of
$\lambda$ and set
\[
h(z)=e^{\lambda(z)+i\mu(z)}\tag{2}
\]


\noindent
Fatou's theorem gives  for almost every $x$ 
a limit
\[
\lim_{y\to 0}\,\lambda(x+iy)=\log\,\,\phi(x)\tag{3}
\]
Or, equivalently
\[
\lim_{y\to 0}\,|h(x+iy)|=\phi(x)\tag{4}
\]


\noindent
From (1) and the fact that the geometric mean value of positive numbers
cannot exceed their arithmetic mean value, one has
\[
\bigl |h(x+iy)\,\bigr |= e^{\lambda(x+iy)}\leq\frac{y}{\pi}\cdot
\int_{-\infty}^\infty\, \frac{\phi(t)}{(x-t)^2+y^2}\cdot dt
\quad\colon\, y>0\tag{5}
\]


\noindent
Then (5) the Schwarz inequality give:
\[
\int_{-\infty}^\infty\, \bigl |h(x+iy)\,\bigr |^2\,dx\leq
\int_{-\infty}^\infty\, \bigl |\phi(x)\,\bigr |^2\,dx\quad\colon\, y>0\tag{6}
\]
Since $h(z)$ is analytic in the upper half-plane
it follows from (6) and Cauchy's formula that
if $\xi<0$, then the integrals
\[
 J(y)=
\int_{-\infty}^\infty\, h(x+iy)\cdot e^{-ix\xi+y\xi}\cdot dx\quad\colon\ y>0\tag{7}
\]
are independent of $y$. Passing to the limit as $y\to\infty$ and 
using the uniform upper bounds on the $L^2$-norms of 
the functions $h_y(x)\mapsto h(x+iy)$,
it follows that $J(y)$ vanishes identically.
So the Fourier transforms of
$h_y(x)$ are supported by $\xi\geq 0$ for all $y>0$.
Passing to the limit as $y\to 0$ the same holds for
the Fourier transform of $h(x)$. Finally (4) gives
\[
\phi(x)=|h(x)|\tag{8}
\]
By Parseval's theorem
$\widehat h(\xi)$ is an $L^2$-function and  we conclude that
$\phi(x)$ has  the requested form (*).


\bigskip







\noindent
{\emph{Necessity.}
Since $F$ is in $L^2$ there exists the Plancherel limit
\[ 
\psi(x)=\lim_{N\to\infty}
\,\frac{1}{2\pi}\cdot\int_0^N\,
e^{ix\xi}\cdot F(\xi)\, d\xi\,\tag{9}
\]
and in
the upper half plane we  get the analytic function
\[ 
\psi(x+iy)=
\,\frac{1}{2\pi}\cdot\int_0^\infty\,
e^{ix\xi -y\xi}\cdot F(\xi)\, d\xi\tag{10}
\]



\noindent
When $F(\xi)$ satisfies (i) in the remark after Theorem 8.1
we have:
\[ 
\psi(i)=1
\]
Consider the conformal map from the upper half-plane into the unit disc where
\[ 
w=\frac{z-i}{z+i}
\]
Here  $\psi(x)$ corresponds to a function
$\Phi(e^{is})$ on the unit circe $|w|=1$ and:
\[ 
\int_{-\pi}^\pi\, |\Phi(e^{is})|^2 \, ds=
2\cdot\int_{-\infty}^\infty\,\frac{|\phi(x)|^2}{1+x^2}\, dx\tag{11}
\]


\noindent
Similarly let $\Psi(w)$ be the analytic function in
$|w|<1$ which corresponds to $\psi(z)$. From (10-11)  it follows that
$\Psi(w)$ is the Poisson extension of $\Phi$, i.e.
\[ 
\Psi(w)=
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \,\frac{1-|w|^2}{
|e^{is}-w|^2}\cdot \Phi(e^{is})\cdot ds\tag{12}
\]
If $0<r<1$ it follows that
\[
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \log^+\,|\Psi(re^{is}|\cdot ds\leq
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \bigl |\Psi(re^{is}\bigr |^2\cdot ds\leq
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \Phi(e^{is}|^2\cdot ds\tag{13}
\]


\noindent 
Now  (12) gives:
\[
\lim_{r\to 1}\,\Psi(re^{is})=\Phi(e^{is})\quad\colon\,
\text{almost everywhere}\quad 0\leq s\leq 2\pi\tag{14}
\]


\noindent 
Next, since
$\psi(i)=1$ we have  $\Psi(0)=1$ which
gives the inequality
\[
\int_{-\pi}^\pi\, \log^+\frac{1}{\,|\Psi(re^{is}|}\cdot ds\leq
\int_{-\pi}^\pi\, \log^+\,|\Psi(re^{is}|\cdot ds\quad\colon 0<r<1\tag{15}
\]


\noindent
By (13-15) a passage to the limit as $r\to 1$ gives
\[
\int_{-\pi}^\pi\, \log^+\frac{1}{\,|\Phi(e^{is}|}\cdot ds\leq
\int_{-\pi}^\pi\, \bigl |\,\Phi(e^{is}\bigr |^2\cdot ds\tag{16}
\]
\medskip

\noindent
Returning to the real $x$-line we get the inequality (ii)
in   Remark 8.2  which at the same time finishes the proof of Theorem 8.1.


\newpage

\centerline{\bf{9. An integral equation.}}
\medskip


\noindent
Let $f(x)$ be an $L^1$-function on the real $x$-line where
the zeros of $\widehat f$ is a discrete subset 
$\{\alpha_\nu\}$
of ${\bf{R}}$ and enumerated so that their 
absolute values are non-decreasing.
Consider the set of all $L^\infty$-functions $\phi(x)$ which
satisfy the convolution equation
\[ 
f*\phi(x)=\int\, f(x-y)\phi(y)dy=0\quad\colon\,-\infty<x<+\infty\tag{*}
\]
The exponential functions $\{e^{-i\alpha_\nu x}\}$
give  solutions to (*) for every zero of $\widehat f$.
More generally an exponential polynomial
\[
P(x)=\sum c_\nu\cdot e^{-i\alpha_\nu x}
\]
solves (*).
It turns out that these exponential polynomials 
is a dense subset of all $L^\infty$-solutions to (*).
\medskip

\noindent
{\bf{9.1 Theorem.}} \emph{To every $L^\infty$-solution $\phi$
there exists a sequence of exponential solutions
$\{P_N(x)\}$ such that
$\lim_{N\to \infty} P_N(x)=\phi(x)$ holds almost everywhere
where $\{P_N\}$ can be chosen so that
their maximum norms over the whole $x$-line satisfy}
\[ 
||P_N||_\infty\leq ||\phi||_\infty
\]

\bigskip

\noindent
The crucial point in the subsequent proof 
is to use the local invertibility for $L^1$-functions whose
Fourier transforms are $\neq 0$ over open intervals on
the $\xi$-line.
To begin with the $L^\infty$-function $\phi$ 
which solves (*) is a tempered
distribution on the real $x$-axis.
Since $\phi$ is not integrable we cannot
find its Fourier transform in an explicit way.
But the following holds:

\medskip

\noindent
{\bf{9.2 Proposition.}}
\emph{The support of $\widehat\phi$
is contained in the discrete set
$\{\alpha_\nu\}$.}
\medskip

\noindent
\emph{Proof.}
Let $J=(a,b)$ be an open interval on the $\xi$-axis
where $\widehat {f}(\xi)$ has no zeros on the closed interval $[a,b]$.
The result in XX about the Banach algebra $L^1({\bf{R}}$
gives  an $L^1$-function $g$ such that

\[ 
\widehat g(\xi)\cdot\widehat f(\xi)=1\quad\colon\,\, a\leq\xi\leq b
\]
Next, consider some  $\psi\in\mathcal S$
whose Fourier transform
$\widehat\psi$ has support 
contained in $[a,b]$.
Now we take  the convolution
$\psi*g*f$ in $L^1$ whose 
Fourier transform becomes
\[
\widehat\psi\cdot \widehat g\cdot \widehat f=\widehat\psi
\]
Since $f*\phi=0$ it follows that
$\psi*g*f*\phi=0$ and hence also $\psi*\phi=0$.
Now $\phi$ belongs to $\mathcal S$
and the space of tempered distributions
is a module over
$\mathcal S$. So in the space of tempered distributions on the
$\xi$-line there exists  the product $\widehat\psi\cdot \widehat\phi$
and the vanishing of the convolution $\psi*\phi$ on the
$x$-line entails that
$\widehat\psi\cdot\widehat \phi=0$.
Above  $\widehat\psi(\xi)$ can be taken as an arbitrary test-function in
$C_0^\infty(a,b)$. It follows that
the support of the distribution $\widehat\phi$
does not intersect the open interval $(a,b)$.
Since $(a,b)$ can be an arbitrary
interval in the complement of the discrete
set of zeros  Proposition 9.2 follows.
\bigskip

\noindent
Proposition 9.2 shows that $\widehat\phi$ is a sum of Dirac distributions
at points from the discrete set $\{\alpha_\nu\}$.
Let us show that every
such Dirac distribution has order zero, i.e. of the form
$c\cdot \delta_{\alpha_\nu}$ for some constant $c$.
To prove this we consider some  $\alpha_\nu$ and choose
$\psi(x)\in\mathcal S$ such that
its Fourier transform a  $\hat \psi(\xi)$ is a test-function which
is identically
one in a small neighborhood of $\alpha_\nu$ while its support does not
contain any other zero.
Now the distribution
\[ 
\hat\psi\cdot\hat\phi=\rho_\nu\tag{i}
\] 
where $\rho_\nu$ is the Dirac distribution determined by
$\hat\phi$ at $\alpha_\nu$.
At the same time (i)
is  the Fourier transform
of
$\psi*\phi$ which is 
a bounded function on the $x$-line, Namely, by the
the $L^1$-norm of
$\psi$ times the sup-norm of $\phi$.
Hence the inverse Fourier transform of the Dirac distribution $\rho_\nu$
is a bounded function on the $x$-line. But this can only occur if
$\rho_\nu$ has order zero.
\medskip

\noindent
\emph{Summing up} we have proved the following:
\medskip

\noindent
{\bf 9.3 Proposition.}}
\emph{The Fourier transform $\widehat\phi$ is given by:}
\[
\widehat\phi=\sum\, a_\nu\cdot \delta_{\alpha_\nu}
\]
\medskip
\emph{where $\{a_\nu\}$ is some sequence of complex numbers.}


\noindent
{\bf{Remark.}}
By Fouriers inversion the $a$-numbers 
are determined via
the equations

\[ 
\sum \, a_\nu\cdot\widehat g(\alpha_\nu)=
\frac{1}{2\pi}\,\int
\phi(x)\cdot g(-x)dx\quad\colon\, g\in\mathcal S
\]
The right hand side is defined for every $L^1$-function.
So  if the maximum norm
$||\phi||_\infty=1$
then the series
\[
 \sum\, a_\nu\cdot \widehat g(\alpha_\nu)
\] 
converges for every 
$L^1$-function $g$ and the absolute value of the
sum is $\leq ||g||_1$.
\medskip

\noindent{\bf{9.4 Approximation by exponential solutions.}}
At this stage we can finish the proof of Theorem 9.1.
First, fix some non-negative function 
$g\in\mathcal S$ such that $\widehat g(\xi)$ is a test-function and
$\hat g(0)=1$.
If $N\geq 2$ we set $g_N(x)=Ng(Nx)$ which gives
\[ 
\widehat g_N(\xi)=\widehat g(\xi/N)
\]
Next,  the Fourier transform of the convolution
$g_N*\phi$ is equal to 
\[ 
\widehat g_N(\xi)\cdot \widehat\phi(\xi)
\]
Since $\hat g_N$ has compact support the left hand side is a finite sum
\[ 
\sum\, \hat g_N(\alpha_\nu)\cdot a_\nu\cdot \delta_{\alpha_\nu}
\]
This gives the exponential polynomial
\[ 
P_N(x)= (g_N*\phi)(x)= 
\frac{1}{2\pi}\cdot \sum\, \widehat g_N(\alpha_\nu)\cdot a_\nu\cdot
e^{i\alpha_\nu x}
\]


\noindent 
Finally, by 
Lebesgue's theorem shows that
\[
 \lim_{N\to\infty}\, P_N(x)=\phi(x)
\] 
holds almost everywhere. For the maximum norms we get
\[ 
||P_N||_\infty\leq |g||_1\cdot ||\phi||_\infty
\]
and Theorem 9.1 follows since
since $||g||_1=\widehat g(0)=1$.




\newpage

\centerline{\bf{10. Spectral synthesis.}}
\bigskip

\noindent
The subsequent material comes from Beurling's article [Beur] 
presented 
in 1938 at the Scandinavian Congress
in Helsinki.
For each  pair $g\in L^1({\bf{R}})$ and
$\phi\in L^\infty({\bf{R}})$ the convolution
\[
g*\phi(x)= \int\, g(x-y)\cdot \phi(y)\cdot dy
\] 
yields a bounded and continuous function whose maximum norm
is majorised by $||g||_1\cdot ||\psi||_\infty$.
So each  $\phi(x)$ gives  an ideal 
in the convolution algebra $L^1({\bf{R}})$:
\[
 J_\phi=\{ f\in L^1({\bf{R}}\quad\colon\, f*\phi=0\}
\]



\medskip

\noindent
{\bf{10.1 Definition.}}
\emph{The set of common zeros of Fourier transforms of 
functions in $J_\phi$ is denoted by $\sigma(\phi)$ and called the spectrum
of $\phi$.}
\medskip

\noindent
The spectrum is non-empty unless $\phi=0$.
For if $\sigma(\phi)=\emptyset$ then
the result from XXX shows that the closed ideal  $J_\phi=
L^1({\bf{R}})$ and since $L^\infty({\bf{R}})$
is the dual space of $L^1$  we get  $\phi=0$.
\medskip


\noindent
{\bf{Exercise.}}
Show that $\sigma(\phi)$ is equal to the support of
the temperate distribution $\widehat\phi$.
The hint is to use the fact that the inverse Fourier transform 
of every test-funtion on the $\xi$-line is an $L^1$-function on the $x$-line.







\medskip

\noindent
{\bf{10.2 The spectral synthesis problem.}}
\emph{Let $f\in L^1({\bf{R}})$ be such that $\widehat f(\xi)=0$ on
$\sigma(\phi)$. Does this imply that $f\in J_\phi$.}
\medskip

\noindent
In general the answer is negative, i.e. there exist
$\phi$-functions for which the spectral synthesis fails.
See XXX (??).
But if $\sigma(\phi)$ satisfies a certain topological condition 
the spectral synthesis holds.
A closed set $K$ without interior  points on the real
$\xi$-line  is called  perfect
if the closure of $K\setminus\{p\}$ is equal to $K$ for
every $p\in K$.
So if $F$ is a closed set with empty interior which does not
contain any perfect subset, then $F$ must contain at least one
isolated point. 
This  property was used in [Beu] to establish the following:

\bigskip

\noindent
{\bf{10.3 Theorem.}}
\emph{Let $\phi\in L^\infty({\bf{R}})$
be such that the boundary of $\sigma(\phi)$ does not contain
any perfect subset. Then spectral synthesis holds for the ideal $J_\phi$.}
\medskip

\noindent
Before the proof of Theorem 10.3 
we establish a result of independent interest.
\medskip

\noindent
{\bf{10.4 Theorem.}}
\emph{Consider a pair 
$\phi\in L^\infty({\bf{R}})$ and
$h\in L^1({\bf{R}})$. Let  $a$ be a real number such that
the Fourier transform $\widehat h(a)=0$. Then
the Fourier transform 
of $h*\phi$ cannot be a constant times
the  Dirac measure $\delta_a$ unless $h*\phi$ is identically zero.}
\medskip

\noindent
\emph{Proof.}
Replacing $h$ by  $e^{-iax}\cdot h(x)$
we may take $a=0$.
So now   $\widehat h(0)=0$ and we 
argue by a contradiction.
Thus, suppose
that
the Fourier transform of $h*\phi$ is $c_0\cdot \delta_0$ for some
constant $c_0\neq 0 $. 
We shall prove that this is imposssible.
The vanishing $\widehat h(0)=0$
and  the result in ¤ XX 
gives a sequence $\{g_N\}$ in $\mathcal S$ such that $\widehat g_N(0)=0$
for all $N$ and at the same time:
\[
\lim_{N\to\infty}\, ||g_N*h-h||_1=0\tag{i}
\]
Next, since every $g_N\in\mathcal S$ we get
\[
\widehat{g_N*h*\phi}=\widehat g_N\cdot\widehat{h*\phi}=
\widehat g_N\cdot c_0\cdot \delta_0=0
\]
where the last equality holds since $\widehat g_N(0)=0$.
Hence  the convolutions $g_N*h*\phi=0$ for all $N$.
Finally, since $\phi\in L^\infty$
(i) would give   $h*\phi=0$ which contradicts
the hypothesis that
the Fourier transform is a non-zero constant times
$\delta_0$.






\bigskip



\noindent
\emph{Proof of Theorem 10.3.} 
Let $f$ be an $L^1$-function such that $\widehat f=0$ on $\sigma(\phi)$.
We must prove that $f*\phi=0$.  Assume the contrary and put
$\psi=f*\phi$. 
One has the inclusion
\[
\sigma(\psi)\subset\sigma(\phi)\tag{1}
\]
Indeed, this follows since the commutative law for convolutions
imply that 
$h\in J_\phi$ gives $h*(f*\phi)= f*(h*\phi)=0$. 
Hence $J_\phi\subset
J_\psi$ and (1) follows. Next  we shall improve (1) and establish the inclusion

\[
\sigma(\psi)\subset\partial(\sigma(\phi))\tag{2}
\]
To prove (2) may assume that the interior of
$\sigma(\phi)\neq\emptyset$
and let 
$(a,b)\subset\sigma(\phi)$ be an open interval.
To every $\rho(\xi)\in C_0^\infty(a,b)$
the inverse Fourier transform is an $L^1$-function which we denote by $\rho_*$.
Since $\hat f=0$ on $\sigma(\phi)$ we get $\rho\cdot \widehat f=0$
which entails $\rho_**f=0$ and then
\[
0=(\rho_**f)*\phi=\rho_**(f*\phi)= \rho_**\psi\implies \rho  \cdot \widehat\psi=0
\]
where  the last product is defined since
$\hat \psi$ is a tempered distribution on the $\xi$-line while $\rho$
is a test-function so we can use  that $\mathcal S^*$ is 
a module over the space of test-functions.
Since  $\rho\in C_0^\infty(a,b)$ was
arbitrary we conclude that
the support of $\hat\psi$ does not intersect $(a,b)$, and
since $(a,b)$ was an arbitrary interval of the interior of
$\sigma(\phi)$  (2) follows from Exercise 1.
\medskip

\noindent
Next, (2) and the hypothesis on the topology of $\partial\sigma(\phi)$
imply that $\sigma(\psi)$ contains at least one isolated point $a$.
Choose a test-function $\rho(\xi)$
which is identically one in a small neighborhood of $a$
while the support of $\rho$ has empty intersection with the rest
of
$\sigma(\psi)$.
Then the support of the tempered distribution $\rho\cdot \hat\psi$
is reduced to $\{a\}$.
Let  $g$ be the inverse Fourier transform of
$\rho$ so that
$\rho\cdot \hat\psi$ is the Fourier transform of $g*\psi$.
Here $g*\psi$ is a bounded continuous function and
exactly as in the proof of Theorem  10.4 we conclude that
the Dirac distribution defined by
$\rho\cdot \hat\psi$ can only be a constant times $\delta_a$.
This means that
\[ 
g*\psi(x)= c_0\cdot e^{aix}
\] 
Let us then consider the $L^1$-function $h=g*f$.
Since $\hat f=0$ holds on $\sigma(\phi)$ we have
$\hat h(a)=0$. At the same time:
\[ 
h*\phi(x)= c_0\cdot e^{aix}\quad\text{where}\quad c_0\neq 0\tag{*}
\]
But this contradicts the result in Theorem 10.4 and
Theorem 10.3 is proved.




 







\newpage





\centerline{\bf{11. On inhomogeneous $\bar\partial$-equations.}}
\bigskip


\noindent
Recall  that $L^1({\bf{R}}^2)$ is a convolution algebra, i.e.
for a pair of $L^1$-functions $f(x,y)$ and $g(x,y)$
one defines
\[ 
f*g(x,y)= \iint f(x-s,y-t)g(s,t)dsdt\tag{1}
\]
The convolution is commutative and satisfies the associative law.
Next, given some $L^1$-function $f(x,y)$ there exists
the \emph{distribution derivatives}}
$\partial_x(f)$Êand $\partial_y(f)$.
We shall impose the condition that these distribution derivatives are
bounded measurable functions, i.e. both belong to
$L^\infty({\bf{R}}^2)$.
\medskip


\noindent
{\bf{Exercise.}}
Recall that $L^\infty({\bf{R}}^2)$
is the dual space of 
$L^1({\bf{R}}^2)$. Use this and  the
definition of distribution derivatives to conclude that
$\partial_x(f)\in L^\infty({\bf{R}}^2)$
if and only if there to every compact set $K$ in
${\bf{R}}^2$ exists a constant $C_K$ such that
\[
\bigl|
 \iint f(x,y)\cdot\partial_x(g(x,y)\cdot dxdy\leq
 C_K\cdot ||g||_1
 \] 
 for every test-function $g(x,y)$ whose support is contained in $K$.
\medskip


\noindent
Next, let $f$ be a complex valued function $L^1$-function
with compact support.
With $\bar\partial=\frac{1}{2}(\partial_x+i\partial_y)$
we get the distribution 
\[
\bar\partial (f)=\frac{1}{2}\bigl(
\partial _x(f)+
i\partial_y (f)\bigr)
\]


\noindent 
{\bf{11.1 Theorem.}}
\emph {The inclusion $\bar\partial(f)
\in L^\infty({\bf{R}}^2)$ implies 
that  $f$ is a continuous function
whose modules of continuity is bounded
by $C\cdot\delta\cdot \log\,\frac{1}{\delta}$
for a  constant $C$ which only depends on the size of the support of $f$.}


\medskip

\noindent
\emph {Proof}
Recall  that
\[
 \bar\partial(\frac{1}{z})=2\pi i\cdot \delta_0\tag{i}
 \]

\noindent
Hence the hypothesis
that $\bar\partial(f)\in
L^\infty({\bf{R}}^2)$ gives:
\medskip


\noindent
\emph{Sublemma.}
\emph{One has the equality:}
\[
2\pi if=\frac{1}{z}*\bar\partial(f)
\]
\emph{where the right hand side is the  convolution of
$\frac{1}{z}$ and the $L^\infty$-function
$\bar\partial(f)$ and the equality holds in $L^1$.}

\medskip

\noindent
\emph{Proof continued.}
Set $g=\bar\partial(f)$.
Given a pair of points $z_1,z_2$ in the complex plane
we get
\[ 
|f(z_2)-f(z_1)|\leq\frac{1}{2\pi}\cdot
\bigl | \iint\,
\bigl[ \frac{1}{z-z_1}-
\frac{1}{z-z_2}\bigr ]\cdot g(z)dxdy\,\bigr|\leq
\]
\[
\frac{||g||_\infty}{2\pi}\cdot  \iint_K\,
\bigl| 
\frac{1}{z-z_1}-
\frac{1}{z-z_2}\bigr |\cdot dxdy
\]
where $K$ is the compact support of $f$.
There remains  to estimate the double integral.
Suppose for example that
$K$ is contained in
the disc $D_R$ of radius $R$ centered at the origin.
Given a pair of distinct points $z_1,z_2$
in this disc we notice that
\[
\frac{1}{z-z_1}-
\frac{1}{z-z_2}=\frac{z_2-z_1}{
(z-z_1)(z-z_2)}
\]
With $\delta=|z_1-z_2|$
Theorem 11.1 follows if we find a constant $C$ such that
\[
\iint_{D_R}\, \frac{dxdy}{|z-z_1|\cdot|(z-z_2|}
\leq C\cdot\text{Log}\,\frac{1}{\delta}\tag{*}
\]
The verification of (*) is left as an exercise  to the reader.


\newpage

\centerline{\bf{12. Some integral equations.}}
\bigskip



\noindent{\bf{A. Planck's equation.}}
Following  [Paley-Wiener. page 40 ] we  recall
the physical background for the integral equation in (*) below.
By Planck's law the radiation per unit volume in a black cavity at temperature
$T$ in a state of steady equilibrium and of frequency between
$\nu$ and $\nu+d\nu$ is given by
\[ 
\frac{8\pi\cdot h\nu^3}{c^3(e^{\frac{h\nu}{kT}}-1}\cdot d\nu\tag{1}
\]
Here $h$ is Planck's constant, $c$  the velocity of light and $k$
the gas constant reckoned for one molecule.
This suggests that the radiation from a source in approximative local equilibrium
but consisting of a mixture of black bodies
of different temperatures, will have a distribution
as a function of $\nu$ given by
\[
\nu^3\cdot \int_0^\infty\, \frac{\phi(T)\cdot dT}{e^{\frac{h\nu}{kT}}-1}\cdot\tag{2}
\]
where $\phi(T)$ represents  the
amount of radiation
coming from black bodies at temperature $T$.
If then, we have an observable radiation with frequency distribution
$\psi(\nu)$, the problem of resolving this
into its constituent black-body radiations is equivalent to the 
solution of the equation:





\[ 
\psi(\nu)=\nu^3\cdot\int_0^\infty\, 
\frac{\phi(T)\cdot dT}{e^{\frac{h\nu}{kT}}-1}\cdot\tag{*}
\]
Following [Paley-Wiener] we show how to  find
$\phi$ for a given $\psi$-function.
Set
\[
\mu=\frac{h}{kT}\quad\colon\, \quad \phi(T)\cdot dT=\Phi(\mu)\cdot d\mu\quad\colon
\quad \frac{\psi(\nu)}{\nu^2}= \Psi(\nu)
\]
Then (*) assumes the form:
\[
\Psi(\nu)= \int_0^\infty\, \Phi(\mu)\cdot 
\frac{\mu\nu}{e^{\mu\nu}-1}\cdot d\mu\tag{**}
\]


\noindent
Above $\Psi$ and $\Phi$ are  defined on ${\bf{R}}^+$ and
recall that on the  multiplicative
group of positive real numbers with
coordinate $\mu$
the invariant Haar measure is
$\frac{d\mu}{\mu}$. Impose the $L^2$-condition:
\[
\int_0^\infty\, |\Psi(\nu)|^2\cdot \frac{d\nu}{\nu}<\infty\tag{iii}
\]
When (iii) holds we seek an $L^2$-function
$\Phi(\mu)$ on the
multiplicative $\mu$-line such that (ii) holds.
\medskip

\noindent
{\bf{Solution.}}
The idea is to  express (**) in terms of Fourier transforms of
$\Psi$ and $\Phi$.
First $\Psi$ yields the $L^2$-function defined on the real $x$-line by
\[ 
\widehat\Psi(x)=
\frac{1}{\sqrt{2\pi}}\cdot
\lim_{\epsilon\to 0}\,
\int_\epsilon^{1/\epsilon}
\Psi(\nu)\cdot \nu^{(ix-1/2)}\cdot d\nu\tag{2}
\]
\medskip

\noindent
Inserting this in (**)
we are led to evaluate the integral below when $\mu>0$
and $x$ a real number:
\[
\lim_{\epsilon\to 0}\,
\int_\epsilon^{1/\epsilon}
\frac{\mu\nu}{e^{\mu\nu}-1}\cdot \nu^{(ix-1/2)}\cdot d\nu\tag{3}
\]
Set
\[ J(x)=
\lim_{\epsilon\to0}\,
\int_\epsilon^{1/\epsilon}
\frac{s}{e^s-1}\cdot s^{(ix-1/2)}\,ds
\]

The substitution $\mu\cdot \nu=s$ shows that  (3) becomes
\[
\lim_{\epsilon\to0}\,
\int_\epsilon^{1/\epsilon}
\frac{s}{e^s-1}\cdot (s/\mu)^{(ix-1/2)}\cdot \frac{ds}{\mu}\tag{4}
=\mu^{-ix-1/2}\cdot J(x)
\]
\medskip


\noindent
If $\Phi\in L^2({\bf{R}}^+)$
its normalised Fourier transform on the real $x$-line is given by:
\[ 
\widehat\Phi(x)=\frac{1}{\sqrt{2\pi}}\cdot 
\lim_{\epsilon\to0}\,
\int_\epsilon^{1/\epsilon}
\Phi(\mu)\cdot \mu^{(ix-1/2)}\cdot d\mu\tag{5}
\]
\medskip

\noindent
With these notations it is clear that 
the equation (**) holds if
\[
\widehat \Phi(-x)=\frac{\widehat \Psi(x)}{J(x)}
\]
The  requested $L^2$-solution $\Phi$ therefore exists
if
\[
|J(x)|\geq c
\]
 hold for some positive constant
$c$ and all real $x$.
This turns out to be true.
More precisely, the crucial formula which by the above
solves  Planck's equation
is as follows:

\medskip

\noindent{\bf{12.A.2 Theorem.}}
\emph{One has the equation}
\[
J(x)= 
\Gamma(\frac{3}{2}-ix)\cdot
\zeta(\frac{3}{2}-ix)
\]
\emph{where the last factor is Riemann's $\zeta$-function.}
\medskip

\noindent{\bf{Exercise.}}
Show the formula and conclude that
there exists a positive constant $c$ as above.







\bigskip



\centerline
{\bf{B. The Laplace equation}}
\medskip


\noindent
Let $f(x)$ be a function such that 
\[
\int_0^\infty\,|f(x)|^2\cdot dx<\infty\tag{1}
\]
This  gives  the analytic function
$G(u+iv)$ in the right half-plane defined by
\[
G(u+iv)=\int_0^\infty\, e^{-ux-ivx}\cdot f(x)\cdot dx\tag{*}
\]
Here  $G(iv)= \widehat f(v)$
so by Parseval's formula (1) entails  that $G$ extends to an $L^2$-function on
the imaginary axis.
Conversely, suppose we are given an analytic function
$G$ in the right half-plane where
$G(iv)$ is in $L^2$.
 Then we shal find an equatio of  its inverse Fourier transform
 $f(x)$
 expressed by the restriction of $G$ to the
 $\{ u>0\}$.
 This corresponds to the integral equation
\[ 
g(u)= 
\int_0^\infty\, e^{-ux}\cdot f(x)\cdot dx\tag{*}
\]
where $g(u)$ is defined when  $u>0$ and one seeks $f$ with
\[
\int_0^\infty\,|f(x)|^2\cdot dx<\infty\tag{1}
\]
The solution relies upon 
the following inversion formula  due to
Laplace.
Introduce the Laplace transform
\[
F(u+iv)= \int_0^\infty e^{-ux-ivx}\, f(x)\, dx
\]



\medskip

\noindent
{\bf{B.1 Theorem.}}
\emph{For each $L^2$-function $f$ supported by
$\{x\geq 0\}$ 
one has  the inversion formula}
\[ 
f(x)=\lim_{A\to\infty}\, \frac{1}{2\pi x}\int_0^\infty\, 
\rho_A(t)\cdot F(\frac{t}{x})\cdot \frac{dt}{\sqrt{t}}\quad
\text{where}\quad \rho_A(t)=
\int_{-A}^A\, \frac{t^{i\xi}\cdot d\xi}{\Gamma(i\xi+\frac{1}{2})}\tag{*}
\]
\medskip

\noindent
{\bf{Exercise.}} Prove  Laplace's inversion formula.
.




\bigskip

\noindent
{\bf{B.2 Widder's solution.}}
In the article \emph{The inversion of the Laplace integral and the
related moment problem}, D.V Widder
found an exceedingly simple method to solve 
the Laplace equation (*).
Consider first a bounded and continuous
function $f(x)$ defined on $x>0$.
Then it is clear that the $g$-function in (*) is infinitely differentiable on $u>0$ and
for every $n\geq 1$ we have
\[ 
(-1)^n\cdot g^{(n)}(u)=\int_0^\infty\, x^n\cdot e^{-ux}\cdot f(x) \,dx
\]



\noindent
With $x>0$ fixed we therefore get the following equality for every $n\geq 1$:
\[
\frac{(-1)^n}{n !}\cdot
 g^{(n)}(\frac {n}{x})\cdot\bigl(\frac{n}{x}\bigr)^{n+1}=
 \frac{
\int_0^\infty\, \xi^n\cdot e^{-n\xi/x}\cdot f(\xi) \,d\xi}
{\int_0^\infty\, \xi^n\cdot e^{-n\xi/x}\,  d\xi}\tag{1}
\]
\medskip


\noindent
{\bf{B.3 Exercise.}} Use the assumption that $f(x)$ is a bounded 
and continuous function on
$x>0$ to show that (1) gives the limit formula:
\[ 
f(x)=\lim_{n\to\infty}\, 
\frac{(-1)^n}{n !}\cdot
 g^{(n)}(\frac {n}{x})\cdot\bigl(\frac{n}{x}\bigr)^{n+1}
\]


\noindent
The hint is to use the functions
$\psi_n(x)=\frac{1}{n !}\cdot x^n\cdot e^{-x}$
which are all $\geq 0$ and the integral over $(0,+\infty)$ is one.
Here $\psi_n(x)$ takes its maximum when $x=n$.
Now we consider the functions
\[ 
\rho_n(x)=\frac{\psi_n(\frac{x}{n})}{n}
\]
Then the reader can verify that if $p(x)$ is an
arbitrary  bounded and continuous
function on
$x>0$, then 
\[ 
p(x)=
\lim_{n\to\infty}\, \frac{1}{n}\cdot
\int_0^\infty\,\psi_n(\frac{x}{n})
\cdot p(x)\cdot dx\quad\text{hold for every}\quad x>0
\]

\newpage


\centerline{\bf{13. The Carleman-Hardy theorem.}}


\medskip

\noindent
The proof of Theorem 0.3.7 from the introduction
relies upon
inequalities about differentiable functions.

\medskip


\noindent
{\bf{13.1 Lemma.}}
\emph{Let $\psi(x)$ be a $C^1$-function defined for $x>0$
such that}
\[
\lim_{x\to 0}\,\psi(x)=0\quad\text{and}\quad |\psi'(x)|\leq \frac{C}{x}\quad \colon
x>0
\] 

\noindent
\emph{holds for some constant $C$. Then it follows that}
\[ 
\lim_{x\to 0}\, x\cdot \psi'(x)=0\tag{*}
\]


\noindent 
The  proof is left as an exercise to the reader. See also
the article \emph{Contributions to the Arithmetic Theory of Series}
by Hardy and Littlewood for
further   limit formulas of
higher order derivatives.
Next we establish a 
result due to Landau
from  the article
\emph{Einige ungleichungen fŸr zweimal differentierbare Funktionen}.
\medskip

\noindent 
{\bf{13.2 Proposition.}}
\emph{Let $\psi(x)$
be a $C^3$-function defined on $x>0$ such that}
\[ 
\lim_{x\to 0} \,\frac{\psi(x)}{x^2}=0\quad\text{and}\quad |\psi'''(x)|\leq \frac{C}{x}
\tag{i}
\] 
\emph{hold for some constant  $C$.
Then it follows  that}
\[
\lim_{x\to 0} \,\psi''(x)=0\tag{ii}
\]



\noindent
\emph{Proof.} Let $x>0$ and set $\xi=\zeta\cdot x$ where $0<\zeta<1/2$.
Keeping these numbers fixed, Taylor's formula gives
\[
\psi(x+\xi)+\psi(x-\xi)-2\psi(x) =\xi^2\psi''(x)+
\frac{\xi^3}{6}\cdot [\psi'''(x+\theta_1\xi)-
\psi'''(x-\theta_2\xi)]\quad\colon\,0<\theta_1,\theta_2<1
\]

\noindent
The triangle inequality gives
\[
|\psi''(x)|\leq 
\]
\[
\frac{1}{\xi^2}\cdot [
|\psi(x+\xi)|+|\psi(x-\xi)|+2|\psi(x)|]+
\frac{\xi^3}{6}\cdot [\bigl(|\psi'''(x+\theta_1\xi)|+
|\psi'''(x-\theta_2\xi)|\bigr)\tag{2}
\]
By the second condition
in (i) the last term  above is majorised by

\[
\frac{C}{6}\cdot \xi\cdot (\frac{1}{x+\theta_1\xi}+\frac{1}{x-\theta-2\xi}]
\leq
\frac{C}{6}\cdot \frac{2\zeta}{1-\zeta}\tag{3}
\]
Given $\epsilon>0$ we can choose $\zeta$ 
so small that (3) is
$<\epsilon/2$.
Next,
keeping $\zeta$ fixed the first term in (2) above is majorised by
\[
\frac{1}{\zeta^2x^2}\cdot\bigl[
(1+\zeta)^2\cdot o(x^2)+
(1-\zeta)^2\cdot o(x^2)+2\cdot o(x^2)\bigr]\tag{4}
\]
where the small ordo terms follows from the first condition in (i).
Now  (ii) in Proposition  13.2  follows from the inequality (2) above.
\medskip




\noindent
{\bf{Proof of Theorem 0.3.7}}
Assume first that $\sum\, A_n$ converges  and
define the  following two functions  when $x>0$:
\[ 
U(x)=\frac{1}{2}A_0\cdot x^2+\sum_{n=1}^\infty\, \frac{A_n}{n^2}
\cdot(1-
\text{cos}(nx))\tag{i}
\]
\[ 
V(x)=\int_0^x\,\bigl[\int_0^y\,u(s)\cdot ds\,\bigr]\cdot dy\tag{ii}
\]
In (i) $U(x)$ is the associated Riemann function of $u$.
Since $u$ is of class $C^2$ when $x>0$ it is clear that
$U''(x)=V''(x)$ when $x>0$ and hence
$U(x)-V(x)$Êis a linear function $C+Dx$ on $(0,+\infty)$.
Since $u$ by assumption is an $L^1$-function we see that
$V(x)=o(x)$ and we also have $U(x)=o(x^2)$ 
by a classical result known as Riemann's Lemma.
It follows that $C=D=0$, i.e. the functions
$U$ and $V$ are identical which gives
\[ 
V(x)=o(x^2)
\]
Next, notice that
\[ 
x>0\implies V'''(x)=u'(x)\tag{ii}
\]
Now $|u''(x)|\leq \frac{C}{x^2}$ was assumed in 0.3.6 
which  gives another constant $C^*$ such that
$|u'(x)|\leq \frac{C^*}{x}$. Hence
(ii) implies 
that
$V$ satisfies the Landau conditions in Proposition 13.2  which gives:
\[ 
\lim_{x\to 0} V''(x)=0\tag{iii}
\]
Finally, since $V''(x)= u(x)$ holds when $x>0$ we conclude that
$\lim_{x\to 0}\, u(x)=0$. This proves one half of Theorem 0.3.7.
\medskip

\noindent
{\bf{The case $\lim_{x\to 0}\,u(x)=0$}}. 
When this is assumed there remains to
show
that
$\sum\, A_n$ converges. By assumption $|u''(x)|\leq \frac{C}{x^2}$
which gives a constantÊ$C^*$ such that
$|u'(x)|\leq \frac{C^*}{x}$ and   Lemma 13.1 gives
\[
u'(x)=0(x)\tag{i}
 \]

 \medskip
\noindent
Next, we use
a  result by Lebesgue from his book
\emph{Lecons des series trigonmŽtriquees} which asserts that the
series $\sum\, A_n$ converges if
\[
\lim_{\epsilon\to 0} 
\int_\epsilon^1\, \frac{|u(x+\epsilon)-u(x)|}{x}\cdot dx=0\tag{ii}
\]
To get (ii) we use Rolle's theorem and write
\[
u(x+\epsilon)-u(x)=\epsilon\cdot u'(x+\theta\cdot\epsilon)\tag{iii}
\]
Now it is clear that (i) and (iii) give (ii) which finishes the proof that
$\sum\,A_n$ is convergent.





\newpage
\centerline{\bf{14. The log-potential and the Abel\vvv Carleman inversion formula}}

\bigskip

\noindent
Let us first recall 
that Abel established a remarkable
inversion formula to express 
potential functions in 
$U(x)$ in
a conservative force field on the real line
in his article [Abel] from 1824.
Adopting Abel's formula, Carleman's 
article
\emph{Abelsche Integralgleichungen mit konstanten Integrationsgrenzen}
give inversion fromulas of a similar kind where
the integals are taken over a fixed interval.
\medskip


\noindent
First we consider the logarithmic potential.
For each  $g(t)\in L^1[0,1]$ we 
\[
T_g(x)= \int_0^1\log\,|x-t|\cdot g(t)\, dt\tag{1}
\]
\medskip

\noindent
The function $T_g(x)$ is restricted to $0<x<1$.
A notable fact due to Legendre
is the following inequality where
$||g||_1=\int_0^1\,|g(t)|\, dt$Êis the $L^1$-norm.


\medskip

\noindent
{\bf{14.0.Legendre's inequality.}}
\emph{There exists a constant $C$ such that}
\[
\int_0^1\, \frac{|T_g(x)|}{\sqrt{x(1-x)}}  \, dx\leq C\cdot ||g||_1\tag{*}
\]

\medskip

\noindent
\emph{Proof.}
A straightforward calculation shows that the function
\[ 
x\mapsto \int_0^1\,\log |x-t|\cdot \frac{1}{\sqrt {t(1-t)}}\cdot dt
\] 
\emph{is a constant function whose value is given by
$-2\pi\cdot \log 2$}. From this the reader can deduce
(*) and notice that one  can take
$C=2\pi\cdot \log 2$.
\medskip



\noindent
We shall establish an
inversion formula which entails 
that
special properties hold  for  functions in the range of $T$.


\medskip

\noindent
{\bf{14.1 Theorem.}}\emph{The necessary and sufficient condition 
that an $L^1$\vvv function $f$ is equal to $T\uuu g$
for some
$g\in L^1[0,1]$ is that 
the integral in (*)  is absolutely convergent. Moreover,
$f$ is absolutely continuous and 
the principal  value convolution of the derivative
$f'$ satisfies}
\[
\frac{1}{\sqrt{x(1-x)}}\cdot \mathcal P_{f'}\in L^1[0,1]
\]
\emph{Moreover, with $K=(2\pi^2\cdot\log 2)^{-1}$
one has the inversion formula:}
\[
g(x)=\frac{1}{\pi^2}\cdot \frac{1}{\sqrt{x(1-x)}}\cdot  \mathcal P_{f'}(x)+
\frac{K}{\sqrt{x(1-x)}}\cdot \int_0^1\, \frac{f(t)}{\sqrt{t(1-t)}}\, dt
\]
\medskip

\noindent
{\bf{Fractional operators.}}
Let $0<\alpha<1$ and this time we set
\[
T_g(x)=
\int_0^1\, \frac{g(t)}{|x-t|^\alpha}\, dt
\]
Again we restrict $T_g(x)$ to $[0,1]$
and one seeks an inversion formula.
It will
be
given under the additional hypothesis that
\[
\int_0^1\, |g(t)|\cdot (t(1-t)^{\frac{1-\alpha}{2}}\, dt<\infty
\]
This enable us to define the Cauchy transform
\[
H(z)= \int_0^1\, \frac{g(t)\cdot (t(1-t)^{\frac{1-\alpha}{2}}}{z-t}\, dt
\]
Here $H(z)$ is analytic outside
$[0,1]$ and for 
a fixed $0<x<1$
one can perform complex line integrals along  rectifiable Jordan
curves 
$\Gamma_x$ which start and end at $x$ while the remaining part of
the curve stays outside $[0,1]$.
In particular we can take such Jordan curves whose winding number around
$z=0$ is one. See figure ¤xx.
With this in mind 
one constructs the function

\[
K(x)=
\int_{\Gamma_x}\, \frac{(z(1-z))^{\frac{1-\alpha}{2}}}{(z-x)^{1-\alpha}}
\cdot H(z)\, dz\quad\colon 0<x<1
\]
\medskip

\noindent
{\bf{Theorem.}}\emph{
The function $K(x)$ is absolutely continuous
and one has the inversion formula}
\[
g(x)=
xxx\cdot \frac{dK}{dx}
\]
\medskip

\noindent
{\bf{Remark.}} In particular the operator in (xx) is injective.






















\medskip

\noindent
\emph{Proof.}
In the upper half plane $\mathfrak{Im} \,z>0$
we choose a single valued branch of the complex log-function
and
get the analytic function
\[ 
G(z)= \int_0^1\, \log (z-t)\cdot g(t)\, dt
\]
Passing to the boundary value we see that
\[
G(x+i0)= T_g(x)+\pi i\cdot \int_x^1\,  g(t)\, dt\quad\colon
0< x< 1\tag{i}
\]
In the lower half-plane we have the branch of the complex
log-function whose argument stays in $(-\pi,0)$
and get  the boundary value
equation
\[ 
G(x-i0)= T_g(x)-\pi i\cdot \int_x^1\,  g(t)\, dt\quad\colon
0< x< 1\tag{ii}
\]
Set $f(x)= T_g(x)$.
Taking derivatives in (i-ii) we get
the equations
\[
G'(x-i0)+G'(x-i0)=2f'(x)\quad\colon
G'(x-i0)'-G'(x-i0)'=-2\pi i\cdot g(x)\tag{iii}
\]



\noindent
Next, the Cauchy transform
gives the single valued analytic function in
${\bf{C}}\setminus [0,1]$:
\[
C_g(z)=\int_0^1\, \frac{g(t)}{z-t}\, dt
\]
Since $\sqrt{z(1-z}$ has a single valued branch
in
${\bf{C}}\setminus [0,1]$ we also get the single-valued function
\[
\Phi(z)=\sqrt{z(z-1}\cdot C_g(z)
\]
Here we notice that
\[
\Phi(x+i0)=i\cdot \sqrt{x(1-x} \cdot C_g(x+i0)
\quad\colon\, \Phi(x-i0)=-i\cdot \sqrt{x(1-x} \cdot C_g(x+i0)\tag{iv}
\]
Together (iii-iv) give the equations below when $0<x<1$

\[
2i\sqrt{x(1-x)}\cdot f'(x)=\Phi(x+i0)-\Phi(x-i0)\tag{v}
\]
\[
2\pi\cdot\sqrt{x(1-x)}\cdot g(x)=\Phi(x+i0)+\Phi(x-i0)\tag{vi}
\]
Next, when $|z|$ is large we have
\[
\Phi(z)=z\cdot \sqrt{1-z^{-1}}\cdot z^{-1}\cdot
\int_0^1\, \frac{g(t)}{1- t/z}\, dt
\]
The right hand side tends to
$\int_0^1\, g(t)\, dt$ and then  (v) entails that
\[
 \Phi(z)= \frac{1}{\pi}\cdot \int_0^1\, 
\frac{\sqrt{t(1-t)}\cdot f'(t)}{z-t}\, dt+\int_0^1\, g(t)\, dt\tag{vii}
\]
Passing to boundary values we get
\[
\Phi(x+i0)+\Phi(x-i0)=2\cdot \int_0^1\, g(t)\, dt+
 \frac{2}{\pi}\cdot \int_0^1\, 
\frac{\sqrt{t(1-t)}\cdot f'(t}{x-t}\, dt\tag{viii}
\]
where the last term  is a principal value  integral.
Finally,  (vi) gives
\[
\sqrt{(1-x)x}\cdot g(x)=
\frac{1}{\pi^2}\cdot \mathcal P_{f'}(x)+
2\cdot \int_0^1\,g(t)\, dt\tag{ix}
\]
Division with
$\sqrt{x(1-x}$ gives  the requested inversion formula via Legendre's constant in
the proof of 14.0.
\bigskip

\noindent
{\bf{14.2 A Fourier transform.}}
The $T$-operator is  a convolution and let us analyze
the Fourier transform
\[
\widehat T_g(\xi)= \iint_\square\, e^{-ix\xi}\cdot \log|x-t|\cdot g(t)\,dt
\]
under the condition that
the mean value $\int_0^1\, g(t)\, dt=0$
which entails that
$\widehat{g}(\xi)=0$.


\noindent
{\bf{14.3 Exercise.}} Verify the formula
\[
\int_{-1}^1\, e^{-iu\xi}\cdot \log|u|\cdot du=
2\cdot \int_{-1}^1\, \cos u\xi\cdot \log u\cdot du=-\frac{2}{\xi}\int_0^\xi\,
\frac{\sin u}{u}\cdot du\tag{i}
\]
Use this to conclcude that
\[
\widehat T_g(\xi)=-2\cdot \frac{\widehat {g}(\xi)}{\xi}+\rho(\xi)\cdot \widehat{g}(\xi)
\tag{0.3.1}
\]
where the $\rho$-function decays at infinity like $\xi^{-2}$, i.e. there 
is an absolute constant $C$ 
for which
\[
|\rho(\xi)|\leq C\cdot \xi^{\vvv 2}\quad\colon\quad |\xi|\geq 1
\]

\bigskip

\centerline{\bf{The equation $f(x)= \int_0^1\, \frac{\phi(t)}{|x-t|^\alpha}\, dt$}}
\medskip


\noindent
Let $0<\alpha<1$ and consider the 
the operator which sends
$\phi(t)\in L^1[0,1]$ to
\[ 
T_g(x)= \int_0^1\, \frac{\phi(t)}{|x-t|^\alpha}\, dt
\]
Since $0<\alpha<1$ this convolution 
implies that $T_g(x)$ is 
an almost everywhere defined  locally integrable function.
In particular it restricts to an $L^1$-function on
$\{0\leq x\leq 1\}$.
We shall prove that this operator is injective and
exhibit an inversion formula.
To achieve this we introduce the function
\[ 
G(z)= \int_0^1\, \frac{\phi(t)}{(z-t)^\alpha}\, dt
\]
It is analytic in the upper half-plane where
branches of $(z-t)^\alpha$ have argument in $(\alpha\cdot \pi)$.
Here we get 
the boundary value function
\[
G(x+i0)= \lim_{\epsilon\to 0}\int_0^1\, \frac{\phi(t)}{(x-t+i\epsilon)^\alpha}\, dt
\]
In the lower half-plane the argument of
$(z-t)^\alpha$ stays in $(-\alpha\pi,0)$
we have 
\[
G(x-i0)= \lim_{\epsilon\to 0}\int_0^1\, \frac{\phi(t)}{(x-t-i\epsilon)^\alpha}\, dt=
T_g(x)+
\]
From this we conclude that the following hold when $0<x<1$:
\[
G(x+i0)= \int_0^x\,  \frac{\phi(t)}{(x-t)^\alpha}\, dt+
e^{-\pi i\alpha}\cdot\int_x^1\,  \frac{\phi(t)}{(t-x)^\alpha}\, dt
=T_g(x)+(e^{-\pi i\alpha}-1)\cdot\int_x^1\,  \frac{\phi(t)}{(t-x)^\alpha}\, dt
\]
In the same way we find that

\[
G(x-i0)= T_g(x)+(e^{\pi i\alpha}-1)\cdot\int_x^1\,  \frac{\phi(t)}{(t-x)^\alpha}\, dt
\]
Together (x-xx) give
\[
e^{2\pi i\alpha}G(x+i0)-G(x-i0)=(e^{2\pi i\alpha}-1)T_g(x)
\]

\medskip


\noindent
{\bf{The case $T_g(x)=0$}}.
Then (xx) gives
\[
G(x-i0)=e^{2\pi i\alpha}G(x+i0)
\]
where this equality holds almost everywhere
on $\{0<x<1\}$.
At the same time we notice that
\[ 
G(x+i0)= G(x-i0)=T_g(x)\quad\colon x>1
\]
\[ 
e^{-\pi i \alpha}G(x+i0)= e^{\pi i\alpha}G(x-i0)=T_g(x)\quad\colon x<0
\]
\medskip

\noindent
So if $T_g(x)=0$ it follows from the above
that
$G(z)$ exists as a multi-valued analytic function
in ${\bf{C}}\setminus \{0,1\}$.
Using (xx) we obtain a single-valued analytic funtion
outside $\{0,1\}$
by
\[
\Phi(z)= xxx\cdot G(z)
\]
We are going to show that the vanishing of $T_g(x)$ implies that
$\Phi(z)=0$.
To prove this we study $\Phi$ locally
around
$z=1$ and $z=0$. Around $z=1$ it has a Laurent expansion
\[
\Phi(z)= \sum_{n=-\infty}^\infty\, c_n(z-1)^n
\]
Now a local analytic branch of $z^\alpha$ exista around
$z=1$
which entails that
$G(z)$ is locally of the form
\[
G(z)=(z-1)^{-\frac{1+\alpha}{2}}\cdot
 \sum_{n=-\infty}^\infty\, a_n(z-1)^n
\]
POINT. Priitive $G$-function is bounded+ Weierstrass to impliy that
no negative $a_m$-occur and then $\Phi$ is meromorphic and even
with a zero at
$z=$. Same true at $z=0$ and
this entire function is zero since it does not increase more than
$|z|$.
Finally classic Abel gives
vanishing of $\phi$.












\newpage

\centerline{\bf{15. An $L^1$-inequality for
inverse Fourier transforms.}}

\bigskip

\noindent
Theorem 15.1 below is due to Beurling in [Beurling].
Let $g(t)$ be a function defined on $t\geq 0$
where the inverse Fourier transform of $tg(t)$ is integrable, i.e.
the function defined on the $x$\vvv axis by
\[  
f(x)=\int\uuu 0^\infty e^{itx}\cdot tg(t)\, dt\tag{*}
\]
belongs to $L^1({\bf{R}})$.
\medskip

\noindent
{\bf{15.1 Theorem.}}
\emph{When $f\in L^1({\bf{R}})$ it follows that
$g(t)$ is integrable and one has the inequality}
\[
\int\uuu 0^\infty\, |g(t)|\, dt\leq \frac{1}{2}
\int\uuu {\vvv \infty}^\infty\, |f(x)|\, dx
\]
\medskip

\noindent
\emph{Proof.}
Since (*) is taken over $t\geq 0$,
$f(x)$ is the boundary value function of
the analytic function
defined in $\mathfrak{Im}(z)>0$ by
\[
f(z)=\int\uuu 0^\infty e^{itz}\cdot tg(t)\cdot dt\tag{1}
\]
We  first prove the inequality in Theorem 15.1 when
$f(z)$ is zero-free in the upper halfplane
and consider the normalised situation where the $L^1$\vvv integral of $|f(x)|$ is one.
Now  the complex square root of $f(z)$  exists 
in $\mathfrak{Im}(z)>0$
and gives
an analytic function $F(z)$ such that   $F^2=f$.
Since  $|F(x)|^2=|f(x)|$ it follows that $F$ belongs to the
Hardy space $H^2({\bf{R}})$ and
Plancherel's theorem gives a function $h(t)$ on $t\geq 0$ where
\[ 
F(z)=\int\uuu 0^\infty \, e^{itz}\cdot h(t) dt\tag{2}
\]
Parseval's equality gives 
\[
1=\int\, |F(x)|^2\, dx=2\pi\cdot \int\uuu 0^\infty\, |h(t)|^2\, dt\tag{*}
\]
The Fourier transform of the convolution $h*h$
is equal to $F^2(x)= f(x)$. This gives
\[ 
t\cdot g(t)=\int\uuu 0^t\, h(t\vvv s)h(s)\, ds\implies
|t\cdot g(t)|\leq H(t)=\int\uuu 0^t\, |h(t\vvv s)|\cdot |h(s)|\, ds\tag{**}
\]
Put
\[ 
F\uuu *(x)=\int\uuu 0^\infty \, e^{itz}\cdot |h(t)| \,dt\tag{4}
\]
Parseval's formula applied to the pair $|h|$ and $F\uuu *$ gives
\[
\int\, |F^2(x)|\,dx=2\pi\cdot \int\uuu 0^\infty\, |h^2(t)|\, dt
\]
We conclude that the $L^2$\vvv norm of $F^*$ also is one
and here
\[
F\uuu *(x)^2= \int\uuu 0^\infty \, e^{itz}\cdot H(t)\, dt\tag{5}
\]
At this stage we use a result from XXX which shows that the function
\[ 
\theta\mapsto 
\log\, \bigl[\int\uuu 0^\infty\, |F\uuu*(re^{i\theta})|^2\cdot dr\,\bigr ]
\] 
is a convex function of $\theta$
where $\vvv \pi\leq\theta\leq 0$.
Apply this when
$\theta=\pi/2$ with   end\vvv values 0 and $\pi$.
This gives
\[
\int\uuu 0^\infty\, |F\uuu*(iy)|^2\cdot dy\leq
\sqrt{\int\uuu {\vvv\infty}^0\, |F\uuu*(x)|^2\cdot dx}
\cdot 
\sqrt{\int\uuu 0^\infty\, |F\uuu*(x)|^2\cdot dx}
\]
Since $x\mapsto |F\uuu *(x)|$ is an even function of
$x$ the equality in (*) entails
that the product above  is equal to one.
Hence we obtain:
\[
\int\uuu 0^\infty\,\bigl[\int\uuu 0^\infty\, e^{\vvv ty}\cdot H(t)\cdot dt\bigr ]
\cdot dy\leq \frac{1}{2}
\]
Integration by parts shows that
the left hand side is equal to 
\[
\int\uuu 0^\infty\, \frac{H(t)}{t}\cdot dt
\]
Finally, by (**) 
$|g(t)|\leq \frac{H(t)}{t}$ and hence  the $L^1$\vvv norm of
$g$ is bounded by $\frac{1}{2}$ as requested.
\bigskip

\noindent
\emph{Removing zeros.}
If $f$ is not zero\vvv free we let $B(z)$ be the Blaschke product of its zeros
and write
\[ 
f=B(z)\phi(z)
\] 
Here $\phi $ is zero\vvv free
and we do not change the $L^1$\vvv norm on the $x$\vvv line since
$|B(x)|=1$ holds almost everywhere.
Notice that we can write

\[ 
f=\phi\bigl(\frac{1+B}{2}\bigr)^2+
\phi\bigl(\frac{1\vvv B}{2}\bigr)^2=
F\uuu 1^2\vvv F\uuu 2^2
\]
where $F\uuu 1$ and $F\uuu 2$ as  above are zero\vvv free in
the Hardy space $H^2$.
Since we have
\[
\bigl|\frac{1+B}{2}\bigr|^2+
\bigl|\frac{1\vvv B}{2}\bigr|^2\leq 1
\]
it follows that
\[
|F\uuu1|^2+|F\uuu 2|^2\leq|\phi|
\]
Now the established  zero\vvv free case  gives
the inequality in
Theorem 15.1












\newpage


\centerline{\bf{16. On functions with spectral gap}}
\bigskip

\noindent
{\bf{Introduction.}}
A fore\vvv runner to distribution theory 
appears in work by Beurling
where spectral gaps
of functions $f$
on the real $x$\vvv line are analyzed.
We expose a result  from a seminar
by Beurling at  at Uppsala University
in March 1942.
\medskip





\medskip

\noindent
{\bf{16.1 Theorem.}}
\emph{Let $f(x)$ be a bounded and continuous function on
the real $x$\vvv line such that $\widehat{f}(\xi)$
is zero on
$\{-1\leq\xi\leq1\}$
and}
\[ 
f(x+h)\vvv f(x)\leq h
\] 
\emph{hold for all $h>0$ and every $x$. Then its maximum norm is
at most $\pi$.}
\medskip


\noindent
The proof is postponed until
¤ 16.3. First we
establish some preliminary results where an essential ingredient
is the
entire function:
\[ 
2\cdot H(z)=\bigl(2\sin \frac{z}{2}\bigr)^2\cdot
\bigl[ \sum\uuu{n=1}^\infty\, \frac{1}{(z\vvv 2\pi n)^2}
\vvv \sum\uuu{n=0}^\infty\, \frac{1}{(z+ 2\pi n)^2}+ \frac{1}{\pi z}\bigr]
\]



\noindent
{\bf{A. Exercise.}}
Verify the identity
\[
\frac{1}{(2\sin \frac{z}{2}\bigr)^2}=
 \sum\uuu{\vvv \infty}^\infty\, \frac{1}{(z\vvv 2\pi n)^2}\tag{*}
\]
The hint is to consider the meromorphic function
\[
\phi(z)=\frac{\cos z/2}{2\sin z/2}
\]
It has simple poles at $\{2\pi n\}$ where $n$ runs over all integers
and we notice that
\[
\psi(z)= \phi(z)\vvv  \sum\uuu{\vvv \infty}^\infty\, \frac{1}{z\vvv 2\pi n}
\] 
is entire. Hence the  derivative 
$\psi'(z)$ is also entire. Since 
$\cos^2\,z/2+\sin^2\, z/2=1$ we get:
\[ 
\psi'(z)=\vvv \frac{1}{(2\sin \frac{z}{2}\bigr)^2}+
\sum\uuu{\vvv \infty}^\infty\, \frac{1}{(z\vvv 2\pi n)^2}
\]
At the same time the reader may verify that the right hand side is
bounded so this entire function must be identically zero which gives (*).

\bigskip

\noindent
{\bf{B. Exercise.}}
Use (*) to show that if $x>0$ then
\[
2H(x)=1\vvv  
\bigl (2\sin \frac{x}{2}\bigr)^2\cdot
\bigr[\sum\uuu{n=1}^\infty\, \frac{2}{(x+2\pi n)^2}+\frac{1}{x^2}\vvv
\frac{1}{\pi x}\bigr]
\]


\noindent
{\bf{The $\theta$\vvv function}}.
It is defined for all real $x$ by:
\[ 
\theta(x)=\frac{1}{2}\cdot \text{sign} (x)\vvv H(x)
\]
where
$\text{sign} (x)$ is $\vvv 1$ if $x<0$ and +1 if $x>0$.
\medskip

\noindent
{\bf{16.2 Proposition.}}
\emph{The $\theta$\vvv function is everywhere $\geq 0$ and}
\[
\int\uuu{\vvv\infty}^\infty \theta(x)\cdot dx=\pi\tag{*}
\]


\noindent
\emph{Proof.}
Exercise B gives for every $x>0$:
\[
\theta(x)=  \frac{1}{2}\bigl (2\sin \frac{x}{2}\bigr)^2\cdot
\bigr[\sum\uuu{n=1}^\infty\, \frac{2}{(x+2\pi n)^2}+ \frac{1}{x^2}\vvv
\frac{1}{\pi x}\bigr]
\]
Next,  notice the two inequalities
\[
\sum\uuu{n=1}^\infty\, \frac{2}{(x+2\pi n)^2}\leq
\int\uuu 0^\infty\,
\frac{2dt}{(x+2\pi t)^2}=\frac{1}{\pi x}\tag{1}
\]
\[
\sum\uuu{n=1}^\infty\, \frac{2}{(x+2\pi n)^2}+\frac{1}{x^2}\geq
\int\uuu 0^\infty\,
\frac{2dt}{(x+2\pi t)^2}=\frac{1}{\pi x}\tag{2}
\]
Here (2) entails that $\theta(x)\geq 0$ on $x>0$ and
(1) obviously implies that the integral
\[
\int\uuu 0^\infty\,\theta(x)\cdot dx<\infty\tag{3}
\]
We leave as an exercise to the reader to verify the similar result for 
$x<0$, i.e. that
$\theta(x)\geq 0$ hold for $x<0$ and that
its integral over $(\vvv \infty,0)$ is  finite.
To establish the equality
(*) in Proposition 16.2 we notice that
the function
\[
\text{sign}(x)
+(2\sin\frac{x}{2})^2\cdot \frac{1}{\pi x}
\]
is odd so its integral over the real line is zero.
The reader may also check the equation
\[ 
\int\uuu{\vvv \infty}\, 
\frac{(\sin \frac{x}{2})^2}{(x\vvv 2\pi n)^2}\cdot dx=
\int\uuu{\vvv \infty}\, 
\frac{(\sin \frac{x}{2})^2}{(x+2\pi n)^2}\cdot dx
\quad\text{for every}\quad  n\geq 1
\] 
and then verify the equality
\[
\int\uuu{\vvv\infty}^\infty \theta(x)\cdot dx=
\int\uuu 0^\infty\, 
\frac{(2\sin \frac{x}{2})^2}{x^2}\cdot dx
\]
where  residue calculus shows that the last integral is $\pi$.
\bigskip


\centerline{\emph{16.3 Proof of Theorem 16.1}}
\bigskip

\noindent
Let  $\mathcal H$ be the Heaviside function
which is one on $x>0$ and zero on
$\{(x\leq 0\}$.
Recall that the distribution derivative
$\partial_x(\mathcal H)=\delta_0$.
Regarding $f$ as a temperate distribution
this gives the equation
\[
f=\partial_x(f\ast( \mathcal H\vvv \frac{1}{2}))\tag{i}
\]
As explained in ¤ XX the Fourier transform $\widehat H(\xi)$
is supported by $[\vvv 1,1]$.
Since the support of $\widehat f$
is disjoint from $[\vvv 1,1]$
it follows that $f\ast H=0$ and hence  the distribution derivative 
\[
\partial_x(f*H)=0\tag{ii}
\]
Next,
notice that
\[
\frac{1}{2}\cdot \text{sign}(x)=\mathcal H\vvv \frac{1}{2}\tag{iii}
\]

\noindent
The construction of $\theta$ in (B)
and (i-iii) therefore give 
\[
f=\partial_x(f\ast\theta)
\]
This  means that one has
the equation
\[ 
f(x)=\int\uuu{\vvv \infty}^\infty \, \theta(x\vvv y)\cdot f'(y)\cdot dy\tag{iv}
\]
By assumption $f'(y)\leq 1$ for all $y$
and since $\theta\geq 0$ 
the right hand side is bounded above by
\[
\int\uuu{\vvv \infty}^\infty \, \theta(x\vvv y)\cdot dy=\pi \implies
f(x)\leq \pi
\] 
To get $f(x)\geq \vvv \pi$ we consider the function
$g(x)=\vvv f(\vvv x)$ which
again is a bounded continuous function
and the reader easily verifies that $g(x+h)\vvv g(x)\leq h$
for all $h>0$. Moreover, $\widehat g(\xi)$ is minus the complex conjugate
of $\widehat f$ so $g$ has the same spectral gap as $f$ and just as above 
we get  the upper bound
$g(x)\leq \pi$ which entails
that $f(x)\geq \vvv \pi$ hold for all $x$. Hence  
its maximum norm is bounded by $\pi$ which finishes the proof of
Theorem 16.1
\medskip


\noindent
{\bf{16.4 Question.}}
Investigate if Theorem 16.1 is sharp, i.e. try to 
use the proof above in order to construct
$f$
whose   maximum norm is close to $\pi$.












\newpage


\centerline{\bf{17. A theorem about limits}}
\medskip

\noindent
The space of complex\vvv valued bounded and uniformly continuous functions
on the real $x$\vvv line is  
a Banach space $\mathcal C\uuu *$
where we use the maximum norm  over the whole line.
A subspace arises as follows: On the  $\xi$\vvv line we have the space
$\mathfrak{M}$
of complex Riesz measures $\gamma$ with a finite total variation
and 
to each $\gamma$ we get the function
\[
\mathcal F\uuu\gamma(x)=\int\uuu{\vvv \infty}^\infty\, e^{ix\xi}\cdot d\gamma(\xi)
\]
It is clear that $\mathcal F\uuu\mu$ belongs to $C\uuu *$.
Denote by $\mathcal A$ the subspace of $C\uuu *$
given by $\mathcal F\uuu\gamma$-functions as $\gamma $ varies over 
$\mathfrak{M}$.
Before we announce Theorem 17.1 below we recall the notion
of weak\vvv star limits in $\mathfrak{M}$.
Let $\{\mu\uuu n\}$ be a bounded sequence of Riesz measures, i.e. 
there exists a constant such that
\[ 
||\mu\uuu n||\leq M
\]
hold for all $n$.
The sequence $\{\mu\uuu n\}$
converges weakly to zero if
\[
\lim\uuu{n\to\infty}\,\int\, e^{ix\xi}\cdot d\mu\uuu n(x)=0
\] 
holds pointwise for every $\xi$.
\medskip

\noindent
{\bf{17.1 Theorem.}} \emph{A function $\psi\in C\uuu *$ belongs to the closure of
$\mathcal A$ if and only if}
\[
\lim\uuu{n\to\infty}\,\int\, \psi(x)\cdot d\mu\uuu n(x)=0\tag{*}
\] 
\emph{whenever $\{\mu\uuu n\}$ is a sequence in $\mathfrak{M}$
which converges weakly to zero.}
\medskip

\noindent
The sufficiency part is easy.
For suppose that $\psi$ belongs to the closure of $\mathcal A$
and let $\{\mu_n\}$ converge weakly to zero.
Since the total variations in this  weakly convergent sequence of measures 
is uniformly bounded, it suffices to show that
(*) holds when $\psi\in\mathcal A$.
So let $\psi=\mathcal F\uuu\gamma$ for some
$\gamma\in\mathfrak{M}$.
Since $\gamma$ and $\mu\uuu n$ both have a finite total variation
it is clear that
\[
 \int \psi(x)\cdot d\mu\uuu n(x)=
 \int\, \mathcal F\uuu{\mu\uuu n}(\xi)\cdot d\gamma(\xi)
 \]
Here $\{\mathcal F\uuu{\mu\uuu n}(\xi)\}$ is a sequence 
of uniformly bounded
continuous functions on the real $\xi$\vvv line which by assumption converges
pointwise to zero. Since the Riesz measure $\gamma$ has a finite total variation,
the Borel\vvv Riesz convergence result in [Measure] shows that
(*) tends to zero with $n$.
\bigskip

\centerline{\emph{Proof of necessity.}}
\medskip

\noindent
There remains to show that if $\psi\in C\uuu*$ is outside the closure of
$\mathcal A$, then there exists a
sequence $\{\mu\uuu n\}$ which converges weakly to zero while
$\{\int\,\psi\cdot d\mu\uuu n\}$ stay away from zero.
To attain this we shall consider a class of variational problem  and
extract a certain sequence of measures
which does the job.
\medskip

\noindent
{\bf{A class of  variational integrals.}}
Let $a,b,s$ be positive numbers and $q>2$.
With $p$ chosen so that
\[ 
\frac{1}{p}+\frac{1}{q}=1
\]
we have the space $L^p[\vvv a,a]$
where $[\vvv a,a]$ is an interval on the $\xi$\vvv line.
To each function $g(\xi)\in L^p[\vvv a,a]$
we get the function 
\[
 \mathcal F\uuu g(x)=
\int e^{ix\xi}\cdot g(\xi)\cdot d\xi
\]
This gives a continuous function which is  
restricted to $[\vvv b,b]$
and we set
\[
||\psi\vvv \mathcal F\uuu g||\uuu q^b=
\bigl[ \int\uuu {\vvv b}^b\,
[\psi(x)\vvv \mathcal F\uuu g(x)|^q\cdot dx\,\bigr]^{1/q}
\]
where the upper index $b$ indicates that we compute a $L^q$\vvv norm on
the bounded interval $[\vvv b,b]$.
To each $g\in L^p[\vvv a,a]$ we set
\[
\mathcal J(g;q,b,a,s)=||\psi\vvv \mathcal F\uuu g||\uuu q^b+||g||\uuu p\tag{*}
\] 


\noindent
where the last term is the $L^p$\vvv norm of $g$ taken over
$[\vvv a,a]$.
Since the Banach space $L^p[\vvv a,a]$ is strictly convex
one easily verifies:
\medskip

\noindent
{\bf{17.2 Proposition.}} \emph{The variational problem where
$\mathcal J$ is minimized
over $g$ while $a,b,s$ are fixed has a unique extremal solution.}
\medskip

\noindent
{\bf{17.3 Exercise.}} Regarding infinitesmal variations via the 
classic device due to Euler and Lagrange, the reader can verify that
there exists a unique
extremal solution $g$ which satisfies
\[
||g||\uuu p)^{1\vvv p}\cdot \frac{|g(\xi)|^p}{g(\xi)}=M^{\vvv 1/p}\cdot
\int\uuu {\vvv b}^b\, e^{i\xi x}\cdot 
\frac{|\psi(x)\vvv \mathcal F\uuu g(x)|^q}{|\psi(x)\vvv \mathcal F\uuu g(x)}
\cdot dx\tag{*}
\]
where we have put
\[ 
M=\int\uuu b^b\, |\psi\vvv \mathcal F\uuu g|^q\cdot dx
\]



\medskip

\noindent
Consider the absolutely continuous
measure  on the
$x$\vvv line defined by
the density
\[ 
d\mu=M^{\vvv 1/p}\cdot 
\frac{\psi(x)\vvv \mathcal F\uuu g(x)|^q}{|\psi(x)\vvv \mathcal F\uuu g(x)}
\quad\colon\quad \vvv b\leq x\leq b
\]


\noindent
This gives
\[
\int\uuu{\vvv b}^b\, 
|d\mu(x)|=M^{\vvv 1/p}\cdot\int\uuu{\vvv b}^{b} 
|\psi(x)\vvv \mathcal F\uuu g(x)|^{q\vvv 1}
\cdot dx
\]
Hšlder's inequality applied to the pair of functions
$|\psi(x)\vvv \mathcal F\uuu g(x)|^{q\vvv 1}$ and 1 on $[\vvv b,b]$
gives the inequality below for the total variation:
\[
||\mu||\leq (2b)^{1/q}\tag{**}
\]




\medskip



\noindent
{\bf{17.4 Lemma.}}
\emph{The following two formulas hold:}
\[
\int\, \psi\cdot d\mu= \mathcal J(g; q,b,a,s)
\]
\[
\int\,\mathcal F\uuu g\cdot d\mu=s\cdot ||g||\uuu p
\]


\noindent
\emph{Proof.}
To begin with we have
\[
\int\, (\psi\vvv \mathcal F\uuu g)\cdot d\mu=
M^{\vvv 1/p}\cdot \int\uuu b^b \, |\psi\vvv \mathcal F\uuu g|\cdot dx
= M^{1\vvv 1/p}\cdot M=M^{1/q}
\]
\medskip

\noindent
Next Fubini's theorem gives

\[
\int\,\mathcal F\uuu g\cdot d\mu
=\int\uuu a^a\, [\int\, e^{ix\xi}\cdot \mu(x)\,]\cdot g(\xi)\cdot d\xi
=
s\cdot \int\uuu a^a\, 
||g||\uuu p)^{1\vvv p}\cdot \frac{|g(\xi)|^p}{g(\xi)}\cdot g(\xi) d\xi
=s\cdot ||g||\uuu p
\]
This proves formula (2) and (1) follows via (i) and the equality

\[
\mathcal J(g; q,b,a,s)=M+s\cdot ||g||\uuu p
\]
\medskip

\noindent {\bf{17.5 Passage to limits.}}
Following [Beurling] we now consider   certain limits where
we first let $q\to+\infty$ and after $b\to\infty$, and finally
use pairs $a=2^m$ and $s=2^{\vvv m}$ where 
$m$ will be large positive integers.
To begin with, the measure $\mu$ depends on $q,b,a,s$
and let us denote it by $\mu\uuu q(b,a,s)$.
The uniform bound (*) from Exercise 17.3
entails that while 
$a,b,s$ are kept fixed, then there is 
a sequence 
$\{q\uuu\nu\}$ which tends to $+\infty$
and give  a weak limit measure
\[
\mu\uuu *(b,a,s)=\lim\, \mu\uuu{q\uuu\nu}(b,a,s)
\]
The extremal $g$\vvv functions depend on $q$ and are denoted by $g\uuu q$.
Their $L^q$\vvv norms remain bounded
and passing to a subsequence we get
an $L^\infty$\vvv function $g\uuu *$ on $[\vvv a,a]$
where $g\uuu{q\uuu\nu}\to g\uuu *$. Here $g\uuu *$ depends on $b,a,s$ and is
therefore indexed as  
$g\uuu *(b,a,s)$.
We have also a limit:
\[ 
\lim_{\nu\to \infty}\, \mathcal J(g\uuu g;q\uuu\nu; b,a,s)=
\mathcal J\uuu *(g\uuu *(a,b,s))
\]
Moreover
\[
\mathcal J\uuu *(g\uuu *(a,b,s))=
\max\uuu{\vvv b\leq x\leq b}\, |\psi(x)\vvv \mathcal F\uuu{g\uuu *(b,a,s)}|
+s\cdot \int\uuu{\vvv a}^a |g\uuu *(b,a,s)(\xi)|\cdot d\xi
\]
\medskip

\noindent
At this stage we use the hypothesis that $\psi$ does not belong to the closure of
$\mathcal A$ which entails that with $a$ and $s$ fixed, then
here is a constant $\rho>0$ such that
\[ 
\liminf\uuu{b\to\infty}\, 
\max\uuu{\vvv b\leq x\leq b}\, |\psi(x)\vvv \mathcal F\uuu{g\uuu *(b,a,s)}|\geq \rho
\]

\bigskip

At this stage proof is easily FINISHED.
















 
 


















\newpage


\centerline{\bf{18. Lindeberg's central limit theorem.}}
\bigskip
\noindent
{\bf \large Introduction}
The classical version of the
CLT (central limit theorem) was proved by De Moivre in 1733
and
asserts that as $n$ tends to infinity, the standardized 
binomial distribution tends to the normal distribution. 
Thus, let $\mathbf B$ be the two point random variable which takes the values
+1 or -1 with probability 1/2. If  $n\geq 2$ we denote by
$\mathbf B_1,\ldots,\mathbf B_n$
an $n$-tuple of independent two points variables. This gives the
random variable
\[
\chi_n=\frac{\bf B_1+\ldots+\bf B_n}{\sqrt{n}}\tag{*}
\]
De Moivre's proof that
$\chi_n$
tends to the normal distribution
was direct in the sense that 
characteristic functions were not used.
To see the idea we let $n=2N$ be a large even integer. If $k\geq 1$ 
we denote by $\rho_N(k)$ the probability that the number of heads
minus the number of tails is $\leq 2k$
after $2N$ many trials. The binomial formula gives
\[ 
\rho_N(k)=\frac{1}{2}+
2^{-2N}\cdot \sum_{\nu=0}^{\nu=N+k}\, \binom{2N}{\nu}
\]
The normal distribution is given by the increasing function
\[
\mathcal N(x)= \frac{1}{\sqrt{2\pi}}\cdot
\int_{-\infty}^x\, e^{-t^/2}\cdot dt
\]
With $k=\sqrt{N}\cdot a$
one wants the limit formula
\[
\lim_{N\to\infty}\,\rho_N(\sqrt{N}\cdot a)=\mathcal N(2a)\tag{1}
\]
for each $a>0$.
This can be  proved directly using Wallis' limit  formula for
products of sine-functions which gives Stirling's formula with
a remainder term and therefore  a quite sharp
estimate for the rate of convergence. 
For readers familiar with Swedish a proof with good
upper bounds for the rate of convergence
is presented  by Carleman in his 
outstanding  text\vvv book from 1926
for first year studies on university level which actually covers the
more general where the equally distributed variables have a finite distribution.
See also the section \emph{Residue Calculus} for
a proof
of Wallis' formula.
\medskip

\noindent
A more general version of the CLT was  formulated by Simon Laplace in his classic treatise on probability from 1812. His assertion was that sums of independent random variables which
are suitably scaled so that the partial sums $\chi_n$ are random 
variables with mean value zero and variances $\sigma_n$ which converge to a number
$\sigma$, 
implies that the sequence $\chi_n$ converges to a 
normal distribution with
variance 
$\sigma$, under the \emph{hypothesis} that the individual random variables
defining the sum variables $\chi_n$ give a \emph{relatively insignificant
contribution}.
A  rigorous proof of the CLT in the spirit of Laplace was given by 
Liapunoff in 1901. His result goes as follows: Let $W_1,W_2,\ldots$
be a sequence of independent random variables, each with mean value zero and
variance $\sigma_\nu$. Assume that there exists a constant
$M$ such that the \emph{moment of order 3} is $\leq M$ for each
$W_\nu$ and that the limit
\[
\lim_{n\to\infty}\frac{\sigma_1^2+\ldots+\sigma_n^2}{\sqrt {n}}=\sigma^2
\]
exists. Then 
that  partial sums variables
defined by
\[
\chi_n=\frac{W_1+\ldots+W_n}{\sqrt {n}}
\]
converge to the normal distribution with variance 
$\sigma$. The conclusive version of the CLT was proved by Lindeberg in 1920.
He weakened the conditions in Liapunoff's result by relaxing the hypothesis about
finite moments of order 3 and proved the following:


\medskip


\noindent
{\bf{1. Theorem}}
\emph{Let $W_1,W_2,\ldots$ be  independent  random variables with mean values zero.
A sufficient condition  that the sum variables}
\[
\chi_n=\frac{W_1+\ldots+W_n}{\sqrt {n}}
\]
\emph{converge to a normal distribution with  variance $\sigma$ is that 
the following three conditions hold:}
\[
\lim_{n\to\infty}\frac{\sigma_1^2+\ldots+\sigma_n^2}{\sqrt {n}}=\sigma^2\tag{1}
\]
\[
\text{There exists a constant} \,\,M\,\quad \text{such that}
\quad\,\sigma_\nu\leq M\,\,\text{for all}\,\,\nu\tag{2}
\]
\[\lim_{n\to \infty}
\frac{\sum_{\nu=1}^{\nu=n}\,\int_{|x|>\delta\sqrt{n}}\, x^2\cdot dW_\nu(x)}{n}=0
\quad\text{hold for all}\quad\delta>0\tag{3}
\]


\medskip

\noindent
{\bf Remark.} Condition (3)
means that the 
individual random variables do not  have fat tails.



\medskip 







\centerline {\emph{Proof of Theorem 1 }}
\bigskip

\noindent
Let us first assume that each $W_\nu$ is a 
finite discrete random variable given by 
a finite sum $\sum\, p_j(\nu)\cdot \delta_{x_j(\nu)}$. Let
$\mathcal C_\nu(\xi)$ be its
characteristic function:
\[
\mathcal C_\nu(\xi)=\sum p_j(\nu)\cdot e^{ix_j(\nu)\xi}\tag{*}
\]
We will    show
that
\[
\lim_{n\to\infty}\,\prod_{\nu=1}^{\nu=n}\, \mathcal C_\nu(\xi/\sqrt{n})\to
e^{-\xi^2\sigma^2/2}\tag{**}
\] 
holds uniformly
when $\xi$ varies in a compact interval $[-A,A]$.
Keeping $A>0$   fixed  we take        $\delta>0$ 
such that 
\[
A\cdot\delta\leq 1\tag{1}
\]
Next, for 
each  $n\geq 1$ we set
\[
\Psi_\nu(n)=\sum_{|x_j(\nu)|\geq \delta\sqrt{n}}\,\,p_j(\nu)x_j(\nu)^2\tag{2}
\]
Notice that Lindeberg's 3rd condition gives
\[ 
\lim_{n\to\infty}\, \frac{1}{n}\cdot
\sum_{\nu=1}^{\nu=n}\,\Psi_\nu(n)=0\tag{3}
\]



\noindent
With the notations above the crucial step is the following:

\medskip

\noindent
{\bf{2. Lemma.}} \emph{For each $\nu$ one has the inequality}
\[
\bigl|\mathcal C_\nu(\xi/\sqrt{n})-1+
\frac{\xi^2}{2n}\cdot \sigma_\nu^2\bigr|\leq\frac{3\Psi_\nu}{\delta^2\cdot n}+
\frac{A^2\Psi_\nu}{n}+\frac{A^3M\delta}{n}\tag{2.1}
\]


\medskip
\noindent
We prove (2.1) in (xx) and show first
how (2.1)  gives  (**) in a uniform way.
Denote the right hand side in (2.1) by $\rho(\nu,\delta,n)$.
Keeping
$\delta$ fixed
 we find an integer $N$ such that
 \[
 n\geq N\implies \frac{A^2M^2}{2n}+\rho(\nu,\delta,n)\leq \frac{1}{2}\tag{i}
\]
Next,
for every complex number
$\alpha$ with absolute value $\leq 1/2$ one has the inequality:
\[ 
|\text{Log}(1+\alpha)-\alpha|\leq |\alpha|^2\tag{ii}
\]
Now $\sigma_\nu^2\leq M^2$ for each $\nu$ and when
$|\xi|\leq A$ it follows from (2.1) and (i-ii):
\[
\bigl|\log(\mathcal C_\nu(\xi/\sqrt{n})+\frac{\xi^2}{2n}\cdot \sigma^2_\nu\,\bigr |\leq
\rho(\nu,\delta,n)+
\bigl(\frac{A^2M^2}{n}+ \rho(\nu,\delta,n) )^2\quad\colon\, \nu=1,2,\ldots \tag{iii}
\]
Set
\[
\rho^*(\nu,\delta,n)=
\rho(\nu,\delta,n)+
\bigl(\frac{A^2M^2}{n}+ \rho(\nu,\delta,n) )^2\tag{iv}
\]


\noindent
Taking a sum in  (iii)  we get
\[
\bigl|\sum_{\nu=1}^{\nu=n}\, \text{log}(\mathcal C_\nu(\xi/\sqrt{n})+
\frac{\xi^2}{2}\cdot \frac{\sigma_1^2+\ldots+\sigma_n^2}{n}\bigr |\leq 
\sum_{\nu=1}^{\nu=n}\,\rho^*(\nu,\delta,n)\tag{v}
\]



\noindent
We want   a uniform limit:
\[
 \lim_{n\to\infty}\, \sum_{\nu=1}^{\nu=n}\, \text{log}(\mathcal C_\nu(\xi/\sqrt{n})=
-\frac{\xi^2\cdot \sigma^2}{2}\quad\colon 
-A\leq\xi\leq A\tag{vi}
\]
From (1) in Theorem 1 and (v) this follows if
if 
\[
\lim_{n\to\infty}\, \sum_{\nu=1}^{\nu=n}\,\rho^*(\nu,\delta,n)=0\tag{vii}
\]
To prove (vii)
 we take  some $\epsilon>0$ and choose $\delta$ so small that
in addition to the previously imposed inequality
$A\cdot\delta\leq 1$ we also have
\[
A^3M\delta<\epsilon/2\tag{viii}
\]
With this choice of $\delta$ we get via the right hand side in (2.1):
\[
\sum_{\nu=1}^{\nu=n}\,\rho(\nu,\delta,n)\leq (\frac{3}{\delta^2}+A)\cdot
\frac{\Psi_1+\ldots+\Psi_n}{n}+\epsilon/2
\]
By (3) above Lemma 2.1
the first term in the right hand side above tends to zero with $n$
and since $\epsilon$ can be made arbitrary small
we get
\[
\lim_{n\to\infty}\, \sum_{\nu=1}^{\nu=n}\,\rho(\nu,\delta,n)=0\tag{ix}
\]

\noindent
The verification that (ix) gives (viii) is left to the reader.
\bigskip

\noindent
{\bf{Remark.}}
The proof above has shown that the rate of convergence with respect
to $n$ in  (vi) only depends upon the conditions imposed in
Lindeberg's theorem.
From this the reader can conclude that
the hypothesis that each
single random variable has a finite
discrete distribution is redundant.
Hence Lemma 2.1 and the above proves Theorem 1.


\bigskip

\centerline{\emph{Proof of Lemma 2.}}

\bigskip
\noindent
For a given $\nu$ we obtain
\[
\mathcal C_\nu(\xi/\sqrt{n})=
\Sigma_* \, p_j(\nu)e^{ix_j(\nu)\xi}+
\Sigma^*\,  p_j(\nu)e^{ix_j(\nu)\xi}\tag{1}
\]
where  $\Sigma_\ast$ denotes summation over those 
$j$ where $|x_j(\nu)|<\delta\sqrt{n}$ and $\Sigma^*$  the sum
when 
$|x_j(\nu)|\geq\delta\sqrt{n}$. 
We  begin to study $\Sigma_*$.
Since $|x_j(\nu)|\cdot \xi/\sqrt{n}|\leq \delta\cdot A\leq 1$  hold under 
$\Sigma_*$, the Taylor estimate in XX applied to each $j$ gives:
\[
\Sigma_* \,p_j(\nu)e^{ix_j(\nu)\xi}=
\Sigma_*\,p_j(\nu)+
\frac{i\xi}{\sqrt{n}}\Sigma_*\,p_j(\nu)x_j(\nu)-
\frac{\xi^2}{2n}\cdot \Sigma_*\,p_j(\nu)x^2_j(\nu)+\text{error}(\nu) 
\]
where 
\[
|\text{error}(\nu)|\leq 
\frac{|\xi|^3}{n\sqrt{n}}\cdot\Sigma_*\,
p_j(\nu)|x_j(\nu)|^3\leq\frac {A^3\delta\sqrt{n}}{n\sqrt{n}}\cdot
\Sigma _*\,p_j(\nu)x_j(\nu)^2\leq
\frac{A^3M\delta}{n}\tag{2}
\]
where the last inequality holds
since
 $M$ is the uniform upper bound of the variances of the random variables 
$\{W_\nu\}$. Next, we use that
\[ 
\Sigma_*\,p_j(\nu)=1- \sum^*\,p_j(\nu)\quad\text{and}\quad
\sum_*\,p_j(\nu)x_j(\nu)=-\Sigma^*\,p_j(\nu)x_j(\nu)\tag{3}
\] 
where the last equality follows since
the mean value of $W_\nu$ is zero.
Now (2-3) and the triangle inequality give:
\[
\bigl|\Sigma_*\,  p_j(\nu)e^{ix_j(\nu)\xi}-1+
\frac{\xi^2}{2n}\cdot \Sigma_*\, \,p_j(\nu)x^2_j(\nu)\bigr|\leq
\]
\[
 \Sigma^*\,p_j(\nu)+
\frac{|\xi|}{\sqrt{n}}\cdot \Sigma^*\,p_j(\nu)|x_j(\nu)|+\frac{A^3M\delta}{n}\tag{4}
\]
\medskip

\noindent
Since
$|x_j(\nu)|\geq \delta\sqrt{n}$ holds under $\Sigma^*$ we obtain
\[
 \Sigma^*\,p_j(\nu)\leq\frac{1}{\delta^2\cdot n}\cdot 
 \Sigma^*\,p_j(\nu)\cdot x^2_j(\nu)=\frac{\Psi_\nu}{\delta^2\cdot n}\tag{5}
 \]
We have also
\[ 
\Sigma^*\,p_j(\nu)\cdot |x_j(\nu)|\leq
\frac{1}{\delta\cdot \sqrt{n}}\cdot
\Sigma^*\,p_j(\nu)\cdot x^2_j(\nu)=\frac{\Psi_\nu}{\delta\cdot \sqrt{n}}\tag{6}
\]
\medskip


\noindent
From (5-6) sum in (4) is estimated above by
\[
\frac{\Psi_\nu}{\delta^2\cdot n}+\frac{|\xi|}{\sqrt{n}}\frac{\Psi_\nu}{\delta\cdot \sqrt{n}}+
\frac{A^3M\delta}{n}\leq \frac{2\Psi_\nu}{\delta^2\cdot n}+
\frac{A^3M\delta}{n}\tag{7}
\]
where the last inequality follows since $|\xi|\leq A$ and 
$\delta\cdot A\leq 1$. Next


\[
\frac{\xi^2}{2n}\cdot \Sigma_*\,p_j(\nu)x^2_j(\nu)=
\frac{\xi^2}{2n}\cdot \sigma_\nu^2-
\frac{\xi^2}{2n}\cdot \Sigma^*\,p_j(\nu)x^2_j(\nu)=
\frac{\xi^2}{2n}\cdot \sigma_\nu^2-\frac{\xi^2}{2n}\cdot \Psi_\nu\tag{8}
\]
\medskip


\noindent
Now we estimate $\Sigma^*$ from (1). Here
\[
\bigl|\Sigma^*\,p_j(\nu)e^{ix_j(\nu)\xi}\bigr| \leq
\Sigma^*\,p_j(\nu) \leq\frac{\Psi_\nu} {\delta^2\cdot n}\tag{9}
\]
We have also
\[
\frac{\xi^2}{n}\cdot \Sigma^* p_j(\nu)x_j^2(\nu)
\leq \frac{A^2\cdot \Psi_\nu}{n}\tag{10}
\]
\medskip

\noindent
Finally, (8-10) together with (4-7)
and the triangle inequality give
the requested estimate:
\[
\bigl|\mathcal C_\nu(\xi/\sqrt{n})-1+
\frac{\xi^2}{2n}\cdot \sigma_\nu^2\bigr|\leq\frac{3\Psi_\nu}{\delta^2\cdot n}+
\frac{A^2\Psi_\nu}{n}+\frac{A^3M\delta}{n}\tag{11}
\]

\newpage

\centerline{\bf{19. Poisson's summation formula.}}
\bigskip

\noindent
Let $\mu$ be a distribution on the $\xi$\vvv line with  compact support  in
the open interval $(\vvv \pi,\pi)$.
Here  $\mu=\widehat\phi$ where
the tempered distribution $\phi$ on the $x$\vvv line
extends to an entire function  of the complex variable 
$z=x+iy$.
For example, if $\mu$ is a Riesz measure we have
\[
\phi(z)=
\frac{1}{2\pi}\int\uuu{\vvv\pi}^\pi\, e^{iz\xi}\cdot d\mu(\xi)\tag{1}
\]
It turns out that  $\phi(x)$ is determined by its value taken on
the set of integers. To see this we introduce the ordinary Fourier
coefficients
\[
c\uuu n=\frac{1}{2\pi}\int\uuu {\vvv \pi}^\pi\,
e^{\vvv in\xi}\cdot d\mu(\xi)\tag{2}
\]
Now $\mu$  is recovered via Fourier's inversion formula 
on the periodic interval $(\vvv\pi,\pi)$:
\[
\mu= \sum\, c\uuu n\cdot e^{in\xi}\tag{3}
\]
At the same time  (1) gives the equalities
\[
c\uuu n= \phi(\vvv n)
\]
for all integers $n$.
This means that we formally can write

\[ 
\phi(x)=\sum\uuu{n\in{\bf{Z}}}\, \phi(\vvv n)\cdot \frac{1}{2\pi}\cdot
\int\uuu{\vvv \pi}^\pi\, e^{i(x+n)\xi}\cdot d\xi
\]
Evaluating the integrals we obtain
\[
\phi(x)=
\sum\uuu{n\in{\bf{Z}}}\, \phi(\vvv n)\cdot 
\frac{\sin\,\pi(x+n)}{\pi}\tag{*}
\]
Under the condition that $\mu$ is smooth, say a density 
given by
a twice continuously differentiable function
one has 
$\phi(\vvv n)=O(|n|^{\vvv 2})$
and  the series in the right hand side of (*) converges pointwise.
Taking    integrals we obtain:
\[
\int\uuu{\vvv\infty}^\infty\,
\phi(x)\cdot dx=
\sum\uuu{n\in{\bf{Z}}}\, \phi(\vvv n)\cdot 
\int\uuu{\vvv\infty}^\infty\,\frac{\sin\,\pi(x+n)}{\pi}
\]
Notice that
\[
\int\uuu{\vvv\infty}^\infty\,\frac{\sin\,\pi(x+n)}{\pi}=1
\quad\text{hold for every integer}\quad n
\]
Hence we get the equality
\[
\int\uuu{\vvv\infty}^\infty\,
\phi(x)\cdot dx=\sum\uuu{n\in{\bf{Z}}}\, \phi(\vvv n)\tag{**}
\]
This is no surprise since Fourier's non\vvv periodic inversion formula gives
\[
\int\uuu{\vvv\infty}^\infty\,
\phi(x)\cdot dx=\mu(0)=\sum\, c\uuu n=\sum\, \phi(\vvv n)
\]
\medskip

\noindent
{\bf{Remark.}}
One refers to (**) as Poisson's summation formula which was established by
Poisson  after Fourier had defined
Fourier series in the periodic case.
\medskip


\noindent
{\bf{19.1 Remark.}}
If we relax the assumption and only assume that
$\mu$ has compact support on the closed interval $[\vvv \pi,\pi]$
then
$\phi$ need not be determined by its restriction to ${\bf{Z}}$.
A counter\vvv example is when 
$\mu$ is the difference of the Dirac measures at
$\pi$ and $\vvv \pi$ for then
\[ 
\phi(x)= \frac{\sin\pi x}{i\pi}
\]
and here the sine\vvv function vanishes on the set of integers.
A more refined question arises if we suppose that
$\mu(\xi)$ is a continuous density where this continuous function
is zero at the two end\vvv points $\pi$ and $\vvv \pi$.
Assume that and suppose also that the inverse Fourier transform
$\phi$ vanishes on ${\bf{Z}}$. This gives
the entire function
\[ 
\psi(z)= \frac{\phi(z)}{\sin\pi z}
\]
Since $\psi$ is a quotient of two entire functions of exponential type 
Lindelšf's division 
theorem in ¤ XX shows that $\psi$ also belongs to
the class $\mathcal E$.
We can consider its restriction to the imaginary axis.
With $z=iy$ and $y>> 0$ 
the absolute value $|\sin\, (\pi iy)|\simeq
\frac{e^{\pi |y|}}{2}$. At the same time 
\[
|\phi(iy)|\leq \int\uuu 0^{\pi}\, e^{|y|\cdot \xi}\cdot |u(\xi)|\cdot d\xi
\]
From this it is clear  that
$\psi$ is bounded on the imaginary axis.
So if $\psi$ is not identically zero it follows
from the Carleman formula in ¤ xx that
\[
\int_{-\infty}^\infty\, \log^+\frac{1}{\,|\psi(iy)|}\cdot \frac{dy}{1+y^2}<\infty
\]

\medskip

\noindent
From this one can analyze how fast $u(\xi)$ tends to zero as
$\xi\to \pi$
and find conditions in order that
$\psi$ cannot be identically zero,  i.e. when
\[ 
\lim_{\xi\to \pi} u(\xi)=0
\] 
holds  sufficiently rapidly, then
its Fourier transform is determined by its values on the integers.
This leads to an involved analysis and we shall not try tenter a more detailed
discussion.




\medskip


\noindent
{\bf{19.2 A class of smoothing functions.}}
In numerical analysis  one often employs $\phi$\vvv functions
via inverse Fourier transforms of even
functions $\mu(\xi)$
which are supported by $[\vvv \pi,\pi]$
and have derivatives up to some order $k$.
In particular we can take such $\mu$\vvv functions where
$\mu(0)=0$ while the derivatives
\[
\partial^j\uuu\xi(\mu)(0)=0\quad\colon\quad 1\leq j\leq k
\]
At the end\vvv points $\pi$ and $\vvv \pi$
we impose the condition that
both $\mu$ and all derivatives up to order $k$ are zero.
Since $\mu$ is even we get:
\[ 
\phi(x)=\frac{1}{\pi}\int\uuu 0^\pi\,
\cos(x\xi)\cdot \mu(\xi)\cdot d\xi
\]
Next, when
$\mu$ is of class $C^k$ we get a constant $C$ such that
 decay condition:
\[
|\phi(x)|\leq C\cdot (1+|x|)^{\vvv k}\tag{1}
\] 
holds on the  $x$\vvv line.
But $\phi$ may   have a rather slow decay.
To see this we consider $L^2$\vvv integrals.
Parseval's equality gives for  each $0\leq p\leq k$  the equality:
\[
\int\uuu {\vvv \infty}^\infty\, 
|x|^{2p}\cdot |\phi(x)|^2\cdot dx=c\uuu *\cdot 
\int\uuu 0^\pi\, |\mu^{(p)}(\xi)|^2\cdot d\xi
\]
In the right hand side we encounter $L^2$\vvv integrals which
appear in Carleman's inequality from ¤ 8.
Let us put
\[
\gamma\uuu p(\phi)=
\bigl|\, \int\uuu {\vvv \infty}^\infty\, 
|x|^{2p}\cdot |\phi(x)\cdot dx\bigr |^{\frac{1}{2p}}
\quad\colon\quad 0\leq p\leq k
\]
Then Theorem 1 from ¤ xx gives the inequality
\[
\sum\uuu{p=1}^{p=k}\, \frac{1}{\gamma\uuu p(\phi)}\leq C\tag{*}
\]
for an absolute constant $C$.
This means that it is not possible to obtain
small $L^2$\vvv integrals  for all $1\leq p\leq k$ while $k$ increases.
In other words, the \emph{a priori inequality} (*)
puts a constraint
when one trues to exhibit $\phi$\vvv functions
which  have a good decay as $|x|\to \infty$ via (1) above and
at the same time do not increase too much before this good decay 
begins to be uniformly effective.
\medskip

\noindent
{\bf{Remark.}}
One reason why it is of interest in numerical investigations to construct
$\phi$\vvv functions as above stems from
Poisson's formula which entails that
via dilations where $\phi$ is replaced by
$\delta\cdot \phi(x/\delta)$ for $\delta>0$, it follows that
certain  discrete moment conditions hold
up to order $k$ which can be used  to approximate
functions $f(x)$ with bounded derivatives up to order $k$ on 
the real $x$\vvv line from
its values on a discrete grid given by integer 
multiples of some positive number.
We shall not pursue this  any further since it
would lead to an extensive discussion related to numerical
analysis. The interested reader can  consult [Zahedi: Chapter 3]
for
some theoretically  interesting material about
approximations by delta functions   adapted for
delicate numerical investigations.

\newpage




\centerline{\bf{20. The heat equation and integral formulas.}}
\medskip


\noindent
{\bf{Introduction.}}
The subsequent material stems from Beurling's
lectures about quasi.analytic functions. See
[Beurling: Collected work xx].
In ¤ 0.X from the introduction we recalled some facts
about the heat-equation.
Here  shall study a restricted class of solutions
which is referred to as the logarithmic class in
[ibid]. The major result appears in
¤ xx which gives
an integral fornula for such solutions
to the heat equation.
The construction of the  kernel function for this
integral formula requires considerable work
which involves properties of analytic functions
in the half-space
$\mathfrak{Re}|, z>0$
defined by
\[
 f(z)= \int_0^\infty\, t^{z-1}\,d\mu(t)
\]
where $\mu$ is a non-negative Riesz measure.
So we begin with a study of such functions and
not until ¤ 3.x we begin to consider the heat equation.





\bigskip

\centerline{\bf{The class $\mathcal P$.}}

\medskip


\noindent
Let $\mu$ be a non-negative measure on the
non-negative real $t$-line such that  $a>-1$ gives
\[ 
\int_0^\infty t^a\cdot |d\mu(t)|<\infty\tag{1}
\]
This yields an analytic function
$f(z)$Êin the half-plane $\mathfrak{Re}\, z>0$
defined by
\[ 
f(z)= \int_0^\infty t^{z-1}\, d\mu(t)\tag{2}
\]
The  class  of $\gamma$-functions which arise in this way
is denoted by
$\mathcal P$ and called 
positive definite analytic functions in the right half-plane.
\medskip

\noindent
{\bf{Exercise.}}
Show that if $\mu$ and $\nu$ is a pair of non-negative measures 
which satisfy 
(1) so does  the convolution $\mu*\nu$.
Conclude  that
a product of two $\mathcal P$-functions again belong to
$\mathcal P$ and use this to show
that when
$f\in\mathcal P$ then the exponential sum 
below also belongs to $\mathcal P$:
\[ 
e^{f(z)}=
1+ \sum_{n=1}^\infty\,\frac{\gamma(z)^n}{n !}
\]



\noindent
Now we construct a class of functions in
$\mathcal P$:
\medskip

\noindent
{\bf{20.1. Proposition.}}
\emph{Let $\mu$ be a positive measure on $\{t\geq 0\}$ such that}
\[ 
\int_0^\infty\, \frac{d\mu(t)}{1+t}<\infty
\]
\emph{Then the analytic function below belongs to  $\mathcal P$
for
all pairs of real numbers $a,B$:}
\[ 
f(z)= \exp\bigl(\, Bz+(z-a)^2\cdot \int_0^\infty\, \frac{d\mu(t)}{z+t}\bigr)
\] 


\noindent
\emph{Proof.}
It is clear that $f$ is analytic in
the right half-plane.
By the observations in the exercise  about the class $\mathcal P$ 
and approximating $\mu$ weakly by finite sums of discrete point-masses
it suffices to show that
\[
\exp\bigl(\, Bz+(z-a)^2\cdot \frac{b}{z+t}\bigr) \in\mathcal P\tag{i}
\]
when $b$ and $t$ are positive real numbers.
To get (i)  we write
\[
\frac{(z-a)^2}{z+t}= z+t+\frac{(t-a)^2}{z+t}-2(a+t)z\tag{ii}
\]
Since 
$e^{cz}\in\mathcal P$ for every real constant $c$
and 
$\mathcal P$ is stable under products, there only remains to verify that
\[
\exp\bigl(\, \frac{b(t-a)^2}{z+t}\bigr)\in\mathcal P\tag{iii}
\]
To prove (iii) we set $k=b(t-a)^2$
and notice that
\[ 
\frac{k}{z+t}=
k\cdot \int_0^t \, s^{z-1}\cdot s^t\cdot ds
\]
Then (iii) follows after we have taken
the exponential sum
\[
\exp\bigl(\, \frac{k}{z+t}\bigr)= 1+\sum_{n=1}^\infty
\frac{1}{n !} \,\cdot \frac{k^n}{(z+t)^n}
\]
\bigskip


\centerline {\bf{20.2. The function $\gamma(z)$.}}
\medskip

\noindent
Let $e$ be Neper's constant. Removing the negative interval
$(-\infty,-e]$ from the complex plane
we have a single valued branch of $\log(z+e)$
and get the analytic function 
\[ 
\gamma(z)=[\log(e+z)]^z
\] 

\medskip

\noindent
{\bf{Exercise.}} Set
\[
\mathcal G(t)=\arctan\, \frac{\pi}{\log\,(t-a)}\quad\colon t>e
\]
Apply residue calculus to prove the equality
\[
\frac{\log\log(z+e)}{z}= \frac{1}{e}+
\frac{1}{\pi}\int_e^\infty
\frac{\mathcal G(t)}{t(t+z)}\, dt+
\int_{e-1}^e\, \frac{dt}{t(t+z)}
\]


\noindent
Deduce from this that
\[
\gamma(z+1/2)=
\exp\bigl[\,A+Bz  \frac{z^2}{\pi}\cdot \frac{1}{\pi}\int_{e-1/2}^\infty
\frac{\Theta(t)(t-1/2)}{t+z)}\, dt\bigr]\tag{i}
\]
where $\Theta(t)= \pi$ in the interval $[e-1/2,e+1/2]$ and after
it is non-increasing and tends to zero as $t\to +\infty$.


\medskip


\noindent
Next,  Euler's exponential formula for the $\Gamma$-function
from the introduction in these notes, together with
(i) above and Proposition 20.1 it follows 
that the function

\[ 
f(z)= \frac{\Gamma(z)}{\gamma(z+1/2)}\in\mathcal P\tag{*}
\]
\medskip

\noindent
{\bf{Remark.}}
The expression  of  the non-negative measure $\mu$ for which
\[ 
f(z)= \int_0^\infty \, t^{z-1}\, d\mu(t)
\]
is rather involved. The  reader is invited to  find $\mu$
numerically with a computer.








\bigskip


\centerline{\bf{20.3 The heat equation and integral formulas.}}
\bigskip

\noindent
Consider the function
$\gamma(z)$ above.
With $a>0$ real and positive we 
get  the function
\[
 y\mapsto \gamma(a+iy)
\]
Notice that
\[ 
\lim_{y\to+\infty}\, \log(a+iy)=\frac{\pi}{2}\cdot i
\]
Passing to the double log-function we have
\[ 
\lim_{y\to+\infty}\, \log\, \log(a+iy)=\log \frac{\pi}{2}+
\frac{\pi}{2}\cdot i
\]
where we used that $\log i= \frac{\pi}{2}\cdot i$.
It follows that the absolute value
\[
|\gamma(a+iy)|\simeq e^{-\pi y/2}
\quad\colon\, y\to +\infty
\]
If $y$ instead tends to $-\infty$  we use that
$\log\,-i= -\frac{\pi}{2}\cdot i$
and find that
\[
|\gamma(a+iy)|\simeq e^{-\pi |y|/2}
\quad\colon\, y\to -\infty
\]
Hence the integral
\[
\int_{-\infty}^\infty\, \gamma(a+iy)\cdot t^{-a-iy}\, dy\tag{*}
\] 
converges for every real and positive $t$.

\medskip

\noindent
{\bf{3.1 Exercise.}}
Show that
(*) is independent of $a$
and set
\[ 
K(t)=
\frac{1}{2\pi}\, \int_{-\infty}^\infty\, \gamma(a+iy)\cdot t^{-a-iy}\, dy
=
\frac{1}{2\pi i}\int_{\mathfrak{Re}\, z=a}\, t^{-z}\gamma(z)\, dz
\quad\colon\, t>0\tag{3.1.1}
\]
It follows that
\[ 
K(t)\leq \inf_{x>0}\, t^{-x}\frac{1}{2\pi}\, \int_{-\infty}^\infty
\,|\gamma(x+iy)|\, dy\tag{3.1.2}
\]
Show that (3.1.1)gives  a function
$\delta(t)$ which tends to zero as
$t\to +\infty$ and 
\[ 
K(t)\leq e^{-e^{t-\delta(t)}}\tag{3.1.3}
\]
which means that $K(t)$ decreases very rapidly as $t\to +\infty$.
Finally, show that Mellin's inversion formula gives:
\[
\gamma(z)= \int_0^\infty\, t^{z-1}\, K(t)\, dt\tag{3.1.4}
\]
From ¤ 2 we already know that
$\gamma$ is positive definite and hence
$K(t)$ is real-valued and non-negative.


\medskip

\noindent
{\bf{3.2 The $W$-function.}}
Let $\Gamma(z)$ be the ordinary  gamma-function and set
\[
 f(z)= \frac{\Gamma(z)}{\gamma(z+1/2)}
\]
Show via Stirling's formula that if $-\pi/2<\theta<\pi/2$ then
\[
\log\, f(re^{i\theta})|=
\quad  \text{Check (23) on page 422 }\tag{3.2.1}
\]
Conclude  that
there exists an analytic function  in the  half-plane 
$\mathfrak{Re}\, z>0$
defined by
\[ 
W(z)=\frac{1}{2\pi i}\cdot 
 \int_{\mathfrak{Re} \zeta=a}\, f(\zeta) \, z^{-\zeta}\quad\colon a>0
\tag{3.2.2}
\]
Moreover, show that
there exists some $\alpha>0$ and $x_0>0$ such
that
\[
x>x_0\implies W(x)\leq e^{-\alpha x\log x}\tag{3.2.3}
\]
\medskip

\noindent
Finally, apply  the result in ¤ 2 to conclude that 
$W(x)\geq 0$ on the non-negtive real $x$-line.
\medskip

\noindent
{\bf{3.3 A harder exercise.}}
Show that
$W(z)$  extends to an entire function in the 
whole complex $z$-plane. The hint is to
change the contour in (3.2.2 ) above when  $z$ 
moves into the left half-plane.


\newpage

\noindent
{\bf{3.4 An integral equation.}}
Using (3.1.4) and by studying the Mellin transform one has
the equation
\[
\int_0^\infty\, W(\frac{x}{t})\cdot \frac{K(t)}{\sqrt{t}}\, dt= e^{-x}\tag{3.4.1}
\]
See page 422 for details of the proof.


\medskip

\noindent
{\bf{3.5 The logarithmic class.}}
Given a postive  real numbers
$A>0$ we consider solutions $u(x,y)$ defined
in a domain $\Omega=\{-\infty < x<+\infty\}\times
\{-A<y<A\}$ to the heat equation
\[
\partial_x^2(u)= \partial_y(u)
\]
Denote by $\mathcal L$ the class of such solutions 
for which there exists a function
$\rho(r)$ which tends to zero as $r\to+\infty$ and 
\[ 
|u(x,y)|\leq e^{\rho(|x|)x^2\cdot \log |x|}
\]
holds in $\Omega$.
\medskip

\noindent
{\bf{3.6 Theorem.}}
\emph{Each $u\in \mathcal L$ is determined by
its values on the vertical line $\{y=0\}$.
Moreover there exists an integral representation of
$u(x,y)$ for $0<y<A$
via the function 
$x\mapsto u(x,0)$.}
\bigskip


\noindent
To achieve this result we
use the $W$-function above
and define another function $V(x,y)$ by
\[
V(x,y)= \frac{W(\frac{x^2}{4y})}{\sqrt{y}}
\]
\medskip

\noindent
The estimate (3.2.3)
entails that
if $u$ belongs toÊ$\mathcal L$ then
the
convolution integral
\[
\frac{1}{2\sqrt{\pi}}\cdot \int_{-\infty}^\infty\, V(x-\xi,y)\cdot u(\xi)\, d\xi
\]
is absolutely convergent for each $y>0$
and defines a function denoted by $v(x,y)$.
With these notations the assetions in
the theorem above
follow from the follonig
\medskip

\noindent
{\bf{3.7 An integral formula.}}
With the notations as above one has
\[ 
u(x,y)=\int_0^\infty\, v(x,yt)\cdot K(t)\, dt\tag{3.7.1}
\]
where the integral in the right hand side converges absolutely
for each
$0\leq y<A$.
\medskip

\noindent
{\bf{3.8 Remark}}.
The  proof of (3.7.1) is given in ¤ xx below.
It uses of course the assumption that
$u$ satisfies the heat equation and
the reason why (3.7.1) holds stems from the
equation
\[ 
U(x,y)= \int_0^\infty\,
W(\frac{x^2}{4yt})\cdot \frac{K(t)}{\sqrt{t}}\,dt
\]
where $U$ is the ordinary heat kernel

\[
U(x,y)=e^{-x^2/y}\quad \colon y>0
\] 
while $U(x,y)=0$ when $y\leq 0$.
































\newpage


\centerline{\bf{21. Calculations of some Fourier transforms.}}
\medskip


\noindent
{\bf{1. Inverse Fourier transforms of $\xi_+^s$}}.
 Let $s$ be  complex  with 
 $\mathfrak{Re}\, s>-1$.
 On the $\xi$-line we get the tempered distribution defined by
 \[ 
 g\mapsto\int_0^\infty\, \xi^s\cdot g(\xi)\, d\xi\tag{i}
 \]
 The inverse Foueier transform
 is the boundary value of an analytic function in
 $\mathfrak{Im}\, z>0$.
 To find it we consider the analytic function 
 in the upper half-plane defined by
 \[ 
 \phi(z)= \frac{1}{2\pi}\cdot 
 \int_0^\infty\,
 e^{iz\xi}\cdot \xi^s\, d\xi\tag{ii}
 \]
Taking the derivative with respect to $z$ gives
\[
\phi'(z)=\frac{i}{2\pi} \int_0^\infty\,
 e^{iz\xi}\cdot \xi^{s+1}\, d\xi
\] 
A partial integration with respect to $\xi$ identifies the right hand side with
\[
 -\frac{i}{2\pi}\cdot \frac{1}{iz}(s+1)
  \int_0^\infty\,
 e^{iz\xi}\cdot \xi^s\, d\xi
\]
It follows that
\[
z\cdot \phi'(z)=-(s+1)\cdot \phi(z)
\]
So  if  $\nabla= z\cdot \frac{\partial}{\partial z}$
is the Fuchsian differential operator then
\[ 
\nabla(\phi)+(s+1)\phi=0
\]
holds in the upper half-plane $U_+$.
The family of  analytic functions in $U_+$  satisfying this
equation are constants times
$z^{-s-1}$.
There remains to find the constant $c(s)$ such that
$\xi_+^s$ is the Fourier transform of
the boundary value distribution
\[
\mu_{-s-1}=c(s)\cdot (x+i0)^{-s-1}
\]
To get $c(s)$ we  take $z=i$ in (ii)
which gives
\[ 
\phi(i)= \frac{1}{2\pi}\int_0^\infty\, e^{-\xi}\cdot \xi^s\, d\xi=
\frac{\Gamma(s+1)}{2\pi}
\]
 Hence we should take 
 \[ 
 c(s)\cdot i^{-s-1}=\frac{\Gamma(s+1)}{2\pi}
\]
Here
\[
i^{-s-1}= e^{-(s+1)\log i}=
e^{-(s+1)\pi i}\implies
c(s)=e^{(s+1)\pi i}\cdot\frac{\Gamma(s+1)}{2\pi}\tag{*}
\]
\medskip

\noindent
Summing up we have proved the following:

\medskip

\noindent
{\bf{21.1Theorem.}}
\emph{The distribution-valued function $\xi_+^s$
extends to a meromorphic function the whole complex $s$-plane and one has}
\[
\xi_+^s=
e^{(s+1)\pi i}\cdot\frac{\Gamma(s+1)}{2\pi}\cdot
\widehat{(x+i0)}^{-s-1}
\]
\medskip


\noindent
{\bf{21.2. Taylor extensions.}}
The Taylor extension of the density
$\xi^{-1}$ on $(0,+\infty)$ is the distribution defined by:
\[ 
g\mapsto 
\int_0^1\, \frac{g(\xi)-g(0)}{\xi}\, d\xi+
\int_1^\infty\, \frac{g(\xi)}{\xi}\, d\xi\tag{2.1}
\]
where $g(\xi)$ belong to the Schwartz class on the $\xi$-line.
To find the inverse Fourier transform we consider the analytic funtion in
the upper half-plane
\[ 
\phi(z)=\frac{1}{2\pi}\cdot \bigl[
\int_0^1\, \frac{e^{iz \xi}-1}{\xi}\, d\xi+
\int_1^\infty\, \frac{e^{iz\xi}}{\xi}\, d\xi\,\bigr]\tag{2.2}
\]
Taking the complex derivative we get
\[
\phi'(z)=\frac{i}{2\pi}\cdot
\int_0^1\, e^{iz \xi}\, d\xi+
\int_1^\infty \, e^{iz\xi}\, d\xi\,\bigr]=\frac{i}{2\pi}\cdot
\int_0^\infty\, e^{iz \xi}\, d\xi\tag{2.3}
\]
The right hand side is $i$ times
the inverse Fourier transform of the Heaviside function $H_+(\xi)$
on the $\xi$-line.
So if $\mu$ is the boundary value distribution of
$\phi$ one has
\[ 
\widehat{\partial_x(\mu)}=i\cdot H_+(\xi)\tag{2.4}
\]
The interchange formula under Fourier transforms gives
\[
\widehat{\partial_x(\mu)}=i\xi\cdot \widehat{\mu}=i\cdot H_+(\xi)
\]
Hence 
$\widehat{\mu}$ is expressed by the density $\frac{1}{\xi}$.
There remains to determine the $\phi$-function in (2.2).
Performing a partial integration of the integral in
the right hand side of (2.3) while $\mathfrak{Im}\, z>0$ gives:
\[
\phi'(z)= -\frac{i}{2\pi}\cdot \frac{1}{iz}
=-\frac{2\pi}{z}\tag{2.5}
\]
In the upper half-plane the  functions which satisfy
this differential equations are of the form
\[
-2\pi\cdot \log z+C
\] 
where $C$ is some constant.
The complex $\log$-function has a boundary value distribution
and
hence the inverse Fourier transform of Taylor's extension of
$\frac{1}{\xi}$ is equal to
\[
\mu=-2\pi\log\,(x+i0)+ C\tag{2.6}
\]
where it  remains to determine the constant $C$.
To find $C$ we take $z=i$ and notice that
\[ 
\phi(i)= 
\phi(z)=\frac{1}{2\pi}\cdot \bigl[
\int_0^1\, \frac{e^{- \xi}-1}{\xi}\, d\xi+
\int_1^\infty\, \frac{e^{-\xi}}{\xi}\, d\xi\,\bigr]
\]
is  a real number.
At the same time
$\log\, i= \frac{\pi i}{2}$ is purely imaginary and
must therefore be cancelled by $C$ which gives:
\[
\mu=-
2\pi\log (x+i0)+2\pi\cdot\frac{\pi i}{2}+a
\]
where $a$ is the real number. 
To find $a$ we consider the $\Gamma$-function. With $s>0$ and small one has
\[
\Gamma(s)= \int_0^\infty\, e^{-\xi}\xi^{-1+s}\,d\xi=
\int_0^1\, \frac{e^{-\xi}-1}{\xi^{1-s}}\,d\xi+
\int_1^\infty\, e^{-\xi}\xi^{-1+s}\,d\xi+
\int_0^1\,\xi^{-1+s}\,d\xi
\]
The last integral is equal to $s^{-1}$.
Hence
$\Gamma(1+s)-\frac{1}{s}$
is equal to the sum of the first teo intergals. When $s\to 0$ it is clear that
this sum converges to $2\pi a$ and which therefore is the constant term at $s=0$
of
$\Gamma(1+s)-\frac{1}{s}$.
The functional equation for the $\Gamma$-function from  ¤ XX Gamma 
entails that $a=0$.
Hence we have proved

\medskip

\noindent
{\bf{3. Theorem.}}
\emph{The inverse Fourier transform of Taylor's extension of
$\xi^{-1}$ from  (2.1) is  given by the distribution}
\[
 -2\pi \log\,(x+i0)+\pi^2 i
\]
\medskip

\noindent
{\bf{4. The distribution $\mathcal T\xi_+^{-2}$.}}
It is the distribution defined by
\[ 
g\mapsto 
\int_0^1\, \frac{g(\xi)-g'(0)\cdot \xi-g(0)}{\xi^2}\, d\xi+
\int_1^\infty\, \frac{g(\xi)}{\xi^2}\, d\xi\tag{4.1}
\]
To find the inverse Fourier transform we consider the function
\[ 
\psi(z)=\frac{1}{2\pi}\cdot
\int_0^1\, \frac{e^{iz\xi}-iz\xi-1}{\xi^2}\, d\xi+
\int_1^\infty\, \frac{e^{iz\xi}}{\xi^2}\, d\xi\tag{4.2}
\]
It follows that
\[ 
\psi'(z)=\frac{1}{2\pi}\cdot
\int_0^1\, \frac{i\xi\cdot e^{iz\xi}-i\xi}{\xi^2}\, d\xi+
\int_1^\infty\, \frac{i\xi \cdot e^{iz\xi}}{\xi^2}\, d\xi\tag{4.3}
\]
Hence we have
\[ 
\psi'(z)= i\cdot \phi(z)=
-2\pi i\cdot \log z-\pi^2\implies
\tag{4.4}
\]
\[ 
\psi(z)=-2\pi i\cdot z\log\,z+(2\pi i-\pi^2)z+C
\]
for some constant $C$
As in ¤ 3 we notice that $\psi(i)$ is real
which implies that $-\pi^2 i+C$ must be real and hence


\[ 
\psi(z)=-2\pi i\cdot z\log\,z+(2\pi i-\pi^2)z+\pi^2 i+ a
\quad\colon\, a\in{\bf{R}}
\]
With $z=i$ we find that
\[
\psi(i)= \pi^2-2\pi+a
\] 
Hence $a$ is determined when we have evaluated the integral (4.2) with
$z=i$.

\medskip

\noindent{\bf{Exercise.}}
FIND $a$ !
\medskip


\noindent
{\bf{5. The general case.}}
For every $n\geq 1$ we have the distribution
$\mathcal T\xi_+^{-n}$
obtained via Taylor's extension of
the density $\xi^{-n}$ on $(0,+\infty)$
Its inverse Fourier transform $\mu_n$
is the boundary value of an analytic function in the upper
half-plane. The following conclusive result holds:

\medskip

\noindent
{\bf{Theorem.}}
\emph{For each positive integer $n$ the inverse Fourier transform of
$\mathcal T\xi_+^{-n}$ is the constant term at $s=-n$ of
the meromorphic distribution-valued function}
\[
s\mapsto e^{(s+1)\pi i}\cdot \frac{\Gamma(s+1)}{2\pi}\cdot
(x+i0)^{-s-1}
\]


\medskip


\noindent
{\bf{Exercise.}} Prove this result.
 
 
 
\newpage

\centerline{\bf{22. Boundary values in two variables.}}
\medskip


\noindent
With two real variables $(x_1,x_2)$ one considers the 2-dimensional complex space
$(z_1,z_2)$ with $z_k=x_k+iy_k$.
In the real $y$-space we consider an open truncated cone:
\[ 
\mathcal K=\{(y_1,y_2)\quad y_2>M\cdot |y_1|\}\cap \{
0<y_1^2+y_2^2<\delta^2\}
\]
where $\delta,M$ are positive constants.
Put
\[
\square=\{ (x_1,x_2\quad -1<x_1,x_2<1\}
\]
The open set $\mathcal T=\square+i\cdot\mathcal K$ 
in ${\bf{C}}^2$
is
called a truncated tube.
Let $f(z_1,z_2)$ be a bounded analytic function in
$\mathcal T$.
To each  point $(y_1^*,y_2^*)\in\mathcal K$
the 1\vvv dimensional results
show that if  $g(x_1,x_2)$ is a test-function in $\square$
then there exists a limit
\[
\lim_{\epsilon\to 0}\, \int_\square\, g(x_1,x_2)
\cdot f(x_1+
i\epsilon y_1^*,x_2+i\epsilon y_2^*)\cdot dx_1dx_2\tag{*}
\]

\noindent
Moreover, (*)  is independent of the point $y^*=(y_1^*,y_2^*)$
and we obtain a distribution in $\square$ denoted by
${\bf{b}}f$.
Since 
$f$ is  bounded the resulting 
distribution has order zero, i.e.
expressed by a Riesz measure $\mu_f$ in $\square$.
The reader may notice the
close interplay to the 1-dimensional case and we remark
that the existence of a limit distribution can be established by
regarding Fatou limits. 
Next, we can relax the assumption that $f$ is bounded. Assume only that
there is some integer $m\geq 1$ such that
\[
|f(x_1+
i y_1,x_2+iy_2)|\leq C_\cdot
(y_1^2+y_2^2)^{-m/2}\tag{*}
\]
hold for some constant $C_m$ and all points in the tube.
To get the distribution ${\bf{b}}f$
one employs small $\bar\partial$-extension of test-functions $g$.
If  $N\geq 1$ we set
\[ 
G_N(x+iy)=
\sum\, i^{k+j}\cdot
\frac{\partial^{k+j}(g)}{\partial^k x_1\partial^j x_2}(x)
\cdot \frac{y_1^k\cdot y_2^j}{k!\cdot j!}
\]
\medskip

\noindent
Using Stokes Theorem one verifies that when (*) above holds, 
then
there exists a distribution ${\bf{b}}\uuu f$ defined on test-functions $g(x)$ by
\[
{\bf{b}}\uuu f(g)=
\lim_{\epsilon\to 0}\, \int_\square\, G_m(x_1,x_2)
\cdot f(x_1+
i\epsilon y_1^*,x_2+i\epsilon y_2^*)\cdot dx_1dx_2\tag{**}
\]
where the limit does not depend upon the chosen
point
$y^*\in\mathcal K$.
The conclusion is that if $\mathcal O(\mathcal T)_{\text{temp}}$
denotes the space of all analytic functions
$f(z)$ in the tube satisfying (**) above for some integer $m$, then
$f\mapsto {\bf{b}}\uuu f$ yields  a linear 
map to a space of distributions in
$\square$.
\medskip




\noindent
{\bf{2.10 The Schwarz reflection in two variables.}}
Let $\mathcal K^*$ be the opposed cone defined by
\[ 
K^* =
\{(y_1,y_2)\quad y_2<-M\cdot |y_1|\}\cap \{
0<y_1^2+y_2^2<\delta2\}
\]
If $\phi(z)$ is a tempered analytic function in the corresponding 
truncated tube domain
$T^*)$
we obtain the distribution  ${\bf{b}}_\phi$.
Suppose  we have an equality of distributions:
\[
{\bf{b}}\uuu \phi=
{\bf{b}}\uuu f
\tag{1}
\]
Then  there exists
an analytic function $\Psi(z)$ defined in a complex neighborhood of
the real square  $\square$ whose restriction to $\mathcal T$ is 
$f$ while $\Psi|\mathcal T^*=g$.
A proof can  be established
by scrutinizing the 1-dimensional case carefully. But the 
efficient  and 
easiest method is to
consider 
the Fourier transforms of
the two distributions
${\bf{b}}\uuu f$ and
${\bf{b}}\uuu \phi$ which
entails that the 
common distribution in (1) has an empty  analytic wave front set  and
is therefore defined by a real\vvv analytic density on
$\square$ which extends to be holomorphic in a small 
complex neighborhood and  yields 
the complex analytic extension of the pair 
$f(z)$ and $\phi(z)$.
Details about this procedure which  extends to every
 any dimension $n\geq 2$
is given in [Bjšrk; Chapter 8].


\noindent
{\bf{2.9 Analytic wave front sets.}}
The result in ¤ 2.10 is often referred to as the Edge of the Wedge theorem.
As indicated above the  proof relies upon the notion of
analytic wave front sets of distributions
which has been introduced independently by Hšrmander and Sato.
In Sato's theory the construction of analytic wave front
sets is expressed by their 
representations  as boundary values of analytic functions.
Hšrmander considered 
decay properties of Fourier transforms in cones
with varying directions.
Apart from the  article
[Hš:xx] the reader may consult Chapter X in [Hšrmander]
or the material in 
[Bjšrk:xx: page. xxx-xx]
for an  account.
about analytic wave front sets
from which one easily deduces
Schwarz' reflection theorem in two variables.



\newpage




\centerline{\bf 23. The Radon transform}

\bigskip

\noindent
In the article  [Radon] from 1917
Johann Radon 
established  an inversion formula which recaptures 
a  test-function $f(x,y)$ in ${\bf{R}}^2$
via   integrals over   lines
in the
$(x,y)$-plane
parametrized by pairs $(p,\alpha)$,
where  $p\in{\bf{R}}$ and $0\leq \alpha<\pi$
give  the line
$\ell(p,\alpha)$:
\[
 t\mapsto 
 \bigl(p\cdot \text{cos}\,\alpha-
 t\cdot \text{sin}\,\alpha\, , \,p\cdot \text{sin}\,\alpha+
 t\cdot \text{cos}\,\alpha\bigr)
 \]


\noindent
The distance to the origin of a point on this line
is
equal to $p^2+t^2$ and the nearest point to the origin
appears when $t=0$.
With $z=x+iy$ we identify ${\bf{R}}^2$ with the complex plane.
The Radon  transform of a function $f$ is defined 
for every $z\neq 0$ by
\[ 
\mathcal R_f(z)= |z|\cdot \int_{-\infty}^\infty\, f(z+izu)\, du\tag{*}
\]
If $z= re^{i\alpha}$
we use the variable substitution $u\mapsto tr$ and 
the left hand side becomes
\[
\mathcal R_f(z)=
\int_{-\infty}^\infty\, f(z+ie^{i\alpha}\cdot t)\, dt
\]
The unit vector $ie^{i\alpha}$ is $\perp$ to the vector
$z$ which means that
$\mathcal R_f(z)$ evaluates the integral of $f$ on the  line
which is $\perp$ to $z$ and passes this point.
\medskip


\noindent
Since the absolute value $|1+iu|\geq 1$ for every real $u$, it is clear that
if $f$ has support in a disc
of radius $R$ centered at the origin then the same holds for
the
Radon transform.
So  $\mathcal R_f$
is a linear operator on the space of 
continuous functions with compact support.
\medskip


\noindent
{\bf{Example.}}
Let $f=\chi_D$ be the characteristic function of the unit disc. Then
$\mathcal R_f(z)=\sqrt{1-|z|^2}$ when $|z|\leq 1$ and  vanishes outside $D$.


\medskip

\noindent
When $z=x$ is real we notice that
\[ 
\mathcal R_f(x)= |x|\cdot \int_{-\infty}^\infty\, f(x+ixu)\, du
=\int_{-\infty}^\infty\, f(x,s)\, ds\tag{1}
\]
\medskip

\noindent
Consider the Fourier transform of $f(x,y)$ in the $(\xi,\eta)$-coordinates.
From (1) we get
\[ 
\widehat f(\xi,0)=\int_0^\infty\, e^{-ix\xi}\, R_f(x)\,dx\tag{2}
\]
When $f$ has compact support 
its Fourier transform is a real-analytic function of
$(\xi,\eta)$ and hence
$\widehat f(\xi,\eta)$ is determined
by its restriction to $\{\eta=0\}$. So  (2)  shows that
$f$ is determined by the restriction of the
Radon transform to the real line. In particular   $\mathcal R$ is an injective operator.
\medskip

\noindent
{\bf{1. Inversion formulas.}}
Let us first  consider the case when $f$ is radial.
So here $f(x,y)$ only depends on $r=\sqrt{x^2+y^2}$.
When $f$ is a radial function with compact support and of class $C^2$
we have
\[
\widehat f(\xi,0)=\int_{-\infty}^\infty\ e^{-ir\xi}\, f(r)\, dr\tag{i}
\]
and Fourier's inversion formula for radial
functions in ¤ X gives
\[
f(r)= \frac{1}{2\pi}\, \int e^{ir\xi}\, \widehat f(\xi,0)\cdot |\xi|\, d\xi
\tag{ii}
\]
where the last integral is given as a limit:
\[
\lim_{A\to\infty}\, \frac{1}{2\pi}\, \int_{-A}^A 
e^{ir\xi}\,\widehat f(\xi,0)\cdot |\xi|\, d\xi
=\lim_{A\to\infty}\, \frac{1}{2\pi}\, \int_{-A}^A 
e^{ir\xi}\cdot e^{-ix\xi}\, \mathcal R_f(x)\cdot |\xi|\,dxd\xi\tag{2}
\]
For each $A>0$
we define 
a function on the real $u$-line by
\[ 
K_A(u)=\frac{1}{2\pi}\, \int_{-A}^Ae^{iu\xi}\, |\xi|\, d\xi
\]
Then (1-2) give
\[ 
f(r)=\lim_{A\to\infty}\int\, K_A(r-x)\cdot \mathcal R_f(x)\, dx\tag{3}
\]
\medskip

\noindent
Above $K(u)$ is an even function of $u$ 
and a computation gives
\[
K_A(u)=\frac{1}{\pi}\, \int_{0}^A\,\cos (u\tau)\, \tau\, d\tau=
\frac{1}{\pi}\cdot\bigl(A\cdot \frac{\sin Au}{u}-
\frac{1-\cos Au}{u^2}\,\bigr)\tag{4}
\]
\medskip

\noindent
Moreover, (3) can be written as:
\[ 
f(r)=\lim_{A\to\infty}\int\, K_A(x)\cdot \mathcal R_f(r+x)\, dx\tag{5}
\]
\medskip



\noindent
{\bf{B. The general case.}}
Above we treated radial functions.
This covers the general case because
the Radon transform commutes with rotations. More precisely, to
each
$e^{i\theta}$  we have the rotation operator
sends a function $f(z)$ to
\[
\mathfrak{r}_\theta(f)(z)= f(e^{i\theta}z)
\]
Then it is clear from (*) that
\[ 
\mathfrak{r}_\theta\circ\mathcal R=
\mathcal R\circ\mathfrak{r}_\theta
\quad\text{hold for all}\quad \theta\tag{**}
\] 
\medskip

\noindent
From (**) and (5) we obtain the general inversion formula:
\medskip

\noindent
{\bf{1.1 Radon's Theorem.}}
\emph{For each $f\in C^0({\bf{R}}^2)$ with compact support 
one has:}
\[ 
f(x,y) =
\lim_{A\to\infty}\,
\frac{1}{2\pi}\int_0^\pi\,\bigl[
\int_{-\infty}^\infty\,
R_\alpha(
x\cdot \text{cos}\,\alpha+
y\cdot \text{sin}\,\alpha-u)\cdot K_A(u) du\,\bigr]
\cdot d\alpha\tag{*}
\]
\medskip

\noindent
{\bf{Remark.}}
The Radon transform has many applications. Especially in
tomography.
Here is a simple illustration:
Let 
$f(x,y)$ be  a positive function in some compact convex subset $K$ 
of ${\bf{R}}^2$
which represents a distribution of
mass.
By evaluation  integrals along different lines
one gets information about the $f$-function and
in this way Radon's inversion formula applies where an actual experiment
in general consists of some finte family of
such
evaluations. 
Passing to the 3-dimensional case
the radon transform of a given function $f(x,y,z)$ in
${\bf{R}}^3$
is defined in a similar fashion. More precisely, for each
$0\neq p\in{\bf{R}}^3$ 
we have the affine plane $\Pi^\perp(p)$ which
passes through $p$ and is 
$\perp$ to the vector $p$. Now
\[ 
\mathcal R_f(p)= \int_{\Pi^\perp(p)}\, f(p+q)\, dA(q)
\]
where $dA(q)$ is the area measure on
$\Pi^\perp(p)$.
Just as in the 2-dimensional case the 
$\mathcal R$-operator commutes with
rotations and using this together with Fourier's inversion formula applied to
$f$
one gets Radon's inversion formula in 
${\bf{R}}^3$ where 
one employs the 
the group of unitary transformations with determinant one
and constructs  a radial $K$-function which gives
the inversion formula via a convolution. The reader is invited to
carry out he details or consult  text-books by
Helgason which treat Radon transforms in great detail.


\newpage



\centerline{\bf{25. An extension of Runge's theorem.}}

\bigskip

\noindent
Consider an open rectangle $\square=\{-a<x<a\}\times \{-b<y<b\}$
in the complex $z$-plane.
Let  $\omega(y)$
be a continuus function which is $>0$ for $y\neq 0$ while $\omega(0)=0$.
Moreover,
$y\to \omega(y)$
decreases as $y$ tends to zero through positive or negative values.
Denote by $C_\omega(\square)$ the space of
complex-valued continuous functions
$f(z)$ 
such that the product $\omega(y)f(z)$
is continuous on the closed rectangle $\overline{\square}$
and vanishes on the real interval $[-a,a]$.
It becomes a Banach space under the  norm:
\[ 
||f||=\max_{x+iy\in \square}\, \omega(y) |f(x+iy)|
\]
Define
\[
A_\omega(\square)=\{ f\in 
C_\omega(\square)\,\colon\, f|\square\in\mathcal O(\square)\}
\]
We have also the larger subspace
$A_\omega^*(\square)$ of functions $f$ in
$C_\omega(\square)$ whose restrictions to the 
rectangles $\square_+$ and 
$\square_+$  
both are analytic functions of $z$.
It is clear that
$A_\omega^*(\square)$  is a closed subspace of
$C_\omega(\square)$, while the closedness of
$A_\omega(\square)$ is not automatic.
It turns out that properties of
$A_\omega(\square)$ depend upon the $\omega$-function.

\medskip

\noindent
{\bf{Theorem.}} \emph{Under the condition}
\[ 
\int_{-b}^b\, \log\log \omega(y)\, dy=-\infty\tag{*}
\]
\emph{one has the equality
$\overline{A_\omega^*(\square)}= A_\omega(\square)$.
If (*) is finite then
$A_\omega^*(\square)$ is a closed proper subspace of
$A_\omega(\square)$.}
\medskip

\noindent
The proof requires several steps
and we begin with the first part, i.e. that
(*) entails that
$A^*_\omega(\square)$ is dense in $A_\omega(\square)$.
To prove this
we consider   a Riesz measure
$\mu$ supported by
$\overline{\square}$ where
$\omega(y)\cdot \mu$
is $\perp$ to
$A^*_\omega(\square)$. It remains to show that
\[
\int\,f\,d\mu=0\quad\colon f\in A^*(\square\tag{1}
\]
To achieve this we proceed as follows.
For each complex number $\zeta$ we have 
$e^{i\zeta z}\in A^*_\omega(\square)$. It follows that
\[
0=
\int_{y\geq 0}\, e^{i\zeta z}\cdot \omega(y)\,d\mu(z)+
\int_{y<0}\, e^{i\zeta z}\cdot \omega(y)\,d\mu(z)=F_+(\zeta)+F_-(\zeta)
\]
Here $F_+$ and $F_-$ are entire functions of exponential type.
If $\zeta=\xi$ is real and non-negative we have
\[ 
|F_+(\xi)|\leq 
\int_{y\geq 0}\, e^{-\xi y}\cdot \omega(y)\,|d\mu(z)|\leq
\max_{0\leq y\leq b}\,\omega(y)\cdot ||\mu||
\]
Hence $F_+(\xi)$ is bounded when
$\xi\geq 0$ and in the same way 
$F_-(\xi)$ is bounded when
$\xi\geq 0$.
Since $F_+(\xi)+F_-(\xi)=0$
on the whole real $\xi$-line we conclude that
$F_+(\xi)$ is bounded.
We have also
\[
|F_+(\xi)\leq 
\int_{y\geq 0}\, e^{-\xi y}\cdot \omega(y)\,|d\mu(z)|\tag{i}
\]
To profit upon (i) we consider the function
\[
 h(y)=-\log \omega(y)\quad\colon y>0
\]
Introduce the lower Legendre envelope defined for $\xi>0$ by 
\[
k(\xi)=\min_{0<y\leq b}\, h(y)+\xi y
\]
Then we have
\[
e^{-\xi y}\cdot \omega(y)=
e^{-\xi y+\log \omega(y)}\leq e^{-k(\xi)}\quad\colon 0<y\leq b\tag{ii}
\]
Hence (i) gives
\[
|F_+(\xi)\leq e^{-k(\xi)}\cdot ||\mu||\quad\colon \xi >0\tag{iii}
\]
At this stage we use the general result about Legendre envelopes from ¤
xx where (*) in Theorem ¤ xx entails that
\[
\int_1^\infty\frac{k(\xi)}{\xi^2}\ d\xi=+\infty\tag{iv}
\]
Next,  (ii) gives
\[
\log^+\frac{1}{|F_+(\xi)|}\geq
k(\xi)-\log \,||\mu||
\]
hence (ii) entials that
\[
\int_1^\infty\,\log^+\frac{1}{|F_+(\xi)|} \cdot \frac{d\xi}{\xi^2}=
+\infty\tag{iv}
\]
At the same time $F_+$ is an entire functionof exponential type which is bounded
on the real axis and hence belongs to the Carleman class and  the result in
¤ xx shows  that $F_+$ must be identically zero.
This means that
the restriction of
$\omega(y)\cdot \mu$ to the closed rectangle $\overline{\square}_+$
is $\perp$ to functions of the form
$z\mapsto e^{i\zeta z}\colon\,\zeta\in {\bf{C}}$.
In the same way the restriction to
the lower rectangle has this property.
There remains to show  that this gives (1).
To achieve this
we consider first the upper triangle where $z_1=ib/2$ is a center.
With $0<\epsilon <1 $ we define
\[
T_\epsilon(z)= -z_1+(1-\epsilon)(z-z_1)
\]
If $f\in A^*_\omega(\square)$
it follows that $f(T_\epsilon(z)$ is analytic
in the closure of $\square_+$. By the standard Runge theorem it
can be uniformly approximated by 
exponential polynomials
$\{e^{iz\zeta}\} $
and the vanishing of $F_+$ entails that
\[
\int_{\square_+}\, 
f(T_\epsilon(z))\cdot \omega(y)\, d\mu(z)=0\tag{v}
\]
Next, the reader may verify that
there exists a constant
$C$ which is independent of $\epsilon$ such
that
\[
\omega(y)\cdot |f(T_\epsilon(z))|\leq C\cdot ||f||_\omega
\quad \colon z\in \square_+
\]
Now

\[
\lim_{\epsilon\to 0}\, 
 f(T_\epsilon(z))=f(z)
 \]
holds in $\square_+$. By (xx) we can apply dominated
convergence which we perform $\mu$-integrals.
Hence the vanishing integrals in (v) imply that
  \[
 \int_{\square_+}\, 
f(z))\cdot \omega(y)\, d\mu(z)\tag[{vi}
\]
In the same way one proves that
the integral over
$\square_-$ is zero. Hence $\mu$ is $\perp$ to
$A_\omega^*(\square)$ which finishes the proof
of the density assertion in
Theorem XX. 


\newpage 





\centerline {\bf{Special chapter: ODE-equations.}}
\medskip

\noindent
Ordinary differential
equations   are best treated by distributions.
On the real $x$-line the space of distributions is denoted by
$\mathfrak{Db}({\bf{R}})$. Notice that we do not insist that
the distriobutions are tempered, i.e.
$\mathcal S^*$ appears as a proper subspace.
As a first  example we take  the first order differential operator
\[
\nabla=x\cdot \frac{\partial}{\partial x}
\]
When $x\neq 0$ the equation $\nabla(f)=0$ has
solutions given by constant functions.
To pass beyond $x=0$ we take  the Heaviside densities
$H^+$ and $H_-$, where $H^+(x)=1$ when $x>0$ and  zero if $x<0$, while
$H_-=1-H^+$. It turns out that
these two linearly independent distributions on the $x$-line
generate the vector space of all distribution solutions to
the equation $\nabla(\mu)=0$. See ¤ xx below for details.
On the other hand, if $f(x)$Êis a $C^1$-function, i.e. continuously
differentiable which  satisfies $\nabla(f)=0$, then it is
clear  that $f$ must be a constant.
So  the set of distribution solutions is more extensive.
Next, let $s$ be a complex number which is not an integer.
If  $\mathfrak{s}>-1$ then $x^s$ is  integrable 
on intervals $(0,a)$ with $a>0$ and there exists a distribution denoted
by $x_+^s$ acting as a linear functional on test-functions
$\phi(x)$ by
\[ 
x_+^s(\phi)= \int_0^\infty x^s\cdot \phi(x)\, dx
\]
On the open interval $(0,+\infty)$
we notice that
\[ 
(\nabla-s)(x^s)=0\quad\colon x>0
\]
It we apply 
$\nabla-s$ to the distribution $x_+^s$
the construction of distribution derivatives means that
$(\nabla-s)(x_+^s)$ acts on test-functions $\phi$ by
\[
\phi\mapsto \int_0^\infty x^s \cdot (-\partial(x\phi)-s\phi)\, dx\tag{i}
\]
When $\mathfrak{Re}\, s>-1$
a partial integration shows that
(i) is zero.
Hence $(\nabla-s)(x_+^s)=0$.
It turns out that there exist more distributions $\mu$ such that
$(\nabla-s)(\mu)=0$. Namely, there exists
the boundary
value distribution 
$\mu=(x+i0)^s$ which also satisfies the equation $(\nabla-s)(\mu)=0$.
Here we recall that $\mu$ is defined on test-functions $\phi(x)$ by
\[
\mu(\phi)= \lim_{\epsilon\to 0}\,
\int\, (x+i\epsilon)^s\cdot \phi(x)\, dx\tag{ii}
\]
Hence we have found two linearly independent 
distribution solutions to the equation $\nabla-s(\mu)=0$.
It turns out that they give a basis for the null solutions which gives the dimension
formula:
\[ 
\dim_{{\bf{C}}}\, 
(\text{Ker}_{\nabla-s}(
\mathfrak{Db}))=2
\]
\medskip

\noindent
{\bf{A special example.}}
Take $Q= \nabla+1$. Here
two boundary value distributions
$(x+i0)^{-1}$ and $(x-i0)^{-1}$ are null solutions.
Let us also recall that
the difference
\[
(x-i0)^{-1}-(x+i0)^{-1}=\pi i\cdot \delta_0
\]
So the Dirac measure at $x=0$ is also a null solution
which of course could have been verified directly.
By the general result in ¤ xx the space of null solutions is
2-dimensional so above we have found a basis.
\medskip

\noindent
In ¤ xx we consider general
differential operators with polynomial coefficients
\[ 
P(x,\partial)=p_m(x)\partial^m+\ldots+p_0(x)
\]
Under the assumption that the real zeros of the
leading polynomial $p_m(x)$
are simple and consists of some $k$-tuple
$\{a_1<\ldots a_k\}$ we show in ¤ xx 
that the
$P$-kernel on
$\mathfrak{Db}$ has dimension $k+m$.
\medskip



\noindent
{\bf{0.1 A first order ODE-equation.}}
Let $p$ and $q$ be a pair of polynomials and set
\[
Q=q(x)\cdot \partial -p(x)
\] 
Assume that 
$q$ is a monic polynomial of some  degree $k\geq 2$ whose  zeros are real and simple and
arranged in strictly increasing order
$\{ a_1<a_2<\ldots <a_k\}$. The polynomial $p$ is such that
$p(a_\nu)\neq 0$  for every $\nu$ and in general it has complex coefficients and
no condition is imposed upon its degree.
Now we seek distributions $\mu$ on the $x$-line such that
$Q(\mu)=0$.
One such solution is found
as the boundary value of the analytic function
defined in the upper half-plane by
\[
f(z)= e^{\int_i^z\, \frac{p(\zeta)}{q(\zeta)}\, d\zeta}
\]
Tos see this we notice
that
when $\mathfrak{Im} z>0$ it is evident that
the complex derivative
\[
\frac{\partial f}{\partial z}=\frac{p(z)}{q(z)}\tag{i}
\]
Since
the passage to boundary value distributions commute
with
derivations it follows that
the boundary value distribution
 $f(x+i0)$ is a null solution to $Q$. Less obvious is that
 each simple and real zero 
$a_\nu$  of $q$ yields a null solution
$\mu_\nu$ supported by the half-line 
$[a_\nu.+\infty)$.This is a consequence of general results in ¤ xx.
Let us remark 
that
without using boundary values of analytic functions it is not
easy to discover all this.



\bigskip






\noindent
{\bf{0.2 The equation $\nabla^2(\mu)=0$}}.
The Fuchsian operator is defined by
$\nabla =x\partial$.
It turns out that the space of distributions
$\mu$ satisfying $\nabla^2(\mu)$ is a 4-dimensional vector space.
One solution is the Heavisde function $H_+$
defined by the density 1 if $x>0$ and zero if
$x\leq 0$.
Here
\[ 
\partial(H_+)(g)=
-\int_0^\infty g'(x)\, dx= g(0)\quad\colon g\in C_0^\infty({\bf{R}})
\] 
This means that the distribution derivative
$\partial(H_+)=\delta_0$ and since
$x\cdot \delta_0=0$ we have 
$\nabla(H_+)=0$. 
Next, on $\{x>0\}$
we see that the density $\log x$ satisfies
$\nabla^2(\log x)=0$.
It is tempting to extend the locally integrable function
$\log x$ on the positive half-line to
${\bf{R}}$ by setting the value zero if $x\leq 0$.
Denote the resulting distribution by
$\log_+x$. Now
\[
\nabla(\log_+x)(g)=
-\int_0^\infty\, -\partial(xg)\cdot \log x\, dx=
\int_0^\infty\,xg\cdot \frac{1}{x}\, dx=
\int_0^\infty\,g dx
\]
Hence $\nabla(\log_+x)= H_+$
Since $\nabla(H_+)=0$
we get
$\nabla^2(\log_+ x)=0$.
Hence we have found two  linearly independent null solutions
given by the pair $(H_+,\log_+ x)$ which are supported by
$x\geq 0$.
In addition we find two other null solutions.
The first is the constant density 1, The second is
the boundary v alue distribution
$\log (x+i0)$.
By the gneral resu,t in ¤ xx the space of null solutions is
4-dimensional so above we have found a basis for these.

\medskip


\noindent
{\bf{0.3. Higher order Fuchsian  equations.}}
Let $m\geq 2$ and consider an operator of the form
\[
Q= \nabla^m+q_{m-1}(x)\nabla^{m-1}+\ldots+q_1(x)\nabla+q_0(x)
\]
where $\{q_\nu(x)\}$ are polynomials.
With $\{c_\nu=q_\nu(0)\}$
we associate the polynomial
\[
Q^*(s)= s^m+c_{m-1}s^{m-1}+\ldots+ c_1s+c_0
\]
Under the assumption that
$Q^*(k)\neq 0$
for all non-negative integers
the solution space
$\mathcal S=\{\mu\colon\, Q(\mu)=0\}$
has dimension $2m$ and a basis is found as follows:
In
the upper half-plane 
the Picard-Fuchs theory about holomorphic differential equations
entails that 
there exists
an $m$-tuple of linearly independent analytic functions
$\{\phi_\nu(z)\}$ which solve $Q(z,\partial_z)(\phi_\nu)=0$.
Similarly one finds an $m$-tuple $\{\psi_\nu\}$ 
of linearly independent analytic functions in  the lower half-plane.
The boundary
value distributions
$\{\phi_\nu(x+i0)\}$ and
$\{\psi_\nu(x-i0)\}$
belong to $\mathcal S$ and  are linearly indepedent.
For if 
$\sum\, c_\nu\phi_\nu(x+i0)+ \sum d_\nu\psi_\nu(x-i0)=0$
where at least some
$c_\nu$ or $d_\nu$ is $\neq 0$
then \[
\phi_*(x+i0)=\psi_*(x-i0)=0\tag{i}
\]
where
$\phi_*=\sum\, c_\nu\phi(x+i0)\neq 0$ and
$\psi_*=-\sum\, d_\nu\psi(x-i0)\neq 0$.
Now (i) cannot hold. The reason is that 
the assumption about
$Q^*(s)$  entails that
the equation $Q(z,\partial_z)(f)=0$ has no holomorphic solutions
at $z=0$. This fact stems from local
$\mathcal D$-module theory and is exposed in ¤ xx.
Now  the  reflection principle  for analytic functions entails
that the analytic wave front
sets of the distributions $\phi_*$ 
 and $\psi_*$ both are non-empty.
 On the other hand the material in ¤ xx shows 
 that these non-empty wave fronts  have opposed directions and hence the 
 equality (i) cannot hold. This proves that 
 $\mathcal S$ is at least $2m$-dimensional
 and by the general results in ¤ xx
 we have equality. So above we have constrcuted a basis for the null solutions.
 

\bigskip




\centerline{\bf{¤ 1. Fundamental solutions to ODE-equations with constant coefficients}}

\bigskip

\noindent
We  consider differential operators  with constant coefficients
acting on the real $x$-line. To
simplify the passage to Fourier transform we introduce the first
order operator
\[ 
D=\frac{1}{i}\cdot \frac{d}{dx}
\]
If $P(\xi)$ is a polynomial of the
$\xi$-variable and $\mu$ is a tempered distributionon
the $x$-line this gives  the equality:
\[
\widehat{P(D)\mu}(\xi)= P(\xi)\cdot \widehat\mu(\xi)\tag{*}
\]
By a tempered fundamental solution to
$P(D)$ we mean a distribution $\mu\in\mathcal S^*$ such that
\[
P(D)\mu=\delta_0
\] 
where $\delta_0$ is the Dirac measure at $x=0$.
Since
the Fourier transform
of $\delta_0$ is the identity on the $\xi$-line 
the Fourier transform
of a fundamental solution satisfies
\[
P(\xi)\cdot \widehat\mu(\xi)=1
\]
When
$P(\xi)$ has no zero on the
real $\xi$-line  there
exists a  fundamental
solution
given as the inverse Fourier transform of
the smooth density $P(\xi)^{-1}$.
If $P(\xi)$ has some real zeros we can write 
\[
P(\xi)=Q(\xi)\cdot R(\xi)
\]
where
$R$ has real zeros and the zeros of
$Q$ are all non-real.
The factorisation is unique when we
choose constants so that
$Q(\xi)$ is a monic polynomial.
The case $\deg Q=0$ is not excluded, i.e. this 
holds  when 
all zeros of $P(\xi)$ are real.
But in general one has a mixed case where
$n=\deg P$ and $1\leq \deg Q\leq n-1$.
\medskip

\noindent
{\bf{1. The case $\deg Q=0$}}.
When all zeros of $P(\xi)$  real there exists the boundary
value distribution on the $\xi$-line defined
by
\[
\gamma= \frac{1}{P(\xi-i0)}\tag{1.1}
\]
By the general results from ¤ XX its inverse Fourier transform is supported by 
the half-line $\{x\geq 0\}$. Let $\mu_+$ denote this distribution.
Then
\[
\widehat{P(D)\mu_+}= P\xi)\cdot\gamma=1
\]
and hence $\mu_+$ is a fundamental
solution.
\medskip

\noindent
{\bf{2. The mixed case}}.
If $P=Q\cdot R$ where
$1\leq \deg Q\leq n-1$
we proceed as follows.
First
one has a bijective map on
the space of tempeted distributions on
the $\xi$-line defined by
\[
\gamma\mapsto
Q(\xi)^{-1}\cdot \gamma
\]
Fourier's inversion fomrula gives
a bijective linear operator
$T_Q$ on the space of tempered distribtutions on the $x$-line such that
\[
\widehat{ T_Q(\mu)}= Q(\xi)^{-1}\cdot\widehat\mu
\]
So if 
$\mu$ is a temepred distribution we get
\[
P(D)(T_Q(\mu))= R(D)(\mu)\tag{2.1}
\]
The zeros of $R(\xi)$ are real which gives
the
fundamental solution $\nu_+$  to $R(D)$
and now
\[ 
\mu=T_Q(\nu_+)\tag{2.2}
\] 
yields a fundamental solution to $P(D)$.
In this way we have constructed  a fundamental
solution in a canonical fashion.
In contrast to the real case where
$\deg Q=0$ the distribution $\mu$ above is in general not supported by
the half-line $\{x\geq 0\}$. We give  examples in ¤ XX below.

\bigskip

\noindent
{\bf{3. The determination of $\mu_+$}}.
Consider the case when $\deg Q=0$ so that
the fundamental solution $\mu_+$ is
the inverse Fourier transform of (xx) above.
Let us for the moment assume that
the real zeros of $P(\xi)$ are all simple
and given by an $n$-tuple $\{\alpha_k\}$.
Define the distribution
$\rho$ on the real $x$-line by  the density
\[
\rho(x)= \sum\, \frac{1}{P'(\alpha_k)}\cdot e^{i\alpha_kx}\quad\colon x\geq
0
\] 
while $\rho(x)=0$ when $x<0$.
It is clear that the distribution 
$P(D)\rho$ vanishes when $x\neq 0$, i.e. 
supported by the singleton set $\{x=0\}$.
Newton's  formula from  ¤ xx gives
\[ 
\sum_{k=1}^n\, \frac{1}{P'(\alpha_k)}\cdot \alpha_k^m=0\quad\colon\,\,
0\leq m\leq n-2
\]

\medskip

\noindent
This entails that
the derivatives up to order
$n-2$
of $\rho$ vanish at $x=0$.
Using this
we  show that $\rho$ up to a  constant gives a fundamental solution to $P(D)$.
For consider a test-function $f(x)$
and
let $P^*(D)$ be the adjoint of $P(D)$. 
The vanishing of the derivatives of $\rho$ at $x=0$ above 
gives after partial integration
\[
\int\, \rho(x)\cdot P^*(D)(f)(x)\, dx=(-1)^{xx}\cdot \rho^{(n-1)}(0)\cdot f(0)
\]
\medskip


\noindent
{\bf{4. Conclusion.}}
The fundamental solution $\mu_+$ supported by  $x\geq 0$ 
is given by the density
\[ 
\mu_+(x)=\frac{n}{xx}\cdot
\rho(x)= \sum\, \frac{1}{P'(\alpha_k)}\cdot e^{i\alpha_kx}
\]


\noindent
{\bf{5. Example.}}
Consider $P(D)= D^2-1$ so that $P(\xi)= \xi^2-1$.
Here 1 and $-1$ are the simple zeros and (xx) gives
\[ 
\mu_+(x)=XXX\cdot \sum\, \frac{1}{-2}\cdot e^{-ix}+\frac{1}{2}\cdot e^{ix}
=-\sin x\quad\colon\, x\geq 0
\]



\noindent
{\bf{6. An example in the mixed case.}}
Let $P(D)= (D^2+1)(D-a)$ 
where $a$ is some real number
$\neq 0$.
So here $Q(\xi)= \xi^2+1$
and the fundamental solution from ¤ 2  becomes
\[
\mu=T_Q(\nu_+)\tag{6.1}
\]
where $\nu_+$ is the inverse Fourier transform
derived from the linear polynomial. $R(\xi)=\xi-a$.
This gives
\[
 \nu_+(x)= -e^{iax}\quad\colon x\geq 0\tag{6.2}
\]



\noindent
{\bf{7. The expression of $\mu$.}}
By the above $\mu$ 
is  the convolution of $\nu_+$ and
the continuous density 
\[ 
\phi(x)= \frac{1}{2\pi}\int\, \frac{e^{ix\xi}}{1+\xi^2}\, d\xi
\]
We leave it to the reader to verify that
\[ 
\phi(x)=
\frac{1}{2}\cdot e^{-|x|}
\]
Hence 
\[
\mu(x)=-\frac{1}{2}\cdot \int_0^\infty\ e^{-[x-y|}\cdot e^{-aiy}\, dy
\]
The reader is invited to analyze this function 
using
a computer to
plot  this function with different choice of $a$.


\newpage



\centerline {\bf{2.0. ODE-equations on the real line}}

\medskip

\noindent
{\bf{0.1.2 Higher order equations.}}
In  ¤ xx we
consider a differential operator
$Q(x,\partial)$ of order $m\geq 2$ with polynomial coefficients:
\[ 
Q(x,\partial)=q_m(x)\partial^m+\ldots+q_1(x)\partial+q_0(x)
\]
Notice that we  get a holomorphic differential operator
when we pass to the complex variable $z=x+iy$
and set
\[
Q(z,\partial_z)=q_m(z)\partial_z^m+\ldots+q_1(z)\partial_z+q_0(z)
\]
Assume that
the polynomials 
$\{q_\nu(x)\}$ have no   common zero in the complex plane and that the leading
polynomial
$q_m$ has real and simple zeros
$\{a_1<\ldots<a_k\}$ for some positive integer $k$.
Since $q_m(z)\neq 0$ when $z$ is outside the real axis
it is easily shown that
in the upper half-plane $U_+=\mathfrak{Im}\, z>0$
there exists an $m$-dimensional subspace of
$\mathcal O(U_+)$
whose functions $f(z)$ satisfy $Q(z,\partial_z)(f)=0$.
Let  $\{f_1,\ldots,f_m\}$ be the basis for the solutions in
$\mathcal O(U_+)$.
To each zero $a_\nu$ we consider small open disc
$D=\{|z-a_\nu|<r\}$
with $r$ so small that $|a_j-a_\nu|\geq r$ for all $j\neq\nu$.
Here  two case can occur: The first  is that  the restriction
of every $f_\nu$ to the half-disc
$D_+$ extends to be analytic in $D$ and then 
$a_\nu$ is called a  negligable singular point for the 
ODE-equation.
If some   $f$-function fails to extend.
Malgrange's index formula from ¤ xx shows
that there exists an $m-1$-dimensional subspace of
these $f$-functions whose restrictions extend to be holomorphic in
$D$.
Using this local index formula 
we show in ¤ xx that if
$k_*$ is the number of zeros of $q_m$ which are
not negligable then
the space of distributions $\mu$ defined on the whole real line
such that $Q(\mu)=0$
is a vector space of dimension $m+k_*$.
\medskip



\noindent
To grasp the notion of distributions
it is natural to  
start  with a  study of distribution solutions to ordinary differential
operators which
leads to  more systematic results as compared to 
studies before  distribution theory was
established.
An example is the confluent hypergeometric function which
arises as a solution to a differential operator of the form
\[
P=x\partial^2+(\gamma -x)\partial -a
\]
where $\gamma$ is a non-zero complex number while
$a$ is arbitrary.
In the classic literature one solves this equation via the
Laplace method which involves a rather cumbersome
use of residue calculus.
More  information about the operator
$P$ arises when one determines its kernel on the  space
of distributions on the real $x$-line.
The  result in Theorem 0.0.1 below shows that
this $P$-kernel is a 3-dimensional subspace of 
$\mathfrak{Db}$. Moreover, there exists a fundamental 
solution supported by the 
half-line $\{x\geq 0\}$.
\medskip

\noindent
Let us now discuss the general situation where one regards 
a differential operator with
polynomial  coefficients
\[
P(x,\partial)=q_m(x)\cdot 
\partial^m+q_{m-1}(x)\partial^{m-1}+
\ldots+q_0(x)\tag{*}
\]
where $m\geq1 $ and  $q_0(x),\dots,q_m(x)$
are polynomials which in general  have complex coefficients.
Let $\mathfrak{Db}$ be the space of distributions on the real
$x$-line.
A first question is to determine the
$P$-kernel, i.e. one seeks all distributions $\mu$ such that
$P(\mu)=0$.
Following material from the thesis by Ismael (xxx - University of
xxx) we 
expose some general facts. The reader may postpone the
subsequent discussion until later since
we shall use notions such as analytic wave front sets and boundary
value distributions  whose contructions are given later on.
But in anny case it is  instructive to pursue the
results below and the reader who has learnt 
the details in the examples 0.0.4-0.0.5  
has begun to master distribution theory.
\bigskip

\noindent
\emph{The local  Fuchsian condition.}
We shall restrict the study to operators $P$
which are  \emph{locally Fuchsian} at every real zero of the leading polynomial
$q_m(x)$. This 
means the following:
Let $a$ be a real zero of
$q_m(x)$ with some multiplicity $e\geq 1$
so that $q_m(x)=q(x)(x-a)^e$ where the polynomial $q$ is
$\neq 0$ at $a$.
Then we can
write
\[
P(x,\partial)=q(x)\cdot 
[(x-a)^e\partial^m+r_{m-1}(x)\partial^{m-1}+
\ldots+r_0(x)]
\] 
where $\{ r_\nu=\frac{p_\nu}{q}\}$ are rational functions with
no pole at $a$ and therefore define analytic functions in a neighbrohood of $a$.
Hence
\[
 P_*(x,\partial)=(x-a)^e\partial^m+r_{m-1}(x)\partial^{m-1}+
\ldots+r_0(x)
\] 
can be identified with a germ of
a differential operator with coefficients in the local ring
$\mathcal O(a)$ of germs of analytic functions
at $a$.
The ring
$\mathcal D$ of such germs of differential operatoes
is
studied in ¤ x where we  define the subfamily of
Fuchsian operators.
For example, if $a=0$ then
a Fuchsian operator in
$\mathcal D$ is of the form
\[
\rho(x)\cdot [\nabla^m+g_{m-1}(x)\nabla^{m-1}+\ldots+g_0(x)]
\] 
where $\rho, g_{m-1},\ldots,g_0$ belong to $\mathcal O$
and
$\nabla=x\partial$ is the first order Fuchsiuan operator.

\medskip

\noindent
From the above
we can
announce the following conclusive result:
\medskip

\noindent
{\bf{0.0.1 Theorem }}
\emph{Let  $P(x,\partial)$ in (*) above be  locally Fuchsian
at the real zeros of $p_m$.
Then $\text{Ker}_P(\mathfrak{Db})$  is a complex vector space
of dimension 
is equal to $m+e_1+\ldots+e_k$
where $\{e_\nu\}$ are the multiplicities
at
the real zeros of $p_m$. Moreover, for each real zero of
$p_m$ there exists a  distribution $\mu$ supported by
$\{x\geq a\}$  such that
$P(\mu)= \delta_a$.}
\bigskip



\noindent


\noindent
{\bf{Remark.}}
The crucial part in the proof of
Theorem 0.1 relies upon 
constructions of boundary values of analytic functions.
Moreover  the following supplement to Theorem 0.0.1 hold.
For   each real zero $a$ of $p_m(x)$ with some multiplicity
$e$ there exists
a distinguished $e$-dimensional subspace
$V_a$
of
$\text{Ker}_P(\mathfrak{Db})$  which consists of distributions
$\mu$ supported by  
the closed half-line $[a,+\infty]$ whose analytic wave front
sets satisfy the following: First 
it contains the whole fiber above $a$ and the remaining part
of the analytic wave front set
is either empty or a  union of half-lines
above some of the 
real zeros 
of $p_m$ which are $>a$.
Moreover, one has a direct sum decomposition 
\[
\text{Ker}_P(\mathfrak{Db})=\mathcal F_+
 \oplus\, V_{a_\nu}\tag{**}
\] 
where the last  direct sum is taken over the real zeros of $p_m$, and
$\mathcal F_+$ is an  $m$-dimensional subspace of
$\mathfrak{Db}$ with a basis given by
an $m$-tuple of     boundary value distributions
$\{\phi_k(x+i0)\}$.
Here  
$\{\phi_k(z)\}$ are analytic functions in
a strip domain 
$U=\{-\infty < x<+\infty\}\times \{0<y<A\}$
with $A>0$ chosen so that
the complex polynomial $p_m(z)$ is zero-free in this domain
and each  $\phi_k(z)$ satisfies the homogeneous equation
$P(z,\partial)(\phi)=0$ in $U$.
\medskip


\noindent
{\bf{Example.}}
Consider the first order differential operator 
\[ 
P=x\partial+1
\]
Outside $x=0$ the density $x^{-1}$ is a solution.
In ¤¤ we shall learn hos to construct the Euler distribution $x_+^{-1}$
which is suppored by $[0,+\infty)$ and find that 
\[
P(x_+^{-1})=\delta_0
\] 
The 1-dimensional
$\mathcal F_+$-space in (**)
is generated by the boundary value distribution
$(x+i0)^{-1}$.









\medskip

\noindent
{\bf{0.0.2 Tempered  solutions.}}
The $P$-kernel in  Theorem 0.0.1 need not consust of 
tempered distributions. 
The reason  is that we have not imposed
the condition that $P$ is locally Fuchsian at
infinity.
So if $\mathcal S^*$ denotes the space of tempered distributions, then
$\text{Ker}_P(\mathcal S^*)$ can have strictly smaller dimension than
$m+k$ and the   determination of the tempered solution space
leads to a more involved analysis.
Already the case $P=\partial-1$ illustrates the situation. Here
the $P$-kernel on
$\mathfrak{Db}$ is the 1-dimensional space given by the exponential density
$e^x$ which is not
tempered so the
$P$-kernel on $\mathcal S^*$ is reduced to zero.
During the search for tempered  fundamental  solutions  to $P$
supported by half-lines $\{x\geq a\}$
one can   use a  result due to PoincarŽ  under the extra assumption that 
$\deg p_k\leq \deg p_m$ hold for every $0\leq k<m$.
For in  this case there are 
series expansions when $x$ is large and positive:
\[
\frac{p_k(x)}{p_m(x)}=c_k+\sum_{\nu=1}^\infty\, c_{k\nu}x^{-\nu}
\quad\colon 0\leq k\leq m-1
\]
The leading coeficients $c_0,\ldots,c_{m-1}$
give a monic
polynomial
\[
 \phi(\alpha)=\alpha^m+c_{m-1}\alpha^{m-1}+\ldots c_0
 \] 
Let us also chose 
$A>0$  so  large that the leading polynomial $p_m$ has no
real zeros on
$[A,+\infty]$. This  gives an
$m$-dimensional  space of null solutions where a basis consists
of real-analytic densities $u_1(x),\ldots,u_m(x))$
on this interval.
 
\medskip

\noindent {\bf{0.0.3 PoincarŽ's theorem.}}
\emph{Suppose that  $\phi$ has  simple
simple zeros 
$\alpha_1,\ldots,\alpha_m$. 
Then, with $A$ as above
one can arrange the $u$-basis so that}
\[
u_k(x)=e^{\alpha_k x}\cdot g_k(x)
\]
\emph{and  there exists a non-negative integer $w$ and a constant $C$ such that}
\[ 
|g_k(x)\leq C\cdot (1+x)^w\,\colon 1\leq k\leq m
\]
\emph{hold for all $x\geq A$.}


\medskip

\noindent
So for 
indices $k$ such that
$\mathfrak{Re}\,\alpha_k\leq 0$, it follows that
$u_k(x)$ has tempered
growth as $x\to +\infty$.
In particular PoincarŽ's result entails
that if the real parts are all $\leq 0$, then the
fundamental solutions from Theorem 0.0.1 
are all tempered.


\medskip

\noindent
{\bf{0.0.4 Example.}}
Consider the operator
\[
 P=x\partial^2-x\partial-B
 \] 
 where  $B> 0$.
 In this case
 \[
 \phi(\alpha)=\alpha^2-\alpha=\alpha(\alpha-1)
\]
so one of the $u$-solutions above increse exponentially
while the other has tempered growth as $x\to +\infty$.
It is easily seen that
 the there exists   an entire solution
 \[ 
 f(x)= x+c_2x^2+\ldots\tag{i}
 \]
such that $P(f)=0$, whose
coefficients are found by the recursive formulas
\[ 
k(k-1)c_k= (k-1+B(c_{k-1}\quad \colon k\geq 2
\]
Hence $\{c_k\}$ are positive and it is clear that
$f$ has exponential growth as $x\to +\infty$.
In addition we have a solution on
$x>0$ of the form
\[ 
g(x)=  f(x)\cdot \log x+a(x)
\]
In  ¤¤ we explain that  $P(g_+)= a\cdot \delta_0$
hold for a non-zero constant
while $P(f_+)=0$.
Next, let et $u_1$ be the tempered solution and $u_2$ the non-tempered solution in
PoincarŽ's theorem on the half-line $x>0$.
There are  constants $c_1,c_2$ such that
\[
f(x)= c_1u_1(x)+c_2u_2(x)
\]
Here   $c_2\neq 0$ because $f$ increases exponentially on $(0,+\infty)$.
At the same time
\[
g(x)= d_1u_1(x)+d_2u_2(x)
\]
hold for some constants $d_1,d_2$. Set
\[ 
\gamma=g_+-\frac{d_2}{c_2}\cdot f_+
\]
From the above $\gamma$ has tempered growth as
$x\to+\infty$ and 
$P(\gamma)= a\cdot \delta_0$
with $a\neq 0$. Hence $\mu= a^{-1}\cdot \gamma$ yields 
a tempered fundamental  solution supported by
$\{x\geq 0\}$.
\medskip

\noindent
In ¤ xx we give further examples
of tempered fundamental solutions.

\medskip



\noindent{\bf{0.5 Another  example.}}
Here we take 
\[
P= \nabla^2+q(x)\tag{0.3.1}
\] 
where $q(x)$ is a polynomial  such that $q(0)=-1$ and $q'(0)=0$.
For example, if $q(x)=x^2-1$ we encounter 
a wellknown Bessel operator.
It is easily  seen that there exists a unique entire solution
$f(x)$  which satisfies $P(f)=0$ with 
a series expansion
\[ 
f(x)= x+c_3x^3+\ldots
\]
Moreover, one verifies easily that there exists another entire
function $g(x)$ with $g(0)=0$ such that
the multi-valued function
\[
\phi(z)= f(z)\cdot \log z+ g(z)\tag{i}
\]
satisfies $P(\phi)=0$.
Theorem 0.0.1 predics that the $P$-kernel on
$\mathfrak{Db}$ is 4-dimensional. To begin with
$f$ restricts to a real analytic densitiy on the
$x$-line and gives a null solution.
A second  solution is obtained by the boundary value distribution
\[
\gamma=\phi(x+i0)= f(x)\cdot \log (x+i0)+ g(x)
\]
Together they give a basis in the 2-dimensional space
$\mathcal F_+$ from (*) in the remark 
after Theorem 0.0.1.
There remains to find two linearly independent distributions in
$V_0$ since the leading polynomial of $P$ has a double zero at $x=0$.
To attain such a pair 
we first consider the boundary value distribution
\[
\gamma_*= f(x)\cdot \log (x-i0)+ g(x)
\]
which also is a null solution.
Here the multi-valuedness of the complex log-function entails that
\[
\gamma-\gamma_*=2\pi i\cdot f(x)\cdot H_-(x)
\]
where
$H_-(x)$ is the Heaviside distribution supported by
the negative half-line. Then
\[
\gamma^*= \gamma-\gamma_*-2\pi i\cdot f(x)
\]
is a null solution supportec by
the half-line $x\geq 0$ and hence belongs to 
the 2-dimensional space 
$V_0$. A second null solution in
$V_0$ is given by the 
 Dirac measure   $\delta_0$.
To see that $\delta_0$.
 is a null solution for $P$
we recall  that
in the non-commutative ring of differential operators one has the equality
$\nabla=\partial x\circ x-1$.
Since $x\cdot \delta_0=0$ we get 
the distribution equation
\[
\nabla(\delta_0)=-\delta_0\implies
\nabla^2(\delta_0)=\delta_0
\] 
Since $q(0)=-1$ is assumed in (0.3.1)
it follows that   $P(\delta_0)=0$.
Hence we have found four linearly independent null solutions
$f_+.f_-,\gamma^*,\delta_0$ in accordance with
Theolrem 0.0.1.
\medskip


\noindent
\emph{The fundamental solution.} 
A fundamental
solution $\mu$ supported by $x\geq 0$ is found as follows: From
(i) we have  the real-analytic density $\phi(x)$ on 
the open half-line $\{x>0\}$ which gives 
the  distribution
$\phi_+$  supported by $\{x\geq 0\}$ defined by
\[
\phi_+= f(x)\cdot (\log x)\cdot H_+ g(x)\cdot H_+
\]
In ¤ xx we shall explain that
\[ 
\nabla(\log x\cdot H_+)=\delta_0
\]
and from this  deduce that
\[
P(\phi_+)=-\delta_0
\] 
Hence $\mu=-\phi_+$ gives the requested fundamental  solution.










\newpage


 


\centerline
{\bf{0.2 PDE-equations with constant coefficients.}}
\medskip


\noindent
The study of PDE-equations with contant coefficients in
${\bf{R}}^n$ for arbitrary $n\geq 2$
is a rich subject.
The interested reader may consult Chapter xx in
[Hšrmander:Vol 2] for
an extensive study
of $PDE$-equations with constant coefficients.
Here we shall give 
a
construction from Hšrmander's article [xxx]
which  
illustrates how analytic function theory can be used  with 
PDE-theory.
Fourier's inversion formula
for an arbitrary $n\geq 1$ asserts the following:
Let $f(x)= f(x_1,\ldots,x_n)$
be  a $C^\infty$-function which 
is rapidly decreasing as
$|x|= \sqrt{x_1^2+\ldots+x_n^2}$ tends to $+\infty$. Then
\[ 
f(x)= 
\frac{1}{(2\pi)^n}\cdot
\int\, e^{i\langle x,\xi\rangle}\cdot \widehat{f}(\xi)\, d\xi
\quad\,\text{where}\quad 
\widehat{f}(\xi)=\int\, e^{-i\langle x,\xi\rangle}\cdot f(x)\, dx\tag{*}
\] 
The inversion 
inversion formula (*) entails that the Fourier transform of
the partial derivative
$\frac{\partial f}{\partial x_j}(x)$ is equal to $i\xi_j\cdot
\widehat{f}(\xi)$.
In PDE-theory one  introduces the first order differential operators
\[ 
D_j=-i\cdot \frac{\partial}{\partial x_j}\quad\colon 1\leq j\leq n
\]
When $\alpha=(\alpha_1,\ldots,\alpha_n)$
is a multi-index we get the higher order differential operator
\[ 
D^\alpha=D_1^{\alpha_1}\cdots 
D_1^{\alpha_n}
\]
We can  take polynomials of these and get differential operatators with
constant coefficients
\[
 P(D)= \sum\, c_\alpha\cdot D^\alpha
\]
Fourier's inversion formula gives
\[ 
P(D)(f)(x)=
\frac{1}{2\pi^n}\cdot
\int\, e^{i\langle x,\xi\rangle}\cdot P(\xi)\cdot \widehat{f}(\xi)\, d\xi\tag{**}
\]
Thus, applying a differential operator with constant coefficients to $f$
corresponds to the product of
its Fourier transform with the polynomial $P(\xi)$
and 
(**) can be used to
construct solutions of the homogeneous equation $P(D)(f)=0$.
Following [Hšrmander]
we  construct distributions
$\mu$ such that
$P(D)(\mu)=0$
for a suitable class of PDE-operators.
Let 
$\phi_1(s),\ldots,\phi_n(s)$ be some  $n$-tuple of analytic functions
of the complex variable $s$
which extend to continuous functions on the boundary of the domain
\[ 
\Omega=
\{\mathfrak{Im}(s)<0\}\cap \{|s|>M\}
\]
 where $M$ is some positive
number.
Assume that the $\phi$-functions satisfy
the growth conditions
\[
|\phi_k(s)|\leq C{|s|^a}\tag{i}
\] 
for a constant $C$ and some $0<a<1$.
If $a<\rho<1$ there exists
the analytic function in $\Omega$ defined by
\[
\psi(s)=e^{-(is)^\rho}
\]
As explained in ¤ xx one has the estimate
\[
|\psi(s)|\leq e^{-\cos\frac {\pi\rho}{2}\cdot |s|^\rho }
\quad\colon \mathfrak{Im}\, s\leq 0
\]
The inequality $a<\rho$
and (i) entail that
the functions
\[ 
s\mapsto e^{ a_1\cdot \phi_1(s)+\dots+a_n\phi_n(s)}\cdot \psi(s)
\]
decrease like 
$e^{-\cos\frac {\pi\rho}{2}\cdot |s|^\rho }$ in $\Omega$.
\medskip

\noindent
{\bf{Exercise.}}
Verify 
that the complex line integrals
 below converge absolutely for every $s$-polynomial $Q(s)$ and
 every $n$-tuple of real numbers
 $x_1,\dots,x_n$:
 \[
 \frac{1}{(2\pi)^n}\cdot \int_{\partial\Omega}\,
 e^{x_1\phi_1(s)+\ldots+x_n\phi_n(s)}\cdot e^{ix_n s}\cdot
 Q(s)\cdot \psi(s)\, ds\tag{ii}
 \]
 and show  that when $x$ varies in ${\bf{R}}^n$
 this gives a $C^\infty$-function $f(x)$. If $1\leq j\leq n-1$
 one has for example
 \[
\frac{ \partial f}{\partial x_j}=
 \frac{1}{(2\pi)^n}\cdot \int_{\partial\Omega}\,\phi_j(s)\cdot 
 e^{x_1\phi_1(s)+\ldots+x_n\phi_n(s)}\cdot e^{ix_n s}\cdot
 Q(s)\cdot \psi(s)\, ds
\]
Less obvious  is that the
$C^\infty$-function $f(x)$ is supported by the half-space
$\{x_n\geq 0\}$.
To prove it one uses the analyticity of the integrand as a function of
$s$
which enable us to shift the contour of integration so that
(ii) is unchanged while we integrate on a horisontal line
$\mathfrak{Im}\, s=-N$ for every $N>M$.
With $s=u-iN$ we have
\[ 
|e^{ix_n\cdot s}|= e^{N\cdot x_n}
\]
If $x_n<0$ this term tends to zero as $N\to +\infty$
and from this the resder should confirm that
the $C^\infty$-function $f(x)$ is identically zero in
$\{x_n<0\}$.
\medskip

\noindent
Suppose now that we are given a PDE-operator $P(D)$
and  the $\phi$-functions  are chosen so
that
\[ 
s\mapsto P(\phi_1(s)\ldots \phi_{n-1}(s),\phi_n(s)+s)=0
\quad \colon s\in \Omega
\]
Then it is clear that
\[
P(D)( e^{x_1\phi_1(s)+\ldots+x_n\phi_n(s)}\cdot e^{ix_n s})=0
\]
hold for all $x\in{\bf{R}}^n$ and  $s\in\Omega$.
Hence 
$P(D)(f)=0$ where $f$ is a $C^\infty$-function supported by the half-space
$\{x_n\geq 0\}$.
In ¤ xx we will show that the construction of solutions 
as above is not so special for
PDE-operators $P$
such that the hyperplane $\{x_n=0\}$ is non-characteristic.

































\newpage

\centerline {\bf{0.1 The distributions $x_+^s$}}
\medskip

\noindent
If $s$ is a complex number where
$\mathfrak{Re} s>-1$
the function defined by $x^s$ for $x>0$ and zero on
the half-line $x\leq 0$ is locally integrable and defines
a distribution denoted by $x_+^s$ acting on test-functions $g$ by
\[
x_+^s(g)= \int_0^\infty\, x^s\cdot g(x)\, dx
\]
The distribution-valued function
$s\mapsto x_+^s$ is analytic in
$\mathfrak{Re} s>-1$. Indeed
 if $x<0$ we have
 $\frac{d}{ds}(x^s=\log x\cdot x^s$
 which entails that
 the complex derivative
 of $x_+^s$ is the distribution defined by
 \[
 g\mapsto 
  \int_0^\infty\, \log x\cdot x^s\cdot g(x)\, dx
 \]
It turns out that $x_+^s$ extends to a meromorphic distribution-valued
function in the whole $s$-plane.
To prove this we perform a partial integration which
gives
\[
x_+^{s+1}(g')=
\int_0^\infty\, x^{s+1}\cdot g(x)\, dx=-(s+1)\cdot
 \int_0^\infty\, x^s\cdot g(x)\, dx\tag{0.0.1}
\]
 By the construction of distribution derivatives this means that
 \[
 \frac{d}{dx}(x_+^s+1)=(s+1)\cdot x_+^s
 \]


\noindent
{\bf{Euler's functional equation.}}
Set $\partial=\frac{d}{dx}$. We can iterate
(0.0.1) which  for every positive integer $m$ gives
\[
(s+1)\cdots(s+m)x_+^s=
\partial^m(x_+^{s+m})\tag{0.0.2}
\]
We refer to (0.0.2) as Euler's functional equation. It entails that
the distribution-valued function
$x_+^s$ extends to a meromorphic function with
at most simple poles at
negative integers.
Let us investigate the situation close to 
a
negative integer. With $s=-m+t$ and $t$ small one has
\[
t(t-1)\cdot (t-m+1)x_+^{-m+t}=\partial^m(x_+^t)
\]
When $x>0$ one has the expansion
\[ 
x^t=1+t\log x+\frac{t^2}{2}\cdot (\log x)^2+
\frac{t^3}{3 !}\cdot (\log x)^3+\ldots
\]
From this we obtain a series expansion
\[
x_+^{-m+t}=t^{-1}\cdot \rho_m+ \gamma_0+t\gamma_1+\ldots
\]
where $\rho_m$ and $\{\gamma_\nu\}$ are distributions.
In particular the reader may verify that
\[
(-1)^{m-1}(m-1)!\cdot \rho_m=\partial^m(H_+)
\]
Let us then consider the constant term $\gamma_0$.
The linear $t$-term in the expansion of
$t(t-1)\cdot (t-m+1)x_+^{-m+t}$
becomes
\[
(-1)^{m-1}(m-1)!\cdot \gamma_0+\frac{m(m-1)}{2}\cdot \rho_m
\]
If $x>0$ we notice that
\[
\partial^m(\log x)=(-1)^{m-1}\cdot (m-1)! \cdot x^{-m}
\]
From the above  $\gamma_0$ restricts to the density $x^{-m}$ when $x>0$.
At the same time $\gamma_0$ is a distribution defined
on the whole $x$--line supported by $\{x\geq 0\}$.
We set
\[ 
x_+^{-m}=\gamma_0\tag{*}
\]
and refer to this as Euler's extension of the density $x^{-m}$ which 
from the start is defined on
$\{x>0\}$.
So in (*) we have found
distributions for every positive integer $m$.
\medskip


\noindent
{\bf{0.1.2 Further formulas.}}
With $s=-1+z$ where $z$ is a small non-zero complex number
one has
\[
z\cdot x_+^{-1+z}=\partial(x_+^z)\tag{i}
\]
Next, if $x>0$ we have
\[
x^z= e^{z\log x}=
1+
\sum_{k=1}^\infty\, \frac{(\log x)^k}{k!}\cdot z^k
\]
Introducing the Heaviside distribution $H_+$ which is 1 on $x\geq 0$ and
zero on $x<0$
this means that
\[
\partial(x_+^z)=\partial(H_+)+
\sum_{k=1}^\infty\,
\partial(\frac{(\log x)^k}{k!}\cdot H_+(x))z^k\tag{ii}
\]
From this we get a Laurent expansion of
$x_+^s$ at $s=-1$. The crucial point
is that the distribution derivative
\[
\partial(H_+)=\delta_0\tag{iii}
\] 
where $\delta_0$ is the Dirac distribution at $x=0$.
It follows that
\[
x_+^{-1+z}= z^{-1}\cdot \delta_0+
\sum_{k=1}^\infty\,
\partial(\frac{(\log x)^k}{k!}\cdot H_+(x))z^{k-1}\tag{iv}
\]
In particular the constant term becomes
\[
\partial(\log x\cdot H_+(x))\tag{v}
\]
To find this distribution we take a test-function $g$
and  a partial integration gives
\[
-\int_0^\infty (\log x\cdot g'(x)\, dx
=\int_0^1\,\frac{g(x)-g(0)}{x}\, dx+
\int_1^\infty \,\frac{g(x)}{x}\, dx
\]
From this we conclude that
the  distribution $x_+^{-1}$ is defined on test-functions by
the formula:
\[
x_+^{-1}(g)=\frac{(-1)^{m-1}}{(m-1)!}\cdot
\int_0^1\,\frac{g(x)- g(0)}{x}\, dx+
\int_1^\infty \,\frac{g(x)}{x}\, dx
\]

\medskip

\noindent
{\bf{0.1.3 Exercise.}}
For each test-function $g$ and integer $m\geq 2$ we set
\[
T_{m-1}(g)(x)= g(0)+ g'(0)x\ldots \frac{g^{(m-1)}(0)}{(m-1)!}\cdot x^{m-1}
\]
Show from the above via  partial integrations
that 
\[
x_+^{-m}(g)=\frac{(-1)^{m-1}}{(m-1)!}\cdot
\int_0^1\,\frac{g(x)- T_{m-1}(g)(x)}{x^m}\, dx+
\int_1^\infty \,\frac{g(x)}{x^m}\, dx
\]
\medskip

\noindent
{\bf{0.1.4 The distributions $(x+i0)^\lambda$ and
$(x-i0)^\lambda$.}}
In the upper half plane there exists the single valued branch of
$\log z$ whose argument stays in $(0,\pi)$
and for every complex number $\lambda$ we have
\[ 
z^\lambda= e^{\lambda\cdot \log z}
\]
In ¤ 3 we shall learn how to contruct boundary value
distributions  of analytic
functions defined in strip domains above or below the real $x$-line.
In particular there exists
the distribution  $(x+i0)^\lambda$
defined on test-functions $g(x)$ by the limit formula
\[
\lim_{\epsilon\to 0}\,
\int\, (x+i\epsilon)^\lambda\cdot g(x)\, dx
\]
Notice   that
this limit  exists for all complex $\lambda$,  i.e even when
the real part becomes very negative.
In the same way we have the single valued branch of $\log z$ in
the lower half-plane whose argument stays in
$(-\pi,0)$
and construct the distribution $(x-i0)^\lambda$
defined by 
\[
(x-i0)^\lambda(g)=
\lim_{\epsilon\to 0}\,
\int\, (x-i\epsilon)^\lambda\cdot g(x)\, dx
\]
Since $\lambda\mapsto e^{\lambda\cdot \log z}$
are entire in
$\lambda$, we get two entire distribution valued functions
by 
$(x-i0)^\lambda$ and $(x-i0)^\lambda$.
Regarding the choice of branches for the log-functions
we see that 
\[
(x-i0)^\lambda= e^{-2\pi i\lambda}\cdot (x+i0)^\lambda
\quad\colon x<0
\]
At the   same time
\[
(x+i0)^\lambda=(x-i0)^\lambda=x^\lambda
\quad\colon x>0
\]
From this we see that the distribution
\[
(x+i0)^\lambda-e^{2\pi i\lambda}\cdot (x-i0)^\lambda
\]
is supported by $x\geq 0$
and expressed by the density
$(1-e^{2\pi i\lambda})\cdot x^\lambda$.
The conclusion is that one has the equation
\[
\mu_\lambda=
\frac{(x+i0)^\lambda-e^{2\pi i\lambda}\cdot (x-i0)^\lambda}
{1-e^{2\pi i\lambda}}
\]

\medskip

\noindent
{\bf{Remark.}}
The equation (xx) is  more involved compared to the previous
description of the meromorphic $\mu$-function
found via Euler's functional equation.
But (xx) has the merit that
the denominator is an entire distribution valued function and
when one passes to Fourier transforms it turns out that
(xx) is quite useful.
\medskip

\noindent
{\bf{Principal value integrals.}}
If $g(x)$ is a test-function there exists a limit
\[
\lim_{\epsilon\to 0}
\int_{|x|>\epsilon}\, \frac{g(x)}{x}\, dx
\]
This yields a distribution denoted by $\text{VP}(x^{-1})$.
Outside $\{x=0\}$ it is given bt the density
$x^{-1}$
where it agrees with $(x+i0)^{-1}$ and
hence the difference
 \[ 
 \mu=
 \text{VP}(x^{-1})-(x+i0)^{.-1}
 \]
 is supported by $\{x=0\}$.
\medskip

\noindent
{\bf{Exercise.}} Notoice that
\[
\lim_{\epsilon\to 0}
\int_{|x|>\epsilon}\, \frac{1}{x+i\epsilon}\, dx
=\log (1+i\epsilon)-\log(-1+i\epsilon)=-\pi i
\]
and use this to show that
\[ 
\mu=-\pi i\cdot \delta_0
\]


 












 
 









\newpage

\centerline {\bf{0.1 The distributions $x_+^s$}}
\medskip

\noindent
If $s$ is a complex number where
$\mathfrak{Re} s>-1$
the function defined by $x^s$ for $x>0$ and zero on
the half-line $x\leq 0$ is locally integrable and defines
a distribution denoted by $x_+^s$ acting on test-functions $g$ by
\[
x_+^s(g)= \int_0^\infty\, x^s\cdot g(x)\, dx
\]
The distribution-valued function
$s\mapsto x_+^s$ is analytic in
$\mathfrak{Re} s>-1$. Indeed
 if $x<0$ we have
 $\frac{d}{ds}(x^s=\log x\cdot x^s$
 which entails that
 the complex derivative
 of $x_+^s$ is the distribution defined by
 \[
 g\mapsto 
  \int_0^\infty\, \log x\cdot x^s\cdot g(x)\, dx
 \]
It turns out that $x_+^s$ extends to a meromorphic distribution-valued
function in the whole $s$-plane.
To prove this we perform a partial integration which
gives
\[
x_+^{s+1}(g')=
\int_0^\infty\, x^{s+1}\cdot g(x)\, dx=-(s+1)\cdot
 \int_0^\infty\, x^s\cdot g(x)\, dx\tag{0.0.1}
\]
 By the construction of distribution derivatives this means that
 \[
 \frac{d}{dx}(x_+^s+1)=(s+1)\cdot x_+^s
 \]


\noindent
{\bf{Euler's functional equation.}}
Set $\partial=\frac{d}{dx}$. We can iterate
(0.0.1) which  for every positive integer $m$ gives
\[
(s+1)\cdots(s+m)x_+^s=
\partial^m(x_+^{s+m})\tag{0.0.2}
\]
We refer to (0.0.2) as Euler's functional equation. It entails that
the distribution-valued function
$x_+^s$ extends to a meromorphic function with
at most simple poles at
negative integers.
Let us investigate the situation close to 
a
negative integer. With $s=-m+t$ and $t$ small one has
\[
t(t-1)\cdot (t-m+1)x_+^{-m+t}=\partial^m(x_+^t)
\]
When $x>0$ one has the expansion
\[ 
x^t=1+t\log x+\frac{t^2}{2}\cdot (\log x)^2+
\frac{t^3}{3 !}\cdot (\log x)^3+\ldots
\]
From this we obtain a series expansion
\[
x_+^{-m+t}=t^{-1}\cdot \rho_m+ \gamma_0+t\gamma_1+\ldots
\]
where $\rho_m$ and $\{\gamma_\nu\}$ are distributions.
In particular the reader may verify that
\[
(-1)^{m-1}(m-1)!\cdot \rho_m=\partial^m(H_+)
\]
Let us then consider the constant term $\gamma_0$.
The linear $t$-term in the expansion of
$t(t-1)\cdot (t-m+1)x_+^{-m+t}$
becomes
\[
(-1)^{m-1}(m-1)!\cdot \gamma_0+\frac{m(m-1)}{2}\cdot \rho_m
\]
If $x>0$ we notice that
\[
\partial^m(\log x)=(-1)^{m-1}\cdot (m-1)! \cdot x^{-m}
\]
From the above  $\gamma_0$ restricts to the density $x^{-m}$ when $x>0$.
At the same time $\gamma_0$ is a distribution defined
on the whole $x$--line supported by $\{x\geq 0\}$.
We set
\[ 
x_+^{-m}=\gamma_0\tag{*}
\]
and refer to this as Euler's extension of the density $x^{-m}$ which 
from the start is defined on
$\{x>0\}$.
So in (*) we have found
distributions for every positive integer $m$.
\medskip


\noindent
{\bf{0.1.2 Further formulas.}}
With $s=-1+z$ where $z$ is a small non-zero complex number
one has
\[
z\cdot x_+^{-1+z}=\partial(x_+^z)\tag{i}
\]
Next, if $x>0$ we have
\[
x^z= e^{z\log x}=
1+
\sum_{k=1}^\infty\, \frac{(\log x)^k}{k!}\cdot z^k
\]
Introducing the Heaviside distribution $H_+$ which is 1 on $x\geq 0$ and
zero on $x<0$
this means that
\[
\partial(x_+^z)=\partial(H_+)+
\sum_{k=1}^\infty\,
\partial(\frac{(\log x)^k}{k!}\cdot H_+(x))z^k\tag{ii}
\]
From this we get a Laurent expansion of
$x_+^s$ at $s=-1$. The crucial point
is that the distribution derivative
\[
\partial(H_+)=\delta_0\tag{iii}
\] 
where $\delta_0$ is the Dirac distribution at $x=0$.
It follows that
\[
x_+^{-1+z}= z^{-1}\cdot \delta_0+
\sum_{k=1}^\infty\,
\partial(\frac{(\log x)^k}{k!}\cdot H_+(x))z^{k-1}\tag{iv}
\]
In particular the constant term becomes
\[
\partial(\log x\cdot H_+(x))\tag{v}
\]
To find this distribution we take a test-function $g$
and  a partial integration gives
\[
-\int_0^\infty (\log x\cdot g'(x)\, dx
=\int_0^1\,\frac{g(x)-g(0)}{x}\, dx+
\int_1^\infty \,\frac{g(x)}{x}\, dx
\]
From this we conclude that
the  distribution $x_+^{-1}$ is defined on test-functions by
the formula:
\[
x_+^{-1}(g)=\frac{(-1)^{m-1}}{(m-1)!}\cdot
\int_0^1\,\frac{g(x)- g(0)}{x}\, dx+
\int_1^\infty \,\frac{g(x)}{x}\, dx
\]

\medskip

\noindent
{\bf{0.1.3 Exercise.}}
For each test-function $g$ and integer $m\geq 2$ we set
\[
T_{m-1}(g)(x)= g(0)+ g'(0)x\ldots \frac{g^{(m-1)}(0)}{(m-1)!}\cdot x^{m-1}
\]
Show from the above via  partial integrations
that 
\[
x_+^{-m}(g)=\frac{(-1)^{m-1}}{(m-1)!}\cdot
\int_0^1\,\frac{g(x)- T_{m-1}(g)(x)}{x^m}\, dx+
\int_1^\infty \,\frac{g(x)}{x^m}\, dx
\]
\medskip

\noindent
{\bf{0.1.4 The distributions $(x+i0)^\lambda$ and
$(x-i0)^\lambda$.}}
In the upper half plane there exists the single valued branch of
$\log z$ whose argument stays in $(0,\pi)$
and for every complex number $\lambda$ we have
\[ 
z^\lambda= e^{\lambda\cdot \log z}
\]
In ¤ 3 we shall learn how to contruct boundary value
distributions  of analytic
functions defined in strip domains above or below the real $x$-line.
In particular there exists
the distribution  $(x+i0)^\lambda$
defined on test-functions $g(x)$ by the limit formula
\[
\lim_{\epsilon\to 0}\,
\int\, (x+i\epsilon)^\lambda\cdot g(x)\, dx
\]
Notice   that
this limit  exists for all complex $\lambda$,  i.e even when
the real part becomes very negative.
In the same way we have the single valued branch of $\log z$ in
the lower half-plane whose argument stays in
$(-\pi,0)$
and construct the distribution $(x-i0)^\lambda$
defined by 
\[
(x-i0)^\lambda(g)=
\lim_{\epsilon\to 0}\,
\int\, (x-i\epsilon)^\lambda\cdot g(x)\, dx
\]
Since $\lambda\mapsto e^{\lambda\cdot \log z}$
are entire in
$\lambda$, we get two entire distribution valued functions
by 
$(x-i0)^\lambda$ and $(x-i0)^\lambda$.
Regarding the choice of branches for the log-functions
we see that 
\[
(x-i0)^\lambda= e^{-2\pi i\lambda}\cdot (x+i0)^\lambda
\quad\colon x<0
\]
At the   same time
\[
(x+i0)^\lambda=(x-i0)^\lambda=x^\lambda
\quad\colon x>0
\]
From this we see that the distribution
\[
(x+i0)^\lambda-e^{2\pi i\lambda}\cdot (x-i0)^\lambda
\]
is supported by $x\geq 0$
and expressed by the density
$(1-e^{2\pi i\lambda})\cdot x^\lambda$.
The conclusion is that one has the equation
\[
\mu_\lambda=
\frac{(x+i0)^\lambda-e^{2\pi i\lambda}\cdot (x-i0)^\lambda}
{1-e^{2\pi i\lambda}}
\]

\medskip

\noindent
{\bf{Remark.}}
The equation (xx) is  more involved compared to the previous
description of the meromorphic $\mu$-function
found via Euler's functional equation.
But (xx) has the merit that
the denominator is an entire distribution valued function and
when one passes to Fourier transforms it turns out that
(xx) is quite useful.
\medskip

\noindent
{\bf{Principal value integrals.}}
If $g(x)$ is a test-function there exists a limit
\[
\lim_{\epsilon\to 0}
\int_{|x|>\epsilon}\, \frac{g(x)}{x}\, dx
\]
This yields a distribution denoted by $\text{VP}(x^{-1})$.
Outside $\{x=0\}$ it is given bt the density
$x^{-1}$
where it agrees with $(x+i0)^{-1}$ and
hence the difference
 \[ 
 \mu=
 \text{VP}(x^{-1})-(x+i0)^{.-1}
 \]
 is supported by $\{x=0\}$.
\medskip

\noindent
{\bf{Exercise.}} Notoice that
\[
\lim_{\epsilon\to 0}
\int_{|x|>\epsilon}\, \frac{1}{x+i\epsilon}\, dx
=\log (1+i\epsilon)-\log(-1+i\epsilon)=-\pi i
\]
and use this to show that
\[ 
\mu=-\pi i\cdot \delta_0
\]


 












\end{document}



















