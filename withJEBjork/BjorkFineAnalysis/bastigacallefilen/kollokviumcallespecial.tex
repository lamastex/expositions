\documentclass{amsart}
\usepackage[applemac]{inputenc}


\addtolength{\hoffset}{-12mm}
\addtolength{\textwidth}{22mm}
\addtolength{\voffset}{-10mm}
\addtolength{\textheight}{20mm}

\def\uuu{_}


\def\vvv{-}

\def\bbb{{\bf{R}}}

\def\bbc{{\bf{C}}}

\def\bbi{\int_{xxx}}





\begin{document}









\centerline {\bf{ Carleman's 
solution to
the Bohr-Schrödinger equation}}.
\medskip
  

\noindent
We expose a proof which was presented by  Carleman's
at the Scandinavian Congress in mathematics
held at
Copenhagen 1925.
Consider a potential function
\[
W(p)=\sum\,\frac{a_\nu}{|p-\xi_\nu|}+b
\]
where $\{\xi_\nu\}$ is a finite set of points in
${\bf{R}}^3$ while
$\{a_\nu\}$ and $b$
are  positive real numbers.
Then
\[ 
T\colon\, \phi\mapsto \Delta(\phi)+ W\cdot \phi
\]
is a densely defined operator on
$L^2({\bf{R}}^3)$.
\medskip

\noindent
{\bf{Main Theorem.}}
\emph{$T$ is self-adjoint with a discrete spectum
and Neumann's resolvent operators
$R_T(\lambda)$ defined when
$\lambda\in {\bf{C}}\setminus \sigma(T)$ are compact.}






\bigskip

\noindent
To prove this theorem we shall  construct a compact operator
$\mathcal G$ on $L^2({\bf{R}}^3$
and also find a positive number
$\kappa$ such that
\[
(T-\kappa^2\cdot E)\circ\mathcal G=-4\pi\cdot E\tag{0.1}
\]
where $E$ is the identity
operator
on $L^2({\bf{R}}^3)$.
If this has been achieved we seek pairs
$(\phi,\lambda)$ where $\phi\in L^2({\bf{R}}^3)$
and $\lambda$ is a real number 
such that
\[
 \Delta(\phi)+(W+\lambda)\phi=0\tag{*}
 \]
To find solutions to (*)
we  shall construct a Greens function
$G(p,q)$ defined 
in ${\bf{R}}^3\times{\bf{R}}^3$ which satisfies
\[
\Delta G+ W\cdot G-\kappa^2G=-4\pi\delta(p-q)\tag{**}
\]
where the right hand side is Dirac's delta-distribution 
with unit mass at $p=q$
and $\kappa$  a positive number
which will
be found in § 1.
Here
we recall that
(**) means that if 
$f$ is a test-function in ${\bf{R}}^3$ then
\[
\int\, G(p,q)\Delta(f)(q)\, dq+(W(p)-\kappa^2)\int\, G(p,q)f(q)\, dq=
-4\pi f(p)\tag{0.1}
\]
hold for each $p$.
Moreover, the constructions in § 1
 ential that  $G$ 
is symmetric, i.e.
\[
G(q,p)=G(p,q)\tag{0.2}
\]
and
$G(p,q)$ yields  a kernel of a  compact  linear operator
$\mathcal G$ defined on
$L^2({\bf{R}}^3)$ by
\[
\mathcal G(g)(p)=\int\, G(p,x)g(x)\, dx\tag{0.3}
\]
\medskip

\noindent
{\bf{Solutions to (*)}}.
Suppose that $G$ has been found and let
$\phi$ be an $L^2$-function which satisfies the integral equation
\[
\phi=\frac{\lambda+\kappa^2}{4\pi}\cdot \int\, G(p,x)\phi(x)\, dx\tag{***}
\]
for some real number
$\lambda$.
Then (**) gives
\[
\Delta(\phi)=(\kappa^2-W)\phi-(\lambda+\kappa^2)\phi
\]
which entails that $\phi$ solves (*). Conversely the reader may check that
if $\phi$ solves (*) then it satisfies the integral equation above.


\bigskip



\centerline {\bf{1. The construction of $G$.}}
\bigskip


\noindent
When $\kappa>0$ we define
a function $H(p,q)$ in ${\bf{R}}^3\times{\bf{R}}^3$ by
\[
H(p.q)=\frac{e^{-\kappa\cdot |p-q|}}{|p-q|}\tag{1.1}
\]
Newton's classical formula gives
\[
\Delta(H)=\kappa^2\cdot H-4\pi\cdot \delta(p-q)\tag{1.2}
\]
Next,  introduce the kernel function:
\[
\Omega(p,q)=H(p,q)\cdot \sqrt{W(p)}\cdot  \sqrt{W(q)}\tag{1.3}
\]
It is clear that  $\Omega$ is everywhere positive and
$\Omega(p,q)=\Omega(q,p)$.
Close to  the diagonal $p=q$ which avoids the points
$\{(\xi_\nu,\xi_\nu)\}$
it has the same singularity as $H$, i.e. like
$\frac{1}{|p-q|}$.
When both $p$ and $q$ approach the  point $(\xi_1,\xi_1)$
we set $p=\xi_1+x$ and $q=\xi_1+y$. Then
$\Omega(p,q)$ increases like
\[
\frac{1}{|x-y|\cdot |x|\cdot |y|}\tag{1.4}
\]
\medskip

\noindent
{\bf{1.5 Exercise.}}
Show that the function  in
${\bf{R}}^3\times{\bf{R}}^3$
defined by
\[
(x,y)\mapsto \frac{1}{|x-y|\cdot |x|\cdot |y|^{\frac{3}{2}}}
\] 
is locally integrable in a neighbohood of
the origin of ${\bf{R}}^3\times{\bf{R}}^3$. Conclude that
the function 
\[
q\mapsto \Omega(p,q)\cdot W(q)
\] 
is locally integrable in the 3-dimensional $q$-space for
each fixed $p\in {\bf{R}}^3$, and that
the construction of $\Omega$ gives the equation
Moreover, the construction of the $\Omega$ in (iii) gives the equality below for every $p$:
\[
\int\, \Omega(p,q)\sqrt{W(q)}\, dq=\sqrt{W(p)}\cdot 
\int\, 
H(p,q)\cdot W(q)\, q\quad\colon\,p\in {\bf{R}}^3\tag{1.5.1}
\]
\medskip

\noindent
{\bf{1.6 Exercise.}}
Show that if 
$\kappa$  sufficiently  large then 
\[
\rho=\max_{p\in{\bf{R}}^3}\,\int\, 
H(p,q)\cdot W(q)\, dq<4\pi\tag{1.6.1}
\]
\medskip

\noindent
Now (1.5.1) and (1.6.1) give
\[
\int\, \Omega(p,q)\sqrt{W(q)}\, dq\leq \rho\cdot \sqrt{W(p)}\tag{1.7}
\]
for all $p$.
Above  $\sqrt{W}$ is a positive function
and hence  the general
result in § xxx  implies
that the  operator on $L^2({\bf{R}}^3)$ defined by
\[
g\mapsto  \int \,\Omega(p,x)g(x)\, dx
\]
has  norm $\leq \rho$.
Dividing by $4\pi$, the strict inequality $\rho<4\pi$
entials that 
the linear operator below has norm $<1$: 
\[
\mathcal S(g)(p)=\frac{1}{4\pi}\cdot \int\, \Omega(p,q)g(q)\, dq\tag{1.8}
\] 


\noindent
{\bf{1.9 An  integral equation.}}
Since $\mathcal S$ has norm $<1$, there exists
the bounded linear operator 
\[
\mathcal L=(E-S)^{-1}\circ S\tag{1.9.1}
\]
where  $E$ is the identity operator on $L^2({\bf{R}}^3)$.
Since $\Omega(p,q)$ is a symmetric function
it follows that
$\mathcal S$ is a symmtric operator which
entails that $\mathcal L$ also is symmetric, and
the reader may check that
$\mathcal L$ is defined by
the kernel function which satisfies the integral equation
\[ 
L(p,q)=\frac{1}{4\pi}\cdot \int \,L(p,x)\cdot \Omega(x,q)\, dx+\Omega(p,q)\tag{1.9.2}
\]
So here $\mathcal L$ is the bounded
operator on
$L^2({\bf{R}}^3)$ defined by
\[
\mathcal L(g)(p)=\int\, L(p,x)g(x)\, dx\tag{1.9.3}
\]

\medskip

\noindent
Now we put
\[ 
G(p,q)=\frac{1}{ \sqrt{W(p)}\cdot \sqrt{W(q)}}\cdot L(p,q)\tag{1.10}
\]
The positive constant $b$ in (**) gives
the inequality below for each pair
$p,q$ in
${\bf{R}}^3$:
\[
\frac{1}{ \sqrt{W(p)}\cdot \sqrt{W(q)}}\leq b^{-1}\tag{1.11}
\]
Since $L(p,q)$ is the kernel of the bounded operator
$\mathcal L$ is, it follows from (1.11)
that $G(p,q)$ also is the kernel
of a bounded operator denoted by
$\mathcal G$.
\medskip

\noindent{\bf{1.12 Exercise.}}
Show from the above that
$G(p,q)$ which satisfies
the integral equation
\[
G(p,q)=H(p,q)+\frac{1}{4\pi}\int\, H(p,x)W(x)G(x,q)\, dx\tag{1.12.1}
\]
and that  this equation entails that 

\[
\Delta(G)(p,q)=\kappa^2\cdot G(p,q)-4\pi\delta(p-q)-W(p)G(p,q)\tag{1.12.2}
\]
which means that   $G$ satisfies (**) above.
.
\medskip


\centerline{\bf{2. Spectral values.}}
\medskip

\noindent
Let us first notice that
(1.9) and (1.11) imply that if
$\mathcal S$ is a compact operator so is $\mathcal G$.
\medskip


\noindent 
{\bf{2.1 Exercise.}}
Show via the explicit construction of $\Omega(p,q)$ in
(1.3) and basic measure theory
that $\mathcal S$ is a compact operator.
\medskip


\noindent 
The exercise entails that
$\mathcal G$ is compact.
Moreover, since $\Omega(p,q)$ is a positive function
it follows that the spectrum of $\mathcal S$ is confined to
positive eigenvalues and then the general formulas from § xx
imply that non-zero points in $\sigma(\mathcal G)$
are real and positive.
Now (*) holds for a real $\lambda$ if and only if
\[
\phi=\frac{\lambda+\kappa^2}{4\pi}\cdot \mathcal G(\phi)
\]
which means that
\[
\frac{4\pi}{\lambda+\kappa^2}\in\sigma(\mathcal G)
\implies \lambda>4\pi-\kappa^2
\]
\medskip

\noindent{\bf{2.2 Remark.}}
From the abve we get some information about the true 
spectrum of the densely
defined operator $T$ from (0.x).
More precisely it is discrete and real and there exists a 
smallest eigenvalue 
$\lambda_*$ of $T$.
it dpends on the chosden $W$.function asnd here
one needs  numerical
investigations to determine
approximations of $\lambda_*$, as well as subsequent eigenvalues
and
their corresponding eigenfunctions.



.


\newpage






\bigskip



\noindent
{\bf{1.5 The case $L=\Delta + c(x,y,z$.}}.
We shall not give all details of the proof of
Theorem 0.2.1 but
describe a crucial  step  the proof which is used to prove that
$L$ is of Class I when $c$ satisfies the condition in the theorem.
Here is the situation.
Let $B_r$ be the open ball of radius $r$ centered at the origin
and $S^2[r]$ thr unit sphere.
The class of functions $u$  which are continuous on the closed ball
and whose interior normal derivative
$\frac{\partial u}{\partial{\bf{n}}}$ is continuous on the boundary
$S^2[r]$ is denoted by
$\mathfrak{Neu}(B_r)$. 
\medskip


\noindent
{\bf{A Neumann equation.}}
Next,
consider  a pair $a,H$ where
$a$ be a continuous function on
$S^2[r]$ and 
$H(p,q)$ a continuous hermitian function on
$S^2[r]\times S^2[r]$, i.e.  $H(q,p)=\bar H(p,q)$ hold for all pairs 
of point $p,q$ on
the sphere $ccc$. Finally, $c$ is some real-valued function in
$L^2(B_r)$.
With these notations the following hold:


\bigskip


\noindent
{\bf{1.5.1 Theorem.}} \emph{For each $f\in L^2(B_r)$ and every
non-real complex number $\lambda$ there exists a unique 
$u\in \mathfrak{Neu}(B_r)$ which 
satisfies the two equations:}
\[ 
\Delta(u)+\lambda\cdot c\cdot u=f\quad\text{holds in}\quad B_r\tag{i}
\] 
\[
\partial u/\partial {\bf{n}}(p)+a(p)u(p)+\int_{S^2[r]} \, H(p,q)u(q)\,dA(q)=0\tag{ii}
\]
 \emph{Moreover, one has the $L^2$-estimate}
\[
\int_{B_r}\, |u|^2\cdot dxdydz\leq
\bigl|\frac{1}{\mathfrak{Im}(\lambda)}\bigr|\leq
\int_{B_r}\, |f|^2\cdot dxdydz\tag{iii}
\]
\bigskip


\noindent
{\bf{Remark.}}The point is that the $L^2$-estimate 
above is independent of
the triple $a,c,H$.
The verification that the two equations (i-ii) give
(iii) follows easily via Greens formula and is left to the reader.
The fact that (i-ii) has a solution is classic and goes  back to work by
Neumann and Poincaré.




















\centerline{\bf{Mathematics by Torsten Carleman}}
\bigskip










\centerline {\bf{Introduction.}}
\bigskip

\noindent
Carleman's  collected work 
covers  fifty  articles of   high standard together with several monographs.
He entered university studies in 1911 at Uppsala  and
five years later he presented
his doctors thesis. 
After the end of World War I he visited Paris 
frequently  where he
met many distinguished mathematicians, among those  Hadamard, Picard, Borel and
Denjoy whose work gave him much inspiration during the years
1919-1924
when many of his most important
discoveries  were achieved, such as the theory about quasi-analytic functions.
He also  published some joint papers with Hardy about
Fourier series, and 
other articles from his early period in his career were inspired from previous work by
Weyl, Schur, Faber, Gros, Hamburger and the brothers F. and M. Riesz.
Of course,  from the very start 
of his studies in mathematics, Carleman  read work by  
the great masters Abel, Riemann, Weierstrass  and Poincaré.
Several  sections in these notes
contain results which have emerged from these eminent mathematicians.
Among Scandinavian mathematicians
one must  mention Lindelöf whose contributions in analytic function theory
was another source of inspiration for the young Carleman.
During his early years at Uppsala he became aquaintd with many
current research problems from lectures  by the two  professors
Holmgren and Wiman.



\medskip


\noindent
He became 
professor at Stockholm University in 1924, and  
from 1927   also   director at  Institute Mittag-Leffler
where he delivered frequent    seminars during the period  1928-1938.
His text-book (in Swedish)  for undergraduate mathematics was published in 1926
and used for several decades.
Personally I find it outstanding
as a beginner's text for students
and during my early  education Carleman's presentation of 
basic material in analysis and
algebra
served as a "veritable bible".

\medskip

\noindent
Carleman was  always  concerned
with  the interaction  between
"pure mathematics" and experimental sciences.
After World War I he studied a year at an engineering school
in Paris. The article entitled \emph{ Sur les équations différentielles
de la mecanique d'avion} published in
[La Technique Aéronautique, vol. 10  1921) was inspired by  Lanchester's pioneering work 
\emph{Le vol aérien}
which played a significant role while airplanes were
designed
at an early stage.
Carleman's article ends with
the following conclusion
after a very interesting  investigation of integral curves
to a certain non-linear differential system:
\emph{Quelle que soit la vitesse initiale, l'avion, après avoir
éxecuté s'il y lieu, un nombre fini des loopings, prend un mouvement
qui s'approche indéfinement du régime de descente
rectiligne ert uniforme.}

\medskip

\noindent
The  reader may also  consult
his  lecture
held 1944 at the Academy of Science in Sweden entitled
\emph{Sur l'action  réciproque entre les mathématiques
et les sciences expérimentales exactes}
which underlines Carleman's  concern about applications of mathematics.
Let us also mention
 that Carleman got much inspiration from
Ivar Fredholm's work
on integral equations. For many decades   
Fredholm was professor in mathematical physics at
Stockholm University
until his  retirement  in 1930
when Oscar Klein became the new professor in
theoretical physics.



\medskip

\noindent
During the last years in
life Carleman  suffered from health problems which caused his decease on
January 11 1949 at the age of 56 years.
A memorial article about his  scientific achievement
appears in [Acta. Math. 1950] written by
Fritz Carlson
who was Carleman's collegue at 
the department of mathematics at Stockholm
university for several decades.


\medskip

\noindent
\emph{Collaboration with Erik Holmgren}.
Carleman's  last major publication   \emph{Sur un probléme d'unicité pour les systèmes
d'équations aux dérivees partielles à deux variables
indépendantes} [Arkiv för matematik 1938] is concerned with a
uniqueness theorem for  elliptic PDE-systems 
where the variable coefficients of the PDE-operators  
are
non-analytic. This  
extended an earlier   result by  Erik Holmgren from 1901
when the coefficients are real-analytic.
Let us recall  that Holmgren served as supervisor while Carleman prepared
his thesis entitled \emph{Über das Neumann-Poincarésche
Problem für ein Gebiet mit Ecken}, presented 
at Uppsala University in 1916 when he was 23 years old.
Later they shared many ideas.
An example is Holmgren's uniqueness theorem for the heat equation
\[
\frac{\partial u}{\partial t}=
\frac{\partial^2 u}{\partial x^2}
\]
Let $u(x,t)$ be  a solution in a domain
$\{-\infty<x<\infty\}\times \{-A<t<A\}$.
If $u$ satisfies the growth condition
\[
|u(x,t)|\leq e^{kx^2\cdot \log\,(|x|+e)}
\] 
for some constant $k$ where $e$ is Neper's number, then Holmgren proved thst
$u$ is determined by its values on a line $\{t=t_0\}$.
He  employed results by Denjoy and Carleman about quasi-analytic classes
to prove the uniqueness, and via 
constructions outside the class of quasi-analytic functions Täcklund later proved
that the result above is  quite sharp. Namely,  for every $\delta>0$
there exists a  non-zero solutions $u$ such that
$u(x,0)=0$ for all $x$ while
\[
|u(x,t)| \leq e^{x^2\cdot  (\log\,(|x|+e))^{1+\delta}}
\] 
It appears that  Holmgren's result is rarely  treated in text-books
in spite of its importance related to
diffusion which for example appears in stochastic PDE-theory.
So in § xx we expose Holmgren's  proof from his article published 
in Arkiv för Matematik och Fysik in 1924. In connection with this we recall a
result due to Hadamard which goes as follows:
Consider the  boundary value
problem where one seeks   a harmonic function
$u(x,y)$ 
in an open half-disc
\[
D_+(r)=\{x^2+y^2<r^2\}\,\cap \{x>0\}
\]
satisfying the boundary conditions:
\[
u(0,y)=\psi(y)\quad\text{and}\quad
u_x(0,y)=\phi(y)
\]
where the functions $\phi$ and $\psi$ are given in advance.
Hadamard proved
that a necessary and sufficient condition for
this  Cauchy problem to be well posed is that 
the function
\[ 
y\mapsto \phi(y)+\frac{1}{\pi}\int_a^b\,
\log\,\frac{1}{|s-y|}\cdot \psi(s)\cdot ds
\]
is real analytic on the interval $(a,b)$ for all pairs $-r<a<b<r$.

\medskip

\noindent
Hadamard's result illustrates how sensible
boundary value problems of elliptic type can be
and therefore the uniqueness result in § xx is quite remarkable. 
\medskip

\noindent
Let us now describe
some central themes in Carleman's work.
\medskip


\centerline {\bf{0.1 Analytic functions.}}
\medskip

\noindent
Function theory appears often as a tool in Carleman's work.
But he also gave some important contributions to the subject itself.
Among these one must mention the fundamental discovery which aserts that if 
$f(z)$ is an analytic function in the upper half-plane $U$
which extends continuously to the real axis where
$|f(z)|\le e^{A|z|}$ hold for all $z\in U$ and some constant $A$,
then the following implication holds:
\[
\int_{-\infty}^\infty\, \log^+|f(x)|\cdot 
\frac{dx}{1+x^2}<\infty\implies
\int_{-\infty}^\infty\, \log^+\frac{1}{|f(x)|}\cdot \frac{dx}{1+x^2}<\infty
\]
\medskip

\noindent
A result which illustrates Carleman's vigour in analysis is
his solution to a problem concerned with asymptotic expansions
which originally was raised by Poincaré. It goes as follows:
Let $\mathcal A=\{A_n\}$ be a sequence of positive real numbers.
Denote by $H(\mathcal A)$ the class of analytic functions
$f(z)$ in the unit disc for which
\[
\max_{z\in D}
\frac{|f(z)|}{|(1-z)^n|} \leq A_n \quad\colon\quad n=1,2,\ldots\tag{*}
\]


\noindent
{\bf  Theorem.}
\emph{The necessary and sufficient condition that
$H(\mathcal A)\neq 0$
is that there exists a constant $C$ such that}
\[
\max_{n\geq 1}\,\int_1^\infty\, \log\,
\bigr(\,\sum_{\nu=1}^{\nu=n}\,
\frac{r^{2\nu}}{A_\nu^2}\,\bigr)\, \, dr
\leq C\quad\colon\quad n=1,2\ldots
\]
\medskip

\noindent
This is proved in the   book [xxx] on quasi-analytic functions.
The proof relies upon
a variational
problem which is exposed in § xx.
\medskip

\noindent
\emph{ Conformal maps of circular domains.}
In 1906 Koebe proved a
result about conformal mappings between
domains bordered by a finite set of circles.
Let $p\geq 2$
and denote by $\mathcal C^*(p)$ the family of connected
bounded  domains $\Omega$ in ${\bf{C}}$ for which
 $\partial\Omega$ is the union of $p$ many disjoint circles.
\medskip

\noindent
{\bf Theorem.} \emph{Let
$f\colon\Omega\to U$
be a conformal map between two domains in
$\mathcal C^*(p)$. Then $f(z)$ is a linear function, i.e.
$f(z)=Az+B$ for some constants $A$ and $B$.}
\medskip

\noindent
Koebe's  proved this via the
uniformisation theorem for Riemann surfaces
and extensive use of reflections over  circular boundaries.
Carleman gave a direct proof
which we expose in § xx since it gives a good lesson 
how one computes winding numbers
in specific situations.
In § x  we
expose a result whose proof relies heavily upon
original work by Weierstrass, but the "final point" which leads to a sharp
isometric inequality for minimal surfaces bordered by a fixed curve in
${\bf{R}}^3$ employs analytic function theory.

\medskip

\noindent
{\bf{An application of Hadamard's spectral radius formula.}}
Consider
a power series
\[
u(z)= \sum_{n=0}^\infty\, c_nz^n\tag{*}
\]
which has some positive and finite radius of convergence $r_0$.
Recall the wellknown formula
\[
\frac{1}{r_0}=\limsup_{n\to \infty}\,|c_n|^{\frac{1}{n}}
\]
In his thesis from 1894, Hadamard went much further. 
Following an original device by
Kronecker who determined the class of
local Taylor series representing rational functions, Hadamard 
considered   the recursive Hankel determinants
of
$\{c_n\}$ and found   precise criteria  in order that
(*) extends to a meromorphic function in
larger discs. 
This  powerful result was adopted by Carleman.
In a letter to Hadamard from 1919, Carleman showed how one gets
expansions of resolvent operators 
which 
describe the spectrum of
compact linear operators arising  in
the Fredholm-Hibert theory about integral kernels.
Since Hadamard's fundamental discovery is rarely  treated in text-books we have included an
account about this in § xx together with
Carleman's application to integral operators.
\medskip

\noindent
Hadamard's famous work \emph{Théorie des ondes}
was another inspiration for Carleman. In his brief note
\emph{Sur les sytèmes linèaires aux dérivées partielles du premier ordre à deux
variables}, Carleman considered the system of equations 
\[
\frac{\partial u}{\partial x}-
\frac{\partial v}{\partial y}= au+bu\quad\colon\quad 
\frac{\partial u}{\partial y}+
\frac{\partial u}{\partial x}= cu+du
\]
where $a,b,c,d$ are real-valued continuous functions defined in a domain in
of ${\bf{R}}^2$. One says that a pair $(u,v)$ is a solution if
they are contonuous in $D$ and  their
first order partial derivatives exists as continous functions in
in $D\setminus\gamma$ where
$\gamma$ is a finite union of rectifiable Jordan curves in $D$
and their maximum norms of these first order
partial derivatives taken over $D\setminus\gamma$ are finite.
Under this condtion we show in § xx that if there exists a point 
$p\in  D\setminus\gamma$ where $u$ and $v$ both vanish of
infinite order, then they are identically zero in $D$.
Let us  remark that this result can be used to relax certain  regularity conditions concerned 
with uniqueness of solutions to non-linear elliptic equations.
which were previously ontained by Hadamard.


 











\bigskip


\centerline {\bf{0.2 Vibrating planes.}}
\medskip

\noindent
Let us describe  a  result
which 
illustrates Carleman's concern to provide strict mathematical proofs
of
expected physical results.
Let
$D$ be a membrance with constant density of mass $m$
and  constant tension $k>0$. The boundary is fixed by a plane curve
$C$ placed in the horizontal $(x,y)$-plane and
the function $u=u(x,y,t)$ is the deviation in the vertical direction
while the membrance is in motion. Here $t$ is a time variable 
and by Hooke's law $u$
satisfies the wave equation
\[
\frac{d^2u}{dt^2}= \frac{k}{m}\cdot \Delta u\tag{*}
\]
where the boundary condition is that $u(p,t)=0$ for each
$p\in C$.
The time dependent kinetic energy becomes
\[
T(t)= \frac{m}{2}\iint_\Omega\, (\frac{du}{dt})^2dxdy
\]
The potential energy becomes
\[
V(t)= \frac{m}{2}\iint_\Omega\,
\bigl[ (\frac{\partial u}{\partial x})^2+
\frac{\partial u}{\partial x})^2\,\bigr]\, dxdy
\]
One solves (*) by a separation of variables.
More precisely, there exists an orthonormal 
sequence of functions $\{\phi_\nu\}$ in $L^2(D)$
and a non-decreasing sequence of positive numbers
$\{\lambda_\nu\}$ such that
\[
\Delta(\phi_\nu)+\lambda_\nu\cdot \phi_\nu=0
\] 
hold in $D$ and
each $\{\phi_\nu\}$ i
vanishes on the boundary curve $C$.
This is a classic result which goes back to work by
Poincaré and Fredholm and is  proved in § XX.
The solution to (*) can be written in the form
\[
u(x,y,t)=
\sum\, c_\nu(t)\phi_\nu(x,y)\tag{**}
\]
where each $c$-function satisfies the second order differential equation
\[
\frac{d^2c_\nu}{dt^2}+\frac{k}{m}\cdot \lambda_\nu\cdot c_\nu(t)=0
\]
The $c$-functions are determined via expansions in the $\phi$-functions of
the intial value functions
$u(xy,0)$ and $\frac{du}{dt}(x,y,0)$ at time $t=0$.
The mean kinetic energy over large time intervals at individual points
$p\in D$ are  defined by 
\[ 
L(p)=
\frac{m}{2}\cdot \lim_{\tau\to\infty}\, \frac{1}{\tau}\cdot \int_0^\tau\,
(\frac{du}{dt})^2(p)\cdot d\tau\tag{1}
\]

\medskip

\noindent
Using (**) one has the equality
\[ 
L(p)=
k\cdot \sum\, |c_\nu|^2\lambda_\nu \phi_\nu(p)^2\tag{2}
\]
We refer to § xx for a detailed verification.

\medskip
\noindent
{\bf{High frequencies.}}
For each positive number
$w$ the contribution from high frequencies is defined by:
\[ 
L_w(p)=k\cdot \sum_{\lambda_\nu>w}
\, |c_\nu|^2\lambda_\nu \cdot \phi_\nu(p)^2
\]


\noindent
Similarly, the   mean potential energy  from high frequencies
is defined by
\[
V_w(p)=k\cdot \sum_{\lambda_\nu>w}\, |c_\nu|^2\cdot \bigl[\frac{\partial \phi_\nu}{\partial x}(p)^2
+\frac{\partial \phi_\nu}{\partial y}(p)^2\bigr]
\]

\medskip



\noindent
Using limit formulas for the eigenvalues
$\{\lambda_\nu\}$
as well as values of the eigenfunctions  in $D$, Carleman proved
the following equality for each $p\in D$:  
\[
\lim_{w\to \infty}\, \frac{L_w(p)}{V_w(p)}=1\tag{1}
\] 
Moreover, he proved  that
\[
\lim_{w\to \infty}\, \frac{L_w(p)}{L_w(q)}=1\tag{1}
\] 
hold for all  pairs of point $p,q$ in $\Omega$.
Let us remark that the proof relies upon a  deep
limit theorem for the values taken by
the eigenfunctions $\{\phi_nu\}$ and their derivaties
in § xx.
\bigskip


\centerline {\bf{0.3 Spectra of compact operators.}}
\bigskip

\noindent
Let $k(x,y)$ be a  Lebesgue measurable function
on $\square=\{0\leq x\leq 1\}\times \{0\leq y\leq 1\}$
which in general is complex-valued.
We assume that
\[
\int_{\square}\, |k(x,y)|^2\, dxdy<\infty
\]
This gives the compact Hilbert-Schmidt operator on
$L^2[0,1]$ defined by
\[
\mathcal K(u)(x)=
\int_\square\, k(x,y)u(y)\, dxdy
\]
It has a discrete spectrum outside the origin and
there exists Fredholm's resolvent function
$D(\lambda)$ for which the operator valued function
\[
\lambda\mapsto \frac{1}{D(\lambda)}\cdot
(E-\lambda \mathcal K)^{-1}
\]
is an entire function of the complex variable
$\lambda$. For readers who are not familiar with Fredholm's theory
we refer to § xx for the construction of
$D(\lambda)$.
In the article 
\emph{Sur le genre du dénominateur $D(\lambda)$
de Fredholm} Carleman proved the following conclusive result:

\medskip



\noindent
{\bf{1. Theorem.}} 
\emph{$D(\lambda)$  is an entire function of the form}
\[ 
D(\lambda)= e^{a\lambda}\prod\,(1-\frac{\lambda}{\lambda_\nu})
\cdot e^{\frac{\lambda}{\lambda_\nu}}
\] 
\emph{where $a$ is some complex constant and}
\[ 
\sum\, \frac{1}{|\lambda_\nu|^2}<\infty
\]
\medskip



\noindent
The proof relies upon a number of basic facts 
from analytic function theory due to
Poincaré, Lindelöf and Wiman which 
illustrates the usefulness of complex analysis in operator theory.
The result above becomes especially useful
when it is combined with the inequality for resolvents of matrices in
§ xx. To begin with
every Hilbert-Schmidt operator  on a separable Hilbert space is
up to a unitary equivalence given by
an integral operator as above.
In particular $\mathcal K$ is compact asnd hence  the spectrum
$\sigma(\mathcal K)$ is 
discrete outside the origin.
Let $\{\mu_n\}$ be the set of spectral values arranged with
non-increasing absolute values  which implies  that
$|\mu_n|\to 0$ when 
$\sigma(\mathcal K\setminus\{0\}$ is an infinite set. As usual spectral values are
repeated when their eigenspaces have dimension $\geq 2$.
Theorem 1 entails that the function
\[
\phi_\mathcal K(\mu)=
e^{a\lambda}\prod\,(1-\frac{\mu_\nu}{\mu})
\cdot e^{\frac{\mu_\nu}{\lambda}}
\]
is analytic outside the origin. Next, let $\mathfrak{h}(\mathcal K)$ denotes the
Hilbert-Schmidt norm of $\mathcal K$. With these notation we have
\medskip

\noindent
{\bf{2. Theorem.}}
\emph{For every complex number
$\mu$ outside $\sigma(T\mathcal K)$ one has the inequality}
\[
|\phi_\mathcal K(\mu)|\cdot ||(\mu\cdot E-\mathcal K)^{-1}||\leq
|\mu|\cdot e^{\frac{1}{2}(1+\frac{\mathfrak{h}(\mathcal K)^2}{|\lambda|^2})}
\]
\medskip

\noindent
This result   follows from
Therem 1 above together with the matrix-valued version in
§ xx. 
The effectiveness of Carleman's inequality
is apparent in the  study of the completeness
properties of eigenfunctions of Hilbert-Schmidt operators
and has therefore a wide range of applications.
We present results about this in § xx.





\medskip





\bigskip


\centerline {\bf{0.4 The use of subharmonic functions.}}
\bigskip

\noindent
In his text-book
\emph{Uniformisation} 
Rolf  Nevanlinna remarks that
it was Carleman who  first recognized the
power of this technique and applied it in many situations.
An example appears in his article
\emph{Sur les fonctions inverse des fonctions entières d'ordre fini}
from 1920 where the crucial result goes as follows:
Let $\Omega$ be an unbounded comnected domain in
the half-plane $\mathfrak{Re}(z)>0$ where the sets
\[
\Omega[\xi]=\Omega\,\cap\,\{\mathfrak{Re}(z)=\xi\}
\]
are non-empty for each $\xi>0$ and the sum of the lengths of the  intervals in
this slice is a finite positive number  $h(\xi)$.
Let $f$ be an analytic function in
$\Omega$ which extends to a continuous function on its
closure and suppose that
$|f(z)|\leq 1$ hold for each $z$ on the boundary.
Set
\[
M(\xi)=\max_{z\in\Omega[\xi]}\, |f(z)|
\]
With these notations the following is proved in [ibid]:

\medskip

\noindent
{\bf{Theorem.}} 
\emph{Either one has $M(\xi)\leq 1$ for all $\xi$, or else there exists
some $\xi_0$ such that $M(\xi_0)> 1$ and
for each
$\xi>\xi_0$ it holds that}
\[
M(\xi)\geq \log\, M(\xi)\cdot e^{\frac{4}{\pi}\cdot \int_{\xi_0}^\xi\,h(t)^{-1}\, dt}
\]
Let us remark that 
inequalities as in the theorem above
later were extended to cover
a more general set-up by  Ahlfors and Beurling in their
proofs of the Denjoy conjecture 
which they found independently of each other in 1929.
\medskip


\noindent
{\bf{A Phragmén-Lindelöf result}}.
Carleman used harmonic measures
to give simplified proofs of
earlier results by Lindelöf and Phragmén.
Here is an example whose  proof appears in § xx.
Let $D^*$ be the punctured disc $\{0<|z|<1\}$
and
when $0<\alpha<\pi$ we set
\[
D^*(\alpha)=\{z\in D\,\colon\,0<\arg(z)<\alpha\}
\]
Let $\Omega$ be a Jordan domain
which is contained in $D^*(\alpha)$
whose boundary consists of two simple  Jordan curves
contained in the closed sector $\overline{D^*(\alpha)}$
and  share the origin as an end-point while they have
distinct end-points on the unit circle $T$
which are  end-points of an interval 
of $T$ which gives the remaining part of
$\partial\Omega$. Let $g(z)$ be analytic in
$\Omega$ and suppose it extends to a continuos function
on
$\partial\Omega\setminus\{0\}$ with a  maximum norm  $\leq 1$.
Next, if $0<\delta<1$ we set $\Omega[\delta]=
\Omega\cap\{|z|=\delta\}$ and 
\[
\rho(\delta)=\max_{z\in \Omega[\delta]}
\,e^{-\delta^{\frac{\pi}{\alpha}}}\cdot  |g(z)|
\]
Using the subharmonic function
$\log \,|g|$ we prove the  following in § xx:
\medskip



\noindent
{\bf{Theorem.}} \emph{Assume that}
\[
\liminf_{\delta\to 0}\,\rho(\delta)<\infty
\]
\emph{Then it follows that $|g(z)|<1$ for all $z\in\Omega$}
 \medskip



\noindent
A deeper result  is the following uniqueness result which  appears in
Carleman's book \emph{xxx} from 1922:
Let $a>0$ and consider an analytic function $\Phi(z)$ in the
half-plane $\mathfrak{Re}(z)>a$ which extends
continuously to the closed half-plane
and is not identically zero.
Suppose there exist two sequences of strictly increasing
real numbers
$\{\beta_k\}$ and $\{\lambda_k\}$ such that
\[
|\Phi(z)|\leq \bigl(\,\frac{\beta_k}{|z|}\,\bigr)^{\lambda_k}
\]
hold for each $k=1,2,\ldots$.
Then the series
\[
\sum\,\frac{\lambda_{k+1}-\lambda_k}{\beta_k}<\infty
\]
The proof appears  in § xx and gives an instructive lesson about
harmonic majorisation.
\medskip

\noindent
Finally the  reader may  contemplate upon the following result which
is proved in § xx using the subharmonicity for  the radius of convergence 
defined via 
Taylor series
of analytic functions defined in open subsets of ${\bf{C}}$.
Consider a pair $f$ and $g$
where $f$ is analytic in the  rectangle 
$\square_+= \{-1<x<1\}\times \{0<y<a\}$
while $g$ is analytic in
$\square_-=\{-1<x<1\}\times \{-a<y<0\}$.
Then they are analytic continuations of each other over
the real
interval $-1<x<1$ if
\[
\lim_{\epsilon\to 0}\, \int_{-1}^1\, |f(x+i\epsilon)-
g(x-i\epsilon)|\, dx=0
\]
Notice  that no growth condition is imposed on the functions from
the start. This result was  established by
Carleman's lectures at
Mittag Leffler in 1935 and can be regarded as the first major result
about 
hyperfunctions. See § xx for further comments.
\bigskip


\noindent
\centerline {\bf{0.5 Extensions of Fredholm's theory.}}
\medskip


\noindent
Operator methods were introduced by Carl Neumann in
a pioneeering work from 1878 for a special class of
ellitptic  boundary value problems. Neumann's method was 
later refined by  Poincaré and 
Fredholm proved existence theorems
for a  quite extensive class of
elliptic boundary value problems via his theory about integral operators.
The merit of  constructing  operators
is that one 
can establish existence theorems without
variational methods which  therefore leads to   a more constructive 
procedure to attain solutions.
For example the standard Dirichlet problem can be
proved via operator methods as follows:
Consider a bounded domain $\Omega$  in
${\bf{R}}^n$ with a $C^1$-boundary
and let $dA$  denote the area measure on
$\partial\Omega$.
When $n\geq 3$  there exists the bounded linear operator on
$C^0(\partial\Omega$ defined by
\[
N(f)(p)=
\int_{\partial\Omega}\, \frac{1}{|p-q|^{n-2}}\cdot f(q)\, dA(q)
\]
If $N$ has a dense range in
$C^0(\partial\Omega)$ the maximum principle for harmonic functions
entails that the Dirichet problem is solvable for every continuous boundary
function.
The proof that $N$ has dense range follows by elementary measure theory and is left as
an exercise to the reader.
Next, we consider
the inhomogeneous  Neumann-Poincaré problem.
Given a strictly positive continouos function
$a$ on $\partial\Omega$ one seeks for each
$f\in C^0(\Omega)$ a harmonic function $u$ in
$\Omega$ which together with its inner normal derivative
extends continuously to the boundary where
\[
\frac{\partial u}{\partial{\bf{n_i}}}= a\cdot u+f\tag{*}
\]
The maximum principle for harmonic functions and the 
positivity of $a$ easily entials that
the solution $u$ is unique if it exists.
To prove existence one introduces
the kernel function defined outside the diagonal in
$\partial\Omega)\times\partial\Omega$ by:
\[
N(p,q)=\frac{\langle p-q,{\bf{n_i}}(q)\rangle}{|p-q|^{n-1}}
\]
where
${\bf{n_i}}(q)$ is the inner normal at the boundsry point $q$.
\medskip


\noindent
Next, when $g\in C^0(\partial\Omega)$ we construct
the harmonic function $U_g$ in $\Omega$ via Newton's potential, i.e.
\[
U_g(p)=xxx\cdot \int_{\partial\Omega}\,  \frac{g(q)}{|p-q|^{n-2}}\, dA(q)
\]
Now $xx\cdot \frac{1}{|x|^{n-2}}$ is the fundamental solution for the
Laplace operator so by 
Greens' formula
\[
\frac{\partial U_g}{\partial{\bf{n_i}}}(p)= g(p)+
\int_{\partial\Omega}\, N(p,q)g(q)\, dA(q)
\]
\medskip


\noindent
Following  the device by Fredholm and Poincaré we
introduce the kernel function on
the product $\partial\Omega\times\partial\Omega$ defined by
\[
K(p,q)=N(p,q)- xxx\cdot
a(p)\cdot \frac{1}{|p-q|^{n-2}}
\]
From the above we wee that $U_g$ solves (*)
if the $g$-function satisfies the intgral equation
\[
\int_{\partial\Omega}\, K(p,q)g(q)\, dA(q)=g(p)+f(p)\tag{**}
\]
To see that (**) has a solution one uses the
$C^1$-hypothesis on
$\partial\Omega$ which implies that the  linear operator on
$C^0(\partial\Omega)$ defined by
\[
\mathcal K(g)(p)=\int_{\partial\Omega}\, K(p,q)g(q)\, dA(q)
\]
is compact.
With an arbitrary $f$ we conclude that
(**) has a unique solution $g$ if
the spectrum of $\sigma(\mathcal K)$ does not contain
1 which  follows from the uniqueness. See § xx for further details
amndlet jus also remark that Carelan also analyzed the spectrum
of $\mathcal K$ via  a symmetrization of a general nature which
reduces the calcuations to determine spectra of
self-adjointopertores and after solve explicit systems of linear equations.
See § xx for this result which later has been adopted extensively in operator theory.


\medskip

\noindent
{\bf{Remark.}}
Carleman's thesis treats also
boundary value problems
where the 
regularity on $\partial\Omega$ is relaxed.
For $C^1$-domains
the kernel $K(p,q)$ above is a bounded function
which entails  compactness of $\mathcal K$.
If  "corners"  are allowed   on a sufficiently  thin subset of
$\partial\Omega$ one has a finite $L^1$-integral
\[
\iint_{\partial\Omega\times\partial\Omega}\, |K(p,q)|\, dA(p)dA(q)<\infty\tag{i}
\]
When (i) holds one seeks solutions to
the boundary value problem
where (*) only is requested
at boundary points outside the  set of corners.
In his thesis, Carleman treated the  case when
(i) holds and  regarded 
functions $f$ which are integrable with respect to the area measure. Then
$\mathcal K$ becomes a densely defined operator on a suitable
weighted $L^1$-space. It was  analysis of this kind which  led Carleman  to
extend the Fredholm theory to
a wider class where singular kernels appear in integral equations.


\bigskip

\noindent
{\bf{A non-linear boundary value problem.}}
In the  article
\emph{Über eine nichtlineare Randwertaufgabe bei der Gleichung $\Delta u=0$}
(Mathematisches Zeitschrift vol. 9 (1921),
Carleman considered
the following 
equation: Let
$\Omega$ be a bounded domain in ${\bf{R}}^3$
with $C^1$-boundary and
${\bf{R}}^+$ the non-negative real line where  $t$ is the coordinate.
Let $F(t,p)$
be a real-valued and continuous function
defined on  ${\bf{R}}^+\times\partial\Omega$.
Assume that 
\[
t\mapsto F(t,p)\tag{0.1}
\]
is strictly increasing  for every $p\in\partial\Omega$
and that $F(0,p)\geq 0$. Moreover,  
\[
\lim_{u\to\infty} F(t,p)=+\infty\tag{0.2}
\] 
holds uniformly with respect to $p$.
For a given point $q_*\in\Omega$ we seek a function $u(x)$
which is harmonic in $\Omega\setminus\{q_*\}$
and at $q_*$ it is locally $\frac{1}{|x-q_*|}$ plus a harmonic function.
Moreover, it is requested that
$u$
extends to a continuous function on
$\partial\Omega$ and that $u\geq 0$ in $\overline{\Omega}$.
Finally, along  the boundary
the  inner normal derivative $\partial u/\partial n$ satisfies the 
equation
\[
\frac{\partial u}{\partial n}(p)= F(u(p),p)\quad \colon p\in\partial\Omega\tag{*}
\]

\medskip

\noindent 
Let us remark that the  case when $F(t,p)= kt^4$ for some positive constant $k$
means that we regard the Stefan-Boltzmann equation whose
physical 
interpretation 
ensures that
(*) has a unique non-negative solution $u$.


\medskip

\noindent {\bf {Theorem.}}
\emph{For each $F$  satisfying (0.1-0.2)
 the boundary value problem has a unique solution $u$.}
\medskip

\noindent
We prove this theorem  in § xx.
Apart from the conclusive result, the
strategy in Carleman's proof deserves attention.
The crucial idea
is to consider
a family of boundary value problems where 
one for each
$0\leq h\leq 1$ seeks $u\uuu h$ to satisfy
\[
\frac{\partial u\uuu h}{\partial n}(p)=(1\vvv h)u\uuu h+ h\cdot  F(u\uuu h(p),p)\quad \colon p\in\partial\Omega\tag{*}
\]
and $u\uuu h$ has the same pole as $u$ above.
The device to pass via linear systems
was put forward by Poincaré  in his famous
lecture \emph{L'avenir des mathématiques}
held in Rome 1908.
Let us remark that the methods which prove
the theorem above can be adopted to other situations and it goes without
saying that extensions to higher dimensions are available and
one can also replace the
Laplace operator by  elliptic operators of positive type.


\newpage



\centerline{\bf{0.6 Taylor series and quasi\vvv analytic functions.}}
\bigskip


\noindent
Let $f(x)$  an infinitely differentiable function
defined on the interval $[0,1]$.
At $x=0$ we can take the derivatives and set
 \[
C\uuu\nu= f^{(\nu)}(0)
\]
In general the sequence
$\{C\uuu \nu\}$ does not determine $f(x)$. The standard example is the 
$C^\infty$\vvv function defined for $x>0$ by $e^{\vvv 1/x}$ and
zero on $x\leq 0$. Here $\{C\uuu\nu\}$ is the null sequence and yet
the function is no identically zero.
Now we seek   growth conditions on the derivatives of $f$ over
the whole interval $(\vvv 1,1)$ such that
$\{C\uuu\nu\}$
determines $f$ over this  interval.
For each non-decreasing sequence of 
$\mathcal A=\{\alpha\uuu\nu\}$  of positive real numbers
we  denote by $\mathcal C\uuu\mathcal A$ the class of $C^\infty$\vvv functions
on $[0,1]$ where the maximum norms of the derivatives satisfy
\[
\max\uuu {0\leq x\leq 1}\, |f^{(\nu)}(x)|\leq k^\nu\cdot \alpha\uuu\nu^\nu
\quad\colon\quad \nu=0,1,\ldots\tag{*}
\]
for some $k>0$ which may depend upon $f$.
One says that $\mathcal C\uuu\mathcal A$ is a quasi\vvv analytic class
if every $f\in C\uuu \mathcal A$ whose Taylor series is identically
zero at $x=0$ vanishes identically on $[0,1)$.
\medskip

\noindent
{\bf{1. The Denjoy class.}}
Let $\mathcal A=\{\alpha\uuu\nu\}$
be such that the series
\[
 \sum\, \frac{1}{\alpha\uuu\nu}=+\infty\tag{**}
\] 
In the article [Denjoy 1921),  Denjoy proved that (**)  entails that 
$C\uuu\mathcal A$
is quasi\vvv analytic.
 
\medskip

\noindent
{\bf{2. The general case.}}
A conclusive result which gives a necessary and sufficient condition on 
the sequence $\{\alpha_\nu\}$ in order  that $C\uuu \mathcal A$
is quasi\vvv analytic was  proved by Carleman
and goes as follows:

\medskip

\noindent
{\bf{3. Theorem.}}
\emph{
The class  $C\uuu\mathcal A$ is quasi\vvv analytic if and only if}
\[
 \int\uuu 1^\infty\, \log\,\bigl[\,\sum\uuu{\nu=1}^\infty\,
\frac{r^{2\nu}}{a\uuu \nu^{2\nu}} \,\bigr] \cdot \frac{dr}{r^2}=+\infty
\]

\medskip

\noindent
For the proof of this result we refer to § XX in Special Topics.
\medskip

\noindent
{\bf{4. The reconstruction theorem.}}
Since quasi\vvv analytic functions by definition
are determined by their Tayor series at a single point
there remains the question how to determine $f(x)$ in a given  
quasi\vvv analytic class $C\uuu \mathcal A$
when the sequence of its Taylor coefficients at $x=0$ are given.
To achieve this
Carleman
considered a class of  
variational problems.
Let $n\geq 1$ and for a given sequence
of real numbers $\{C\uuu 0,\ldots,C\uuu{n\vvv  1}\}$
we consider the class of $n$\vvv times differentiable functions $f$
on $[0,1]$ for which
\[
f^{(\nu)}(0)= C\uuu\nu\quad\colon\quad \nu=0,\ldots ,n\vvv 1\tag{i}
\]
Next, let $\{\gamma\uuu 0,\gamma\uuu 1,\ldots,\gamma\uuu n\}$
be some $n+1$\vvv tuple of positive numbers and consider
the variational problem
\[
\min\uuu f J\uuu n(f)=
\sum\uuu {\nu=0}^{\nu=n}\,\gamma\uuu\nu^{\vvv 2\nu}
\cdot \int\uuu 0^1\, [f^{(\nu)}(x)\,]^2\cdot dx\tag{ii}
\]
where the competing family consist
of $n$\vvv times differentiable functions on 
$[0,1]$ satisfying (i) above. 
The strict convexity of $L^2$\vvv norms
entail  that the variational problem has a unique minimizing function 
$f\uuu n$
which depends linearly upon $C\uuu 0,\ldots,C\uuu {n-1}$.
In other words, there exists a unique doubly indexed sequence
of functions $\{\phi\uuu{p,n}\}$ defined for pairs $0\leq p\leq n$
such that 
\[
f\uuu n(x)= \sum\uuu{p=0}^{p=n\vvv 1} \, C\uuu p\cdot \phi\uuu{p,n\vvv 1}(x)
\]
where the functions
$\{\phi\uuu {0,n\vvv 1},\ldots \phi\uuu {n\vvv 1,n\vvv 1}\}$
depend upon $\gamma  \uuu 0,\ldots,\gamma  \uuu n$ and
\[
\phi_{n,p}^{(\nu)}(0)=\text{Kronekcer's delta-function}\,\,  \delta(\nu,p)
\]


\bigskip

\noindent
{\bf{5. A specific choice of the $\gamma$\vvv sequence.}}
Let $\{\alpha\uuu \nu\}$ be  a Denjoy sequence, i.e. 
(**) above diverges. Set $\gamma\uuu 0=1$ and 
\[ 
\gamma\uuu\nu= \frac{1}{\alpha\uuu\nu}\cdot
\sum\uuu{p=1}^{p=\nu}\,
\alpha\uuu p\quad\colon\quad \nu\geq 1
\]
To each $n\geq 1$ we consider the variational problem above
using the $n$\vvv tuple 
$\gamma\uuu 0,\ldots,\gamma\uuu{n\vvv 1}$
which yields the extremal function $f\uuu n(x)$.
With these notations the following result is proved in
Carleman's cited monograph:
\medskip

\noindent
{\bf{ 6. Theorem.}}
\emph{If  $F(x)$ belongs to some $\mathcal  A$ given by a
Denjoy sequence it follows that}
\[
\lim\uuu{n\to\infty}\, f\uuu n(x)=F(x)
\] 
\emph{where the convergence holds uniformly on interval $[0,a]$ for every $a<1$.
Moreover, there exists
a doubly indexed sequence $\{a\uuu{\nu,n}\}$ defined for pairs $0\leq \nu\leq n$
which only depends on the sequence $\{\alpha\uuu\nu\}$
such that 
every    $F(x)\in \mathcal C\uuu\mathcal A$
then is given as a limit of the form:}
\[
F(x)=\lim\uuu{n\to\infty}\, \sum\uuu{\nu=0}^{\nu=n}
\, a\uuu{\nu,n}\cdot \frac{F^{(\nu)}(0)}{\nu\,!}\cdot x^\nu\quad\colon\quad 
0\leq x<1
\]
\medskip


\noindent
{\bf{ 7. Remark.}}
Theorem 6 gives a  reconstruction for  quasi\vvv analytic classes of the Denjoy type.
For a general quasi\vvv analytic class $C_\mathcal A$
a similar result is proved in
[Carleman]. Here the
final result is more involved and 
the doubly indexed $a$\vvv sequence it is found in a rather implicit
manner via solutions to the variational problems which 
in general depend 
upon the given sequence $\mathcal A$. So up to the present date
there remain
open problems about 
effective reconstruction formulas in quasi-analytic classes.
The interested reader should   consult [Carleman: page xxx]
for some specific open  questions about this.

\medskip


\noindent
{\bf{8. Quasi\vvv analytic boundary values.}}
Another  problem 
is concerned with  boundary values of analytic functions
where
the set of non\vvv zero Taylor\vvv coefficients is sparse.
In general, consider a power series $\sum\, a\uuu nz^n$
whose radius of convergence equal to one. Assume that there exists an interval $\ell$
on the unit circle such that
the analytic function $f(z)$ defined by the series extends to
a continuous function in the closed sector where
$\text{arg}(z)\in\ell$. So on $\ell$ we get a continuous boundary
value function $f^*(\theta)$
and suppose that $f^*$ belongs to some quasi\vvv analytic class on
this interval.
Let $f$ be given by the series
\[
f=\sum\, a\uuu n\cdot z^n
\]
Suppose that gaps occur
and write  the sequence of non\vvv zero coefficients
as $\{ a\uuu{n\uuu 1}, a\uuu{n\uuu 2}\ldots\}$
where $k\mapsto n\uuu k$ is a  strictly increasing sequence.
With these notations the following result is due to Hadamard:
\medskip

\noindent
{\bf{9. Theorem.}}\emph{
Let $f(z)$ be analytic in the open unit disc
and assume it has a continuous extension to some open  interval on the 
unit circle where 
the boundary function $f^*(\theta)$ is real\vvv analytic. Then there exists an integer 
$M$ such that}
\[ 
n\uuu{k+1}\vvv n\uuu k\leq M\tag{9.1}
\]
\emph{for all $k$. In other words,   the sequence of non\vvv zero coefficients 
cannot be too  sparse.}
\bigskip

\noindent
Hadamard's result was extended to the quasi\vvv analytic case in
[Carleman] where it is proved that if $f^*$ belongs to some quasi\vvv analytic class
determined by a sequence $\{\alpha\uuu\nu\}$
then the gaps cannot be too sparse, i.e. after a rather involved analysis
one finds that $f$ must be identically zero if
the integer function $k\mapsto n\uuu k$ increases too fast.
The rate of increase 
need not be of the type (9.1), but depends upon $\{\alpha\uuu\nu\}$.
Up to the present date
it appears that no precise descriptions of
the growth of $k\mapsto n\uuu k$ which would ensure unicity
is known for a general quasi\vvv analytic class, i.e. even in
the situation considered by
Denjoy.
So there remains many basic  questions concerned with quasi-analyticity.

\newpage



\centerline {\bf{Symmetric operators on Hilbert spaces.}}
\bigskip


\noindent
Among Carleman's 
contributions to mathematics one should first of all
mention 
the
monograph  \emph{Sur les équations singulières
à noyaux réel et
symmetrique} [Uppsala University 1923].
Here
the existence of 
spectral resolutions for unbounded
and self-adjoint
operators on separable  Hilbert space was established.
The expositary 
article 
\emph{La theorie des equations intégrales singuliérs} 
[Ann. l'Institut Poincaré Vol. 1 (1931)] from his lectures in Paris
during the spring 1930 gives a good introduction to [ibid]
and contains several  instructive examples. 
The  study  in [ibid] was    inspired by
Hilbert's spectral theorem for bounded
self-adjoint operators from 
his famous book \emph{Integralgleichungen} [xxx: 1904], and put forward
by Carleman during  his plenary talk at the IMU-congress  at Zürich in 1932:
\medskip

\noindent
\emph{La théorie, crée par Hilbert, des formes quadratiques (ou hermitiennes)
à une infinité de variables en connexion avec la théorie
des équations intégrales à noyeau symmetrique est certainement
la plus importante découverte qui ait été faite dans la
théorie des équations intégrales
aprés les travaux  fondamentaux de Fredholm.}

\medskip

\noindent
The need for a theory of unbounded operators was put forward by Weyl in 1908
in a famous article devoted to second order differential operator
on the real $x$-line defined by
\[
P=\frac{d^2}{dx^2}+q(x)
\]
where $q(x)$  is a real-valued and locally square integrable function.
Weyl found examples of such operators for which there exists
a complex.valued $L^2$-function $u(x)$ on the real line 
such that
\[
 P(u)= i\cdot u
\]
where $i$ is the imaginary unit.
This appears to contradict the usual spectral theorem for 
real and symmetric matrices and raised at an early stage
many new problems devoted to spectral theory of linear operators.
It goes without saying that Weyl's  studies also served as  a 
major inspiration for Carleman when he developed a general theory in
the cited monograph. 
Let us give an example from [ibid]
where  a wave equation  is solved via
an operator-valued  spectral function.

\medskip


\noindent
{\bf{2.1. Propagation of sound}}.
With $(x,y,z)$ as space variables in
${\bf{R}}^3$ and a time variable $t$ one  considers the 
propagation of sound
in the infinite  open complement $U={\bf{R}}^3\setminus \overline{\Omega}$
of a bounded open subset $\Omega$ with a $C^1$-boundary
$\partial\Omega$. It is governed by 
solutions $u(x,y,z,t)$ defined in $U\times \{t\geq 0\}$
to the wave equation
\[ 
 \frac{\partial^2 u}{\partial t^2}= \Delta u\tag{1}
 \] 
 where 
 $\Delta$ is the Laplace operator in $x,y,z$.
Moreover, the normal derivative
taken along $\partial\Omega$ are zero,  i.e. 
\[
\frac{\partial u}{\partial n}(p,t)=0\quad\colon p\in \partial \Omega\tag{2}
\]
hold for each $t\geq 0$.
It turns out that there exists a unque $u$-function
satisfying (1-2) and initial conditions
\[
u(p,0)= f_0(p)\quad\colon\,\frac{\partial u}{\partial t}(p,0)= f_1(p)\tag{3}
\]
for a pair of functions $f_0,f_1$ in $L^2(U)$ 
such that $\Delta(f_1)$ and $\Delta(f_2)$ also belong to
$L^2(U)$, and whose
normal derivatives along $\partial\Omega$ are 
identically zero.
In [ibid] this result is proved via the construction of an operator-valued
spectral function $\Theta(\lambda)$
defined on an interval $[c,+\infty)$ for 
a positive real number $c$ and the unque solution $u$
is given by
\[
u= 
\int_c^\infty\,\cos(\sqrt{\lambda t})\cdot \frac{d\Theta}{d\lambda}(f_0)+
\int_c^\infty\,\frac{\sin(\sqrt{\lambda t})}{\sqrt{\lambda}}
\cdot \frac{d\Theta}{d\lambda}(f_1)\tag{*}
\]
The new feature in Carleman's  proof as compared to earlier
studies was the construction of $\Theta$
which arises via a certain densely defined and self-adjoint operator.
More precisely,   denote by $L^2_*(U)$ the family of
functions $g$ in $U$ for which both
$g$ and $\Delta(g)$ are in $L^2(U)$ and
$\frac{\partial g}{\partial n}=0$ on $\partial\Omega$. Then
the following hold:
\[
g=\int_c^\infty\, \frac{d\Theta}{d\lambda}(g)\quad\colon\, g\in L^2_*(U)\tag{i}
\]
Moreover, 
for every interval $[a,b]\subset [c,+\infty)$ and
continuous function $\rho(\lambda)$ on $[a,b]$ one has 
\[
\Delta\bigl(\int_a^b\, \rho(\lambda)
\cdot \frac{d\Theta}{d\lambda}(g)\bigr)=
-\int_a^b\, \lambda\cdot \rho(\lambda)
\cdot \frac{d\Theta}{d\lambda}(g)\quad\colon\, g\in L^2_*(U)\tag{ii}
\]
Since the second order derivative of
$t\mapsto \cos(\sqrt{\lambda t})$ is equal to $-\lambda\cdot \cos(\sqrt{\lambda t}$
and similarly for the sine-function, we see from
(i-ii) that (*) yields a solution to the wave equation for
each pair $f_0,f_1$ in $L^2_*(U)$.
When $t=0$ the vanishing of the sine-function at zero gives
$u(p,0)= f_0(p)$ and taking the first order $t$-derivative
the reader can confirm the second initial condition in (3).
\medskip

\noindent
{\bf{Remark.}}
In § xx we expose the constructions 
of the $\Theta$-function.
Carleman's original methods from 1923 was  later been
adopted in work related to boundary
value problems and scattering. The reader may consult
Chapter XIV in volume 2 of Hörander's text-books
in linear partial differential operators which
contains a wealth of results dealing with boundary problems as above,
based upon the use of spectral functions.
\medskip

\noindent
{\bf{A limit formula.}}
One 
merit in the constructions  from [ibid]
is that  they 
confirm 
that the solution $u(x,t)$ satisfies:
\[
\lim_{t\to \infty}\, (\frac{\partial u}{\partial x})^2(p,t)+
(\frac{\partial u}{\partial y})^2(p,t)+(\frac{\partial u}{\partial z})^2(p,t)=0\tag{**}
\]
with uniform convergence when $p$ stays in a relatively compact subset of
$U$.
Namely, the Riemann-Lebesgue theorem
and the equation (*) for the $u$-solution, entail (**)
if the spectral $\Theta$-function is absolutely continuous with
respect to $\lambda$.
In § xx we expose Carleman's proof that this holds which relies upon the following
result:
 

\medskip

\noindent
Let $\{a\leq s\leq b\}$ be a 
compact interval on the real $s$-line and
$s\mapsto G_s$ is  a function with values in the Hilbert space
$L_*^2(U)$ which  is  continuous 
in the sense that 
\[
\lim_{s\to s_0}\, ||G_s-G_{s_0}||_2=0
\]
It is called   absolutely continuous if there to 
each
$\epsilon>0$ exists some $\delta>0$ 
such that 
\[
\sum\, ||G_{s_{\nu+1}}-G_{s_\nu}||_2<\epsilon
\] 
hold for every partition $a=s_0<s_1<\ldots<s_M=b$
with $\sum\, (s_{\nu+1}-s_\nu)<\delta$.
\medskip

\noindent
\noindent
{\bf{Theorem.}}
\emph{Assume that 
the following 
holds for
every sub-interval $[\alpha,\beta]$ of $[a,b]$:}
\[
\Delta(G_\beta-G_\alpha)=-\int_\alpha^\beta\, s\cdot \frac{dG_s}{ds}
\] 
\emph{Then 
$s\mapsto G_s$ is absolutely continuous}.


\bigskip




\centerline{\bf{§ 0.1 Spectral functions of unbounded hermitian operators}}

\bigskip






\noindent
In view of the importance 
we describe  already in this introduction some 
results from [ibid].
The general situation  below covers
unbounded self-adjoint operators as a special case.
We expose the theory from [ibid]  in a  general context
since this   is  needed
to
grasp  material about   moment problems in § xx.
Let us ony remark that spectral resolutions of
of unbounded self-adjoint operators
is an easy  consequence of Hilbert's
results for bounded self-adjoint operators and  exposed in
many text-books. See for example  my notes devoted to functional analysis
for the  details about the 
extension of Hilbert's theorem to  unbounded self-adjoint operators.

\medskip






\noindent
Recall that a separable Hilbert space is isomorphic to $\ell^2$ whose vectors
are sequences of complex numbers
$\{x_p\}$ indexed by integers with
$\sum\, |x_p|^2<\infty$.
A doubly indexed sequence
$\{c_{pq}\}$ is Hermitian if:
\[
 c_{q,p}= \overline{c}_{p,q}
\]
Impose the condition that
each column of this infinite matrix belongs to $\ell^2$, i.e.
\[
\sum_{q=0}^\infty |c_{pq}|^2<\infty\quad\colon\, p=1,2,\ldots \tag{1}
\] 
The Cauchy-Schwarz inequality entails that if
$x\in \ell^2$ then
the series
\[
\sum_{q=0}^\infty c_{p,q}\cdot x_q\tag{2}
\] 
converges absolutely for
each $p$ and let  $y_p$ denote the sum.
But  (1) does not imply that
$\{y_p\}$ belongs to $\ell^2$.
So we  get a subspace $\mathcal D$ of $\ell^2$
which consists of vectors
$x$ such that
\[
\sum_{p=0}^\infty \, \bigl|\sum_{q=0}^\infty c_{p,q}\cdot x_q\bigr|^2<\infty\tag{3}
\]
Notice that (1) implies that
$\mathcal D$ contains
the $\ell^2$-vectors $\{x_p\}$ for which only finitely many
$x_p$ are non-zero.
Hence there
exists 
the densely defined linear operator
$S$  sending a vector $x$
to the vector $Sx=y$  where
\[ 
y_p=\sum_{q=0}^\infty  c_{qp}\cdot x_q\quad\colon p=0,1,2\ldots
\]
By definition the domain of definition of $S$ is
the subspace $\mathcal D$ of $\ell^2$.
\medskip


\noindent
{\bf{Spectral decomposition.}}
Given an infinite matrix as above we
get finite hermitian matrices
$\{C_N\}$ for each positive integer $N$ whose  elements
are $c_{pq}$ for pairs $1\leq p,q\leq N$
and otherwise zero.
Each $C_N$   gives bounded linear opertors on the complex Hilbert space
$\ell^2$ denoted by $\mathcal C_N$.
The spectral theorem for
hermitian matrices gives for each
$N$  an $N$-tuple of pairwise orthogonal
vectors $\phi_1^{(N)}\,\ldots,,\phi_1^{(N)}$ such that
\[
\mathcal C_N(\phi_k^{(N)})=\mu_k\cdot (\phi_k^{(N)})
\]
where the eigenvalues $\{\mu_k\}$ are real.
A positive real number
$\lambda$ gives  for each $N$
a bounded linear operator $E_N(\lambda)$ defined 
on vectors $x\in\ell^2$ by 
\[
E_N(\lambda)(x)=
\sum^\lambda \, \langle \phi_k^{(N)},x\rangle\cdot  \phi_k^{(N)}
\]
where the summation index indicates  that e the sum is restricted to
eigenvectors of $\mathcal C_N$ for which
\[
0<\mu_k\leq \frac{1}{\lambda}\tag{i}
\]
It is clear that $E_N(\lambda)$ is a self-adjoint projection
with a finite dimensional range
given by the
subspace of $\ell^2$ whose basis consists of
eigenvectors
of $\mathcal C_N$ for which (i) holds.
It is now tempting to perform limits as $N\to infty$.
In [ibid: Chapter I] it is shown via basic Hilbert space theory
that
there exist weakly convergent subsequences of these $E$-operators.
More precisely, there exists  a family of
operator valued functions
$\lambda\mapsto \Theta(\lambda)$ is 
where each such 
$\Theta$ is  a limit from a subsequence of the $E$-operators, i.e.
there exists a sequence $1\leq N_1<N_2<\ldots$ such that
\[
\Theta(\lambda)(x)= \lim_{\nu\to \infty}\, E_{N_\nu}(\lambda(x)
\]
hold for every $\ell^2$-vector $x$. Here  the limit is weak which  means that
\[
\langle \Theta(\lambda)(x),y\rangle= 
\lim_{\nu\to \infty}\,\langle  E_{N_\nu}(\lambda(x),y\rangle 
\]
hold for all pairs $x,y$ in $\ell^2$. One refers to every such limit  $\Theta$ as a 
spectral operator associated to $\mathcal C$.
From the constructions above it  is clear that
the functions
\[
\lambda\mapsto  \langle E_{N_\nu}(\lambda(x),x\rangle 
\]
are non-decreasing on
the positive  $\lambda$-line for each vector $x$.
After a passage to the limit it follows that
\[
\lambda\mapsto\langle \Theta(\lambda)(x),y\rangle
\] 
is non-decreasing function which is
left continuous, i.e.
\[
\lim_{\epsilon\to 0}
\langle \Theta(\lambda-\epsilon)(x),y\rangle=\langle \Theta(\lambda)(x),y\rangle
\] 
hold for each fixed vector $x$ and every $\lambda>0$, where
$\epsilon>0$ in the limit above.
Next, for each $N$ we notice that the opertors
$\{E_N(\lambda)\,\colon \lambda>0\}$ commute
and
\[
E_N(\lambda_2)\circ E_N(\lambda_1)=
E_N(\lambda_1)
\] 
hold for pairs $0<\lambda_1<\lambda_2$.
Passing to a limit  the same hold for
each spectral $\Theta$-family.
Moreover, if $x\in \ell^2$
then the vector-valued function
$\lambda\mapsto \Theta(\lambda)(x)$ has a finite total variation. In fact, for
each finite partition $0<\lambda_1<\ldots<\lambda_M$ over
$(0,+\infty)$ one has the Bessel inequality
\[
||\Theta(\lambda_k)(x)||+
\sum _{k=1}^{k=M-1}\, ||\Theta(\lambda_{k+1}(x)-
\Theta(\lambda_k)(x)||\leq ||x||
\]
where we have taken norms in $\ell^2$.
It follows that if $0<a<b<\infty$ and $g(\lambda)$ is a continuous function on
$[a,b]$, then there exists a bounded linear operator
on $\ell^2$ defined by
\[
x\mapsto \int_a^b\, g(\lambda)\cdot \frac{d\Theta}{d\lambda}(x)
\]
where the $\ell^2$-valued integral is 
taken in the sense of Stieltjes.
Thus,  a  pair $(\Theta,g)$ where
$\Theta$ is a spectral operator on the positive real
$\lambda$-line and $g\in C^0[a,b]$ gives a bounded linear operator
denoted by
$\Theta_g$.
In [ibid] it s proved that all these operators have range contained in
$\mathcal D(S)$ and
commute with $S$ in the sense that
\[
S\circ \Theta_g(x)=\Theta_g\circ S(x)\quad\colon\, x\in \mathcal D(S)
\]
In particular we apply this to an
interval
$[\delta,1/\delta]$ with $0<\delta<1$
where $g(\lambda)= 1/\lambda$. A crucial result from [ibid] 
asserts the following:

\medskip

\noindent
{\bf{Proposition.}} \emph{For each vector 
$x\in \mathcal D(S)$ 
there exists a constant $M$  such that}
\[
 \int_\delta^{1/\delta}\, \lambda^{-1}\cdot ||\frac{d\Theta}{d\lambda}(x)||\leq M
 \] 
 \emph{for all $\delta>0$.
 In other words, the vector-valued integral below is 
 absolutely convergent}
\[
\int_0^\infty \, \lambda^{-1}\cdot \frac{d\Theta}{d\lambda}(x)
\]
\medskip

\noindent
Similar constructions as above can be   
done when we regard negative eigenvalues of the $E$-operators.
If $\lambda<0$ we set
\[
E_N(\lambda)(x)=
\sum^\lambda \, \langle \phi_k^{(N)},x\rangle\cdot  \phi_k^{(N)}
\]
where the summation index means that we take the sum over
those eigenvectors of $\mathcal C_N$ for which
\[
\frac{1}{\lambda}\leq \mu_k<0
\]
Notice that if $\delta$ is so small that
the absolute values of all eigenvalues of
$\mathcal C_N$  belong to $[\delta,1/\delta]$, then
\[
\mathcal C_N(x)=
\int_{-1/\delta}^{-\delta} \, \lambda^{-1}\cdot \frac{dE_N}{d\lambda}(x)+
\int_\delta ^{1/\delta}
 \,  \lambda^{-1}\cdot \frac{dE_N}{d\lambda}(x)
\]
\medskip

\noindent
Next, exactly as above we take subsequences which give
weak limits and operator $\Theta$-functions 
which now are defined on 
$(-\infty,0)$.
In particular we take subsequences
$1\leq N_1<N_2<\ldots$ for which weak limits
exist for all real $\lambda\neq 0$. This
gives  operator-valued
spectral $\Theta$-function defined for all real $\lambda$.
The same finiteness as in Proposition 1 hold when we 
integrate $1/\lambda$ over intervals $[-1/\delta,-\delta]$ and 
the  following conclusive result was  proved in  [ibid:Chapter 2]:
\medskip

\noindent
{\bf{Theorem.}}
\emph{For each  spectral $\Theta$-function and every
$x\in \mathcal D(S)$ one has}
\[
S(x)= 
\lim_{\delta\to 0}\,
\int_{-1/\delta}^{-\delta} \, \lambda^{-1}\cdot \frac{d\Theta}{d\lambda}(x)+
\int_\delta ^{1/\delta}
 \,  \lambda^{-1}\cdot \frac{d\Theta}{d\lambda}(x)
\]
\medskip

\noindent
{\bf{The inhomogenous equation $S(x)=\zeta \cdot x+y$}}.
Let $y$ be a given no-zero vector in $\ell^2$ and 
$\zeta $ is a  complex number whose imaginary part is $>0$.
Since each operator $\mathcal C_N$ has a real 
spectrum there exists
a unique vector $x_N(\zeta)$ such that
\[
\mathcal C_N(x_N(\zeta))=\zeta\cdot x_N(\zeta)+y
\]
We leave it to the reader to verify that
the reality of $\sigma(\mathcal C_N)$ entails that
\[
||x_N(\zeta)||\leq \frac{1}{\mathfrak{Im}(\zeta)}\cdot ||y||
\]
\medskip

\noindent
Recall that bounded subsets of $\ell^2$ are relatively compact with
respect to the weak topology.
We can therefiore pass to subsequences where
$x_{N_k}(\zeta)$ converges weakly to a oimit
vector 
$x_*(\zeta)$ and at the same time $\{N_k\}$ produces a spectral
$\Theta$–function.
Using Theorem xx it follows that
\[
S(x_*(\zeta))=\zeta \cdot x_*(\zeta)+y
\]
So this homogeneous equation has at least one solution.
However, it is in general not unique and
we shall give examples in § xx in connection with the moment problem
where a description of all solution vectors to (xx)
is available. In a similar way we get  solutions to the equation
(xx) for complex numbers $\zeta$ with negative imaginary part.
\medskip


\centerline{\bf{Class I operators.}}
\medskip

\noindent
The densely defined hermitian operator $S$ is of Class I
if $iE-S$ and $iE+S$ both are injective. 
When this holds it is proved in [ibid] that 
if $\mathfrak{Im}(\zeta)\neq 0$
then the equation
\[
S(x)=\zeta\cdot x
\]
has no non-zero solution.
It means that the inhomgenous equation above has a unique solution
$x_*(\zeta)$ for every $y$ and   gives an everywhere defined linear operator
$R(\zeta)$ where
\[
R(\zeta)(y)= x_*(\zeta)
\]
A detailed study of Class I operators appears in
Chapter III-IV in [ibid].
Let us remark that one also refers to Class I opertors as self-adjoint operators.
In fact, this terminology stems from the following result in [ibid]:
\medskip

\noindent
{\bf{Theorem.}}
\emph{The operator $S$ is of class I if and only if}
\[
\langle Sx,y\rangle=
\langle x,Sy\rangle
\]
\emph{hold for each pair $x,y$ in $\mathcal D(S)$.
Moreover,  a Case I  operator has a unique spectral $\Theta$-function
obtained as the unrestricted limit}
\[ 
\lim_{N\to\infty}\, E_N(\lambda)= \Theta(\lambda)
\]
\medskip

\noindent
{\bf{The closure property.}}
Let $S$ be of Class I which gives a unique spectral function
$\Theta$ where $\mathcal D(S)$ consists of vctor $x$ for which
the integral
\[
\int_{-\infty}^\infty \, \lambda^{-1}\cdot \frac{d\Theta}{d\lambda}(x)
\]
is absolutely convergent.
One says that $S$ has the closure property if
\[
x=\lim_{\delta\to 0}\, 
\int_{-1/\delta}^\delta \, \frac{d\Theta}{d\lambda}(x)+
\int_\delta^{1/\delta} \, \frac{d\Theta}{d\lambda}(x)
\]
hold for every vector $x$.
In [ibid] it is proved that this closure property holds if 
$S$ is injective, i.e. $S(x)\neq 0$ for every non-zero vector in
$\mathcal D(S)$.



















 


  























\newpage










\centerline {\bf{§ 0.2 Applications to quantum mechanics.}}
\bigskip

\noindent
Carleman's  cited monograph was published before quantum mechanics was born
and around 1920
he was concerned with   applications to
the moment problem of Stieltjes and extension of 
Fredholm's theory to cases where singular integral operators appear.
It was therefore quite exciting  when
Niels Bohr in a lecture held at the Scandinavian Congress  in
Copenhagen 1925, talked about the new quantum mechanics
and  adressed new problems
to the
mathematical  community.
Recall that a crucial point in
quantum mechanics 
is the hypothesis on energy levels which correspond to 
orbits in Bohr's theory of atoms. 
For this  physical  background
the  reader should
consult 
Bohr's  
plenary talk when 
he received the Nobel Prize in physics 1923.
In the "new-born" quantum mechanics
the following second order PDE-equation plays a crucial role:
\[ 
\Delta\phi+2m\cdot\bigl( E-U\bigr)\bigl(\frac{2\pi}{h}\bigr)^2\cdot \phi=0\tag{*}
\] 
Here $\Delta$ is the Laplace operator in the 3-dimensional $(x,y,z)$-space,
$m$ the mass of a particle and $h$  Planck's constant
while   $U(x,y,z)$ is a potential function.
Finally $E$ is a parameter and one seeks values on $E$
such that (*) has a solution $\phi$
which belongs to $L^2({\bf{R}}^3)$.
Leaving physics aside, the  mathematical problem
amounts to study   second order
PDE-operators:
\[ 
L=\Delta+c(x,y,z)\quad\colon
\Delta=\partial_x^2+\partial_y^2+\partial_z^2\tag{**}
\]
where $c(x,y,z)$ is a real-valued and Lebesgue measurable
function
which is locally square integrable in
${\bf{R}}^3$. 
Above
$L$ 
is   defined on the
dense subspace of $L^2({\bf{R}}^3)$ which
consists of
test-functions. Moreover, 
Greens' formula entails that it is symmetric, i.e. for each pair $f,g$ in
$C_0^\infty({\bf{R}}^3)$ one has:
\[
\iint\, L(f)\cdot g\, dxdydz=
\iint\, L(g)\cdot f\, dxdydz
\]
So the eigenvalue equation (*)
boils down to find conditions
on
the potential function $c$ in order that the operator $L$ is of class I.
In physical  applications one is foremost concerned with  the
case
when $c$ is  a potential function
 \[
W(p)=\sum\,\frac{\alpha _\nu}{|p-\xi_\nu|}+\beta
\]
where $\{\xi_\nu\}$ is a finite subset of
${\bf{R}}^3$  and  $\{\alpha_k\}$ and 
$\beta$ are real and positive numbers. 
For this special $c$-function
results from Carleman's cited monograph easily imply
that
$L$ is of Class  I
and  the real spectrum of $L$ is a discrete sequence of real numbers
whose absolute values tend to $+\infty$. See § xx for the proof. 
In general  one does not know precise conditions on $c$ in order that $L$
is of Class I.
The following  sufficient condition was presented during
in Carleman's  lectures at Sorbonne in 1930 and
a detailed account appears in the 
article
\emph{Sur la théorie mathématique de l'équation de Schrödinger}
[Arkiv för matematik och fysik:  1934]:
\medskip

\noindent
{\bf{Theorem }}
\emph{
If there 
exists if there is a  constant $M$
such that}
\[
\limsup_{x^2+y^2+z^2\to \infty}\, c(x,y,z)\leq M
\]
\emph{Then the    operator $L$ is of Class 1}.

\medskip


\noindent{{\bf{Remark. }} Hundreds - or rather thousands -  of 
articles have later exposed
the Bohr-Schrödinger equation with
various variants where one also regards a
time variable in 
Schrödinger's equation
\[ 
i\cdot \frac{\partial u}{\partial t}(x,y,z,t)=L(u)(x,y,z,t)
\]
In all these studies the spectral theorem
for unbounded self-adjoint operators plays a significant role.
My personal opinion is that Carleman's
original proofs superseed most of
later articles since
they are carried out in a constructive way
where the sole technical ingredients
involve Green's formula.
But it is  of course valuable to 
to give probabalistic interpretations 
of solutions since they appear naturally in the context of quantum mechanics
via the uncertainty principle.
\medskip

\noindent
{\bf{Another Schrödinger equation.}}.
In the    article 
\emph{Théorie relativiste de l'electron et l'interprétation
de la mécanique quantique} [xxx  1932.] Schrödinger
raised new and unorthodox question 
leading to  mathematical problems of considerable interest.
More precisely, consider a Brownian motion which takes place in a bounded
region $\Omega$ of some euclidian space
${\bf{R}}^d$ for some $d\geq 2$.
At time $t=0$
the densities of particles 
under observation is given by some
non\vvv negative function $f\uuu 0(x)$ 
defined on $\Omega$.
Classically the density at a later time $t>0$
is equal to
a function
$x\mapsto u(x,t)$ where
$u(x,t)$ solves the heat equation
\[
\frac{\partial u}{\partial t}= \Delta(u)
\] 
with boundary conditions 
\[
u(x,0)=f\uuu 0(x)\quad\text{and}\quad
\frac{\partial u}{\partial {\bf{n}}}(x,t)= 0
\quad\text{when }\quad x\in \partial\Omega\quad\text{and}\quad t>0\tag{1}
\]
Schrödinger took into the account
the reality of quantum physics which
means that in an  actual experiment
the observed density of particles at a time
$t\uuu 1>0$ does not coincide with $u(x,t\uuu 1)$.
He posed the problem to find the most probable development during the time
interval $[0,t\uuu 1)$ which leads to the state at time
$t\uuu 1$.
He concluded  that
the the requested density
function   which
substitutes the heat\vvv solution $u(x,t)$
should belong to a non\vvv linear class of functions formed by
products
\[ 
w(x,t)= u\uuu 0(x,t)\cdot u\uuu 1(x,t)\tag{*}
\]
where $u\uuu 0$ is a solution to (1) 
while $u\uuu 1(x,t)$ is a solution to an adjoint equation
\[
\frac{\partial u\uuu 1}{\partial t}= \vvv\Delta(u)
\quad\colon\quad
\frac{\partial u\uuu 1}{\partial {\bf{n}}}(x,t)= 0
\quad\text{on}\quad \partial\Omega\tag{2}
\] 
defined when $t<t\uuu 1$.
This leads to a new type of Cauchy problems
where one asks if there exists a  $w$\vvv function in  (*)
satisfying the initial conditions
\[ 
w(x,0)= f\uuu 0(x)\quad\colon\quad w(x,t\uuu 1)=f\uuu 1(x)
\]
when $f\uuu 0,f\uuu 1$ are non\vvv negative functions
such that
\[
\int\uuu\Omega\, f\uuu 0\cdot dx=
\int\uuu\Omega\, f\uuu 1\cdot dx
\]
\medskip

\noindent
The solvability of this non\vvv linear boundary value problem was left open
by Schrödinger and the search for  solutions remains open up to the present date.
So far the sole essential contribution is due to   Beurling in an article from 1956
whose contents is exposed in my notes about his work.
Let us remark that when  $\Omega$ is a bounded set
with a  smooth boundary, then 
one can use the Poisson\vvv Greens function for the
classical equation (*)  and 
rewrite Schrödinger's equation  to 
a system of non\vvv linear integral equations.
Examples occur already  on the product
of two copies of the real line where Schrödinger's equations lead to a
non\vvv linear equation for measures which goes as follows:
Consider the Gaussian density function
\[
g(x)=\frac{1}{\sqrt{2\pi}}\cdot e^{\vvv x^2/2}
\]

\medskip

\noindent
Next, consider the family $\mathcal S\uuu g^*$
of all non\vvv negative product measures
$\gamma\uuu 1\times\gamma\uuu 2 $ for which
\[
\iint g(x\uuu 1\vvv x\uuu 2)\cdot d\gamma\uuu 1(x\uuu 1)
\cdot d\gamma\uuu 2(x\uuu 2)=1\tag{i}
\]
The product measure gives another product measure 
\[
\mathcal T\uuu g(\gamma\uuu 1\times\gamma\uuu 2)=
\mu\uuu 1\times\mu\uuu 2
\]
where
\[
\mu\uuu 1(E\uuu 1)\cdot \mu\uuu 2(E\uuu 2)=
\iint \uuu {E\uuu 1\times E\uuu 2}\,
g(x\uuu 1\vvv x\uuu 2)\cdot d\gamma\uuu 1(x\uuu 1)
\cdot d\gamma\uuu 2(x\uuu 2)
\] 
hold for all pairs of bounded Borel sets.
Notice that $\mu\uuu 1\times \mu\uuu 2$
becomes a probability measure since (i) above holds.
With these notations one has:

\medskip

\noindent
{\bf{0.1 Theorem.}}
\emph{For every product measure
$\mu\uuu1\times\mu\uuu2$ which in addition is a probability measure there exists
a unique $\gamma\uuu 1\times\gamma\uuu 2$ in $S^*\uuu g$
such that}
\[
\mathcal T\uuu g(\gamma\uuu 1\times\gamma\uuu 2)=\mu\uuu1\times\mu\uuu2
\]
\medskip


\noindent
In [Beurling]
a more general result is established
where the  $g$\vvv function can be replaced by
an arbitrary  non\vvv negative and bounded function $k(x\uuu 1,x\uuu 2)$
such that
\[
\iint\uuu{{\bf{R}}^2}\,\log \, k\cdot dx\uuu 1dx\uuu 2>\vvv \infty
\]
At the end of his article Beurling points out that
the variational methods which he  used to achieve this result cannot be duplicated in
higher dimensions.
So Schrödinger's original set-up remains as a veritable 
challenge for the mathematical community.

\bigskip
  


\centerline {\bf{ Carleman's 
solution to
the Bohr-Schrödinger equation}}.
\medskip
  

\noindent
We expose a proof baed upon Carleman's
article  from the congress in Copenhagen 1925.
Consider the potential function
\[
W(p)=\sum\,\frac{a_\nu}{|p-\xi_\nu|}+b
\]
We seek pairs
$(\phi,\lambda)$ where $\phi\in L^2({\bf{R}}^3)$
and $\lambda$ is a real number 
such that
\[
 \Delta(\phi)+(W+\lambda)\phi=0\tag{*}
 \]
To find solutions to (*)
we  shall construct a Greens function
$G(p,q)$ defined 
in ${\bf{R}}^3\times{\bf{R}}^3$ which satisfies
\[
\Delta G+ W\cdot G-\kappa^2G=-4\pi\delta(p-q)\tag{**}
\]
where the right hand side is Dirac's delta-distribution with unit mass at $p=q$
and $\kappa$  a positive number
which will
be chosen in § xx below.
To be precise, (**) means that if 
$f$ is a test-function in ${\bf{R}}^3$ then
\[
\int\, G(p,q)\Delta(f)(q)\, dq+(W(p)-\kappa^2)\int\, G(p,q)f(q)\, dq=
-4\pi f(p)
\]
hold for each $p$.
Moreover, we will show that   $G$ 
is symmetric, i.e.
\[
G(q,p)=G(p,q)
\]
and
$G(p,q)$ yields  a kernel of a  bounded linear operator
$\mathcal G$ defined on
$L^2({\bf{R}}^3)$ by
\[
\mathcal G(g)(p)=\int\, G(p,x)g(x)\, dx
\]
\medskip

\noindent
{\bf{Solutions to (*)}}.
Suppose that $G$ has been found and let
$\phi$ be an $L^2$-function which satisfies the integral equation
\[
\phi=\frac{\lambda+\kappa^2}{4\pi}\cdot \int\, G(p,x)\phi(x)\, dx\tag{***}
\]
for some real number
$\lambda$.
Then (**) gives
\[
\Delta(\phi)=(\kappa^2-W)\phi-(\lambda+\kappa^2)\phi
\]
which entails that $\phi$ solves (*). Conversely the reader may check that
if $\phi$ solves (*) then it satisfies the integral equation above.


\bigskip



\centerline {\bf{1. The construction of $G$.}}
\bigskip


\noindent
When $\kappa>0$ we define
a function $H(p,q)$ in ${\bf{R}}^3\times{\bf{R}}^3$ by
\[
H(p.q)=\frac{e^{-|p-q|}}{|p-q|}
\]
Newton's classical formula gives
\[
\Delta(H)=\kappa^2\cdot H-4\pi\cdot \delta(p-q)\tag{i}
\]
Suppose we have found    $G(p,q)$ which satisfies
the integral equation
\[
G(p,q)=H(p,q)+\frac{1}{4\pi}\int\, H(p,x)W(x)G(x,q)\, dx\tag{ii}
\]
Then (i) entails that
\[
\Delta(G)=\kappa^2G-4\pi\delta(p-q)-W(p)G(p,q)\tag{iii}
\]
and hence  $G$ satisfies (**) above.
To show that (ii) has a solution 
we introduce the kernel function:
\[
\Omega(p,q)=H(p,q)\cdot \sqrt{W(p)}\cdot  \sqrt{W(q)}\tag{iii}
\]
Notice that $\Omega$ is everywhere positive and
$\Omega(p,q)=\Omega(q,p)$.
Close to  the diagonal $p=q$ which avoids the points
$\{(\xi_\nu,\xi_\nu)\}$
it has the same singularity as $H$, i.e.
$\frac{e^{|p-q|}}{|p-q|}$.
When both $p$ and $q$ approach the diagonal point $(\xi_1,\xi_1)$
we set $p=\xi_1+x$ amd $q=\xi_1+y$. Then
$\Omega(p,q)$ increases like
\[
\frac{1}{|x-y|\cdot |x|\cdot |y|}
\]
and the reader can check that $(x,y)\mapsto \Omega(\xi_1+x,\xi_1+y)$
is locally integrable as a function of
$(x,y)$ close to the origin in
${\bf{R}}^3\times{\bf{R}}^3$.
Moreover, the construction of the $\Omega$ in (iii) gives the equality below for every $p$:
\[
\int\, \Omega(p,x)\sqrt{W(x)}\, dx=\sqrt{W(p)}\cdot 
\int\, 
H(p,x)\cdot W(x)\, dx\tag{iv}
\]
\medskip

\noindent
{\bf{1.2. Exercise.}} Show that if 
$\kappa$  sufficiently  large then 
\[
\rho=\max_{p\in{\bf{R}}^3}\,\int\, 
H(p,x)\cdot W(x)\, dx<4\pi
\]
\medskip

\noindent
This gives
\[
\int\, \Omega(p,x)\sqrt{W(x)}\, dx\leq \rho\cdot \sqrt{W(p)}\tag{1.2.1}
\]
for all $p$.
Here $\sqrt{W}$ is a positive function
and by the general
result in § xx, (1.2.1) implies
that the  operator on $L^2({\bf{R}}^3)$ defined by
\[
g\mapsto  \int \,\Omega(p,x)g(x)\, dx
\]
has  norm $\leq \rho$.
Dividing by $4\pi$ 
the linear operator below has norm $<1$: 
\[
S(g)(p)=\frac{1}{4\pi}\cdot \int\, \Omega(p,x)g(x)\, dx\tag{1.2.2}
\] 


\noindent
{\bf{1.3 Another  integral equation.}}
Since $S$ has norm $<1$, there exists a kernel
function $L(p,q)$ which solves the equation
\[ 
L(p,q)=\frac{1}{4\pi}\cdot \int \,L(p,x)\cdot \Omega(x,q)\, dx+\Omega(p,q)\tag{1.3.1}
\]
In fact, $L$ is found by a Neumann series and
the symmetry of  $\Omega$ entails that 
$L(p,q)= L(q,p)$. Moreover,
we get a
bounded operator on
$L^2({\bf{R}}^3)$ defined by
\[
\mathcal L(g)(p)=\int\, L(p,x)g(x)\, dx
\]
To be precise, if $E$ is the identity operator on $L^2({\bf{R}}^3)$ we have
\[
\mathcal L=(E-S)^{-1}\circ S\tag{1.3.2}
\]

\medskip

\noindent
Now we put
\[ 
G(p,q)=\frac{1}{ \sqrt{W(p)}\cdot \sqrt{W(q)}}\cdot L(p,q)\tag{1.3.3}
\]
The positive constant $b$ in (0.1) gives 
\[
\frac{1}{ \sqrt{W(p)}\cdot \sqrt{W(q)}}\leq b^{-1}
\]
for all $p$ and $q$.
Since $\mathcal L$ is a bounded linear
operator it  follows that 
\[
g\mapsto \int\, G(p,x)g(x)\, dx\tag{1.3.4}
\]
also is a bounded linear operator.
At this stage we leave it to the reader to verify that
$G$ satisfies the equation (**) which
finishes the construction.
\medskip

\noindent{\bf{1.4 Spectral values.}}
There remains to find those $\lambda$ for which the integral equation
(***) has a solution.
This amounts to seek eigenvalues of the bounded
operator $\mathcal G$.
Here the spectrum of $\mathcal G$ is a discrete 
real set the origin  and the corresponding 
eigenspaces at the non-zero real eigenvalues
are finite dimensional.
However, the determination of spectral $\lambda$-values for which
(*) have non-zero $L^2$-solutions is 
a  non-trivis affair.
Here numerical
solutions are needed which
has been studied extensively in numerical analysis.

\bigskip



\noindent
{\bf{1.5 The case $L=\Delta + c(x,y,z$.}}.
We shall not give all details of the proof of
Theorem 0.2.1 but
describe a crucial  step  the proof which is used to prove that
$L$ is of Class I when $c$ satisfies the condition in the theorem.
Here is the situation.
Let $B_r$ be the open ball of radius $r$ centered at the origin
and $S^2[r]$ thr unit sphere.
The class of functions $u$  which are continuous on the closed ball
and whose interior normal derivative
$\frac{\partial u}{\partial{\bf{n}}}$ is continuous on the boundary
$S^2[r]$ is denoted by
$\mathfrak{Neu}(B_r)$. 
\medskip


\noindent
{\bf{A Neumann equation.}}
Next,
consider  a pair $a,H$ where
$a$ be a continuous function on
$S^2[r]$ and 
$H(p,q)$ a continuous hermitian function on
$S^2[r]\times S^2[r]$, i.e.  $H(q,p)=\bar H(p,q)$ hold for all pairs 
of point $p,q$ on
the sphere $ccc$. Finally, $c$ is some real-valued function in
$L^2(B_r)$.
With these notations the following hold:


\bigskip


\noindent
{\bf{1.5.1 Theorem.}} For each $f\in L^2(B_r)$ and every
non-real complex number $\lambda$ there exists a unique $u\in 
\mathfrak{Neu}(B_r)$ which 
satisfies the two equations:}
\[ 
\Delta(u)+\lambda\cdot c\cdot u=f\quad\text{holds in}\quad B_r\tag{i}
\] 
\[
\partial u/\partial {\bf{n}}(p)+a(p)u(p)+\int_{S^2[r]} \, H(p,q)u(q)\,dA(q)=0\tag{ii}
\]
 \emph{Moreover, one has the $L^2$-estimate}
\[
\int_{B_r}\, |u|^2\cdot dxdydz\leq
\bigl|\frac{1}{\mathfrak{Im}(\lambda)}\bigr|\leq
\int_{B_r}\, |f|^2\cdot dxdydz\tag{iii}
\]
\bigskip


\noindent
{\bf{Remark.}}The point is that the $L^2$-estimate 
above is independent of
the triple $a,c,H$.
The verification that the two equations (i-ii) give
(iii) follows easily via Greens formula and is left to the reader.
The fact that (i-ii) has a solution is classic and goes  back to work by
Neumann and Poincaré.

















\newpage




\centerline {\bf{Glimpses from Carleman's work.}}


\bigskip



\centerline {\emph{Contents.}}
\bigskip



\noindent
\emph{§ 0. Abel's  inversion formula.}                  
\medskip


\noindent
\emph{  §  1. An approximation theorem.                }
\medskip


\noindent
\emph{ § 2. An inequality for differentiable functions.                  }
\medskip


\noindent
\emph{§ 3. An inequality for
inverse Fourier transforms in $ L^2({\bf{R^+}})$.}
\medskip


\noindent
\emph{§ 4. The Bergman kernel. }
\medskip


\noindent
\emph{§ 5. Fourier series and  convergence of arithmetical means }
\medskip


\noindent
\emph{§ 6. An inequality for resolvents.}
\medskip


\noindent
\emph{§ 7. The Denjoy conjecture             }
\medskip


\noindent
\emph{§ 8. Approximation by fractional powers                 }
\medskip


\noindent
\emph{ § 9. Theorem of Müntz                   }
\medskip


\noindent
\emph{§ 10. Ikehara's theorem.                 }
\medskip


\noindent
\emph{§ 11. Fourier-Carleman transforms              }
\medskip


\noindent
\emph{§ 12. The generalised Fourier transform.                }
\medskip


\noindent
\emph{§ 13. The Carleman-Hardy theorem.                 }
\medskip


\noindent
\emph{§ 14. The use of  subharmonic majorizations.                 }
\medskip


\noindent
\emph{§ 15. Convergence under substitution.               }
\medskip


\noindent
\emph{§ 16. Asymptotic  series.                }
\medskip


\noindent
\emph{§ 17. Representations of rotation invariant harmonic functions.                 }
\medskip


\noindent
\emph{§ 18. Conformal maps of circular domains.                  }
\medskip


\noindent
\emph{§ 19. On spectra of compact operators.               }
\medskip


\noindent
\emph{§ 20. Eigenvalues for a class of singular operators.                   }
\medskip


\noindent
\emph{§ 21. An entire spectral function.              }
\medskip


\noindent
\emph{§ 22. Two problems in the calculus of variation.                   }
\medskip


\noindent
\emph{§ 23  Lindelöf functions.}
\bigskip


\noindent
\emph{Appendix:      Entire functions of exponential type}


\bigskip

\noindent
The subsequent sections  present material from some
of his articles devoted to analytic function theory and
Fourier analysis.
Personally I find that  few mathematical texts (if any)  superseed
Carleman's  fundamental   approach to many problems.
Several of his 
articles appear as veritable "classics"
which  merit a study  up to the present date.
The reader is expected to be familiar with basic
facts in analytic function theory of one complex variable and
some measure theory.
Apart from this the 
proofs in the subsequent sections
are self-contained, and 
for  students interested in analysis I
personally think that a detailed study of these proofs 
offer more  valuable lessons
compared to digesting "general concepts".
Before we enter
sections § 0-xx we insert a classic result to illustrate the flavour of these notes.
Readers who do not  appreciate 
the convergence theorem below 
will
probably not be prepared pursue the studies of the
subsequent material
where no "abstract concepts" appear while
most of the results require a fairly involved analysis.
\newpage




\centerline{\bf{Power series and arithmetic  means.}}

\bigskip

\noindent
Consider a power series
\[ 
f(x)=\sum\, a\uuu n\cdot x^n\tag{*}
\]
which converges when $|x|<1$ and  assume also that
\[
\lim\uuu{x\to 1}\,\sum\, a\uuu n\cdot x^n=0\tag{**}
\]
Euler's  example with
$a_\nu=(-1)^\nu$ shows that this need not entail that 
$\sum\, a_\nu$ converges with a series sum equal to zero.
So one needs extra conditions to get this convergence. 
A sufficient condtion expressed
in the  lemma  
below was
already known in special cases by
Abel, and  later  demonstrated in detail by
Riemann. For each pair of integers $p$ and $n_0$ we set
\[
J(n_0,p)= 
\int\uuu 0^1\, \frac{\sin 2p\pi(x\vvv 1)}{x\vvv 1}\cdot 
\sum\uuu{n=n\uuu 0}^\infty\, a\uuu n x^n
\cdot dx
\]

\medskip

\noindent
{\bf{The Abel-Riemann  Lemma.}}
 \emph{The series $\sum\, a\uuu n$ converges if there to every
$\epsilon>0$ exists a pair $(p\uuu 0,n\uuu 0)$ such that}
\[
p\geq p\uuu 0\implies |J(n_0,p)|<\epsilon
\]

\medskip

\noindent
{\bf{Exercise.}}
Prove this result or consult the literature.

\medskip

\noindent
{\bf{A criteron via Cesaro sums.}}
Given $f(x)$ as in (*) we get for each
$k\geq 0$ a unique sequence
$\{S\uuu n^{(k)}\colon n=0,1,\ldots\}$
such that
\[
f(x)=\frac{(1\vvv x)^{k+1}}{(k+1)!}\cdot \sum\, S\uuu n^{(k)} n^k\cdot x^n\tag{1}
\]
One has for example
\[
S\uuu n^{(1)}=\frac{na\uuu 0+(n\vvv 1)a\uuu 1+\ldots+a\uuu n}{n}
\]
while $S_n^{(0)}$ give the arithmetical means.
One refers to 
$\{S\uuu n^{(k)}$ as the Cesaro sequence of order $k$.

\medskip




\noindent
{\bf{A convergence theorem.}}\emph{ Assume (**) and that there exists some integer 
$k\geq 1$ such that}
\[
\lim\uuu{n\to\infty}\, S\uuu n^{(k)}=0
\]
\emph{Then the series $\sum\, a \uuu n$ converges.}
\medskip

\noindent
\emph{Proof}.
First the inequalities below 
hold for all pairs of positive integers $p$ and $n$:
\[
\bigl|\, \int\uuu 0^1\, \sin (2p\pi x)\cdot x^k(1\vvv x)^n
\cdot dx\,\bigr|\leq 2\pi(k+2)\,!\cdot\frac{p}{n^{k+2}}\tag{i}
\]
\[
\bigl|\, \int\uuu 0^1\, \sin 2p\pi x\cdot x^k(1\vvv x)^n
\cdot dx\,\bigr|\leq \frac{C(k)}{p\cdot n^k}\tag{ii}
\]
where the constant $C(k)$ in (ii)  only depends upon $k$.
The verification of (i\vvv ii) is left to the reader.
Next, let $\epsilon>0$. The hypothesis in the theorem gives
some $n\uuu 0$ such that
\[ 
n\geq n\uuu 0\implies |S\uuu n^{(k)}|<\epsilon\tag{iii}
\]
Next, from (1) it follows that
\[
\sum\uuu{n=n\uuu 0}^\infty\, a\uuu n x^n=
\frac{(1\vvv x)^{k+1}}{(k+1)!}\cdot \sum\uuu{n=n\uuu 0}^\infty
\, S\uuu n^{(k)} n^k\cdot x^n+Q(x)\tag{iv}
\]
where $Q(x)$ is a polynomial of degree
$n_0+k$ at most.
Then   (iii-iv) and the triangle inequality give
\[
|J(n_0,p)|\leq
\epsilon\cdot 
\sum\uuu{n=n\uuu 0}^\infty
\frac{n^k}{(k+1)!}\cdot
\bigl|\,
\int\uuu 0^1\, \sin (2p\pi x)\cdot x^k(x\vvv 1)^n
\cdot dx\,\bigr|+
\bigl|\int\uuu 0^1\, \frac{\sin 2p\pi(x\vvv 1)}{x\vvv 1}\cdot Q(x)\, dx\bigr|
\tag{v}
\]
For an arbitrary $p\geq 
n\uuu 0+1$
we decompose the sum in the first term above
from $n\uuu 0$ up to $p$ and
after we take a sum with $n\geq p+1$. Hence this first term
is majorized by the sum of the following two expressions:
\[
\sum\uuu{n=n\uuu 0}^{n=p}
\frac{n^k}{(k+1)!}\cdot
\bigl|\,
\int\uuu 0^1\, \sin (2p\pi x)\cdot x^k(x\vvv 1)^n
\cdot dx\,\bigr|\tag{vi}
\]
\[
\sum\uuu{n=p+1}^\infty
\frac{n^k}{(k+1)!}\cdot
\bigl|\,
\int\uuu 0^1\, \sin (2p\pi x)\cdot x^k(x\vvv 1)^n
\cdot dx\,\bigr|\tag{vii}
\]

\noindent
Using (i) above it follows that (vi) is estimated by

\[
2\pi\cdot (k+2) !\cdot \frac{C(k)}{p}\cdot (p\vvv n\uuu 0)
\leq 2\pi\cdot (k+2) !\cdot C(k)=K\uuu 1
\]
Next, using (ii) it follows that (vii) is estimated by

\[
\pi\cdot \frac{k+2}{k+1}\cdot p\cdot \sum\uuu{n=p+1}^\infty n^{\vvv 2}
\leq\pi\cdot \frac{k+2}{k+1}=K\uuu 2
\]
So with $K=K\uuu 1+K\uuu 2$ we obtain from (iv)
\[ 
|J(n\uuu 0,p)|\leq 2K\cdot \epsilon+
\bigl|\int\uuu 0^1\, \frac{\sin 2p\pi(x\vvv 1)}{x\vvv 1}\cdot Q(x)\, dx\bigr|\tag{viii}
\] 
Here (viii) hold for every $p\geq n\uuu 0+1$.
Since $Q(x)$ is a polynomial of degree $\leq n_0+k$ it follows from
the Riemann-Lebegue Lemma that the last term in
(viii)
tends to zero when $p$ increases. Hence we can find
$p_0$ such that 
\[
p\geq p_0\implies |J(n\uuu 0,p)|\leq 2K\cdot \epsilon+
\]
Since $\epsilon$ can be arbitrary
small the condition in
the Abel-Riemann Lemma  holds and
the proof  is finished.

\newpage


\newpage

\centerline {\bf{§ 0. Abel's  inversion formula.}}
\bigskip

\noindent
In the article \emph{xxx} from 1823,
Niels Henrik  Abel established  an inversion formula for
the potential function
$U(x)$
in a conservative field of forces which goes as follows:
\medskip

\noindent
Let $U(x)$ be an even function of
$x$ with $U(0)=0$ and $x\to U(x)$ is strictly increasing and convex
on $x\geq 0$.
A particle of unit mass which moves on
the real $x$-line satisfies Newton's equation
\[
\ddot x(t)=-U'(x(t))
\] 
where the initial conditions are $x(0)=0$ and $\dot x(0)= v>0$.
It follows that
\[
\frac{\dot x(t)^2}{2}+U(x(t))= \frac{v^2}{2}\implies
\]
\[
\dot x(t)=\sqrt{v^2-2U(x(t))}\tag{1}
\]
during a time interval $[0,T]$ where $\dot  x(t)>0$
when $0\leq t<T$ and
$\dot  x(T)=0$.
From (1) we get the equation
\[
T=\int_0^{x(T)}\, \frac{dx}{\sqrt{v^2-2U(x)}}\quad\colon\, 2\cdot U(x(T))=v^2
\]

\noindent
Abel's  inversion formula
recaptures $U$ when the function
$v\mapsto T(v)$ is known.
For suppose that $v\mapsto T(v)$ is given on an interval $0\leq v\leq v^*$.







\bigskip

\noindent
In the article \emph{Abelsche Intergalgleichung mot konstanten
Integralgrenzen}
[Mathematische Zeitschrift 1922], Carleman established
inversion formulas in Abel's spirit.
An example is as follows:
For every fixed real $0\leq x\leq 1$ 
\[ 
t\mapsto \log\,|x-t|
\]
is integrable on the unit interval $[0,1]$ and 
yields a bounded linear operator 
on the  Banach space $C^0[0,1]$
sending
every
$g\in C^0[0,1]$ to 
\[ 
T_g(x)= \int_0^1\, \log\,|x-t|\cdot g(t)\, dt
\]
It is not difficult to show that $T_g$ is injective. Moreover there
is 
an inversion formula  which
at the same time gives
a description of its range.
\medskip

\noindent
{\bf{0.1 Theorem.}}
\emph{With $f=T_g$
one has the inversion formula}
\[
\sqrt{x(1-x)}\cdot g(x)= \frac{1}{\pi^2}\cdot
\int_0^1\, 
\frac{f'(t)\cdot \sqrt{t(1-t)}}{x-t}\,dt+\frac{1}{\pi}\cdot \int_0^1\,g(t)\, dt\tag{*}
\]
\emph{Moreover one has the equation}
\[
\int_0^1\,g(t)\, dt=-\frac{1}{2\pi\cdot \log 2}\cdot
\int_0^1\, \frac{f(x)}{\sqrt{(1-x)x}}\, dx\tag{**}
\]

\medskip

\noindent
{\bf{Remark.}}
This  inversion formula shows that 
a function 
$f$ in the range of $T$ must satisfy certain regularity properties. The reason is that 
in (*) the first order derivative $f'(t)$ appears in an integral where we 
have taken a principal value. Before we enter the proof we recall
how one should grasp principal values.
In general, let $h(t)$ be a contionuous funvtionon
$[0,1]$.
In ${\bf{C}}|setminus [0,1]$ there exists the analytic function
\[
H(z)=\int_0^1\, \frac{h(t)}{z-t}\, dt
\]
With $\epsilon>0$ we consider the difference
\[
H(x+i\epsilon)-H(x-i\epsilon)=
\int_0^1\, \frac{h(t)}{z-t}\, dt=
-2i\epsilon\int_0^1\, \frac{h(t)}{(x-t)^2+\epsilon^2}\, dt
\]
For each $0<t<1$ the reader can check that
the limit of the right hand side as $\epsilon\to 0$
besomes $-2\pi i\cdot h(t)$. This
\[A con
\lim_{\epsilon\to 0}\, H(x+i\epsilon)-H(x-i\epsilon)=
-2\pi i\cdot h(t)
\]
Next, we have
\[
H(x+i\epsilon)+H(x-i\epsilon)=2\cdot \int_0^1\, \frac{x-t}{(x-t)^2+\epsilon^2}
\cdot h(t)\, dt\tag{i}
\]
When $0<x<1$ it is not always true that
the right hand side has a limit as $\epsilon\to 0$.
A counterexample os to take $h=0$ when $t\leq x$
while $h(t)=(\log(t-x))^{-1}$ when $t>x$.
Moreover, from cacluus one learns that
(i) has a limit at $x$ if and only if there exists
the limit
\[
\lim_{\epsilon\to 0}\, \int_0^{x-\epsilon }\,\frac{h(t)}{x-t}\, dt+
\int_{x+\epsilon}^1\,\frac{h(t)}{x-t}\, dt
\]
and when the latter limit exists one refers to a principal  value and writes
\[
\text{PV}\, 
\int_0^1\,\frac{h(t)}{x-t}\, dt
\]
Let us remark that this principal value exists for all $x$ when 
$h$ is a $C^1$-function on $[0,1]$.


\bigskip


\centerline{\emph{Proof of Theorem 0.1}}
\medskip

\noindent
The
complex log-function 
\[
z\mapsto \log\,( z-t)
\]
is defined when
$z\in {\bf{C}}\setminus (-\infty,1]$
for each $0\leq t\leq 1$. 
The single-valued branches are chosen so that
the argument of these  log-functions stay in $(-\pi,\pi)$
and  $\log x-t$ is real if $x>t$. It follows that
\[
\lim_{\epsilon\to 0}\, \log (x+i\epsilon-t)=
 \log |x-t|+ \pi i\quad\colon x<t\tag{1}
 \]
where  the limit is taken as $\epsilon>0$ decrease to zero.
Let $g(t)$ be a continuous function on $[0,1]$ and
put
\[
 G(z)= \int_0^1\, \log(z-t)\cdot g(t)\, dt\tag{2}
\]
\medskip

\noindent
{\bf{A. Exercise.}} Show that  (1) gives:
\[
G(x+i0)=T_g(x)+\pi i\cdot \int_x^1\, g(t)\,dt \quad\colon 0< x<1\tag{i}
\]
where $G(x+i0)$ is the limit as $z=x+i\epsilon$ and $\epsilon>0$
decrease to zero.
Show in a similar way that
\[
G(x-i0)=T_g(x)-\pi i\cdot \int_x^1\, g(t)\,dt \quad\colon 0< x<1\tag{ii}
\]
\medskip

\noindent
Next, outside $[0,1]$
the complex derivative of $G$ becomes
\[ 
G'(z)=
\int_0^1\, \frac{g(t)}{z-t}\, dt
\]
Then (i-ii) give
\[
G'(x+i0)+G'(x-i0)= 2\cdot \frac{T_g(x)}{dx}
\quad\colon
\quad
G'(x+i0)-G'(x-i0)=-2\pi \cdot g(x)\tag{iii}
\]
\medskip


\noindent
{\bf{B. The $\Phi$-function.}}
In ${\bf{C}}\setminus [0,1]$ we have
the analytic function $h(z)=\sqrt{z(z-1)}$
whose branch is chosen so that it is real and positive when
$z=x>1$. It follows that
\[
h(x+i0)=i\cdot \sqrt{x(1-x)}\quad\colon\quad
h(x-i0)=i\cdot \sqrt{x(1-x)}\quad\colon 0< x< 1 \tag{b.1}
\]
Consider the analytic function
\[
\Phi(z)=\sqrt{z(z-1)}\cdot G'(z)
\]
With $f=T_g$ we see
that (iii-iv) give the two equations

\[
\Phi(x+i0)+\Phi(x-i0)=2\pi\cdot \sqrt{x(1-x)}\cdot g(x)\tag{b.2}
\]
\[
\Phi(x+i0)-\Phi(x-i0)=2i\cdot f'(x)\cdot \sqrt{x(1-x)}\tag{b.3}
\]

\noindent
{\bf{C. The $\Psi$-function.}}
Set
\[
\Psi(z)=\int_0^1\, \frac{1}{z-t}\cdot
f'(t)\cdot \sqrt{t(1-t)}\,dt\tag{c.1}
\]
The equation (b.3)  and the general formula from § XX give
\[
\Phi(x+i0)-\Phi(x-i0)=\Psi(x+i0)-\Psi(x-i0)\quad\colon\, 0<x<1\tag{c.2}
\]
\medskip

\noindent
{\bf{D. Exercise.}}
Deduce from (c.2) that
\[ 
\Phi(z)= \Psi(z)+\int_0^1\,g(t)\, dt
\]
where the equality holds when
$z\in{\bf{C}}\setminus (-\infty,1]$.
Conclude from
the above that 
\[
2\pi\cdot \sqrt{x(1-x)}\cdot g(x)=\Psi(x+i0)+\Psi(x-i0)+2\cdot \int_0^1\,g(t)\, dt\tag{d.1}
\]
\medskip

\noindent
Next, from (c.1 ) and the general formula in § XX we have

\[
\Psi(x+i0)+\Psi(x-i0)=\frac{2}{\pi}\cdot 
\int_0^1\, 
\frac{f'(t)\cdot \sqrt{t(1-t)}}{x-t}\,dt\tag{d.2}
\]
where the last integral is taken as a principal value.
Together  (d.1-2)  give (*) in  Theorem 0.1.









\newpage



\centerline{\bf{§ 1. An approximation theorem.}}
\bigskip


\noindent
The result below was proved in
the article \emph{Sur un théorème de Weierstrass}
[Arkiv för mathematik och fysik. vol 20 (1927]:
\medskip

\noindent
{\bf{Theorem.}}
\emph{Let $f$ be a continuous and complex valued function on
the real $x$-line. To each $\epsilon>0$ there exists an
entire function $\phi(z)= \phi(x+iy)$
such that}
\[ 
\max_{x\in{\bf{R}}}\, |f(x)-\phi(x)|<\epsilon
\]



\medskip

\noindent
In the cited article Carleman gave an 
 elementary proof using Cauchys integral formula. 
His constructions can be extended to 
cover a more general situation which goes as follows.
Let $K$ be an unbounded  closed null\vvv set in ${\bf{C}}$.
If $0<R<R^*$ we put
\[
K[R,R^*]= K\cap \{ R\leq |z|\leq R^*\}
\]
and if  $R>0$ 
we put
$K\uuu R= K\cap \bar D\uuu R$ where
$\bar D\uuu R=\{|z|\leq R\}$.

\medskip

\noindent
{\bf{1.1 Theorem.}}
\emph{Suppose  there exists a strictly increasing sequence $\{R\uuu\nu\}$
where $R\uuu\nu\to +\infty$ such that 
${\bf{C}}\setminus K\uuu{R\uuu 1}$ and the sets}
\[ 
\Omega\uuu\nu={\bf{C}}\setminus \bar D\uuu {R\uuu \nu}\,\cup K[R\uuu\nu,
R\uuu{\nu+1}]
\] 
\emph{are connected for each $\nu\geq 1$.
Then every continuous function on $K$ can be uniformly approximated by entire functions.}
\bigskip


\noindent
To prove this result we first establish the following.

\medskip

\noindent {\bf{1.2 Lemma.}}
\emph{Consider some $\nu\geq 1$
a continuous function
$\psi$  on 
$S= \bar D\uuu{R\uuu n}\cup\, K[R\uuu \nu,R\uuu{\nu+1}]$
where $\psi$ is analytic in the open disc $D\uuu{R\uuu\nu}$.
Then $\psi$ can be uniformly approximated on $S$ by polynomials in $z$.}

\medskip

\noindent 
\emph{Proof}.
If 
we have found a sequence of polynomials
$\{p\uuu k\}$ which approximate $\psi$ uniformly on
$S\uuu *=\{|z|=R\uuu\nu\}\cup K[R\uuu \nu,R\uuu{\nu+1}]$
then this sequence approximates $\psi$ on $S$. In fact, this follows since
$\psi$ is analytic in the disc $D\uuu{R\uuu \nu}$
so by the maximum principle for analytic functions in a disc
we have
\[
||p\uuu k\vvv\psi||\uuu S=
||p\uuu k\vvv\psi||\uuu {S\uuu *}
\] 
for each $k$.
Next, if uniform approximation on $S\uuu *$ fails
there exists a Riesz\vvv measure $\mu$ supported by
$S\uuu *$ which is $\perp$ to all analytic polynomials while
\[
\int\, \psi\cdot d\mu\neq 0\tag{1}
\]
To see that this cannot occur we consider the Cauchy transform
\[
\mathcal C(z)=\int\, \frac{d\mu(\zeta)}{z\vvv\zeta}
\]
Since $\int\, \zeta^n\cdot d\mu(\zeta)=0$ for every $n\geq 0$
we see that $\mathcal C(z)=0$ in the exterior disc
$|z|> R\uuu{\nu+1}$.
The connectivity hypothesis implies that
$\mathcal C(z)=0$ in the whole open complement of $S$.
Now $K$ was a null set which means that the
$L^1\uuu{\text{loc}}$\vvv function 
$\mathcal C(z)$ is zero in the exterior disc
$|z|>R\uuu\nu$ and hence its distribution derivative
$\bar\partial(\mathcal C\uuu\nu)$ also vanishes in this exterior disc.
At the same time we have the equality
\[ \bar\partial(C\uuu\nu)= \mu
\]
We conclude that the support of $\mu$ is confined to the circle
$\{|z|=R\uuu\nu\}$.
But then (1) cannot hold since
the restriction of $\psi$ to
this circle by assumption extends to be analytic in the disc
$D\uuu {R\uuu\nu}$ and therefore can be uniformly approximated by
polynomials on the circle.

\medskip

\noindent
\emph{Proof of Theorem 1.1}
Let $\epsilon>0$ and
$\{\alpha\uuu \nu\}$ is a sequence of positive numbers such that
$\sum\,\alpha\uuu\nu<\epsilon$.
Consider some $f\in C^0(K)$. Starting with the set
$K\uuu{R\uuu 1}$
we use the assumption that its complement is connected
and using   Cauchy transforms as in  Lemma 1.2
one shows that the restriction of $f$ to this compact set
can be uniformly approximated by polynomials. So we find
$P\uuu 1(z)$ such that
\[
||P\uuu 1\vvv f||\uuu {K\uuu{R\uuu 1}}<\alpha\uuu 1\tag{i}
\]
From (i) one easily construct a continuous function
$\psi$ on $\bar D\uuu{R\uuu 1}\cup K[R\uuu 1,R\uuu 2]$
such that
$\psi=P\uuu1 $ holds in the disc
$\bar D\uuu{R\uuu 1}$ and
the maximum norm
\[
||\psi\vvv f||\uuu { K[R\uuu 1,R\uuu 2]}\leq \alpha\uuu 1
\]
Lemma 1.2 gives a polynomial $P\uuu 2$ such that
\[
||P\uuu 2\vvv P\uuu 1||\uuu {D\uuu{R\uuu 1}}<\alpha\uuu 2
\quad\text{and}\quad 
||P\uuu 2\vvv f||\uuu {K[R\uuu 1,R\uuu 2]}\leq
\alpha\uuu 1+\alpha\uuu 2
\]
Repeat the construction where Lemma 1.2 is used as $\nu$ increases.
This gives
a sequence of polynomials $\{P\uuu\nu\}$
such that
\[
||P\uuu \nu \vvv P\uuu {\nu\vvv 1}||\uuu {D\uuu{R\uuu \nu }}<\alpha\uuu \nu
\quad\text{and}\quad 
||P\uuu\nu\vvv f||\uuu {K[R\uuu {\nu\vvv 1},R\uuu \nu]}<
\alpha\uuu 1+\ldots+\alpha\uuu\nu
\]
hold for all $\nu$.
From this it is easily seen that we obtain an entire function
\[ 
P^*(z)= P\uuu 1(z)+\sum\uuu{\nu=1}^\infty
P\uuu{\nu+1}(z)\vvv P\uuu\nu(z)
\]
Finally the reader can check that the inequalities above imply that
the maximum norm
\[
 ||P^*\vvv f||\uuu K\leq \alpha\uuu 1+ \sum\uuu{\nu=1}^\infty\,\alpha\uuu\nu
\]
Since the last sum is $\leq 2\epsilon$ and $\epsilon>0$ was arbitrary
we have proved Theorem 1.1

 
\bigskip




\noindent
{\bf 1.3 Exercise.}
Use similar methods as above to show that if
$f(z)$ is analytic in the upper half plane
$U^+=\mathfrak{Im}(z)>0$
and has continuous boundary values on the real line, then
$f$ can be uniformly approximated by an entire function, i.e. to
every $\epsilon>0$ there exists an entire function
$F(z)$ such that
\[
\max_{z\in U^+}\, |F(z)-f(z)|\leq\epsilon
\]

\newpage


\centerline {\bf{2. An inequality for differentiable functions.}}
\bigskip

\noindent
A fundamental result 
was proved by Carleman in 
the article \emph{Sur un théorème de M. Denjoy}
[C.R. Acad. Sci. Paris 1922]

\medskip

\noindent
{\bf{2.1 Theorem.}}
\emph{There exists an absolute constant $\mathcal C$
such that the inequality below holds
for every pair $(f,n)$, where $n$ is a positive integer
and $f$
a non-negative real-valued $C^\infty$- function 
defined on  the closed unit interval $[0,1]$
whose  derivatives up to order $n$ vanish at the
two end points.}
\[
\sum_{\nu=1}^{\nu=n}\,
\,\frac{1}{[\beta_\nu]^{\frac{1}{\nu}}}\leq
\mathcal C\cdot\int_0^1\,f(x)dx\quad\colon\quad
\beta_\nu=\sqrt{\int_0^1\, [f^{(\nu)}(x)]^2\cdot dx}\tag{*}
\]

\noindent
{\bf{Remark.}}
The proof below shows that one can take
\[ 
C\leq 2e\pi\cdot  (1+
\frac{1}{4\pi^2 e^2-1})\tag{*}
\]
The best constant $\mathcal C_*$ which would give
\[
\sum_{p=1}^{p=n}\,
\frac{1}{\beta_p(f)}\leq\mathcal C^*\tag{i}
\]
for all $n$ and every $f\in\mathcal S_n$ is not known.
Let us also remark that 
the inequality (*)
is sharp in the sense that there exists a constant $C_*$
such that  for every $n\geq 2$ there exists a 
function $f_n(x)$ as above so that 
the opposed inequality
(*) holds with $C_*$. Hence
(*) 
demonstrates
that the standard cut-off  functions which are used
in  many applications 
to keep maximum norms of derivatives small up to
order $n$ small, are optimal up to a constant.
So the theoretical result in (*)
plays 
a role in numerical analysis where one often uses smoothing
methods.
The  proof  of (*) 
employs
estimates for harmonic measures
applied to the subharmonic Log-function of the absolute value of the
Laplace transform of $f$, i.e. via a "detour into the complex domain"
which in 1922 appeared as a  "revolutionary method".

\bigskip
 
\centerline{\emph{Proof of Theorem 2.1}.}
\medskip


\noindent
Let $n\geq 1$ and 
keeping $f$ fixed we put $\beta_p=\beta_p(f)$
to simplify notations. 
Using partial integrations and the Cauchy-Schwarz inequality 
one shows that the
$\beta$-numbers are non-decreasing. i.e. 
\[ 
1=\beta_0\leq\beta_1\leq \ldots\leq \beta_n\tag{*}
\]
Define the complex Laplace transform
\[ 
\Phi(z)=\int_0^1\, e^{-zt}f(t) dt
\]
Since $f$ by assumption is $n$-flat at the end-ponts, 
integration by parts $p$ times  gives:
\[
 \Phi(z)=z^{-p}\int_0^1\, e^{-zt}\cdot \partial^p(f^2)(t) dt\quad\colon\quad 1\leq p\leq n+1
\]
where
$\partial^p(f^2)$ is the derivative of order $p$ of $f^2$.
We have
\[
\partial^p(f^2)=\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}\cdot
f^{(\nu)}\cdot f^{(p-\nu)}\quad\colon\,
1\leq p\leq n+1 \tag{1}
\]
Now we  study the absolute value of $\Phi$ on the vertical
line $\mathfrak{Re}(z)=-1$. 
Since $|e^{t-iyt}|= e^t$
for all $y$, the triangle inequality gives
\[ 
|-1+iy|^p\cdot |\Phi(-1+iy)|\leq
\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}\cdot
\int_0^1\, e^t\cdot |f^{(\nu)}(t)|\cdot |f^{(p-\nu)}(t)|\cdot dt\tag{2}
\]
Since  $e^t\leq e$ on $[0,1]$, the 
Cauchy-Schwarz inequality and 
the definition of the $\beta$-numbers give:
\[
|-1+iy|^p\cdot |\Phi(-1+iy)|\leq e\cdot 
\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}\cdot
\beta_\nu^\nu\cdot \beta_{p-\nu}^{p-\nu}\tag{3}
\]
From (*) it follows that
$\beta_\nu^\nu\cdot \beta_{p-\nu}^{p-\nu}\leq \beta_p^p$
for each $\nu$ and since
$\sum_{\nu=0}^{\nu=p}\, \binom  {p}{\nu}=2^p$ we obtain
\[
|-1+iy|^p\cdot |\Phi(-1+iy)|\leq e\cdot 2^p\cdot \beta_p^p\tag{4}
\]
Passing to the logarithm we get
\[
\log\, |\Phi(-1+iy)|\leq 1+p\cdot \log\,\frac{2\beta_p}{|-1+iy|}\tag{5}
\]
Here (5) holds when $1\leq p\leq n+1$ and 
the assumption that $\beta_0=1$ also gives
\[
\log\, |\Phi(-1+iy)|\leq 1\tag{6}
\]

\noindent
{\bf{The $\omega$-function}}.
To each $1\leq p\leq n+1$
we find a positve number $y_p$ such that
\[
|-1+iy_p|=2e\beta_p
\]
Now we define a function $\omega(y)$ where
$\omega(y)=0$ when $y<y_1$ and
\[
\omega(y)=p\quad\colon\quad y_p\leq y<y_{p+1}
\]
and finally $\omega(y)=n+1$ when $y\geq y_{n+1}$.
Then (5-6) give
the inequality
\[
\log\,|\phi(-1+iy)|\leq 1-\omega(y)
\quad\colon\,-\infty<y<+\infty
\tag{7}
\]

\medskip

\noindent
\emph { A harmonic majorisation.}
With $1-\omega(y)$ as boundary function in the half-plane
$\mathfrak{Re}(z)>-1$
we construct the harmonic extension $H(z)$
which by
Poisson's formula is given by:
\[ 
H(0)=
\frac{1}{\pi}\int_{-\infty}^\infty\, \frac{1-\omega(y)}{1+y^2}\cdot dy
\]
Now  $\log\,|\Phi(z)|$ is subharmonic in this half-plane and hence
(7) gives:
\[
0=\log|\Phi(0)|\leq H(0)
\]
We conclude that
\[
\int_{-\infty}^\infty\, \frac{\omega(y)}{1+y^2}\cdot dy
\leq \pi\tag{8}
\]
Since  $\omega(y)=0$ when $y\leq y_1$ we see that
(8) gives the inequality
\[
\int_{y_1}^\infty\, \frac{\omega(y)}{y^2}\cdot dy
\leq \frac{y_1^2}{1+y_1^2}\cdot \pi\tag{9}
\]
The construction of the $\omega$-function gives the equation 
\[
\int_{y_1}^\infty\, \frac{\omega(y)}{y^2}\cdot dy
=\frac{1}{y_1}+\ldots+\frac{1}{y_{n+1}}\tag{10}
\]
\medskip

\noindent
Next, the construction of the $y_p$-numbers entail that
$y_p\leq 2e\beta_p$ so (9-10) 
give
\[
\frac{1}{\beta_1}+\ldots+\frac{1}{\beta_{n+1}}\leq
2e\pi\cdot  
\frac{1}{1+\frac{1}{y_1^2}}\tag{11}
\]

\noindent
Finally, we have $1+y_1^2=4e^2\beta_1^2$ and 
recall that Wirtinger's inequality gives
$\beta_1\geq \pi$. Hence
\[
\frac{1}{1+\frac{1}{y_1^2}}\leq
1+\frac{1}{4\pi^2e^2-1}\tag{12}
\]
and then (11-12) give the requested inequality in Theorem 2.1.
\bigskip












\newpage

\centerline {\bf {§ 3. An inequality for
inverse Fourier transforms in $ L^2({\bf{R^+}})$.}}
\medskip

\noindent 
By Parsevel's theorem the Fourier transform sends $L^2$-functions 
on the real $\xi$-line to $L^2$-functions on the $x$-line.
We seek the class of non-negative $L^2$-functions $\phi(x)$
such that there exists
an $L^2$-function $F(\xi)$ supported by the half-line  $\xi\geq 0$ and
\[ 
\phi(x)=\bigl|\,\int_0^ \infty\,
e^{ix\xi}\cdot F(\xi)\cdot d\xi\bigr|\tag{*}
\]


\noindent
The theorem  below was proved in [Carleman] which 
apart from  applications  to 
quasi-analytic functions    has several
other consequences which are put forward by
Paley and Wiener in their text-book
[Pa-Wi]. 

\bigskip



\noindent
{\bf 3.1 Theorem. } \emph{An $L^2$-function $\phi(x)$ is of the form
(*) if and only if}
\[
\int_{-\infty}^\infty\, \log^+\bigl [\,\frac{1}{\phi(x)}\,\bigr ]
\cdot \frac{dx}{1+x^2}<\infty\tag{i}
\]
\emph{Moreover, when (*) holds and
$F(\xi)$ satisfies the 
weighted mean-value equality}
\[ 
\int_0^\infty\, F(\xi)\cdot e^{-\xi}\ d\xi=1\tag{ii}
\]
then 
\[
\int_{-\infty}^\infty\, \log^+\bigl [\,\frac{1}{\phi(x)}\,\bigr ]
\cdot \frac{dx}{1+x^2}\leq 
\int_{-\infty}^\infty\, \frac{\phi(x)^2}{1+x^2}\cdot dx\tag{iii}
\]
\medskip

\noindent
\emph{Proof.}
First we prove the suffiency.
Let  $\phi(x)$ be  a non-negative  $L^2$-function where the  integral  
(i)  is finite.
The harmonic extension of
$\log\,\phi(x)$ to the upper half-plane is given by:
\[
\lambda(x+iy)=\frac{y}{\pi}\cdot 
\int_{-\infty}^\infty\, \frac{\log\,\,\phi(t)}{(x-t)^2+y^2}\cdot dt
\quad\colon\, y>0\tag{1}
\]


\noindent Let $\mu(z)$ be the conjugate harmonic function of
$\lambda$ and set
\[
h(z)=e^{\lambda(z)+i\mu(z)}\tag{2}
\]


\noindent
Fatou's theorem gives  for almost every $x$ 
a limit
\[
\lim_{y\to 0}\,\lambda(x+iy)=\log\,\,\phi(x)\tag{3}
\]
Or, equivalently
\[
\lim_{y\to 0}\,|h(x+iy)|=\phi(x)\tag{4}
\]


\noindent
From (1) and the fact that the geometric mean value of positive numbers
cannot exceed their arithmetic mean value, one has
\[
\bigl |h(x+iy)\,\bigr |= e^{\lambda(x+iy)}\leq\frac{y}{\pi}\cdot
\int_{-\infty}^\infty\, \frac{\phi(t)}{(x-t)^2+y^2}\cdot dt
\quad\colon\, y>0\tag{5}
\]


\noindent
Then (5) the Schwarz inequality give:
\[
\int_{-\infty}^\infty\, \bigl |h(x+iy)\,\bigr |^2\,dx\leq
\int_{-\infty}^\infty\, \bigl |\phi(x)\,\bigr |^2\,dx\quad\colon\, y>0\tag{6}
\]
Here  $h(z)$ is analytic in the upper half-plane
so that (6) and Cauchy's formula entail that
if $\xi<0$, then the integrals
\[
 J(y)=
\int_{-\infty}^\infty\, h(x+iy)\cdot e^{-ix\xi+y\xi}\cdot dx\quad\colon\ y>0\tag{7}
\]
are independent of $y$. Passing to the limit as $y\to\infty$ and 
using the uniform upper bounds on the $L^2$-norms of 
the functions $h_y(x)\mapsto h(x+iy)$,
it follows that $J(y)$ vanishes identically.
So the Fourier transforms of
$h_y(x)$ are supported by $\xi\geq 0$ for all $y>0$.
Passing to the limit as $y\to 0$ the same holds for
the Fourier transform of $h(x)$. Finally (4) gives
\[
\phi(x)=|h(x)|\tag{8}
\]
By Parseval's theorem
$\widehat h(\xi)$ is an $L^2$-function and hence
$\phi(x)$ has  the requested form (*).


\medskip







\noindent
{\emph{Necessity.}
Since $F$ is in $L^2$ there exists the Plancherel limit
\[ 
\psi(x)=\lim_{N\to\infty}
\,\frac{1}{2\pi}\cdot\int_0^N\,
e^{ix\xi}\cdot F(\xi)\, d\xi\,\tag{9}
\]
and in
the upper half plane we  get the analytic function
\[ 
\psi(x+iy)=
\,\frac{1}{2\pi}\cdot\int_0^\infty\,
e^{ix\xi -y\xi}\cdot F(\xi)\, d\xi\tag{10}
\]



\noindent
Suppose that  $F(\xi)$ satisfies (ii) in the  Theorem which gives
\[ 
\psi(i)=1
\]
Consider the conformal map from the upper half-plane into the unit disc where
\[ 
w=\frac{z-i}{z+i}
\]
Here  $\psi(x)$ corresponds to a function
$\Phi(e^{is})$ on the unit circe $|w|=1$ and:
\[ 
\int_{-\pi}^\pi\, |\Phi(e^{is})|^2 \, ds=
2\cdot\int_{-\infty}^\infty\,\frac{|\phi(x)|^2}{1+x^2}\, dx\tag{11}
\]


\noindent
Similarly let $\Psi(w)$ be the analytic function in
$|w|<1$ which corresponds to $\psi(z)$. From (10-11)  it follows that
$\Psi(w)$ is the Poisson extension of $\Phi$, i.e.
\[ 
\Psi(w)=
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \,\frac{1-|w|^2}{
|e^{is}-w|^2}\cdot \Phi(e^{is})\cdot ds\tag{12}
\]
If $0<r<1$ it follows that
\[
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \log^+\,|\Psi(re^{is}|\cdot ds\leq
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \bigl |\Psi(re^{is}\bigr |^2\cdot ds\leq
\frac{1}{2\pi}\
\int_{-\pi}^\pi\, \Phi(e^{is}|^2\cdot ds\tag{13}
\]


\noindent 
Now  (12) gives:
\[
\lim_{r\to 1}\,\Psi(re^{is})=\Phi(e^{is})\quad\colon\,
\text{almost everywhere}\quad 0\leq s\leq 2\pi\tag{14}
\]


\noindent 
Next, since
$\psi(i)=1$ we have  $\Psi(0)=1$ which
gives the inequality
\[
\int_{-\pi}^\pi\, \log^+\frac{1}{\,|\Psi(re^{is}|}\cdot ds\leq
\int_{-\pi}^\pi\, \log^+\,|\Psi(re^{is}|\cdot ds\quad\colon 0<r<1\tag{15}
\]


\noindent
By (13-15) a passage to the limit as $r\to 1$ gives
\[
\int_{-\pi}^\pi\, \log^+\frac{1}{\,|\Phi(e^{is}|}\cdot ds\leq
\int_{-\pi}^\pi\, \bigl |\,\Phi(e^{is}\bigr |^2\cdot ds\tag{16}
\]
\medskip

\noindent
Returning to the real $x$-line  the inequality (iii) follows 
which at the same time finishes the proof of the theorem.







\newpage


\centerline {\bf{§ 4. The Bergman kernel.}}
\medskip

\noindent
Let $\Omega$ be a bounded and simply
connected domain in ${\bf{C}}$.
If $a\in\Omega$ a famous result due to Stefan Bergman
gives  the conformal mapping
function $f_a\colon \Omega\to D$
via the kernel function of the Hilbert space
$H^2(\Omega)$.
\medskip

\noindent
{\bf{A. Bergman's  Theorem.}}
\emph{The conformal map $f_a$ is given by}
\[ 
f_a(z)= \sqrt{\frac{\pi}{K(a,a)}}
\cdot \int_a^z\, K(z,a)\, dz
\]
\medskip

\noindent
Next, the  Gram-Schmidt construction gives
an orthonormal basis $\{P_n(z)\}$
in $H^2(\Omega)$
where  $P_n$ has degree $n$ and
\[ 
\iint_\Omega \, P_k\cdot \bar P_m\cdot dxdy=
\text{Kronecker's delta function}
\]
From Bergman's result  one
expects that these polynomials are related to
a conformal mapping function.
We shall consider the case
when
$\Omega$ is a Jordan domain whose boundary
curve
$\Gamma$ is \emph{real-analytic}.
Let $\phi$
be the conformal map
from the \emph{exterior domain}
$\Omega^*=\Sigma\setminus\bar\Omega$ onto
the exterior disc $|z|>1$.
Here $\phi$ is normalised so that it maps the point at infinity
into itself.
The inverse conformal mapping function
$\psi$   is defined in $|z|>1$ and has a series expansion
\[ 
\psi(z)=\tau\cdot z+ \tau_0+\sum_{\nu=1}^\infty\, \tau_\nu\cdot
\frac{1}{z^\nu}\tag{*}
\]
where $\tau$ is a positive real number.
The assumption that $\Gamma$ is real-analytic gives
some $\rho_1<1$ such that
$\psi$ extends to a conformal map from the
exterior disc $|z|>\rho_1$ onto a domain whose compact
complement is contained in $\Omega$.
\medskip

\noindent
It turns out that the polynomials $\{P_ n\}$
are  approximated 
by functions expressed by
$\phi$ and is complex derivative
on $\partial\Omega$.
Inspired by Faber's article \emph{Über Tschebyscheffsche
Polynome} [Crelle. J. 1920], Carleman
proved an asymptotic result  in
the article \emph{Über die approximation analytischer funktionen
durch linearen aggregaten von vorgegebenen potenzen} [Arkiv för matematik och fysik. 1920].
\bigskip

\noindent
{\bf{B. Theorem.}}
\emph{There exists a constant $C$ which depends upon $\Omega$ only
such that to every
$n\geq 1$ there is an analytic  function $\omega_n(z)$ defined in
$\Omega^*$ and}
\[
 P_n(z)=
 \sqrt{\frac{n+1}{\pi}}
 \cdot \phi'(z)\cdot \phi(z)^n\cdot
 \bigl(1+\omega_n(z)\bigr)
 \quad\colon z\in \partial \Omega
 \]
\emph{where }
\[ 
\max_{z\in\partial \Omega}\,\, |\omega_n(z)|\leq
C\cdot \sqrt{n}\cdot \rho_1^n\quad\colon\quad n=1,2,\ldots
\]

\medskip



\centerline {\emph{Proof.}}
\medskip


\noindent
For each $n\geq 2$ we denote by $\mathcal M_n$ the space of monic polynomials
of degree $n$:
\[ 
Q(z)= z^n+b_{n-1}z^{n-1}+\ldots +b_0
\]
Put 
\[ 
I(Q)=  \iint_ \Omega\, |Q(z)|^2\,  dxdy
\]
and with $n$ kept fixed we set 
\[ 
I_ *(n)=\min_{Q\in \mathcal M_n} \,I(Q)
\]
To each $Q$ we introduce the
primitive polynomial 
\[ 
\widehat{Q}(z)=\frac{z^{n+1}}{n+1}+ \frac{b_ {n-1}}{n}z^n+\ldots+b_0z
\]
\medskip

\noindent
{\bf{1. Exercise.}} Use Green's formula to show that
\[
I(Q)=\frac{1}{4}\int_ {\partial \Omega}\, |\partial_ n(\widehat{Q})|^2\, ds
\] 
where $ds$ is the arc-length measure on $\partial\Omega$
and we have taken the outer normal derivative of
$\widehat{Q}$.
Next,  take the inverse conformal  map $\psi(\zeta)$ in (*) and set
\[ 
F(\zeta)= \widehat{Q}(\psi(\zeta))
\]
Then $F$ is analytic in the exterior disc $|\zeta|>1$
and by (*) above,
$F$ has a series expansion
\[
F(\zeta)=\tau^{n+1}\bigl[ \frac{\zeta^{n+1}}{n+1}+
A_n\zeta^n+\ldots+A_ 1\zeta+A_ 0+
\sum_{\nu=1}^\infty\, \alpha_\nu\cdot \zeta^{-\nu}\bigr]\tag{1.1}
\]


\noindent
{\bf{2. Exercise.}}
Use a variable substitution via $\psi$ to show that
\[
I(Q)= \int_ {|\zeta|= 1}\, \frac{d}{dr}( |F(e^{i\theta})|^2)\, d\theta
\]
Show also that  the series expansion (1.1) identifies 
the right hand side with
\[ 
\pi\cdot \tau^{2n+2}\cdot [\frac{1}{n+1}+ \sum_{k=1}^{k=n}\,
k\cdot |A_k|^2-
\sum_{\\nu=1}^\infty\, \nu\cdot |\alpha_\nu|^2\,\bigr]\tag{2.1}
\]
\medskip

\noindent
{\bf{3. An upper bound for $I_ *(n)$}}.
In (2.1) the coefficients $A_ 1,\ldots,A_ n$ are determined via $Q$
and
the reader may verify that there exists  $Q\in\mathcal M_n$
such that
$A_ 1=\ldots=A_ n=0$.
It follows that
\[
I_ *(n)\leq \pi\cdot \tau^{2n+2}\cdot [\frac{1}{n+1}
-
\sum_{\nu=1}^\infty\, \nu\cdot |\alpha_\nu|^2\,\bigr]
\leq \pi\cdot \tau^{2n+2}\cdot \frac{1}{n+1}\tag{3.1}
\]


\noindent
{\bf{4. A lower bound for $I_ *$}}.
The upper bound (3.1) did not use that
$\partial\Omega$ is real- analytic, i.e. (3.1)  is valid for
every Jordan domain whose boundary curve is of class $C^1$.
To get a lower bound we use the constant $\rho-1<1$ from the above
and choose  $\rho_ 1<\rho<1$. Now
$\psi$
maps the exterior disc
$|\zeta|>\rho$ conformally to an exterior domain
$U^*=\Sigma\setminus \bar U$ where $U$  is a relatively compact
Jordan  domain inside $\Omega$.
Choose  $Q_n\in\mathcal M_n$
so that
\[
I(Q_n)=I_ *(n)
\]
Since  $\Omega\setminus \bar U\subset \Omega$  we have
\[
I_*> \iint_{\Omega\setminus \bar U}\,|Q_n(z)|^2\, dxdx\tag{4.1}
\]


\noindent
{\bf{5. Exercise.}}
Show that (4.1)  is equal to
\[
\int_ {|\zeta|= 1}\, \frac{d}{dr}( |F(e^{i\theta})|^2\cdot d\theta
-
\int_ {|\zeta|= \rho}\, \frac{d}{dr}( |F(e^{i\theta})|^2\cdot \rho\cdot d\theta=
\]
\[
\pi\cdot \tau^{2n+2}\cdot 
[\frac{1- \rho^{2n+2}}{n+1}+ 
\sum_{k=1}^{k=n}\,
k\cdot |A_ k|^2\cdot (1- \rho^{2\nu})+
\sum_{\\nu=1}^\infty\, \nu\cdot |\alpha_\nu|^2
\cdot (\frac{1}{\rho^{2\nu}}-1)\,\bigr]
\]
\medskip

\noindent
and conclude that
one has the
lower bound
\[ 
I_ *(n)\geq\frac{\pi}{n+1}\cdot \tau^{2n+2}\cdot (1- \rho^{2n+2})
\tag{5.1}
\]
\medskip

\noindent
Together (4.1) and (5.1)
give the inequality
\[
\sum_ {k=1}^{k=n}\,
k\cdot |A_ k|^2\cdot (1- \rho^{2\nu})+
\sum_{\nu=1}^\infty\, \nu\cdot |\alpha_\nu|^2
\cdot (\frac{1}{\rho^{2\nu}}- 1)\,\leq \frac{\pi}{n+1}\cdot \rho^{2n+2}\tag{5.2}
\]
Since $1- \rho^2\leq 1- \rho^{2\nu}$ for every $\nu\geq 1$
it follows that
\[
\sum_{k=1}^{k=n}\,
k\cdot |A_ k|^2+
\sum_{\nu=1}^\infty\, \nu\cdot |\alpha_\nu|^2\leq
\frac{\pi}{(1-\rho^2)\cdot n+1}\cdot \rho^{2n+2}\tag{5.3}
\]
\medskip

\noindent
{\bf{6. Conclusion.}}
Recall that $F(\zeta)= \widehat{Q_n}(\psi(\zeta)$.
So after a derivation 
we get
\[ 
F'(\zeta)= \psi'(\zeta)\cdot Q_n(\psi(\zeta))
\]
Hence the series expansion  of $F(\zeta)$ gives
\[
Q_n(\psi(\zeta))=
\frac{\tau^{n+1}}{\psi'(\zeta)}\cdot \bigl[
\zeta^n+
\sum_ {k=1}^{k=n}\, k\cdot A_ k\zeta^{k- 1}
+\sum_{\nu=1}^\infty \, \nu\cdot \alpha_\nu \cdot \zeta^{- \nu- 1}\,\bigr]\tag{6.1}
\]
where the equality holds for $|\zeta|>\rho$.
Put

\[
\omega^*(\zeta)=
\sum_{k=1}^{k=n}\, k\cdot A_ k\zeta^{k- 1}
+\sum_ {\nu=1}^\infty \, \nu\cdot \alpha_\nu \cdot \zeta^{-\nu- 1}
\]
When $|\zeta|=1$ the triangle inequality gives
\[
|\omega^*(\zeta)|\leq
\sum_{k=1}^{k=n}\, k\cdot |A_ k|
+\sum_{\nu=1}^\infty \, \nu\cdot |\alpha_\nu| \tag{6.2}
\]
\medskip

\noindent
{\bf{7. Exercise.}}
Notice  that (5.3) holds for every $ \rho>\rho_ 1$
and use this together with suitable Cauchy-Schwarz inequalities to show that
(6.1)  gives a constant $C$ which is independent of $n$ such that
\[
|\omega^*(\zeta)|\leq C\cdot  \sqrt{n}\cdot \rho_ 1^{n+1}\tag{7.1}
\]

\medskip

\noindent
\emph{Final part of the proof.}
Since $\psi$ is the inverse of $\phi$ we have
\[
\psi'(\phi(z))\cdot Q_n(\psi(\phi(z)= \frac{Q_n(z)}{\phi'(z)}
\]
Define the function  on $\partial\Omega$ by
 \[
\omega_ n(z)=\frac{\omega^*(\phi(z))}{\phi'(z)}\tag{i}
\]
Then (6.2) gives
\[
Q_n(z)= \tau^{n+1}\cdot \phi'(z)\cdot [\phi(z)^n+\omega_n(z)\,\bigr]\tag{ii}
\]
where Exercise 7 shows that $|\omega_ n(z)|$ satisfies the estimate in
Theorem 2.
Finally, the polynomial $Q_n$ minimized the $L^2$-norm
under the constraint  that the leading term is $z^n$ and for this variational problem
the upper and the lower bounds in (4.1-5.1) imply that
\[ 
|I_ *(n)-\frac{\pi}{n+1}\cdot \tau^{2n+2}|\leq 
\frac{\pi}{n+1}\cdot \tau^{2n+2}\cdot \rho^{2n+2}
\]
If we normalise $Q_n$ so that its $L^2$-norm is one gets a
polynomial $P_ n(z)$ where 
the factor $\tau^{n+1}$
is replaced by
$\frac{\sqrt{n+1}}{\sqrt{\pi}}$ which finishes the proof of
Theorem B.









\bigskip

\newpage

\centerline{\bf{§ 5. Fourier series and  convergence of arithmetical means}}
\bigskip

\noindent
Let $f(x)$ be a real\vvv valued and square integrable function
on $(\vvv \pi,\pi)$, i.e.
\[
\int\uuu{\vvv\pi}^\pi\, |f(x)|^2\, dx<\infty
\]
We say that
$f$ has a determined value $A=f(0)$ at $x=0$ if the following two conditions hold:
\[
\lim\uuu{\delta\to 0}
\frac{1}{\delta}\cdot \,\int\uuu 0^\delta\,
|f(x)+f(\vvv x)\vvv 2A|\, dx=0\tag{i}
\]
\[
\int\uuu 0^\delta\,
|f(x)+f(\vvv x)\vvv 2A|^2\, dx\leq C\cdot \delta
\quad
\text{holds for some constant} \quad C\tag{ii}
\]


\noindent
{\bf{Remark.}}
In the same way we can impose this  condition at  every point
$\vvv \pi<x\uuu 0<\pi$. To simplify the subsequent notations
we take $x=0$. 
If  $x=0$ is a Lebesgue point for $f$
and $A$  the  Lebesgue value we have (i).
Hence Lebesgue's Theorem entails  that (i)
holds almost everywhere when 
$x=0$ is replaced by other points $x\uuu 0$.
We leave it to the reader to show
that the second condition also is valid almost everywhere
when $f$ is square integrable but
in general there appears a  null set $\mathcal N$
where (ii) fails to hold while $\mathcal N$ 
contains some Lebegue points.
Next,  expand $f$ in a Fourier series
\[ 
f(x)=\frac{a\uuu 0}{2}+ \sum\, a\uuu k\cdot \cos kx+\sum\, b\uuu k\cdot \sin kx
\]
and with $x=0$ we consider the partial sums
\[ 
s\uuu n(0)= \frac{a\uuu 0}{2}+ a\uuu 1 +\ldots+a\uuu n+
b\uuu 1+\ldots+b\uuu n
\]
The result below is proved 
in [Carleman] and shows  that
$\{s\uuu n\}$ are  close to the determined value  for many $n$\vvv values.


\medskip

\noindent
{\bf{5.1 Theorem.}}
\emph{Assume that $f$ has a determined value $A$ at $x=0$.
Then the following hold for every positive integer $k$}
\[
\lim\uuu{n\to\infty}\, 
\frac{1}{n+1}\cdot
\sum\uuu{\nu=0}^{\nu=n}\, |s\uuu\nu\vvv A|^k=0\tag{*}
\]

\bigskip

\noindent
{\bf{Remark.}}
Recall the famous theorem by Lennart Carleson
which asserts that $\{s\uuu n(x)\}$ converge to
$f(x)$ almost everywhere for each  $f\in L^2$.
When   pointwise convergence holds 
the limit formula (*)  is  obvious.
However, it is in general not true that
the  pointwise convergence exists  at \emph{every point}
where  $f$ has a determined value.
So  "ugly points"  may appear in a null\vvv set
where pointwise convergence fails and here
Carleman's result offers a substitute.

\medskip

\noindent
{\bf{The case when $f\in \text{BMO}(T)$}}.
If $f$ has bounded mean oscillation it is wellknown
that
(i\vvv ii) hold at every Lebesgue point of 
$f$.
So here one has  a  control for  averaged Fourier series of
$f$ expressed via its set of Lebesgue points.

\medskip


\noindent
{\bf{The case when $f$ is continuous.}}
Here (i-ii) hold everywhere so the averaged limit formulas hold
at every point.
We can say more
since $f$ is uniformly continuous.
Let $\omega_f(\delta)$ be the modulos of continuity
function and for each $n\geq 1$,
$||s_n-f||$ is the maximum norm of $s_n-f$
over
$[0,2\pi]$. Set

\[
\mathcal D_n(f)= \sqrt{\frac{1}{n+1}\cdot
\sum\uuu{\nu=0}^{\nu=n}\, ||s\uuu\nu\vvv f||^2}
\]


\medskip




\noindent
{\bf{5.2 Theorem}}. \emph{There exists an absolute constant $K$
such that the following hold for every
continuous function $f$ with maximum norm
$\leq 1$:}


\[ 
\mathcal D_n(f)\leq K\cdot \bigl[ \frac{1}{\sqrt{n}}+\omega_f(\frac{1}{n})\bigr]
\]





\newpage

\noindent
\centerline {\emph{Proof of Theorem 5.1}}
\medskip


\noindent
Set $A=f(0)$ and $s_n=s_n(0)$. Introduce the function:
\[ 
\phi(x)= f(x)+f(\vvv x)\vvv 2A
\]
Applying Dini's kernel we have
\[
s\uuu n\vvv A=
\int\uuu 0^\pi\, \frac{\sin (n+1/2)x}{\sin\, x/2}\cdot \phi(x)\cdot dx
\]
By
trigonometric formulas   the  integral is  expressed by 
three terms for each
$0<\delta<\pi$:
\[
\alpha\uuu n=\frac{1}{\pi}\cdot \int\uuu 0^\delta\, 
\sin nx\cdot\cot x/2\cdot
\phi(x)\cdot dx
\]
\[ 
\beta\uuu n= 
\frac{1}{\pi}\cdot\int\uuu \delta ^\pi\, \sin nx\cdot\cot x/2\cdot
\phi(x)\cdot dx
\]
\[
\gamma\uuu n=\frac{1}{\pi}\cdot\int\uuu 0^\pi\, \cos nx\cdot \phi(x)\cdot dx
\]
\medskip

\noindent
By Hölder's inequality it suffices to show Theorem F.1 if
$k=2p$ is an even integer. Minkowski's inequality gives

\[
\bigl[\,\sum\uuu{\nu=0}^{\nu=n} |s\uuu\nu\vvv A|^{2p}\,\bigr]^{1/2p}\leq
\bigl[\,\sum\uuu{\nu=0}^{\nu=n}|\alpha\uuu \nu|^{2p}\,\bigr]^{1/2p}+
\bigl[\,\sum\uuu{\nu=0}^{\nu=n}|\beta\uuu \nu|^{2p}\,\bigr]^{1/2p}+
\bigl[\,\sum\uuu{\nu=0}^{\nu=n}|\gamma\uuu \nu|^{2p}\,\bigr]^{1/2p}\tag{1}
\]
\medskip

\noindent
Denote by $o(\delta)$ small ordo and $O(\delta)$ is big ordo.
When $\delta\to 0$
we shall establish the following:
\[
\bigl[\,\sum\uuu{\nu=0}^{\nu=n}|\alpha\uuu \nu|^{2p}\,\bigr]^{1/2p}=
n^{1+1/2p)}\cdot o(\delta)\tag{i}
\]
\[
\bigl[\,\sum\uuu{\nu=0}^{\nu=n}|\beta\uuu \nu|^{2p}\,\bigr]^{1/2p}\leq K\cdot p\cdot
\delta^{\vvv 1/2p}\tag{ii}
\]
\[
\bigl[\,\sum\uuu{\nu=0}^{\nu=n}|\gamma\uuu \nu|^{2p}\,\bigr]^{1/2p}\leq K
\tag{iii}
\]
\medskip

\noindent
In (ii-iii) $K$ is an absolute constant which is independent of
$p,n$ and $\delta$.
Let us first see why (i\vvv iii) give Theorem F.1.
Write $o(\delta)= \epsilon(\delta)\cdot \delta$
where $\epsilon(\delta)\to 0$.
With these notations (1) gives:
\[
\bigl[\,\sum\uuu{\nu=0}^{\nu=n} |s\uuu\nu\vvv A|^{2p}\,\bigr]^{1/2p}\leq
n^{1+1/2p} \cdot \delta\cdot \epsilon(\delta)
+Kp\cdot \delta^{\vvv 1/2p}+K\tag{*}
\]


\noindent
Next, let  $\rho >0$ and choose $b$ so large that
\[
pKb^{\vvv 1/2p}<\rho/3
\]
Take $\delta=b/n$ and with $n$ large it follows that
$\epsilon(\delta)$ is so small that
\[ 
b\cdot \epsilon(b/n)<\rho/3
\]
Then right hand side in (*) is majorized by
\[
\frac{2\rho}{3}\cdot n^{1/2p}+ K
\]
When $n$ is large we also have
\[
K\leq \frac{\rho}{3}\cdot n^{1/2p}
\]



\noindent 
Hence the left hand side in (*) is majorized by
$\rho\cdot n^{1/2p}$ for all sufficiently large $n$.
Since $\rho>0$ was arbitrary we get Theorem F.1 when  the power 
is raised by $2p$.


\bigskip

\centerline{\emph{Proof of (i\vvv iii)}}
\bigskip

\noindent
To obtain (i) we use the triangle inequality
which gives the following for every integer $\nu\geq 1$:
\[ 
|a_\nu|\leq \frac{2}{\pi}\cdot \max_{0\leq x\leq\delta} 
|\sin \nu x\cdot\cot x/2|\cdot\int_0^\delta\, |\phi(x)|\, dx
=\nu\cdot o(\delta)\tag{1}
\]
where the small ordo  $\delta$-term comes from the hypothesis expressed by (*)
in the introduction. Hence
the left hand side in (i) is majorized by
\[
\bigl[\sum_{\nu=1}^{\nu=n}\, \nu^{2p}\,\bigr]^{\frac{1}{2p}}
 \cdot o(\delta)=
n^{1+1/2p}\cdot o(\delta)
\]
which was requested to get  (i).
To prove (iii) we  notice  that
\[
\gamma_0^2+2\cdot \sum _{\nu=1}^\infty
\gamma_\nu^2=\frac{1}{\pi}\int_0^\pi\, |\phi(x)|^2\, dx
\]
Next, we have
\[
\sum_{\nu=1}^\infty \, |\gamma_\nu|^{2p}\leq
\bigl[\, \sum_{\nu=1}^\infty \, |\gamma_\nu|^2\, \bigr ]^{1/2p}\leq K
\]
where $K$
exists since
$\phi$ is square-intergable on $[0,\pi]$.
\medskip


\noindent
\emph{Proof of (ii)}.
Here several steps are required.
For each $0<s<\pi$
we define the  function $\phi\uuu s(x)$
by
\[
\phi\uuu s(x)=\phi(x)\quad\colon\quad 0<x<s
\] 
and extend it to an odd function, i.e. $\phi\uuu s(\vvv x)=\vvv \phi\uuu s(x)$
while  $\phi\uuu s(x)=0$ when $|x|>s$.
This odd function has a sine series
\[
\phi\uuu s(x)=\sum\uuu{\nu=1}^\infty
c\uuu\nu(s)\cdot \sin x\tag{1}
\]
Let us also introduce the functions
\[
\rho(s)=\int\uuu 0^s\, |\phi(x)|\cdot dx\quad\text{and}\quad
\Theta (s)=\int\uuu 0^s\, |\phi(x)|^2\cdot dx\tag{2}
\]


\noindent
The crucial step   towards the proof of (ii)
is the following:
\medskip

\noindent
{\bf{Lemma.}} \emph{One has the inequality}
\[
\sum\uuu{|nu=1}^\infty\, |c\uuu\nu(s)|^{2p}\leq
(\frac{2}{\pi})^{2p\vvv 1}\cdot \Theta(s)\cdot \rho(s)^{2p\vvv 2}
\]


\noindent
\emph{Proof.}
We  employ convolutions and define inductively a sequence
of functions $\{\phi\uuu{n,s}(x)\}$
where
$\phi\uuu{1,s}(x)= \phi\uuu s(x)$ and 
\[ 
\phi\uuu{n+1,s}(x)=\frac{1}{\pi}
\int\uuu {\vvv \pi}^\pi\, 
\phi\uuu{n,s}(y)\phi\uuu s(x+y)\cdot dy
\]
Since convolution yield products of the Fourier coefficients
and $2p$ is an even integer we  have the
standard formula:
\[
\sum\uuu{\nu=1}^\infty \, c\uuu n(s)^{2p}
=\phi\uuu{2p,s}(0)\tag{1}
\]
Next, using the Cauchy\vvv Schwarz inequality the reader may verify that

\[
|\phi\uuu{2,s}(x)|\leq \frac{2}{\pi}\cdot \Theta(x)
\]
This entails that
\[
\phi\uuu{3,s}(x)\leq
\frac{1}{\pi}
\int\uuu{\vvv \pi}^\pi\,
|\phi\uuu{2,s}(y)|\cdot |\phi\uuu s(x+y)|\cdot dy
\leq 
\frac{2}{\pi^2}\cdot \Theta(s)\cdot 
\int\uuu{\vvv \pi}^\pi\,
|\phi\uuu s(x+y)|\cdot dy=(\frac{2}{\pi})^2\cdot
 \Theta(s)\cdot \rho(s)
\]
Proceeding in this way it follows by an induction that
\[
\phi\uuu{2p,s}(x)\leq (\frac{2}{\pi})^{2p\vvv 1}
 \cdot \Theta(s)\cdot (\rho(s))^{2p\vvv 2}
\]
This holds in particular when $x=0$ and then (1) above gives Lemma 1.
\bigskip

\noindent
{\bf{A formula for the $\beta$\vvv numbers.}}
We have by definition

\[
\beta\uuu\nu=\frac{2}{\pi}\int\uuu{\delta}^\pi\,\sin\,\nu x\cdot
\frac{1}{2}\cot (\frac{x}{2})\cdot \phi(x)\cdot dx
\]
An  integration by parts and the construction of the Fourier coefficients
$\{c\uuu\nu(s)\}$ which applies with $s=\delta$
give:
\[
\beta\uuu\nu=
\vvv \frac{1}{2}
\cdot \,\cot \delta/2\cdot c\uuu\nu(\delta)+
+\frac{1}{4}
\int \uuu\delta^\pi\, 
c\uuu\nu(x)\cdot
\text{cosec}^2 (\frac{x}{2})\cdot dx\tag{*}
\]
Now we  profit upon Minkowski's inequality.
Let $q$ be the conjugate of $2p$, i.e $\frac{1}{q}+\frac{1}{2p}=1$
and choose  $\{\xi\uuu\nu\}$ to be the   sequence in $\ell^q$
of unit norm such that
\[
|\sum \xi\uuu\nu\cdot \beta\uuu\nu|=||\beta\uuu\bullet||\uuu{2p}
\]
where the last term is the left hand side in (ii).
At the same time (*) above and the triangle inequality give
\[
||\beta\uuu\bullet||\uuu{2p}\leq 
\vvv \frac{1}{2}
\cdot \,\cot (\delta/2)\cdot \sum\, |c\uuu\nu(\delta)|\cdot |\xi\uuu\nu|+
\frac{1}{4}\int \uuu\delta^\pi\, 
\text{cosec}^2 (\frac{x}{2})\cdot \sum\,|
c\uuu\nu(x)\cdot\xi\uuu\nu|\cdot dx\leq
\]
\[
 \frac{1}{2}
\cdot \,\cot (\delta/2)\cdot ||c\uuu\bullet(\delta)||\uuu{2p}
+\frac{1}{4}\int \uuu\delta^\pi\, 
\text{cosec}^2 (\frac{x}{2})\cdot 
||c\uuu\bullet(x)||\uuu{2p}\cdot dx\tag{**}
\]
\medskip

\noindent
At this stage we apply Lemma 1 and the assumption which 
give a constant $K$ such that
\[
\Theta(s)\leq K\quad\text{and}\quad \rho(s)\leq K\cdot s
\]

\medskip

\noindent
The last estimate actually is weaker than the hypothesis
but it will be  sufficient to get the requested
estimate of the $\ell^{2p}$\vvv norm  in (ii).
Lemma 1 gives a constant $K\uuu 1$ such that
\[
||c\uuu\bullet(\delta)||\uuu{2p}\leq K\uuu 1\cdot \delta^{1\vvv 1/p}
\]
At the same time we have a constant
$K\uuu 2$ such that
\[
\cot (\delta/2)\leq \frac{K\uuu 2}{\delta}
\]
The product in the first term from (**) is therefore majorized by
$K\uuu 1K\uuu 2\cdot \delta^{\vvv 1/2p}$ as requested in (ii).
For the second term we use Lemma 1 which first gives
\[
||c\uuu\bullet(x)||\uuu p\leq K\cdot x^{\vvv 1/2p}
\]
At this stage we leave it to the reader to verify that
we get a constant $K$ so that
\[
\int \uuu\delta^\pi\, 
x^{\vvv 1/2p}\cdot 
\text{cosec}^2 (\frac{x}{2})\cdot dx\leq K\cdot \delta^{\vvv 1/2p}
\] 
which finishes the proof of (ii).
\bigskip

\centerline{\bf{The case when
$f$ is continuous.}}

\medskip

\noindent
Under the normalisation that
the $L^2$-integral of $f$ is $\leq 1$
the inequalities (ii-iii) hold for an absolute constant $K$.
In (i) we notice that
the construction of
$\phi$ and the definition of $\omega_f$
give the estimates
\[ 
|a_\nu|\leq \nu\cdot \delta\cdot \omega_f(\delta)
\]
With $p=2$ this entails 
that (i) from the proof of Theorem F.1 is majorised by
\[
n^{1+1/2}\cdot \delta\cdot \omega_f(\delta)
\]
This holds for every $0\leq x\leq 2\pi$ and from the previous proof we conclude that
the following hold for each
$n\geq 2$ and every $0<\delta<\pi$:
\[ 
\mathcal D_n(f)\leq\frac{1}{\sqrt{n+1}}\cdot
[n^{1+1/2}\cdot \delta\cdot \omega_f(\delta)+2K\delta^{-1/2}+K]\tag{i}
\]
With $n\geq 2$ we take $\delta=n^{-1}$ and see that
(i) gives a requested constant in Theorem 5.2.






\newpage

\centerline{\bf{§ 6. An inequality for resolvents.}}
\medskip

\noindent

\noindent
{\bf{Introduction }} Theorem 6.1 below was proved by
Carleman in the article
\emph{Sur le genre du denominateur $D(\lambda)$
de Fredholm}
from 1917 and  used 
to study  integral equations expressed by Hilbert-Schmidt kernels.
\medskip

\noindent
{\bf{The Hilbert-Schmidt norm. }} It is defined 
for an  
$n\times n$-matrix $A=\{a_{ik}\}$  by:
\[
\mathfrak{h}(A)= \sqrt{ \sum\sum\, |a_{ik}|^2}
\]


\noindent
where the double sum extends over all pairs
$1\leq i,k\leq n$.
Notice that 
\[
\mathfrak{h}(A)^2= \sum_{i=1}^{i=n}\, ||A(e_i)||^2
\] 
where $e_1,\ldots,e_n$ can be taken as an arbitrary orthogonal basis in
${\bf{C}}^n$.
Next, 
for a linear operator $S$
on ${\bf{C}}^n$
its \emph{operator norm} is defined by
\[
||S||=
\max_x\, ||S(x)||\quad\text{with the maximum taken over unit vectors.}
\] 

\noindent
{\bf{6.1 Theorem.}}
\emph{Let $\lambda_1,\ldots,\lambda_n$ be the roots of 
$P_A(\lambda)$ and  $\lambda\neq 0$ is outside $\sigma(A)$. Then
one has the inequality:}
\[ 
\bigl|\prod_{i=1}^{i=n}\, 
\bigl(1-\frac{\lambda_i}{\lambda}\bigr )\cdot
e^{\lambda_i/\lambda}\bigr|\cdot ||R_A(\lambda)||
\leq |\lambda|\cdot e^{\frac{1}{2}\bigl(1+ \frac{\mathfrak{h}(A)^2}{ |\lambda|^2}\bigr)}
\]
\medskip

\noindent
The proof requires some preliminary results.
First we  need  inequality due to  Hadamard which
goes as follows:
\medskip

\noindent
{\bf {6.2 Hadamard's inequality.}}
\emph{For every matrix $A$ with a non-zero determinant one has the inequality}
\[
\bigl|\text{det}(A)\bigr|\cdot ||A^{-1}||\leq
\frac{\mathfrak{h}(A)^{n-1}}{(n-1)^{n-1)/2}}
\]


\noindent
{\bf{Exercise.}} Prove this  result. 
The hint is to  use
expansions of certain determinants while one
considers 
$\text {det}(A)\cdot \langle A^{-1}(x),y\rangle$ 
for all pairs of unit vectors $x$ and $y$.

\bigskip

\noindent
{\bf{6.3 Traceless matrices.}}
Let $A$ be an  $n\times n$-matrix. The trace is by definition given by:
\[
\text{Tr}(A)= b_{11}+\ldots+b_{nn}\tag{i}
\]
Recall  that 
$-\text{Tr}(A)$ is
equal to the sum of the roots of $P_A(\lambda)$.
In particular the trace of two equivalent matrices are equal.
This will be used to prove the following:
\medskip

\noindent
{\bf{6.4 Theorem.}}
\emph{Let $A$ be an $n\times n$-matrix whose trace is zero. Then there
exists a unitary matrix
$U$ such that  the diagonal elements of $U^*AU$ all are zero.}
\medskip


\noindent
\emph{Proof}. Consider
first consider the case $n=2$. By Theorem 4.0.7
it suffices to consider the case when the $2\times 2$-matrix $A$
is upper diagonal and since the trace is zero it has the form
\[ 
A=
\bigl(\,\begin{matrix} a&b\\0&-a
\end{matrix}\,\bigr)
\]
where $a,b$ is a pair of complex numbers.
If $a=0$ then the two diagonal elements are zero and wee can take $U=E_2$ to be the identity in Lemma 6.5. If $a\neq 0$ we consider a vector $\phi=(1,z)$ in ${\bf{C}}^2$.
Then $A(\phi)$ is the vector $(a+bz,-az)$ and hence the inner product becomes:
\[
\langle A(\phi),\phi\rangle=a+bz-a|z|^2\tag{i}
\]
We can write
\[
\frac{b}{a}= re^{i\theta}
\]
where $r>0$ and then (i) is zero if
\[
|z|^2=1+se^{i\theta}\cdot z\tag{ii}
\]
With $z=se^{-i\theta}$
it amounts to find a positive real number $s$ such that
$s^2=1+s$ which clearly exists.
Now we get the vector
\[ 
\phi_*=\frac{1}{1+s^2}(1,se^{-i\theta})
\]
which has unit length and 
\[
\langle A(\phi_*),\phi_*\rangle=0\tag{ii}
\]
By 4.0.6 we find another unit vector $\psi_*$ so that
$\phi_*,\psi_*$ is an orthonormal base in
${\bf{C}}^2$ and hence there exists a unitary matrix
$U$ such that $U(e_1)=\phi_*$ and $U(e_2)= \psi_*$.
If $B=U^*AB$ the vanishing in (ii) gives $b_{11}=0$. At the same time
the trace is unchanged, i.e. $\text{tr}(B)=0$ holds and hence
we also get
$b_{22}=0$. This means  that  the diagonal elements of $U^*AU$ 
are both zero as required.
\medskip

\noindent{\bf{The case $n\geq 3$}}.
For the
induction
the following is needed:
\medskip

\noindent
\emph{Sublemma.} \emph{Let $n\geq 3$
and assume as above that
$\text{Tr}(A)=0$. Then there exists some
non-zero vector $\phi\in{\bf{C}}^n$ such that}
\[
\langle A(\phi),\phi\rangle=0\tag{*}
\]

\noindent
\emph{Proof.}
If (*) does not hold we
get the positive number
\[
m_*=\min_\phi\, \bigl|\langle A(\phi),\phi\rangle\bigr|
\]
where the minimum is taken over unit vectors in
${\bf{C}}^n$.
The minimum is achieved by some unit vector $\phi_*$. Let
$\phi_*^\perp$ be its orthonormal complement
and $E$ the self-adjoint projection from
${\bf{C}}^n$ onto $\phi_*^\perp$.
On the $(n-1)$-dimensional inner product space
$\phi_*^\perp$ we get the linear operator
$B=EA$, i.e. 
\[ 
B(\xi)= E(A(\xi))\quad\colon\quad \xi\in \phi_*^\perp\tag{i}
\]
If $\psi_1,\ldots,\psi_{n-1}$ is an orthonormal basis in
$\phi_*^\perp$ then the $n$-tuple $\phi_*,\psi_1,\ldots,\psi_{n-1}$
is an orthonormal basis in ${\bf{C}}^n$ and since the trace of $A$ is zero we get
\[
0=\langle A(\phi_*),\phi_*\rangle+
\sum_{\nu=1}^{\nu=n-1}\, \langle A(\psi_\nu),\psi_\nu\rangle=
m+\sum_{\nu=1}^{\nu=n-1}\, \langle B(\psi_\nu),\psi_\nu\rangle\tag{ii}
\]
where we used that $E(\psi_\nu)=\psi_\nu$ for each $\nu$
and that $E$ is self-adjoint so that

\[
\langle A(\psi_\nu),\psi_\nu\rangle=
\langle A(\psi_\nu),E(\psi_\nu)\rangle=\langle E(A(\psi_\nu)),\psi_\nu\rangle
=\langle B(\psi_\nu),\psi_\nu\rangle
\]
Now (ii)  gives
\[ 
\text{Tr}(B)=-m
\]
Hence the $(n-1)\times(n-1)$-matrix which represents
$B+\frac{m}{n-1}\cdot E$
has trace zero. By an induction over $n$ we find a unit vector
$\psi\in \phi_*^\perp$
such that
\[
\langle B(\psi_*),\psi_*\rangle=-\frac{m}{n-1}
\]
Finally, since $E$ is self-adjoint we have already seen that
\[
\langle A(\psi_*),\psi_*\rangle=\langle B(\psi_*),\psi_*\rangle\implies
\bigl|\langle A(\psi_*),\psi_*\rangle\bigr |=\bigl|\frac{m}{n-1}\bigr |=
\frac{m_*}{n-1}
\]
Since $n\geq 3$ the last number is $<m_*$ which contradicts the minimal choice 
of $m_*$.
Hence we must have $m_*=0$ which proves lemma 6.5
\bigskip

\noindent
{\emph{Final part of the proof.}
Let $n\geq 3$. The Sublemma  gives unit vector $\phi$
such that
$\langle A(\phi),\phi\rangle=0$.
Consider the hyperplane
$\phi^\perp$ and the operator $B$ from the Sublemma  which now has trace
zero on this $(n-1)$-dimensional space. So by an induction over
$n$
there exists an orthonormal basis $\psi_1,\ldots,\psi_{n-1}$ in
$\phi^\perp$ such that
$\langle B(\psi_\nu),\psi_nu\rangle=0$ for every $\nu$.
Now $\phi,\psi_1,\ldots,\psi_{n-1}$
is an orthonormal basis in ${\bf{C}}^n$ and if $U$
is the unitary matrix which has this $n$-tuple as column vectors
it follows that the diagonal elements of $U^*AU$ all vanish.
This finishes the proof of Theorem 6.4.


 
\newpage

\centerline{\bf{Proof Theorem 6.1}}.



\noindent
Set $B=\lambda^{-1}A$ so that $\sigma(B)=\{ \lambda_i/\lambda\}$ and
$\text{Tr}(B)=\sum\,\frac{\lambda_i}{\lambda}$.
We also have 
\[
\mathfrak{h}(B)=\frac{\mathfrak{h}(A)}{|\lambda|}\quad\text{and}\quad
\bigl |\lambda\bigr |\cdot ||R_A(\lambda)||=||(E-B)^{-1}||
\]


\noindent Hence Theorem 6.1 follows if we prove the inequality
\[
\bigl |e^{\text{Tr}(B)}\bigr|\cdot
\bigl|\prod_{i=1}^{i=n}\, 
\bigl[1-\frac{\lambda}{\lambda_i}\bigr ]
\cdot
||E-B)^{-1}||
\leq \text{exp}\bigl[\frac{1+ \mathfrak{h}(B)^2}{2}\bigr]\tag{*}
\]


\noindent
To prove (*) we choose an arbitrary integer $N$ such that
$N>\bigl |\text{Tr}(B)\bigr|$ and for each such $N$ we define the linear operator
$B_N$ on the $n+N$-dimensional complex space with points 
denoted by $(x,y)$ with  $y\in{\bf{C}}^N$
as follows:
\[
B_N(x,y)= (Bx\, , \, -\frac{\text{Tr}(B)}{N}\cdot y)\tag{**}
\]


\noindent
The
eigenvalues of the linear operator $E-B_N$ is the union of the $n$-tuple 
$\{1-\frac{\lambda_i}{\lambda}\}$ and 
the $N$-tuple of equal eigenvalues given by 
$1+\frac{\text{Tr}(B)}{N}$.
This gives the determinant formula
\[
\text{det}(E-B_N)=
\bigl(1+\frac{\text{Tr}(B)}{N}\bigr)^N
\cdot \prod_{i=1}^{i=n}\, (1-\frac{\lambda_i}{\lambda}\bigr)\tag{1}
\]
The choice of $N$ implies that (1) is $\neq 0$ so 
the inverse $(E-B_N)^{-1}$ exists.
Moreover, the construction of $B_N$ gives
for any pair $(x,y)$ in ${\bf{C}}^{N+n}$:
\medskip
\[
(E-B_N)^{-1}(x,y)=
\bigl (E-B)^{-1}(x), \frac{y}{
1+\frac{1}{N}\cdot \text{Tr}(B)}\bigr)
\]


\noindent
It follows that 
\[
||(E-B)^{-1}||\leq
||(E-B_N)^{-1}||\implies
\]
\[
\bigl|\text{det}(E-B_N)\cdot ||(E-B)^{-1}||\leq
\bigl|\text{det}(E-B_N)\bigr|\cdot
||(E-B_N)^{-1}||\tag{2}
\]


\noindent 
Hadarmard's inequality
estimates the
hand side in (2) by:
\[
\frac{\mathfrak{h}(E-B_N)^{N+n-1}}{(N+n-1)^{N+n-1)/2}}\tag{3}
\]
\medskip

\noindent
Next, the construction of $B_N$ implies that its trace is zero.
So  by the result in 6.3 we can find
an orthonormal basis $\xi_1,\ldots,\xi_{n+N}$
in ${\bf{C}}^{n+N}$ such that
\[ 
\langle B_N(\xi_k),\xi_k\rangle=0\quad\colon 1\leq k\leq n+N
\]


\noindent
Relative to this basis the matrix of $E-B_N$ 
has 1 along the diagonal and the negative of the
elements of $B_N$ elsewhere. It follows that the Hilbert-Schmidt norm
satisfies the equality:
\[
\mathfrak{h}(E-B_N)^2=
N+n+\mathfrak{h}(B_N)^2=N+n+\mathfrak{h}(B)^2+ N^{-1}\cdot
|\text{Tr}(B)|^2\tag{4}
\]

\medskip

\noindent Hence, (1) and the inequalities from (2-3) give:
\[
\bigl(1+\frac{\text{Tr}(B)}{N}\bigr)^N
\cdot \prod_{i=1}^{i=n}\, (1-\frac{\lambda_i}{\lambda}\bigr)\cdot
||(E-B)^{-1}||\leq
\] 
\[
\frac{\bigl(N+n+\mathfrak{h}(B)^2+
N^{-1}\cdot
|\text{Tr}(B)|^2\bigr)^{(N+n-1)(2}}{
\bigl(N+n-1\bigr)^{N+n-1/2}}=
\frac{\bigl(1+\frac{\mathfrak{h}(B)^2}{N+n}+
\frac{|\text{Tr}(B)|^2}{N(N+n)}\bigr)^{(N+n-1)/2}}{
(1-\frac{1}{N+n}\bigr)^{N+n-1/2}}
\]
\medskip

\noindent
This inequality holds for
arbitrary large $N$.
Passing to the limit as $N\to\infty$  the definition of Neper's constant $e$
give

\[
\lim_{N\to\infty}\, \bigl(1+\frac{\text{Tr}(B)}{N}\bigr)^N=
e^{\text{Tr}(B)}
\]
and the reader may also verify that
the limit of the last term above is equal to
$\text{exp}\bigl[\frac{1+ \mathfrak{h}(B)^2}{2}\bigr]$ which finishes the proof of
(*) above and hence also of Theorem 6.1.

\newpage





\centerline{\bf{§ 7. The Denjoy conjecture}}

\bigskip

\noindent {\bf Introduction.}
Let $\rho$ be a positive integer and 
$f(z)$  is an entire function such that there exists some
$0<\epsilon<1/2 $  and a constant $A_\epsilon$ such that
\[
|f(z)|\leq A_\epsilon\cdot e^{|z|^{\rho+\epsilon}}\tag{0.1}
\]


\noindent
hold for every $z$. Then we say that 
$f$ has integral order $\leq\rho$.
Next, the entire function $f$ has an asymptotic value $a$
if there exists a Jordan curve
$\Gamma$ parametrized
by
$t\mapsto\gamma(t)$ for $t\geq 0$ such that
$|\gamma(t)|\to \infty$ as $t\to+\infty$ and
\[
\lim_{t\to+\infty}\, f(\gamma(t))=a\tag{0.2}
\]


\noindent
In 1920 Denjoy raised the conjecture that
(0.1) implies that the entire function $f$ has at most
$2\rho$ many different asymptotic values. Examples show that
this upper bound is sharp.
The Denjoy conjecture was proved in 1930 by  Ahlfors in [Ahl].
A few years later T. Carleman found an alternative  proof based
upon a certain differential inequality.
Theorem A.3 below 
has  applications beyond the proof of
the Denjoy conjecture
for estimates of
harmonic measures. See [Ga-Marsh].

\bigskip

\centerline{\bf A. The  differential inequality.}
\bigskip


\noindent
Let $\Omega$ be a connected open set in ${\bf{C}}$ whose
intersection $S\uuu x$ between
a  vertical line  $\{\mathfrak{Re}\, z=x\}$
is a bounded set
on the real $y$-line for every $x$.
When $S_x\neq\emptyset $ it is the disjoint union
of open
intervals $\{(a_\nu,b_\nu)\}$ and we set
\[ 
\ell(x)=\max\uuu \nu \,(b_\nu-a_\nu)\tag{*}
\]

\medskip


\noindent
Next, let
$u(x,y)$ be a positive harmonic   function
in $\Omega$ which 
extends to a continuous function on
the closure $\bar\Omega$  with the boundary values identical to zero.
Define the function $\phi$ by:
\[ 
\phi(x)=\int_{S_x}\,u^2(x,y)\cdot dy\tag{1}
\]
The Federer-Stokes theorem gives
the following  formula for the derivatives of $\phi$:
\[ 
\phi'(x)=2\int_{S_x}\,u_x\cdot u(x,y) dy\tag{2}
\]
\[
\phi''(x)=2\int_{S_x}\,u_{xx}\cdot u(x,y) dy+
2\int_{S_x}\,u^2_x\cdot dy\tag{3}
\]


\noindent
Since $\Delta(u)=0$ when $u>0$ we have
\[
2\int_{S_x}\,u_{xx}\cdot u(x,y) dy=-
2\int_{S_x}\,u_{yy}\cdot u(x,y) dy=
2\int u_y^2 dy\tag{4}
\]
The Cauchy-Schwarz inequality applied in (2) gives
\[
\phi'(x)^2\leq 4\cdot \int_{S_x}\,u^2_x\cdot\int_{S_x} u^2(x,y) dy
=4 \cdot \phi(x)\cdot \int_{S_x}u_x^2dy\tag{5}
\]
Hence (4) and (5) give:
\[ 
\phi''(x)\geq 2\int\uuu{S\uuu x} \,u^2_y(x,y)\cdot dy+\frac{1}{2}\cdot \frac{\phi'^2(x)}{\phi(x)}\tag{6}
\]
Next, since $u(x,y)=0$ at the end-points of all intervals of $S_x$,
\emph{Wirtinger's 
inequality}
and the definition of $\ell(x)$ give:
\[
\int\uuu{S\uuu x} u^2_y(x,y)\cdot dy\geq \frac{\pi^2}{\ell(x)^2}\cdot\phi(x)\tag{7}
\]


\noindent
Inserting (7) in (6) we have  proved
\medskip

\noindent
{\bf A.1 Proposition} \emph{The $\phi$-function satisfies the differential inequality}
\[
\phi''(x)\geq \frac{2\pi^2}{\ell(x)^2}\cdot\phi(x)+\frac{\phi'^2(x)}{2\phi(x)}
\]


\noindent
\emph{Proof continued.}
The maximum
principle for harmonic functions implies that the $\phi(x)>0$
when $x>0$ and hence there exists
a $\psi$-function where
$\phi(x)= e^{\psi(x)}$. It follows that

\[ 
\phi'=\psi' e^\psi\quad\text{and}\quad\,\phi''=
\psi''e^\psi+\psi'^2e^\psi
\]

\noindent
Now  Proposition A.1 gives
\[
 \psi''+\frac{\psi'^2}{2}\geq \frac{2\pi^2}{\ell(x)^2}\tag{*}
\]
\medskip


\noindent
{\bf {A.2 An integral inequality.}}
From (*) we obtain
\[
\frac{2\pi}{\ell(x)}\leq\sqrt{\psi'(x)^2+2\psi''(x)}\,\leq
\psi'(x)+\frac{\psi''(x)}{\psi'(x)}
\]
\medskip

\noindent
Taking the integral we get
\[ 
2\pi\cdot\int_0^x\,\frac{dt}{\ell(t)}\leq \psi(x)+\log\,\psi'(x)+O(1)
\leq \psi(x)+,\psi'(x)+O(1)\tag{**}
\]
where $O(1)$ is a remainder 
term which is bounded  independent of $x$. Taking the integral once more we 
obtain:
\medskip

\noindent
{\bf {A.3 Theorem.}}
\emph{The following inequality holds:}
\[
2\pi\cdot\int_0^x\, \frac{x-s}{\ell(s)}\cdot ds\leq
\int_0^x\,\psi(s)\cdot ds+\psi(x)+O(x)
\]
\emph{where the remainder term $O(x)$ is bounded by $Cx$ for 
a fixed constant.}

\bigskip


\centerline {\bf B. Solution to the Denjoy conjecture}
\bigskip

\noindent
{\bf B.1 Theorem.}
\emph{Let $f(z)$ be entire of some integral order
$\rho\geq 1$. Then $f$ has at most $2\rho$ many different asymptotic values.}
\bigskip

\noindent
\emph{Proof.}
Suppose $f$ has $n$ different asymptotic values
$a_1,\ldots,a_n$.
To each  $a_\nu$ there exists a Jordan arc $\Gamma_\nu$ as described in the introduction.
Since the $a$-values are different the $n$-tuple of
$\Gamma$-arcs are separated from each other when
$|z|$ is large.
So we can find some $R$ such that
the arcs are disjoint in the exterior disc
$|z|>R$. We may also consider the tail of each arc, i.e. starting from
the last point on $\Gamma_\nu$ which intersects the circle
$|z|=R$. So now we have an $n$-tuple of disjoint Jordan
curves in $|z|\geq R$ where each curve intersects $|z|=R$ at some point $p_\nu$ and after the curves moves to the point at infinity. See figure.
Next, we take one of these curves, say $\Gamma_1$. Let
$D_R^*$ be the exterior disc $|\zeta |>R$.
In the domain
$\Omega={\bf{C}}\setminus \Gamma_1\cup\,D_R^*$ we can choose a single-valued
branch of $\log \zeta$ and with $z=\log\,\zeta $
the image of $\Omega$ is a simply connected domain 
$\Omega^*$
where
$S_x$ for each $x$ has length strictly less than
$2\pi$
The images of the $\Gamma$-curves
separate $\Omega^*$
into $n$ many disjoint connected
domains
denoted by $D_1,\ldots,D_n$ where
each $D_\nu$ is bordered by a pair of images of $\Gamma$-curves
and a portion of the vertical line $x=\log \,R$.

\medskip

\noindent
Let $\zeta=\xi+i\eta$ be the complex coordinate
in $\Omega^*$.
Here we get the analytic function
$F(\zeta)$ where
\[ F(\text{log}(z))= f(z)
\]
We notice that $F$ may have more growth than $f$. Indeed, we get
\[
|F(\xi+i\eta)|\leq \text{exp}\bigl(e^{(\rho+\epsilon)\xi}\bigr)\tag{1}
\]

\medskip

\noindent
With $u=\text{Log}^+\,|F|$ it follows that
\[ 
u(\xi,\eta)\leq e^{(\rho+\epsilon)\xi}\tag{2}
\]


\noindent
Hence the $\phi$-function constructed
during the proof of Theorem A.3  satisfies
\[
\phi(\xi)\leq e^{2(\rho+\epsilon)\xi}
\]
It follows that the $\psi$-function satisfies


\[ 
\psi(\xi)=2\cdot (\rho+\epsilon)\xi+O(1)\tag{3}
\]


\noindent Now we  apply Theorem A.3  in each region $D_\nu$
where we have a function
$\ell_\nu(\xi)$ constructed by (0) in section A. 
This gives the inequality
\[
2\pi\cdot \int_R^\xi\, \frac{\xi-s}{\ell_\nu(s)}\cdot ds\leq
\int_R^\xi\, (\rho+\epsilon)s\cdot ds+(\rho+\epsilon)\xi+O(1)\quad\colon\quad
1\leq \nu\leq n\tag{4}
\]
\medskip

\noindent
Next, recall the elementary inequality which asserts that if $a\uuu 1,\ldots,a\uuu n$
is an arbitrary $n$\vvv tuple of positive numbers then
\[
\sum\,a\uuu \nu\cdot \sum\, \frac{1}{a_\nu}\geq n^2
\tag{5}
\]
For each $s$ we apply this to the $n$\vvv tuple
$\{\ell\uuu \nu(s)\}$ where we also have
\[ 
\sum\,\ell\uuu \nu(s)\leq 2\pi
\] 
\noindent
So  a summation in (4) over $1\leq \nu\leq n$ gives
\[
n\cdot  \int_R^\xi\, (\xi-s)\cdot ds\leq
\int_R^\xi\, (\rho+\epsilon)s\cdot ds+(\rho+\epsilon)\xi+O(1)\tag{6}
\]
Another integration gives:
\[ 
n\cdot\frac{\xi^2}{2}\leq (\rho+\epsilon)\cdot \xi^2+O(\xi)\tag{7}
\]
\medskip

\noindent
This inequality can only hold for large $\xi$ if
$n\leq 2(\rho+\epsilon)$ and since  $\epsilon<1/2$ is assumed
it follows that 
$n\leq 2\rho$ which finishes the proof of the Denjoy conjecture.

\newpage 


\centerline{\bf § 8. Approximation by fractional powers }

\bigskip

\noindent 
Here is the set-up in
the article \emph{Über die approximation analytischer funktionen}
by Carleman from 1922.  
Let $0<\lambda_1<\lambda_2<\ldots$ 
be a sequence of positive real numbers and
$\Omega$ is a simply connected
domain contained in
the right half-space
$\mathfrak{Re}(z)>0$.
Notice that  
the functions 
$q_\nu(z)= z^{\lambda_\nu}$
are analytic in the half-plane,  i.e. with
$z=re^{i\theta}$ and $-\pi/2<\theta<\pi/2$ we have:
\[ 
q_\nu(z)=r^{\lambda_\nu}\cdot e^{i\lambda_\nu\cdot\theta}
\]


\noindent
{\bf C.1 Definition.}
\emph{We say that the sequence $\Lambda=\{\lambda_\nu\}$
is dense for approximation if there for each
$f\in\mathcal O(\Omega)$ exists a sequence of
functions of the form}
\[ 
Q_N(z)=\sum_{\nu=1}^N
\, c_\nu(N)\cdot q_\nu(z)\quad\colon\quad N=1,2,\ldots
\]
\emph{which converges uniformly to $f$ on compact subsets of $\Omega$.}

\bigskip

\noindent
{\bf C.2 Theorem.}
\emph{A sequence $\Lambda$ is dense if }
\[
\limsup_{R\to\infty}\,
\frac{\sum_R\,\frac{1}{\lambda_\nu}}{\text{Log}\,R}>0\tag{*}
\]
\emph{where $\sum_R$ means that we take the sum over
all $\lambda_\nu<R$.}
\medskip

\noindent
{\bf Remark.}
Above condition (*)  is the same for every
simply connected  
domain $\Omega$. Theorem C.2 gives
a \emph{sufficient} condition for an   approximation.
To get  necessary condition one must specify the domain
$\Omega$ and we shall not try to discuss this
more involved problem.
The proof of Theorem C.2 requires several steps, the crucial
is the 
uniqueness theorem in C.4 while the proof of Theorem C.2 is
postponed until C.5.
\medskip


\centerline {\bf C.3 A uniqueness theorem.}
\medskip

\noindent
Consider a closed Jordan curve
$\Gamma$ of class $C^1$ which is contained in
$\mathfrak{Re}\, z>0$.
When $z=re^{i\theta}$ stays in the right
half-plane  we get an entire function of the complex 
variable $\lambda$ defined by:
\[ 
\lambda\mapsto z^\lambda= r^\lambda \cdot e^{i\theta\cdot\lambda}
\] 
We conclude that
a real-valued 
and continuous function $g$ on $\Gamma$ gives
an entire function of $\lambda$ defined by:
\[
 G(\lambda)=\int_\Gamma\, g(z)\cdot z^\lambda\cdot \bigl|dz\bigr|_\Gamma
 \]
where $|dz|_\Gamma$  is the arc-length on $\Gamma$.
With these notations one has
\bigskip

\noindent
{\bf C.4 Theorem.}
\emph{Assume that $\Lambda$ satisfies the condition in
Theorem C.2. Then, if $G(\lambda_\nu)=0$ for every
$\nu$ it follows that 
the $g$-function is  identically zero.}

 


\medskip

\noindent
\emph{Proof.} If we have shown that
the $G$-function is identically zero then the reader may verify
that $g=0$.  There remains to show that if
$G(\lambda_\nu)=0$ for every $\nu$ then
$G=0$.
To attain this one first   shows that
there exist constants $A,K$ and $0<a<\frac{\pi}{2}$
such that:
\[ 
|G(\lambda)|\leq K\cdot e^{|\lambda|}\quad\text{and}\quad
|G(is)|\leq K\cdot e^{|s|\cdot a}\quad\colon\,\lambda\in{\bf{C}}\,\,
\colon s\in{\bf{R}}\tag{i}
\]


\noindent
The easy verification of (i) is left to the reader. 
Next,  the first inequality in (i) means that
$G$ is an  entire function of exponential type one.
By assumption  $G(\lambda_\nu)=0$ for every  $\nu$.
Now we can use
Carleman's  formula for analytic functions in a half-space
from XXX to conclude that $G=0$. Namely, set
\[ 
U(r,\phi)=\log\,\bigl |G(re^{i\phi})\bigr |\tag{ii}
\]


\noindent
Let $\{ r_\nu e^{i\phi_\nu}\}$
be the zeros of $G$ in $\mathfrak{Re}(z)>0$ which 
by the hypothesis contains the set $\Lambda$.
By Carleman's formula the following hold for each
$R>1$:
\[
\sum_{1<r_\nu<R}\,
\bigl[\frac{1}{r_\nu}-\frac{r_\nu}{R^2}\bigr]\cdot\text{cos}\,\theta_\nu=
\frac{1}{\pi R}\cdot\int_{-\pi/2}^{\pi/2}\,
U(R,\phi)\cdot\text{cos}\,\phi\cdot d\phi+
\]
\[
\frac{1}{2\pi R}\cdot\int_1^R\, \bigl(\frac{1}{r^2}-\frac{1}{R^2}\bigr)
\cdot\bigr[\, U(r,\pi/2)+U(r,-\pi/2)\,\bigr]\cdot dr+
c_*(R)
\]
where $c_*(R)\leq K$ holds for some constant which is independent of
$R$.
Finally, the set  
$\Lambda$ satisfies (*)  in
Theorem C.2  and the  sum over zeros in Carleman's  formula above
majorizes   the  sum extended over
the real $\lambda$-numbers
from $\Lambda$ satisfying $1<\lambda_\nu<R$.
At this stage we leave it to the reader to
verify that the second inequality in (i) above implies 
that $G$ must be identically zero.



\bigskip

\centerline{\bf Proof of Theorem C.2}

\bigskip
\noindent
Denote by $\mathcal O^*(\Lambda)$ the linear space of analytic functions
in the right half-plane given by finite ${\bf{C}}$-linear combinations of the fractional
powers $\{z^{\lambda_\nu}\}$.
To obtain uniform approximations over relatively compact
subsets when 
$\Omega$ is a simply connected  domain in $\mathfrak{Re}(z)>0$,
it suffices to regard a 
closed Jordan arc
$\Gamma$ 
which borders a Jordan domain $U$ where
$U$ is a relatively compact subset of
$\Omega$. In particular $\Gamma$ has a positive distance to
the imaginary axis and there remains  to show
that when (*) holds in Theorem C.2, then
an arbitrary analytic function $f(z)$ defined in some open
neighborhood of $\bar U$ can be uniformly approximated
by $\mathcal O^*(\Lambda)$-functions over a relatively compact subset
$U_*$ of $U$.
To achieve this 
we shall use a trick which
reduces the proof of uniform approximation
to a problem concerned with $L^2$-approximation on
$\Gamma$.
To begin with
we have
\medskip

\noindent
{\bf C.5 Lemma.}
\emph{The uniqueness in Theorem C.4 implies that
if $V$ is a real-valued function on
$\Gamma$ then there exists a sequence 
$\{Q_n\}$ from the family $\mathcal O(\Lambda)$
 such that}
\[
\lim_{n\to\infty}\, \int_\Gamma\,\bigl|Q_n-V|^2\cdot |dz|=0
\]
\medskip

\noindent 
The proof of this result is left as an exercise.

\medskip

\noindent
{\bf C.6 A tricky construction.}
Let $f(z)$ be analytic in a neighborhood of the closed
Jordan domain $\bar U$ bordered by
$\Gamma$. Define a new analytic function
\[ 
F(z)=\int_{z_*}^z\,\frac{f(\zeta)}{\zeta}\cdot d\zeta\tag{1}
\]
where $z_*$ is some point in $\bar U$ whose specific  choice
does not affect the
subsequent discussion.
We can write $F=V+iW$ where $V=\mathfrak{Re}(F)$.
Lemma 6.5 gives a sequence $\{Q_n\}$ which approximates
$V$ in the $L^2$-norm on $\Gamma$.
Using this $L^2$-approximation we get
\medskip

\noindent
{\bf Lemma C.7}
\emph{Let $U_0$ be relatively compact in $U$.
Then there exists a sequence of real numbers
$\{\gamma_n\}$ such that}
\[
\lim_{n\to\infty}\, \bigl|| Q_n(z)-i\cdot\gamma_n-F(z)\bigl|_{U_0}=0
\]
\medskip

\noindent
Again we leave out the proof as an exercise.
Next, taking complex derivatives  Lemma C.7  implies that
if $U_*$ is even smaller, i.e. taken to be a relatively compact in
$U_0$, then we a get uniform approximation of derivatives:
\[
Q'_n(z)\to F'(z)=\frac{f(z)}{z}
\]
Well, this means that
\[
 z\cdot Q'_n\to f(z)
\]
holds uniformly in
$U_*$. Next, notice that  
\[
z\cdot \frac{d}{dz}(z^{\lambda_\nu})
=\lambda_\nu\cdot z^{\lambda_\nu}
\]
hold for each $\nu$. Hence
$\{z\cdot Q'_n(z)\}$  again belong to  the $\mathcal O(\Lambda)$-family.
So we achieve the required uniform approximation of
the given $f$ function on $U_*$.
This completes the proof of
Theorem C.2.




\newpage



\centerline{\bf § 9. Theorem of Müntz}
\bigskip



\noindent
{\bf Introduction.} Theorem D.1   below
is due to Müntz. See his article
\emph{Über den Approximationssatz von
Weierstrass} from 1914. The simplified version of the original proof below
is given in [Car].
Here is the set up: Let
$0<\lambda_1<\lambda_2<\ldots$. To
each $\nu$ we get the function $x^{\lambda_\nu}$
defined on the real unit interval $0\leq x\leq 1$.
We say that the sequence $\Lambda=\{\lambda_\nu\}$
is $L^2$-dense if the family
$\{x^{\lambda_\nu}\}$
generate a dense linear subspace of the Hilbert space of
square integrable functions on $[0,1]$.
\medskip

\noindent
{\bf 9.1 Theorem.} \emph{The necessary and sufficient condition for
$\Lambda$ to be $L^2$-dense is that
$\sum\,\frac{1}{\lambda_\nu}$ is convergent.}
\bigskip

\noindent
\emph{9.2 Proof of necessity.} 
If
$\Lambda$ is not $L^2$-dense there
exists some $h(x)\in L^2[0,1]$
which is not identically zero while
\[ 
\int_0^1\, h(x)\cdot x^{\lambda_\nu}\cdot dx=0
\quad\colon\quad\nu=1,2,\ldots\tag{1}
\]
Now 
consider the function
\[ 
\Phi(\lambda)= 
\int_0^1\, h(x)\cdot x^{\vvv i\lambda}\cdot dx\tag{2}
\]
It is clear that
$\Phi$ is analytic in
the right half plane
$\mathfrak{Im}\,\lambda>0$.
If $\lambda=s+it$ with $t>0$ we have
\[ 
|x^\lambda|= x^t\leq 1
\]
for all $0\leq x\leq 1$. 
From this and the Cauchy\vvv Schwarz inequality we
see that
\[
|\Phi(\lambda)|\leq ||h||_2\quad\colon \lambda\in U_+\tag{3}
\]


\noindent 
Hence $\Phi$ is a bounded analytic function in
the upper half-plane. At the same time
(1) means that the zero set of
$\Phi$ contains the sequence 
$\{\lambda\uuu\nu\cdot i\}$.
By the  integral formula formula we have seen in XX that this entails that
\[
\sum\,\frac{1}{\lambda_\nu}<\infty\tag{*}
\]
which proves the necessity.

\medskip

\noindent
\emph{Proof of sufficiency.}
There remains to show that ifwe have the convergence in 
(*) above then
there exists a non-zero
$h$-function i $L^2[0,1]$ such that
(1) above holds. 
To find $h$ we first construct an analytic function
$\Phi$ by
\[
\Phi(z)= \frac{\prod_{\nu=1}^\infty\,
\bigl(1-\frac{z}{\lambda_\nu}\bigr)}
{ \prod_{\nu=1}^\infty\,\bigl(1+\frac{z}{\lambda_\nu}\bigr)}\cdot
\frac{1}{(1+z)^2}\quad\colon\quad \mathfrak{Re}\, z>0\tag{i}
\]
Notice that $\Phi(z)$ is defined in the right half-plane
since 
the series (*) is convergent. 
When $\mathfrak{Re}(z)\geq 0$ we notice that
each quotient
\[
\frac{1-\frac{z}{\lambda_\nu}}
{1+\frac{z}{\lambda_\nu}}
\]
has absolute value $\leq 1$.
It follows that
\[ 
|\Phi(x+iy)|\leq\frac{1}{1+x+iy|^2}=\frac{1}{(1+x)^2+y^2}\tag{ii}
\]
In particular the function $y\mapsto \Phi(iy)$
belongs to  $L^2$ on the real $y$\vvv line.
Now we set
\[
f(t)=
\frac{1}{2\pi}
\int_{-\infty}^\infty\, e^{ity}\cdot
\Phi(iy)\cdot dy\tag{ii}
\]
using the inequality (ii)
If $t<0$
we can move the line integral of $e^{tz}\cdot \Phi(z)$ from
the imaginary axis to a line $\mathfrak{Re}(z)= a$
for every $a>0$ and it is clear that

\[
\lim\uuu{a\to +\infty}\, 
\int_{-\infty}^\infty\, e^{\vvv at+ity}\cdot
\Phi(a+iy)\cdot dy=0
\]
We conclude that $f(t)=0$ when $t<0$.
Next, since $y\mapsto \Phi(iy)$ is an $L^2$\vvv function it follows by
Parseval's equality that

\[
\int\uuu 0^\infty\, |f(t)|^2\cdot dt<\infty
\]
Moreover, for a fixed $\lambda\uuu \nu$ we have
\[
\int_0^\infty\, f(t) e^{-\lambda_\nu t}\cdot dt=
\frac{1}{2\pi}\cdot \int\uuu 0^\infty\,[
\int_{-\infty}^\infty\, e^{ity}\cdot
\Phi(iy)\cdot dy\,]\cdot e^{\vvv \lambda\nu t}\cdot dt=
\]
\[
\int_{-\infty}^\infty\, \frac{1}{iy\vvv \lambda\uuu\nu}\cdot 
\Phi(iy)\cdot dy
\]
where the last equality follows when the repeated integral is reversed.
By construction $\Phi(z)$ has a zero at $\lambda\uuu\nu$
and therefore (xx) above remains true with
$\Phi$ replaced by
$\frac{\Phi(z)}{z\vvv \lambda\uuu\nu}$ which entails that

\[
\int\uuu 0^\infty\, f(t)\cdot e^{\vvv \lambda\uuu\nu t}\cdot dt=0
\]

\noindent
At this stage we obtain the requested
$h$\vvv function. Namely, since $t\mapsto e^{\vvv t}$ identifies
$(0,+\infty)$ with $(0,1)$ we get a function $h(x)$ on $(0,1)$
such that
\[ 
h(e^{\vvv t})= e^{t/2}\cdot f(t)
\]
The reader may verify
that
\[
\int\uuu 0^1\, |h(x)|^2\cdot dx=\int\uuu 0^\infty\, |f(t)|^2\cdot dt
\]
and hence $h$ belongs to $L^2(0,1)$.
Moreover, one verifies that the vanishing in (xx) above entails that
\[
\int\uuu 0^1\,  h(x)\cdot x^{\lambda\uuu\nu}\cdot dx=0
\]
Since this holds for every $\nu$ we have proved the
sufficiency which therefore finishes the proof of Theorem XX.


\newpage





\centerline{\bf § 10. Ikehara's theorem.}
\bigskip


\noindent
{\bf{Introduction.}}
The proof below was presented by Carleman during lectures at 
Institute Mittag-Leffler in 1935.
Ikehara's original result appears in Theorem 10.1 while Theorem 10.x
gives a slight extension since certain regulasrity properties are relaxed.
Let
$\nu$ be a non-negative Riesz measure supported on
$[1,+\infty)$ and assume that
\[
\int_1^\infty x^{-1-\delta}\cdot d\nu(x)<\infty\quad
\text{for all}\,\, \delta>0
\]
This gives
an analytic function
$f(s)$ of the complex variable $s$ defined in
the right half plane
$\mathfrak{Re}(s)>1$ by
\[ 
f(s)=\int_1^\infty x^{-s}\cdot d\nu(x)
\]
\medskip

\noindent
{\bf 10.1 Theorem.}
\emph{Assume that there exists a constant
$A$ and a locally integrable  function
$G(u)$ defined on the real $u$-line such that}
\[
\lim_{\epsilon\to 0}\, \int_{-b}^b\, \bigl|
f(1+\epsilon+iu)-\frac{A}{1+\epsilon+iu}-G(u)\bigr|\cdot du=0\quad
\text{holds for each}\,\, b>0\tag{*}
\]
\medskip

\noindent
\emph{Then it follows that }
\[ 
\lim_{x\to+\infty}\,\frac{1}{x}\int_1^x\,d\nu(t)=A\tag{**}
\]
\medskip



\noindent
{\emph{Proof}.
Define the  measure $\nu^*$ on the non-negative real $\xi$-line by
\[
d\nu^*(\xi)= e^{-\xi}\cdot d\nu(e^\xi)-A\cdot d\xi\,\quad\colon\,\,\xi\geq 0\tag{1}
\]

\noindent
If $\eta>1$ we notice that
\[
\int_0^\eta\, e^{-\eta+\xi}\cdot d\nu^*(\xi)=
e^{-\eta}\int_0^\eta d\nu(e^\xi)-A(1-e^{-\eta})
=e^{-\eta}\int_0^{e^\eta} d\nu(t)-A(1-e^{-\eta})
\]
\medskip


\noindent
hence (**) holds if and only if
\[
\lim_{\eta\to\infty} \int_0^\eta\, e^{-\eta+\xi}\cdot d\nu^*(\xi)=0\tag{2}
\]

\noindent
It is also clear that condition (xx) for  $\nu$ entails that
\[ \int_0^\infty\, e^{-\delta\cdot \xi}\cdot d\nu^*(\xi)<\infty
\quad\text{for all}\,\,\delta>0\tag{3}
\]

\noindent
Moreover, a variable substitution gives
\[ 
f(s)-\frac{A}{s-1}=\int_0^\infty e^{(1-s)\xi}d\nu^*(\xi)\tag{4}
\]

\medskip
\centerline {\emph{10.2  A reformulation of Ikehara's theorem.}}


\medskip

\noindent
From (1-4)   we
can restate  Ikehara's theorem.
Let
$\nu^*$ be a non-negative measure on $0\leq\xi<+\infty$
such that 
\[ \int_0^\infty\, e^{-\delta\cdot \xi}\cdot d\nu^*(\xi)<\infty
\quad\text{for all}\,\,\delta>0\tag{1.1}
\]
\medskip

\noindent
Let $A>0$ be some positive constant and define the measure $\mu$ by
\[
d\mu(\xi)=d\nu^*(\xi)-A\cdot d\xi\tag{1.2}
\]
Then (1.1) gives
the analytic function
$g(s)$ defined in $\mathfrak{Re}(s)>0$ by
\[
g(s)=\int_0^\infty\, e^{-s\cdot\xi}\cdot d\mu(\xi)\tag{1.3}
\]
\medskip

\noindent
{\bf 10.2.1. Definition.}
\emph{We say that the  measure $\mu$ is of the
Ikehara type if there exists a locally integrable function
$G(u)$ defined on the real $u$-line such that}
\[
\lim_{\epsilon\to 0}\, \int_{-b}^b\, \bigl|
g(\epsilon+iu)-G(u)\bigr|\cdot du=0\,\quad
\text{holds for each}\,\, b>0
\]
\medskip

\noindent
{\bf {10.2.2 The space $\mathcal W$.}}
Let $\mathcal W$ be the space of continuous functions
$\rho(\xi)$ defined on $\xi\geq 0$ which satisfy:
\[
\sum_{n\geq 0}\,||\rho||_n<\infty\,
\quad\text{where}\,\,||\rho||_n=\max_{n\leq u\leq n+1}\, |\rho(u)|
\]
The dual space
$\mathcal W^*$ consists of Riesz measures
$\gamma$ on $[0,+\infty)$ such that
\[ 
\max_{n\geq 0}\,\int_n^{n+1}\, |d\gamma(\xi)|<\infty
\]
With these notations we shall prove:
\bigskip

\noindent
{\bf 10.2.3. Theorem.}
\emph{Let $\nu^*$ be a non-negative meausure
on $[0,+\infty)$ and $A\geq 0$ some constant
such that the measure $\mu=\nu^*-A\cdot d\xi$
is of Ikehara type.
Then $\mu\in \mathcal W^*$
and for every
function $\rho\in\mathcal W$ one has}
\[
\lim_{\eta\to+\infty}\, \int_0^\eta
\rho(\eta-\xi)\cdot d\mu(\xi)=0
\]
\medskip

\noindent
{\bf {10.2.4 Exercise.}} 
Use the material above to show that
Theorem 10.2.3  gives Theorem 10.1 where a
hint is to use the function $\rho(s)=e^{-s}$ above.

\bigskip

\centerline {\emph{Proof of Theorem 10.2.3.}}
\bigskip

\noindent
Let $b>0$ and define the function $\omega(u)$ by
\[
\omega(u)= 1-\frac{|u|}{b}\,,\quad
-b\leq u\leq b\,\,\quad\text{and}\,\,
\omega(u)=0\,\,\text{outside this interval}\tag{i}
\]


\noindent
Set
\[ J_b(\epsilon,\eta)=
\int_{-b}^b\, e^{i\eta u}\cdot g(\epsilon+iu)\cdot \omega(u)\cdot du\tag{ii}
\]
From Definition C.1.1 we have the $L^1_{\text{loc}}$-function $G(u)$
and since $\omega(u)$ is a continuous function on the compact
interval $[-b,b]$
we have
\[ 
\lim_{\epsilon\to 0}\, J_b(\epsilon,\eta)=J_b(0,\eta)=
\int_{-b}^b\, e^{i\eta u}\cdot G(u)\cdot \omega(u)\cdot du\tag{iii}
\]
With $b$ kept fixed  the right
hand side
is a Fourier transform of an
$L^1$-function. So  the Riemann-Lebesgue theorem gives:
\[
\lim_{\eta\to+\infty}\, J_b(0,\eta)=0\tag{iv}
\]
Moreover, the triangle inequality gives the inequality:
\[
|J_b(0,\eta)|\leq 
\int_{-b}^b\,\bigl| G(u)\bigr|\cdot du\tag{v}
\]
\medskip


\noindent{\bf Some integral formulas.}
From the above
it  is clear that
\[ J_b(\epsilon,\eta)=
\int_0^\infty\,
\bigl[\int_{-b}^b\, e^{i\eta u-i\xi u}\cdot \omega(u)\cdot du\bigr]
\cdot e^{-\epsilon\cdot\xi}\cdot d\mu(\xi)\tag{1}
\]


\noindent
Next, notice that
\[
\int_{-b}^b\, e^{i\eta u-i\xi u}\cdot \omega(u)\cdot du=
2\cdot\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}\tag{2}
\]
Hence we obtain
\[ J_b(\epsilon,\eta)=
2\cdot\int_0^\infty\, 
\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}\cdot e^{-\epsilon\xi}
\cdot d\mu(\xi)\tag{3}
\]

\noindent
From (iii) above it follows that  (3)
has a limit as $\epsilon\to 0$ which is equal to 
the integral in the right hand side in (iii) which is
denoted by $J_b(0,\eta)$. Next, it is 
easily seen that there exists the limit

\[
\lim_{\epsilon\to 0}\, 
2\cdot\int_0^\infty\, 
\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}\cdot e^{-\epsilon\xi}
\cdot Ad\xi=2\pi\cdot A\tag{4}
\]
\medskip

\noindent
Hence (3-4) imply that there exists the limit
\[
\lim_{\epsilon\to 0}\, 
2\cdot\int_0^\infty\, 
\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}\cdot e^{-\epsilon\xi}
\cdot d\nu^*(\xi)=J_b(0,\eta)+2\pi\cdot A\tag{5}
\]
\medskip

\noindent
Next, the measure  $\nu^*\geq 0$ and the function
$\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}\geq 0$
for all $\xi$. So the existence of a finite limit in (5) entails that there exists
the convergent integral 
\[
\int_0^\infty\, 
\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}
\cdot d\nu^*(\xi)=J_b(0,\eta)+2\pi\cdot A\tag{6}
\]



\medskip


\noindent
{\bf Proof that
$\mu\in\mathcal W^*$.}
Since $A\cdot d\xi$ obviously belongs to
$\mathcal W^*$ it suffices to show that
$\nu^*\in\mathcal W^*$.
To prove this we consider some integer $n\geq 0$ and with $b=1$
it is clear that
(6) gives
\[
\bigl|\int_n^{n+1}\, 
\frac{1-\text{cos}\,(\eta-\xi)}{(\eta-\xi)^2}
\cdot d\nu^*(\xi)\bigr|\leq |J_1(0,\eta)|+2\pi=
\int_{-1}^1\, |G(u)|\cdot du+2\pi\cdot A
\]
Apply this with
$\eta=n+1+\pi/2$ and notice that

\[
\frac{1-\text{cos}\,(n+1+\pi/2-\xi)}{(n+1+\pi/2-\xi)^2}
\geq a\quad\,\text{for all}\,\, n\leq\xi\leq n+1
\]
This gives a constant $K$ such that
\[
\int_n^{n+1}\, d\nu^*(\xi)\leq K\quad\, n=0,1,\ldots
\]
\medskip

\noindent
{\bf {Final part of the proof.}}
We have proved that
$\mu\in \mathcal W^*$. Moreover, from
(iv) above and the integral formula (6) we get
\[
\lim_{\eta\to+\infty}\, \int_0^\infty
\frac{1-\text{cos}\,b(\eta-\xi)}{b(\eta-\xi)^2}\cdot d\mu(\xi)=0
\quad\,\text{for all}\,\, b>0\tag{*}
\]
Next, for each fixed 
$b>0$ we notice that the function
\[
\rho_b(\xi)=2\cdot \frac{1-\text{cos}\,(b\xi)}{b\cdot \xi^2}
\]
belongs to $\mathcal W$ and its
Fourier is  $\omega_b(u)$.
Here $\omega_b(u)\neq 0$ when
$-b<u<b$.
So the family of these $\omega$-functions have no common
zero on the real $u$-line. By the Remark in XX this means that
the linear subspace of
$\mathcal W$ generated by
the translates of all $\rho_b$ -functions with
arbitrary large
$b$ is dense in $\mathcal W$. 
Hence (*) above implies
that
we get a zero limit as $\eta\to+\infty$ for every function
$\rho\in\mathcal W$. But this is precisely the
assertion in
Theorem 10.2.3.




\newpage

\centerline{\bf § 11. Fourier-Carleman transforms}
\bigskip

\noindent
{\bf Introduction.}
The Fourier transform can be 
obtained from a pair of analytic functions
defined in the upper - resp. the lower half plane.
The idea is that a Fourier transform 
\[ 
\widehat g(\xi)= \int\, e^{-i x\xi}\cdot g(x)\,dx
\]
becomes a sum when we integrate over $(-\infty,0)$ respectively
$(0,+\infty)$.
For each of these  we get
analytic functions
$G_+(\zeta$ and  $G_-(\zeta)$ in the upper,  resp. the lower
half plane of the complex $\zeta$-plane where $\zeta=\xi+i\eta$.
After one can  take their boundary values.
This construction has special interest 
when
the support of the Fourier transform  has gaps, i.e. when its complement consists
of many open intervals.



\bigskip




\noindent
{\bf 3.1 The functions $G_+$ and $G_-$}.
Consider a continuous complex-valued function 
$g(x)$ defined on the real $x$-line which is   absolutely integrable:
\[
\int_{-\infty}^\infty\,|g(x)|\, dx<\infty
\]
We obtain  analytic functions $G_+(\zeta)$ and $G_-(\zeta)$
defined in the upper,  respectively the lower half-plane of the complex
$\zeta$-plane where $\zeta=\xi+i\eta$.
\[
 G_+(\zeta)=
\int_{-\infty}^0\, g(x)e^{-i\zeta x}\, dx\quad\colon\quad
 G_-(\zeta)=
\int_0^{\infty}\, g(x)e^{-i\zeta x} \,dx\tag{*}
\]
\medskip

\noindent
With $\zeta=\xi+i\eta$ we have $ |e^{-i\zeta x}|=
e^{\eta x}$. This number is  $<1$ when $x<0$ and $\eta>0$, and vice versa.
We conclude  that $G_+(\zeta)$ is analytic in $\mathfrak{Im}(\zeta)>0$
while $G_-(\zeta)$ is analytic in $\mathfrak{Im}(\zeta)<0$.
Since $|g|$ is integrable we see that $G_+$ extends continuously to
the closed upper half
 plane where
\[ 
G_+(\xi)=
\int_{-\infty}^0\, g(x)e^{-i\xi x} dx
\]
Similarly $G_-$ extends to
$\mathfrak{Im}(\zeta)\leq 0$ and we have:
\[
 G_+(\xi)+ G_-(\xi)=
\int_{-\infty}^\infty\, g(x)e^{-i\xi x} dx=\widehat g(\xi)\tag{**}
\]
\bigskip

\noindent
{\bf 3.2 The case when
$\widehat g$ has compact support.}
Then there are  two  intervals 
$(-\infty,a)$ and $(b,+\infty)$ and and  family of bounded
interval $\{(\alpha_\nu,\beta_\nu)\}$
whose union is the open complement of
$\text{Supp}(\widehat g)$.
On each such interval $G_+(\xi)+G_-(\xi)$ is identically zero.
Hence 
we get
\bigskip

\noindent {\bf 3.3 Theorem}
\emph{Put  $\Omega= {\bf{C}}\setminus\text{Supp}(\widehat g)$.
Then there exists a  function $\mathcal G\in\mathcal O(\Omega)$
such that $\mathcal G=G_+$ in the upper half plane and
$\mathcal G=-G_-$ in the lower half plane.}
\bigskip

\noindent Consider some $R>0$ which is chosen so large that
the open disc $D_R$ centered at the origin in the $\zeta$-space contains
the compact set
$\text{Supp}(\widehat g)$.
For each real $x$ the function $e^{ix\zeta}\mathcal G(\zeta)$
is again analytic in $\Omega$. Put
\[ 
J\uuu R(x)=\int_{|\zeta|=R}\,
e^{ix\zeta}\cdot \mathcal G(\zeta)\, d\zeta\tag{i}
\]
\newpage

\noindent
{\bf{Exercise.}} Show that if $[\vvv R,R]$ contains the support of $g$
then  

\[ 
J\uuu R(x)=
\int_{-R}^R\,e^{ix\xi} G_+(\xi)\,d\xi+
\int_{-R}^R\,e^{ix\xi} G_-(\xi)\,d\xi=
\int_{-R}^R\,e^{ix\xi}\cdot  \widehat g(\xi)\, d\xi
\]
\medskip

\noindent The last integral appears in Fourier's inversion formula
which gives:

\medskip

\noindent {\bf 3.4 Theorem} \emph{Let $g(x)\in
L^1({\bf{R}})$ be such that $\widehat g$
has compact support in the interval $[\vvv R\uuu *,R\uuu *]$.
Then}
\[ 
g(x)=\frac{1}{2\pi}\cdot 
\int_{|\zeta|=R}\,
e^{ix\zeta}\cdot \mathcal  G(\zeta)\, d\zeta\quad\colon\quad R>R\uuu *
\] 

\bigskip

\noindent {\bf 3.5 A more general case.} The
condition that $\widehat g$ has compact support is 
restrictive  since it implies that  $g(x)$ extends to an entire function
in the complex $z$-plane. A relaxed condition
is
that
the complement of $\text{Supp}(\widehat g)$  contains some
open  intervals both on positive and the negative real
$\xi$-axis. With  $\Omega= C\setminus\text{Supp}(\widehat g)$ we have
$\mathcal G\in\mathcal O(\Omega)$. So if $R>0$ is a positive number
such that 
$R$ and $-R$ both are outside the support of $\widehat g$
we have the equality
\[
\frac{1}{2\pi}\cdot\int_{|\zeta|=R}\,
e^{ix\zeta}\mathcal G(\zeta)\, d\zeta=
\frac{1}{2\pi}\cdot
\int_{-R}^R\,e^{ix\xi} \cdot \widehat g(\xi)\,d\xi\tag{*}
\]
\medskip

\noindent
If $\widehat g$ is absolutely integrable
Fourier's inversion formula 
gives
\[ 
g(x)=\lim_{R\to\infty}\, 
\frac{1}{2\pi}\cdot
\int_{-R}^R\,e^{ix\xi}\,  \widehat g(\xi)\,d\xi
\]


\noindent 
So when
$\widehat g\in L^1({\bf{R}})$
and  
there exists some
sequence
$\{R_\nu\}$ where $R_\nu$ and $-R_\nu$ both are outside
$\text{Supp}(\widehat g)$, then
\[
g(x)=\lim_{\nu\to\infty}\,
\frac{1}{2\pi}\cdot\int_{|\zeta|=R_\nu}\,
e^{ix\zeta}\cdot \mathcal G(\zeta)\, d\zeta\tag{**}
\]

\bigskip


\centerline {\bf 3.6 Further extensions}
\medskip

\noindent
Above we assumed that $g(x)$ was absolutely integrable which 
implies that $\widehat g$ is a bounded and continuous  function.
Suppose now that $g(x)$ is a continuous function such that
\[ 
\int_{-\infty}^\infty\,
\frac{|g(x)|}{1+|x|^N}\cdot x<\infty
\]
holds for some positive integer $N$.
We can still define the two analytic functions $G_+$ and $G_-$.
Consider the behaviour of $G_+$ as $\zeta$ approaches the real
$\xi$-line. We have by definition
\[
G_+(\xi+i\eta)=
\int_{-\infty}^0\,
g(x)^{-i\xi x}e^{\eta x}dx
\]


\noindent 
Taking absolute values we get for $\eta>0$:
\[
|G_+(\xi+i\eta)|\leq
\int_{-\infty}^0\,
\frac{|g(x)|}{(1+|x|)^N}\cdot
(1+|x|)^N\cdot e^{\eta x}dx
\]
\medskip
Notice
that when  $\alpha>0$, then the function
\[
t\mapsto (1+t)^Ne^{-\alpha t}\,\colon t\geq 0
\]
takes its maximum when $1+t=\frac{N}{\alpha}$
so the maximum value  
over $[0,+\infty)$ is 
$\leq \frac{N^N}{\alpha^N}$.
Apply this with $\eta>0$ and $x<0$ above which gives
a constant $C$ such that
\[
|G_+(\xi+i\eta)|\leq \frac{C}{\eta^N}\cdot 
\int_{-\infty}^\infty\,\frac{|g(x)| \cdot dx}{1+|x|^N}\tag{*}
\]

\medskip

\noindent Hence $G_+$ has temperate growth as $\eta\to 0$ so its boundary
value distribution $\mathfrak{b}(G_+)$
exists.
Similarly we find the boundary value distribution  $\mathfrak{b}(G_-)$.
The Fourier transform of $g(x)$  regarded as a tempered
distribution is equal to  
$\mathfrak{b}(G_+)+\mathfrak{b}(G_-)$.
Again, if $\text{Supp}(\widehat g)$ has gaps
we can proceed as in 3.5
and construct 
the complex line integral
\[
J\uuu R(x)=
\frac{1}{2\pi}\cdot\int_{|\zeta|=R}\,
e^{ix\zeta}\mathcal G(\zeta)\, d\zeta
\]
for those values of $R$ such that $-R$ and $R$ are outside
the support of $\hat g$.

\medskip

\noindent
{\bf{Exercise.}}
Let $g$ be as above and assume that
there exists a sequence $\{R\uuu\nu\}$
where
$-R\uuu\nu $ and $R\uuu\nu$ are outside the support of $g$.
Show that the following hold for
every test\vvv function
$f(x)$ 
\[
\int g(x)\cdot f(\vvv x)\, dx=
\lim\uuu {\nu\to \infty}\, 
\frac{1}{2\pi}\cdot\int_{|\zeta|=R\uuu\nu }\,
\mathcal G(\zeta)\cdot \widehat f(\zeta)\,d\zeta
\]
where $\widehat f(\zeta)$ is the entire Fourier\vvv Laplace transform of $f$.




\bigskip

\centerline{\bf 3.7 Use of Fourier's inversion formula.}

\medskip

\noindent
Consider the following situation:  Let $f(x)$ be a function in the Schwartz
class
and
assume that  $\widehat f(\xi)$ vanishes on some open
interval $a<\xi<b$. 
Set $c=\frac{a+b}{2}$
and $g(x)= e^{ixc}\cdot f(x)$. Then
we get
\[ 
\widehat g(\xi)=\widehat f(\xi+c)
\]
Here $\widehat g$ is zero on an interval centered at $\xi=0$
and we may therefore assume from the start
that $\widehat f$ is zero on some interval $(-A,A)$. Set
\[ 
F_+(x+iy)=
\frac{1}{2\pi}\cdot\int_A^\infty\, e^{(x+iy)i\xi}\,
\widehat f(\xi)\,d\xi\quad\colon\quad
F_-(x+iy)=-\frac{1}{2\pi}\cdot\int_{-\infty}^{-A}\, e^{(x+iy)i\xi}\,
\widehat f(\xi)\, d\xi
\]


\noindent
When $y=0$ we see that
\[ F_+(x)-F_-(x)=\frac{1}{2\pi}\cdot\int_{-\infty}^\infty\, e^{ix\xi}\,
\widehat f(\xi)\, d\xi\tag{*}
\]
By Fourier's inversion formula the last integral is equal to
$f(x)$ since 
$\widehat f=0$ on $(-A,A)$.
Hence $f(x)$ is represented as a difference of
two analytic functions defined in the upper and the lower
half-plane respectively where  one has  the estimates:
\[ 
\bigl|F_+(x+iy)\bigr|\leq
\int_A^\infty\, e^{-y\xi}\cdot |\widehat f(\xi)|\, d\xi\leq
e^{-Ay}\cdot\int_A^\infty\, |\widehat f(\xi)|\,d\xi\tag{1}
\]
\[
|F_-(x+iy)|\leq e^{-A|y|}\cdot\int_{-\infty}^{-A}\, |\widehat f(\xi)|\, d\xi
\tag{2}
\]


\noindent
Suppose now that $f(x)$ also is zero on some
interval, say $a<x<b$. This means that
the two analytic functions
$F_+(z)$ and $F_-(z)$ agree on this interval and  by the Schwarz
reflection principle they are analytic continuations of each other.
Hence, we get the following:
\medskip

\noindent
{\bf 3.8 Proposition.}
\emph{Assume that $\text{Supp}(f)$ is a proper subset
of ${\bf{R}}$ and consider the open complement
\[
U=\,\cup\, (a_\nu,b_\nu)
\] 
where $\{(a_\nu,b_\nu)\}$ is a family of disjoint open
intervals. Then there exists
an analytic function
$\mathcal F(z)$ defined in the connected
set
${\bf{C}}\setminus\text{Supp}(f)$ where}
\[ 
\mathcal F(z)=F_+(z)\quad\colon\,z\in U_+\quad\colon\quad
\mathcal F(z)= F_-(z)\quad\colon\, z\in U_*
\]
\emph{We refer to $\mathcal F$ as the inverse Fourier-Carleman transform of
$\widehat f(\xi)$.}
\medskip

\noindent
{\bf 3.9 A local estimate.}
Consider an open interval $(a_\nu,b_\nu)$ in $U$.
Set 
\[r=\frac{b_\nu-a_\nu}{2}\quad\colon\, 
\quad c=\frac{a_\nu+b_\nu}{2}
\]
Hence the open disc $D_r(c)$ stays in
the open set
$\Omega={\bf{C}}\setminus\text{Supp}(f)$.
Next, when
$0<\phi<\pi$ we have
\[ 
\mathcal F(c+re^{i\phi})=
\frac{1}{2\pi}\cdot
\int_A^\infty\, 
e^{(c+r\text{cos}\phi)i\xi-
r\text{sin}\,\phi\cdot\xi}\cdot
\widehat f(\xi)\cdot d\xi\
\]
Since $\bigl|e^{(c+r\text{cos}\phi)i\xi}\bigr|=1$
the triangle inequality gives
\[
|\mathcal F(c+re^{i\phi})|\leq\frac{1}{2\pi}\cdot
e^{-rA\cdot\text{sin}\,\phi}\cdot 
\int_A^\infty\,
\bigl|\widehat f(\xi)\,\bigr|\cdot d\xi\
\]
\medskip

\noindent 
When $-\pi\leq\phi\leq 0$ we get a similar 
estimate where we now use that
$\mathcal F=F_-$.
Introducing the $L^1$-norm of $\widehat f$
we conclude
\medskip

\noindent
{\bf 3.10 Proposition.} \emph{One has the inequality}
\[
\mathcal F(c+re^{i\phi}\bigr|\leq \frac{||\widehat f||_1}{2\pi}\cdot
e^{-Ar\cdot|\text{sin}\,\phi|}\quad\colon\quad 0\leq\phi\leq 2\pi
\]
\medskip

\noindent
{\bf 3.11 The subharmonic function
$U=\text{Log}\,|\mathcal F|$}.
Replacing $f$ by $c\cdot f$
with some constant $c$
we 
assume that $\frac{||\widehat f||_1}{2\pi}\leq 1$.
Then Proposition 3.10 gives the inequality
\[ 
U(c+re^{i\phi})\leq 
-Ar\cdot|\sin\,\phi\,|\quad\colon\quad -\pi\leq\phi\leq\pi
\]
\medskip
\noindent Since $U$ is subharmonic we can apply Harnack's inequality from
XX and conclude
\medskip

\noindent
{\bf 3.12 Proposition.} \emph{One has the inequality}
\[
U(x)\leq -\frac{Ar}{2\pi}\cdot \quad\colon\quad c-\frac{r}{2}\leq x\leq
c+\frac{r}{2}
\]
\medskip

\noindent
{\bf 3.13 A vanishing theorem.}
In addition to the
inequality in Proposition 3.12 which is valid for 
every open interval  of the $x$-axis outside the support of $f$, we also have
the estimate from Proposition 3.10. This gives
\[
U(x+iy)\leq -A|y|\tag{*}
\]
when 
$||\widehat f||_1\leq 2\pi$.
Now we can apply the general result from XX.
Namely, if  
suppose that there is  a sequence of disjoint intervals
$\{(a\uuu\nu,b\uuu\nu){}$ 
are outside the support of $f$.
Then 
\[
\sum\,(b_\nu-a_\nu)\cdot\int_{a_\nu}^{b_\nu}\,
\frac{dx}{1+x^2}<\infty\tag{**}
\]
must hold unless $f$ is identically zero.
This gives a uniqueness theorem which can be phrased as follows.
Let
$0<c_1<c_2\ldots$ where each $c\uuu\nu$ is the mid\vvv point of an
interval $(a\uuu\nu,b\uuu\nu)$
and these intervals are disjoint. We say that this interval family is thick if
\[
\sum\, \frac {(b\uuu\nu\vvv a\uuu\nu)^2}{c\uuu\nu^2}=+\infty
\]
\medskip

\noindent
{\bf{3.14 Theorem.}} \emph {Let $f(x)$ be a continuous function on
the $x$\vvv line be such its support is disjoint from
a thick union of intervals and 
$\widehat f(\xi)$ is integrable.
Then $\widehat f$ cannot be identically zero on any open subinterval of 
the $\xi$\vvv line unless $f$ is identically zero.}

\medskip


\noindent
{\bf Remark.}
The  proofs above are taken from  i
[Benedicks] and we refer to [loc.cit] 
for further gap-theorems
which are derived using the Fourier-Carleman
transform. 
\newpage



\centerline {\bf {§ 12. The generalised Fourier transform.}}
\bigskip

\noindent
{\bf Introduction.}
The book \emph{L'Integrale de Fourier et questions qui
s'y rattachent}  published in 1944 by
Institute Mittag-Leffler  is
based upon Carleman's lectures
at the institute in 1935.
In the introduction he writes:
\emph{C'est avant tous les travaux fondamentaux de M. Wiener
et Paley qui ont attiré mon attention}.
The  book \emph{Fourier transforms
on the complex domain} by Raymond Paley and Norbert Wiener was published
the year before.
We  expose material
from Chapter II in [Car]
which 
leads  a generalised 
Fourier transform and goes beyond the ordinary Fourier transform
for tempered distributions on the real line.
This generalised Fourier transform is used when
analytic function theory is applied to study
singular integral equations with non-temperate solutions.
An example is the
Wiener-Hopf equation
where one seeks eigenfunctions
$f(x)$ to 
the integral equation
\[ 
f(x)=\int_0^\infty\, K(x-y)f(y)dy\tag{*}
\] 
In many physical applications the kernel $K$ has
exponential decay and one seeks eigenfunctions
$f$ which are  allowed to increase  exponentially.
The major result about solutions (*) appear in
Theorem XVI on page 56 in [Pa-Wi] based upon
the 
article  
[Ho-Wi].
This  
inspired Carleman to 
the constructions  in
§ 1 below.
Let us  remark that
the generalised inversion formula  in Theorem 6.3 leads to the calculus
of 
hyperfunctions. For  comments about the relation between
Carleman's original constructions and later
studies of
hyperfunctions we refer to 
the article [Kis] by Christer
Kiselman.
\medskip


\noindent
{\bf{6.0 A special construction.}}.
Let $f(z)$ be a bounded analytic in the upper half plane
$\mathfrak{Im}\, z>0$ and suppose it
extends to a continuous function on the closed half-plane and
that the boundary function $f(x)$ is integrable, i.e.
\[
\int_{-\infty}^\infty\, |f(x)|\, dx<\infty
\]
To each $0\leq \theta\leq \pi$
we set
\[ 
G_\theta(\zeta)=
\int_0^\infty\, e^{i\zeta re^{i\theta}}\cdot f(re^{i\theta})
e^{i\theta}\, dr\tag{6.0.1}
\]
With $\zeta= se^{i\phi}$
we have
\[
 |e^{i\zeta re^{i\theta}}|= e^{-sr\sin(\phi+\theta)}
\]
Hence (6.0.1) converges if
$\sin(\phi+\theta)>0$, i.e when
\[
-\theta<\phi<\pi-\theta\tag{ii}
\]
So $G_\theta(z)$ is analytic in a half-space.
In particular $G_0$ is analytic in
$\mathfrak{Im}\,\zeta>0$ while
$G_\pi $ is analytic in the lower half-plane.
Moreover these $G$-functions are glued
as $\theta$-varies.
To see this we notice that (0.1) is the complex line integral
\[
\int_{\ell_+(\theta)}
e^{i\zeta z}\cdot f(z)
\, dz
\] 
where
$\ell_+(\theta)$ is the half-line $\{ re^{i\theta}\,\colon\, r\geq 0\}$.
Hence 
there exists an analytic function $G^*(z)$
in
${\bf{C}}\setminus [0,+\infty)$
which is equal to $G_\theta(z)$ in every half-space
defined via (ii).
Next, with $\zeta=\xi+i\eta$
there exists a limit
\[
\lim_{\epsilon\to 0}
G_0(\xi+i\epsilon)=
\int_0^\infty\, e^{i\xi x}
 f(x) \,dx
\]
Similarly the reader may verify that
\[
\lim_{\epsilon\to 0}
 G_\pi(\xi-i\epsilon )=-\int_0^\infty\, e^{-i\xi r}f(-r)\,dr=
 -\int_{-\infty}^0\,  e^{i\xi r}f(r)\,dr\tag{iii}
 \]
Passing to the usual Fourier transform of $f(x)$ we therefore get the equation
\[
\widehat{f}(-\xi)=
G_0(\xi+i0)-G_\pi(\xi-i0)\tag{iv}
\]
where we have taken boundary values of
the analytic functions $G_0$ and $G_\pi$.
Now
\[ G^*(\xi)=
G_0(\xi+i0)=G_\pi(\xi-i0)\quad\colon \xi<0\tag{v}
\]
Hence (iv) entials that 
$\widehat{f}(-\xi)=0$ 
when $\xi<0$ and reversing signs
we conclude that the support of
$\widehat{f}$ is contained
in the
half-line
$\{\xi\leq 0\}$. This inclusion has been seen before since
the $L^1$-function $f(x)=f(x+i0)$ is the boundary value of an
analytic function in
the upper half-plane.
Moreover (iv) means  that
$\widehat{f}$ on $\{\xi<0\}$
is expressed as the difference of the boundary values
of $G_0$ and $G_\pi$ taken on the positive real $\xi$-line.
Notoce that this difference is expressing obstructions for
the $G^*$-function to extend across intervals
on the positive $\xi$-line.
So in this sense $G^*$ alone
determines $\widehat{f}$.
\medskip

\noindent
The observations above which
were used in work by Plaey and Wiener
led Carelan to perform similar cointructions where
regularity and growth properties are relaxed.

\bigskip


\centerline
{\bf { 6.1 Carleman's constructions}} 
\bigskip

\noindent
Let $U^*$ be  the upper
half-plane.
To each pair of real  numbers
$a,b$ we denote
by
$\mathcal O_{a,b}(U^*)$
the family of  functions $f\in\mathcal O(U^*)$
such that for every $0<\theta_0<\pi/2$ there exists a constant
$A(\theta_0)$ and
\[ 
|f(re^{i\theta})|\leq A(\theta_0)\cdot \bigl( r^a+\frac{1}{r^b}\,\bigr )\quad\colon\quad
\theta_0<\theta<\pi-\theta_0\tag{*}
\]
\medskip

\noindent
{\bf Remark.}
No condition is imposed on the
$A$-function
as $\theta_0\to 0$.
In particular $f(z)$ need not have tempered growth
as one approaches the real line.
In the same way we define the family
$\mathcal O_{a,b}(U_*)$
of analytic functions defined in the lower half-plane $U_*$
satisfying similar estimates as above. 
\medskip

\noindent {\bf Example.} Let $f(z)$ be the ordinary Fourier-Laplace
transform
of a tempered distribution $\mu$ on the real $t$-line supported
by the half-line
$t\leq 0$.  Recall that this gives an integer $N$ and a constant
$C$ such that
\[
|f(x+iy)|\leq C\cdot y^{-N}\quad\colon\quad y>0
\]
Here we can take $a=b=N$ and $A(\theta)=\frac{C}{\text{sin}(\theta)}$
to get $f(z)$ in $\mathcal O_{a,b}(U^*)$.
\bigskip

\noindent
Let us return to the general case. 
Consider some
$f\in\mathcal O_{a,b}(U^*)$. If
$b\geq 1$ we choose a positive integer $m$ so that
$b<1+m$ and when
$0<\theta<\pi$ we consider the half space
\[
U^*_\theta=\{ z=re^{i\phi}\quad\colon
-\pi-\theta<\phi<-\theta\}
\]

\medskip
\noindent
The choice of $m$ and (*) give an analytic function
in  $U^*_\theta(z)$ defined by:
\medskip
\[ 
F_\theta(z)=\frac{i}{\sqrt{2\pi}}\cdot 
\int_0^\infty\,
e^{-iz re^{i\theta}}\cdot r^m\cdot e^{i m\theta}\cdot f(re^{i\theta})e^{i\theta}\cdot dr
\tag{i}
\]
Cauchy's theorem applied to the analytic function
$f(z)$ shows that these  $F_\theta$-functions
are glued together as we rotate the angle $\theta$
in the open interval $(0,\pi)$.
Notice  that
\[ 
\cup_{0<\theta<\pi} \, U^*(\theta)=
{\bf{C}}\setminus [0,+\infty)\tag{ii}
\]
Hence there exists  an analytic function $F^*(z)$
in
${\bf{C}}\setminus [0,+\infty)$ such that
\[
F^*\bigl |\, U^*_\theta=G_\theta\quad\colon\quad 0<\theta<\pi\tag{iii}
\]

\medskip

\noindent
Next, let $U_*$ be the lower half-plane where one defines the family
$\mathcal O_{a,b}(U_*)$.
If 
$g(z)$ belongs to  $\mathcal O_{a,b}(U_*)$
we obtain exactly as above 
analytic functions

\[ 
G_\theta(z)=\frac{i}{\sqrt{2\pi}}\cdot
\int_0^\infty\,
e^{iz re^{i\theta}}\cdot r^m\cdot e^{im\theta}\cdot g(re^{-i\theta})e^{-i\theta}\cdot dr
\quad\colon\quad 0<\theta<\pi
\]
defined in the half-planes
\[ 
U_*(\theta)=\{ z=re^{i\phi}\quad\colon
-\pi+\theta<\phi<\theta\}
\]
These $G_\theta$-functions are again glued together and give 
an analytic function $G_*(z)$   in 
${\bf{C}}\setminus(-\infty,0]$ where
which satisfies:
\[
G_*\bigl|\, U_*(\theta)=G_\theta
\quad\colon\quad 0<\theta<\pi\tag{iii}
\]

\medskip

\noindent
{\bf The $\mathcal{S}$-transform.}
Consider a pair  $f\in\mathcal{O}_{a,b}(U^*)$
and $g\in \mathcal{O}_{a,b}(U_*)$.
We get the functions $F^*$ and $G_*$ and here
$G_*-F^*$
is analytic outside the real axis and 
can be restricted to both the upper and the lower
half-plane. This enable us to give the following:
\medskip

{\noindent
{\bf 6.2 Definition.} \emph{To every pair $f,g$ as above we set}
\[ 
\mathcal{S}^*(z)=G_*( z)-F^*(z)\quad\colon\quad
\mathfrak{Im}(z)>0
\]
\[
\mathcal{S}_*(z)= 
G_*( z)- F^*( z)\quad\colon\quad
\mathfrak{Im}(z)<0
\]
\medskip

\noindent
{\bf Remark.}
The constructions of $F^*$
and $G_*$ entail that
$G_*\vvv F^*$  restricts to a function in
$\mathcal O_{a,b}(U)$ when
$U$ is the upper or the lower half-plane.
Hence $\mathcal S$ is a map from
$ O_{a,b}(U^*)\times \mathcal O_{a,b}(U_*)$ into itself.
\medskip

\noindent
{\bf 6.3 The reflection  operator.}
If $\phi\in\mathcal{O}(U^*)$ 
we get the analytic function in the lower
half-plane defined by
\[ 
T(\phi)(z)=\bar \phi(\bar z)
\]
In the same way $T$ sends an analytic function defined in $U_*$ to an
analytic function defined in $U^*$.
The
composed operator
$T\circ\mathcal{S}$   gives a pair
of analytic functions  defined by
\[
(T\circ\mathcal {S})^*(z)=\mathcal {\bar S}_*(\bar z)
\quad\colon\quad
\mathfrak{Im}(z)>0
\]
\[
(T\circ\mathcal {S})_*(z)=\mathcal {\bar S}^*(\bar z)
\quad\colon\quad
\mathfrak{Im}(z)<0
\]



\bigskip

\noindent
With the notations  above 
the  result below
extends Fourier's  inversion formula for tempered
distributions.
Below $\simeq$ means that two functions
differ by a polynomial in $z$.
\medskip

\noindent
{\bf 6.3 Inversion Theorem.}
\emph{For each pair $(f,g)$
in $\mathcal O_{a,b}(U^*)\times\mathcal O_{a,b}(U^*)$
one has}
\[
T\circ\mathcal{S}\circ T\circ\mathcal{S}(f)\simeq f
\quad\colon\quad
T\circ\mathcal{S}\circ T\circ\mathcal{S}(g)\simeq g
\]
where $\simeq$ means that
the differences are polynomials in $z$.
\medskip

\noindent
{\bf Remark.}
Theorem 6.3 is the assertion from p. 49
in [Car]. For details of the proof we refer to
[loc.cit. p. 50-52]. The proof relies upon
results of  analytic extensions across 
a real interval.
Since these results  have independent  interest 
we proceed to discuss material from  from [ibid]
and once
this has   been done we leave it to the reader
to discover
the proof of Theorem 6.3 or consult Carleman's proof.

\bigskip


\centerline {\bf 6.4 Some analytic extensions.}
\medskip

\noindent
Let $D$ be the unit disc centered at
the  origin and set
\[
D^*=D\cap\mathfrak{Im}(z)>0\quad\text{and}\quad
D_*=D\cap\mathfrak{Im}(z)<0
\]

\noindent
{\bf 6.5 Theorem.}
\emph{Let  $f^*\in\mathcal O(D^*)$
and 
$f_*\in\mathcal O(D_*)$ be such that}
\[
\lim_{y\to 0}\, f^*(x+iy)-f_*(x-iy)=0 \tag{*}
\]
\emph{holds uniformly with respect to $x$. 
Then there exists $F\in\mathcal O(D)$
with $F|D^*=f^*$
and
$F|D_*=f_*$.}


\medskip

\noindent
{\bf Remark.}
No special assumptions are imposed on
the two functions except for (*). For example, it is from
the start not assumed that they  have moderate growth as  one approaches
the real $x$-line in (*).
\medskip

\noindent
\emph{Proof.}
In $D^*$ we get the analytic function
\[ 
G(z)=f^*(z)-\bar f_*(\bar z)\tag{i}
\]
Write $G=U+iV$ and notice that
(*) gives
\[ 
\lim_{y\to 0}\, U(x,y)=0\tag{ii}
\]
Hence the harmonic function $U$ in $D^*$
converges uniformly to zero on
the part of $\partial  D^*$
defined by $y=0$.
If $\delta>0$ is small we restrict $U$ to the
upper half-disc $D^*(\delta)$
of radius
$1-\delta$. Now (ii) implies that
when $G$ is expressed by the Poisson kernel of
$D^*(\delta)$ then the boundary integral is only taken over
the upper half-circle.
It follows by the analyticity of the kernel function for
$D^*(\delta)$ that $G(x,y)$ extends to 
a real analytic function across the
the real interval $-1+\delta<x<1-\delta$.
The same holds for the derivatives
$\partial G/\partial x$ and $\partial G/\partial y$.
The Cauchy Riemann equations show that
the complex derivative of $F(z)$ extends analytically across
the real interval and   the reflection principle by
Schwarz finishes the proof.




                                                                                                        
\medskip

\noindent
{\bf 6.6 Another continuation.}
We 
expose  another result from
[ibid]. See 
[Car: p. 40: Théorème 3] whose the essential ingredient is 
a subharmonic property for the radius of convergence of analytic functions.
Put  
\[
\square=\{ (x,y)\,\colon\, -1<x<1\quad\text{and}\quad 0<y<1\}
\]
Consider some
$F(z)\in\mathcal  O(\square)$.
With a  small $\ell>0$ we put
\[
D_+(\ell)=\{ |\zeta|<\ell\,\cap \mathfrak{Im}(\zeta)>0\}
\]
With $z_0=x_0+iy_0$ where $-1/2<x_0<1/2$ and $0<y_0<1-\ell$.
we get an analytic function
\[ 
G_\zeta(z)= F(z+\zeta)-F(z)\tag{i}
\]
which is defined in some neighborhood of $z_0$. It has a series expansion:
\[ 
G_\zeta(z)=F(z+\zeta)-F(z)=\sum\, P_\nu(\zeta)(z-z_0)^\nu\quad \text{where}:
\]
\[
P_\nu(\zeta)=
\frac{1}{\nu !}\cdot [F^{(\nu)}(z_0+\zeta)-F^{(\nu)}(z_0)]\tag{*}
\]
\medskip
Let
$\rho(\zeta)$ be the radius of convergence for the series (*).
Hadamard's formula gives:
\[ 
\log\,\frac{1}{\rho(\zeta)}=
\limsup_{\nu\to\infty}\,
\frac{\log\,|P_\nu(\zeta)|}{\nu}\tag{**}
\]


\noindent
Suppose we knew that
\[
\rho(\zeta)\geq y_0\quad\colon\quad
\zeta\in D_+(\ell)\tag{***}
\]
Then we can pick $\zeta=\frac{iy_0}{2}$
and conclude that the function
\[ 
z\mapsto F(z+\frac{iy_0}{2})-F(z)\tag{ii}
\]
is analytic in the disc $|z-z_0|<y_0$.
At the same time
the function $z\mapsto F(z+\frac{iy_0}{2})$ is analytic when
$\mathfrak{Im}(z)>-\frac{y_0}{2}$
and hence  $F(z)$ extends as an analytic function
across a small interval on the real $x$-axis centered at $x_0$.
So if  (***) holds for every
$-1/2<x_0<1/2$. it follows that
$F(z)$ extends analytically across
the real interval $-1(2<x<1/2$.
There remains to find a condition on $F$ in order that
(***)  holds. Notice  that it suffices to get (***)
for sufficiently small $y_0$ if we seek 
some analytic extension of $F$ across the real $x$-line.
To obtain (***) Carleman imposed the following:


\medskip

\noindent
{\bf 6.7 Hypothesis on $F$}. \emph{There exists a pair 
$\ell>0$ and $\delta>0$ such that if $\xi$ is real with
if $|\xi|<\ell$ then $z\mapsto G_\xi(z)$
extends to an analytic function
in the domain where
$|z|<1/2$ and $\mathfrak{Im}(y)>-\delta$.}
\medskip

\noindent
It is clear that this hypothesis implies that
if $y_0$ is sufficiently small then
there exists a constant $k$ such that
\[ 
|P_\nu(\zeta)\leq k^\nu\quad\colon\quad \zeta\in D_+(\ell)\quad\colon \nu=1,2,\ldots\tag{1}
\]


\noindent
Moreover, we see from a figure that the hypothesis also implies that
\[
\rho(\zeta)\geq y_0\quad\colon
\quad |\zeta|=\ell\quad\colon\mathfrak{Im}(\zeta)\geq 0\tag{2}
\]
It is also trivial that
\[
\rho(\zeta)\geq y_0\quad\colon  |\zeta|=\ell\quad\colon\mathfrak{Im}(\zeta)= 0\tag{3}
\]


\medskip
\centerline{\emph{Proof that  (***) holds}}

\medskip
\noindent
The functions
$\zeta\mapsto \log\,|P_\nu(\zeta)|$ are subharmonic in
$D_+(\ell)$ for every $\nu$.
So if $G$ is Green's function for 
$D_+(\ell)$ we have the inequality

\[
\log\, |P_\nu(\zeta)|\leq
\frac{1}{2\pi}\int_{\partial D_*(\ell)}\,
\frac{\partial G(\zeta,w)}{\partial n_w}\cdot 
\frac{\log\, |P_\nu(w)|}{\nu}\cdot |dw|\tag{i}
\]


\noindent
Now (1) above entails that
\[
\frac{\log\, |P_\nu(w)|}{\nu}\leq k\quad\colon
w\in\partial D_+(\ell) \tag{ii}
\]
At the same time (2-3) and Hadamard's formula give
\[
\limsup_{\nu\to\infty}\,
\frac{\log\, |P_\nu(w)|}{\nu}
\leq \log\, \frac{1}{y_0}
\quad\colon w\in\partial D_+(\ell)
\tag{iii}
\]
\medskip

\noindent Thanks to (ii) we can apply Lebesgue's dominated convergence theorem
when we pass to the limes superior  in (i) and hence (iii) gives
\[
\limsup_{\nu\to\infty}\,
\frac{\log\, |P_\nu(\zeta)|}{\nu}
\leq \log\, \frac{1}{y_0}\quad\colon\zeta\in D_+(\ell)\tag{iv}
\]

\noindent
Now we apply  Hadamard's formula for points in
$D_+(\ell)$ and  (***) follows.
\bigskip

\noindent
{\bf Remark.}
The continuation found above can be applied to relax the
assumption in 
Theorem 6.5. For example, there exists
an analytic
extension for a pair $f^*,f_*$
under the less restrictive condition that
\[
\lim_{y\to 0}\, \int_a^b\, \bigl [f^*(x+iy)-f_*(x-iy)\bigr ]\cdot dx=0
\]
\medskip

\noindent
This follows when
6.6  is applied to the primitive functions of the pair.


\newpage







\centerline{\bf{§ 13. The Carleman-Hardy theorem.}}



\bigskip

\noindent
Before we announce and prove Theorem 13.x
we recall the Dini condition which ensures that converges pointwise
in Fourier's inversion formula.
Let $f(x)$ be  an  even and continuous function
which is zero outside $[-1,1]$.
\medskip

\noindent
{\bf{13.1 Dini's condition.}} \emph{It holds at $x=0$ when}
\[ 
\int_0^1\,\frac{|f(x)|}{x}\cdot dx<\infty\tag{*}
\]
From now on (*) is assumed. Since $f$ is even we have:
\[ 
\widehat f(\xi)=2\cdot\int_0^1\, \text{cos}(x\xi)\cdot f(x)\cdot dx
\]
With $A>0$ we set
\[
\gamma(A)=\frac{1}{2\pi}\int_{-A}^A\, \widehat f(\xi)\cdot d\xi\tag{1}
\]
Our aim is to show that Dini's condition implies that
\[ 
\lim_{A\to\infty}\,\gamma(A)=f(0)\tag{**}
\]

\medskip

\noindent
To prove (**) we first evaluate (1) which gives
\[ 
\gamma(A)=\frac{2}{\pi}\int_0^1\, \frac{\text{sin}(Ax)}{x}\cdot f(x)\cdot dx\tag{2}
\]
Next, we have the limit formula
\[
\lim_{A\to\infty}\frac{2}{\pi}\int_0^1\, \frac{\text{sin}(Ax)}{x}\cdot dx=
\frac{2}{\pi}\int_0^A\, \frac{\text{sin}(t)}{t}\cdot dt=1\tag{3}
\]
So in order to get
$\gamma(A)\to f(0)$ we can replace $f$ by $f(x)-f(0)$, i.e.
it suffices to show that $\gamma(A)\to 0$ when
$f(0)=0$ is assumed. To obtain this
we  fix some $0<\delta<1$
and put
\[
\gamma_\delta(A)=\frac{2}{\pi}\int_0^\delta\, \frac{\text{sin}(Ax)}{x}\cdot f(x)\cdot dx
\tag{4}
\]
\medskip


\noindent
Since $|\text{sin}(Ax)|\leq 1$
the triangle inequality gives
\[
\gamma_\delta(A)\leq\int_0^\delta\,\frac{|f(x)|}{x}\cdot dx<\infty\tag{5}
\] 
for all $A$ and every $\delta>0$. Dini's condition implies that the right
hand side tends to zero as $\delta\to 0$.
Next, we
set
\[ 
\gamma^\delta(A)= \frac{2}{\pi}\int_\delta^1\, \
\frac{\text{sin}(Ax)}{x}\cdot f(x)\cdot dx\tag{6}
\]
Here  $\frac{f(x)}{x}$ 
is continuous on $[\delta,1]$ and has therefore
a finite modulus of continuity, i.e. we get the function
\[
\omega_\delta(r)=\max_{\delta\leq x_1,x_2\leq 1}
\, \bigl|\frac{f(x_1)}{x_1}-\frac{f(x_2)}{x_2}\bigr|
\quad\text{where}\quad |x_1-x_2|\leq r\tag{7}
\]
With these notations one has  the inequality:
\[
\gamma^\delta(A)
\leq\frac{8\pi}{\pi}\cdot 
\omega_\delta(\frac{2\pi}{A})\tag{***}
\]
The verification is left to the reader as an exercise.
We remark only that the extra factor 4 replacing 2 by 8 comes form
$4=\int_0^{2\pi}\, |\text{sin}(t)|\cdot dt$.
Hence we have
\[ 
\gamma(A)\leq \gamma_\delta(A)+\frac{8\pi}{\pi}\cdot 
\omega_\delta(\frac{2\pi}{A})\tag{8}
\]
This holds for all pairs $\delta$ and $A$ and now we conclude
that
Dini's condition indeed gives
the  limit formula in (**).

\medskip

\noindent
{\bf{Remark.}}
Above $x=0$. More generally we can impose 
Dini's condition
for $f$ at an arbitrary point $a$, i.e. for every $a$ we set

\[
D_f(a)=\int\, \frac{|f(x)-f(a)|}{|x-a|}\cdot dx
\]
The results above show that whenever 
$D(a)<\infty$ one has a pointwise limit
\[
f(a)=\lim_{A\to\infty}\, \frac{1}{2\pi}\cdot
\int_{-A}^A\, e^{ia\xi}\cdot \widehat f(\xi)\cdot d\xi\tag{1}
\]
An example when this occurs is when $f(x)$ is Hölder continuous of some order
$>0$.


\bigskip

\noindent
{\bf{13.2  Another criterion for pointwise convergence.}}
Let $u(x)$ be  an even   $L^1$-function
which is  zero outside $[-1,1]$ and 
of class $C^2$ when $x\neq 0$. Moreover,  we assume
that there exists a constant $C$ such that
\[
|u''(x)|\leq \frac{C}{x^2}\quad\colon\quad x\neq 0\tag{13.2.1 }
\]
Since $u$ is an $L^1$-function we can construct the Fourier
series
\[ 
F_u(x)=\sum_{n=0}^ \infty \, A_n
\cdot \text{cos}\,nx\quad\text{where}\quad A_n=\frac{1}{2\pi}\int_0^{2\pi}\,
\text{cos}(n\xi)\cdot u(\xi)\cdot d\xi
\]
Since $u$ is a $C^2$-function when $x\neq 0$
the series converges uniformly to $u$ on
every interval $[\delta,1]$ when $0<\delta<1$.
There remains to analyze the situation at $x=0$.
The following result was proved by Carleman and Hardy in 
their joint article \emph{xxx}.

 

\medskip

\noindent{\bf{13.3  Theorem.}} \emph{Under the conditions above
the series $\sum\, A_n$ converges
if and only if there exists a finite  limit}
\[
\lim_{x\to 0}\, u(x)=S_*
\]
\emph{Moreover, when this holds one has the equality
$\sum\, A_n=S_*$.}

\medskip


\noindent
The proof of relies upon some
inequalities about differentiable functions which we begin to expose.

\medskip


\noindent
{\bf{13.4 Lemma.}}
\emph{Let $\psi(x)$ be a $C^1$-function defined for $x>0$
such that}
\[
\lim_{x\to 0}\,\psi(x)=0\quad\text{and}\quad |\psi'(x)|\leq \frac{C}{x}\quad \colon
x>0
\] 

\noindent
\emph{holds for some constant $C$. Then it follows that}
\[ 
\lim_{x\to 0}\,  \psi'(x)=0\tag{*}
\]


\noindent 
The  proof is left as an exercise to the reader. See also
the article \emph{Contributions to the Arithmetic Theory of Series}
by Hardy and Littlewood for
further   limit formulas of
higher order derivatives.
Next we establish a 
result due to Landau
from  the article
\emph{Einige ungleichungen für zweimal differentierbare Funktionen}.
\medskip

\noindent 
{\bf{13.5 Proposition.}}
\emph{Let $\psi(x)$
be a $C^3$-function defined on $x>0$ such that}
\[ 
\lim_{x\to 0} \,\frac{\psi(x)}{x^2}=0\quad\text{and}\quad |\psi'''(x)|\leq \frac{C}{x}
\tag{i}
\] 
\emph{hold for some constant  $C$.
Then it follows  that}
\[
\lim_{x\to 0} \,\psi''(x)=0\tag{ii}
\]



\noindent
\emph{Proof.} Let $x>0$ and set $\xi=\zeta\cdot x$ where $0<\zeta<1/2$.
Keeping these numbers fixed, Taylor's formula gives
\[
\psi(x+\xi)+\psi(x-\xi)-2\psi(x) =\xi^2\psi''(x)+
\frac{\xi^3}{6}\cdot [\psi'''(x+\theta_1\xi)-
\psi'''(x-\theta_2\xi)]\quad\colon\,0<\theta_1,\theta_2<1
\]

\noindent
The triangle inequality gives
\[
|\psi''(x)|\leq 
\]
\[
\frac{1}{\xi^2}\cdot [
|\psi(x+\xi)|+|\psi(x-\xi)|+2|\psi(x)|]+
\frac{\xi^3}{6}\cdot [\bigl(|\psi'''(x+\theta_1\xi)|+
|\psi'''(x-\theta_2\xi)|\bigr)\tag{2}
\]
By the second condition
in (i) the last term  above is majorised by
\[
\frac{C}{6}\cdot \xi\cdot (\frac{1}{x+\theta_1\xi}+\frac{1}{x-\theta-2\xi}]
\leq
\frac{C}{6}\cdot \frac{2\zeta}{1-\zeta}\tag{3}
\]
Given $\epsilon>0$ we can choose $\zeta$ 
so small that (3) is
$<\epsilon/2$.
Next,
keeping $\zeta$ fixed the first term in (2) above is majorised by
\[
\frac{1}{\zeta^2x^2}\cdot\bigl[
(1+\zeta)^2\cdot o(x^2)+
(1-\zeta)^2\cdot o(x^2)+2\cdot o(x^2)\bigr]\tag{4}
\]
where the small ordo terms follows from the first condition in (i).
Now  (ii) in Proposition  13.2  follows from the inequality (2) above.
\bigskip





\centerline {\bf{Proof of Theorem 13.3}}
\bigskip




\noindent
Assume first that $\sum\, A_n$ converges  and
define the  following two functions  when $x>0$:
\[ 
U(x)=\frac{1}{2}A_0\cdot x^2+\sum_{n=1}^\infty\, \frac{A_n}{n^2}
\cdot(1-
\text{cos}(nx))\tag{i}
\]
\[ 
V(x)=\int_0^x\,\bigl[\int_0^y\,u(s)\cdot ds\,\bigr]\cdot dy\tag{ii}
\]
In (i) $U(x)$ is the associated Riemann function of $u$.
Since $u$ is of class $C^2$ when $x>0$ it is clear that
$U''(x)=V''(x)$ when $x>0$ and hence
$U(x)-V(x)$ is a linear function $C+Dx$ on $(0,+\infty)$.
Since $u$ by assumption is an $L^1$-function we see that
$V(x)=o(x)$ and we also have $U(x)=o(x^2)$ 
by a classical result known as Riemann's Lemma.
It follows that $C=D=0$, i.e. the functions
$U$ and $V$ are identical which gives
\[ 
V(x)=o(x^2)
\]
Next, notice that
\[ 
x>0\implies V'''(x)=u'(x)\tag{ii}
\]
By (13.2.1) we have
$|u''(x)|\leq \frac{C}{x^2}$ which  
gives another constant $C^*$ such that
$|u'(x)|\leq \frac{C^*}{x}$. Hence
(ii) implies 
that
$V$ satisfies the Landau conditions in Proposition 13.5  which gives:
\[ 
\lim_{x\to 0} V''(x)=0\tag{iii}
\]
Finally, since $V''(x)= u(x)$  when $x>0$ we conclude that
$\lim_{x\to 0}\, u(x)=0$. This proves one half of Theorem 13.3
\medskip

\noindent
{\bf{The case $\lim_{x\to 0}\,u(x)=0$}}. 
There remains to
show that when this limit condition holds, then 
the series $\sum\, A_n$ converges. By assumption 
$|u''(x)|\leq \frac{C}{x^2}$
which gives a constant $C^*$ such that
$|u'(x)|\leq \frac{C^*}{x}$ and   Lemma 13.4 gives
\[
\lim_{x\to 0}\, u'(x)=0\tag{i}
 \]

 \medskip
\noindent
Next, we use
a  result by Lebesgue from his book
\emph{Lecons des series trigonmétriquees} which asserts that the
series $\sum\, A_n$ converges if
\[
\lim_{\epsilon\to 0} 
\int_\epsilon^1\, \frac{|u(x+\epsilon)-u(x)|}{x}\cdot dx=0\tag{ii}
\]
To get (ii) we use Rolle's theorem and write
\[
u(x+\epsilon)-u(x)=\epsilon\cdot u'(x+\theta\cdot\epsilon)\tag{iii}
\]
Now it is clear that (i) and (iii) give (ii) which finishes the proof that
$\sum\,A_n$ is convergent.




\newpage

\centerline{\bf{14. The use of  subharmonic majorizations.}}
\bigskip

\noindent
Let $\{0<\beta\uuu 1<\beta\uuu 2<\ldots\}$ be a sequence of positive real numbers.
Given $a>0$ we construct harmonic functions in the right half\vvv plane
$\Omega=\{\mathfrak{Re}\, z> a\}$ as follows: Set $q\uuu\nu=a+i\beta\uuu\nu$ and
to each $z\in\Omega $  we get  the triangle
with corner points at the three points $z,eq_\nu,eq\uuu{\nu+1}$
where $e$ is Neper's constant.
Denote the angle at $z$ by $\theta\uuu\nu(z)$. Notice that 
$0<\theta_\nu(z)<\pi$.
As explained in
§ XX  $\theta_\nu(z)$ is a harmonic function
with the boundary value $\pi$  on $\mathfrak{Re}\, z=a$
when  $\beta\uuu\nu<y<\beta\uuu{\nu+1}$ 
while the boundary value is zero outside the closed 
$y$\vvv interval $[\beta\nu,\beta\uuu{\nu+1}]$.
If we instead consider the points $\{q^*\uuu\nu=a\vvv ie\beta\uuu\nu\}$
we get similar harmonic angle functions
$\{\theta\uuu\nu^*\}$
when we regard the angle at $z$ formed by the triangle
with corner points at $z \vvv eq\uuu\nu,\vvv eq\uuu{\nu+1}$.

\medskip

\noindent
{\bf{Exercise.}} Show by euclidian geometry that
if $b<0$ is real and positive then
\[ 
\sin\,\theta\uuu\nu(a+b)= \frac{eb(\beta\uuu{\nu+1}\vvv\beta\uuu\nu)}{
\sqrt{ (\beta\uuu\nu^2+b^2)(\beta\uuu{\nu+1}^2+b^2)}}\tag{1}
\]
Use also that $\beta\uuu \nu<\beta\uuu{\nu+1}$ and show
that (1) gives

\[
\theta\uuu\nu (a+b)> \frac{e b\beta\uuu 1^2\cdot (\beta\uuu{\nu+1} \vvv\beta\uuu\nu)}
{\beta\uuu{\nu+1}\cdot \beta\uuu\nu\cdot(e^2 \beta\uuu 1^2+b^2)}=
C(b,\beta\uuu 1)\cdot (\frac{1}{\beta\uuu\nu}\vvv\frac{1}{\beta\uuu{\nu+1}})
\quad\colon\quad
C(b,\beta\uuu 1)=\frac{e b\beta\uuu 1^2}{e^2 \beta\uuu 1^2+b^2}
\]

\medskip

\noindent
In addition to these $\theta\uuu\nu$\vvv functions we get the angle functions
$\{\theta^*\uuu n\}$ where we for each $n\geq 2$ consider the
harmonic extension to the half\vvv plane whose boundary
values are $\pi$  on $y>\beta\uuu n$ and zero when
$y<\beta\uuu n$.
This harmonic function is denoted by $\theta^*\uuu n(z)$
and by a figure the reader can verify  that
\[
\sin\, \theta^*\uuu n(a+b)=\frac{b}{\beta\uuu n^2+b^2)}\implies
\theta^*\uuu n(a+b)>\frac{eb\beta\uuu 1^2}{e^2 \beta\uuu 1^2+b^2}
\cdot \frac{1}{\beta\uuu n}\tag{2}
 \]
 





\medskip

\noindent
{\bf{7.1 A class of harmonic functions.}}
Let us also consider a sequence
of positive real numbers
$\{\lambda\uuu\nu\}$. To each  $n\geq 2$ we get the harmonic function
$u\uuu n(x,y)$ in $\Omega$
defined by
\[
u\uuu n(x,y)=\frac{1}{\pi}\cdot \sum\uuu{\nu=1}^{\nu=n\vvv 1} \lambda\uuu\nu\cdot
(\theta\uuu\nu+\theta^*\uuu\nu)+
\lambda\uuu n\cdot (\theta\uuu n+\theta^*\uuu n)\tag{3}
\]
If $z=a+b$ is real with $b>0$ the inequalities in (1\vvv 2) give
\[
u\uuu n(a+b)\geq \frac{C(b,\beta\uuu 1)}{\pi}
\cdot
\bigl[\, \sum\uuu{\nu=1}^{\nu=n\vvv 1}\,
\lambda\uuu\nu(\frac{1}{\beta\uuu\nu}\vvv \frac{1}{\beta\uuu{\nu+1}})+
\frac{\lambda\uuu n}{\beta\uuu n}\,\bigr]\tag{4}
\]



\noindent
From the above we get:


\medskip

\noindent
{\bf{7.2 Proposition.}}
\emph{Let $\{\lambda\uuu\nu\}$ and $\{\beta\uuu\nu\}$ be such that}
\[ 
\lim\uuu{n\to\infty}\,
\bigl[\, \sum\uuu{\nu=1}^{\nu=n\vvv 1}\,
\lambda\uuu\nu(\frac{1}{\beta\uuu\nu}\vvv \frac{1}{\beta\uuu{\nu+1}})=+\infty\tag{*}
\]
\emph{Then the sequence $\{u\uuu n(a+b)\}$ increases to $+\infty$ for every $b>0$.}

\medskip

\noindent
{\bf{Remark.}} If  
the $\lambda$\vvv sequence  increases  a partial summation gives
\[
\sum\uuu{\nu=1}^{\nu=n}\, \frac{\lambda\uuu \nu\vvv\lambda\uuu{\nu\vvv 1}}
{\beta\uuu\nu}= \sum\uuu{\nu=1}^{\nu=n\vvv 1}\,
\lambda\uuu\nu(\frac{1}{\beta\uuu\nu}\vvv \frac{1}{\beta\uuu{\nu+1}})
\]
where we have put $\lambda\uuu 0=0$. Hence (*) is equivalent to the divergence of
the 
positive series 
\[
\sum\uuu{\nu=1}^\infty \, \frac{\lambda\uuu \nu\vvv\lambda\uuu{\nu\vvv 1}}
{\beta\uuu\nu}\tag{**}
\]
\medskip


\noindent
{\bf{7.3 An application.}}
Let $\{\beta\uuu\nu\}$ and $\{\lambda\uuu\nu\}$ 
be  two  strictly increasing sequences
of positive real numbers.
Consider an analytic function $\Phi(z)$ defined in
the half\vvv plane $\mathfrak{Re}\,z>a$ with continuous
boundary values on $\mathfrak{Re}\,z=a$ which satisfies the inequalities

\[
|\Phi(z)|\leq \bigl(\frac{\beta\uuu\nu}{|z|}\,\bigr )^{\lambda\uuu\nu}
\quad\colon\quad \nu=1,2,\ldots\tag{*}
\]
\medskip

\noindent
{\bf{7.4 Exercise.}}
Denote by $u\uuu *(z)$ the harmonic function in
the half\vvv plane whose boundary values are one on
$\vvv\beta\uuu 1<y<\beta\uuu 1$ and otherwise zero.
Show that   (*) 
gives the following inequality on
$\mathfrak{Re}\, z=a$ for every $n\geq 0$ and $-\infty<y<+\infty$
 \[
\log\,|\Phi(a+iy)|+u\uuu n(a+iy)\leq 
\log K\cdot u\uuu *(a+iy)\quad\colon\quad 
K=\max\uuu {\vvv\beta\uuu 1\leq  y\leq \beta\uuu 1}\, |\Phi(a+iy)|\tag{7.4.1}
\]

\medskip

\noindent
Since $u\uuu n$ and $u\uuu *$ are  harmonic functions
while $\log\,|\Phi\,|$ is subharmonic, 
the principle of harmonic majorization implies that  (7.4.1) holds
in $\Omega$.
In particular, for every
real 
$b>0$ we have
\[
\log\,|\Phi(a+ib)|+u\uuu n(a+ib)\leq \log K\cdot u\uuu *(a+ib)\tag{7.4.2}
\]


\noindent
When $\Phi$ is not identically zero  we can  fix some
$b>0$ where
$\Phi(a+ib)\neq 0$ and (7.4.2) entails that
the sequence $\{u\uuu n(a+ib)\}$ is bounded.
Hence Proposition 7.2  gives

\medskip

\noindent
{\bf{7.5 Theorem.}} \emph{Assume there exists a non\vvv zero analytic function
$\Phi(z)$ in the half\vvv plane
$\mathfrak{Re}\, z>a$ such that (*) holds in (7.3). Then}
\[
\sum\uuu{\nu=1}^\infty \, \frac{\lambda\uuu \nu\vvv\lambda\uuu{\nu\vvv 1}}
{\beta\uuu\nu}<\infty
\]
\medskip

\noindent
{\bf{Remark.}} We can rephrase the result above and get a 
vanishing principle. Namely, if the positive series in Theorem 7.5 is divergent
an analytic function $\Phi(z)$ in the half\vvv plane satisfying
(7.3) must be identically zero.
\medskip


\noindent
{\bf{7.6 Example.}}
Let $\{c\uuu n\}$ be a sequence of positive real numbers.
Suppose that $\Phi(z)$ is analytic in the half\vvv space
and satisfies
\[
|\Phi(z)|\leq \frac{c\uuu n}{|z|^n}\quad\colon\quad n=1,2,\ldots
\]
Then $\Phi$ must vanish identically if the series

\[
\sum\uuu{n=1}^\infty\, \frac{1}{c\uuu n^{\frac{1}{n}}}=+\infty
\]




\newpage

\centerline{\bf {15. Convergence under substitution.}}
\bigskip

\noindent
{\bf{Introduction.}}
Let $\{a_k\}$ be a sequence of complex numbers where the additive series
$\sum\, a_k$ is convergent. This gives an analytic function
$f(z)$ defined in the open disc by
\[
f(z)=\sum\, a\uuu n\cdot z^n\tag{1}
\]
If $0<b <1$
we can expand $f$ around $b$ and obtain another series
\[
f(b+z)=\sum\, c\uuu n\cdot z^n\tag{2}
\]
From the   convergence of $\sum\, a\uuu k$
one  expects 
that the series
\[
\sum\, c\uuu n\cdot (1\vvv b)^n\tag{3}
\]
also is convergent. This is indeed true and was proved by Hardy and Littlewood
in (H\vvv L]. A more general result was established in [Carleman]
and we are going to expose results from Carleman's article.
In general, consider a
power series
\[ 
\phi(z)=\sum\, b_\nu\cdot z^\nu\tag{1}
\]
which 
represents an analytic function
$D$ where
$|\phi(z)|<1$ hold when $|z|<1$. There exists  the
composed analytic function 
\[ 
f(\phi(z))= \sum_{k=0}^\infty\ c_k\cdot z^k\tag{*}
\]
We seek conditions on $\phi$ in order that  the convergence of
$\{a\uuu k\}$ entails that
the series
\[
 \sum\, c\uuu k\quad\text{also converges}\tag{**}
\] 

\medskip

\noindent
First we consider the special case when
the $b$\vvv coefficients are real and non\vvv negative.
\medskip


\noindent
{\bf{8.1. Theorem.}} \emph{Assume that $\{b\uuu \nu\geq 0\}$
and that $\sum\, b\uuu \nu=1$. Then  (**) converges and the sum is equal to 
$\sum\, a\uuu k$.}



\bigskip


\noindent
\emph{Proof.}
Since  $\{b\uuu\nu\}$ are real and non\vvv negative
the Taylor series for $\phi^k$ also has non\vvv negative
real coefficients for every  $k\geq 2$. Put
\[ 
\phi^k(z)=\sum \, B\uuu{k\nu}\cdot z^ \nu
\]
and for  each pair of integers $k,p$ we set
\[
\Omega\uuu{k,p}=\sum\uuu{\nu=0}^{\nu=p} \, B\uuu{k\nu}\
\]
If $k\geq 2$ we notice that
\[
B_{kj}=\sum_{\nu=0}^j\, b_{j-\nu}\cdot B_{k-1,\nu}
\]
Since $\{b_\nu\}$ are non.-begstive with sum equal to one
the reader can easiy verify that the following hold:
\[ 
\lim_{N\to\infty}\, \Omega_{N,p}=0
\quad\text{for every}\quad p\tag{i}
\]
\[ 
k\mapsto \Omega_{k,p}
\quad\text{decreases for every }\quad p\tag{ii}
\]
\[
\sum\uuu {\nu=0}^\infty\, B\uuu{k\nu}=1
\quad\text{hold for   every }\quad k\tag{iii}
\]
\medskip

\noindent
Next, the  Taylor series of  
$f(\phi(z))$ is given by
\[
\sum a\uuu k\cdot \phi^k(z)
=\sum\uuu{\nu=0}^\infty\,\bigl[\sum\uuu {k=0}^\infty\, a\uuu k\cdot B\uuu{k\nu}\bigr ]\cdot z^\nu
\]

\noindent
For  each positive integer $n^*$ we set
\[ 
\sigma_p[n^*]=
\sum_{\nu=0}^{\nu=p}\, \,\bigl[\,\sum_{k=0}^{k=n^*}\, a_k\cdot B_{k,\nu}\bigr]\tag{1}
\]
\[
\sigma_p(n^*)= \sum_{\nu=0}^{\nu=p}\, \,\bigl[\,\sum_{k=n^*+1}^\infty\, a_k\cdot B_{k,\nu}\,\bigr]=\sum\uuu{k=n^*+1}^\infty\,a\uuu k \cdot \Omega\uuu{k,p}
\tag{2}
\]
Notice that 
\[
\sigma_p[n^*]+
\sigma_p(n^*)=\sum\uuu {k=0}^{k=p}c\uuu k\quad\text{hold for each}\quad p
\]
Our aim is to show that the last partial sums converge to 1 as  
$p\to\infty$.
To obtain  this we
study the $\sigma$\vvv terms   separately. Introduce the partial sums
\[
s\uuu n=\sum\uuu{k=0}^{k=n}\, a\uuu k
\]
By assumption  there exists a limit $s\uuu n\to S$ 
where $S=1$.
This   entails that
the sequence $\{s\uuu k\}$ is bounded and so is
the sequence $\{a\uuu k=s\uuu k\vvv s\uuu{k\vvv 1}\}$.
By (i) above it follows that
the last term in (2) tends to zero when $n^*$ increases. So if $\epsilon>0$
we find
$n*$ such that
\[
n\geq n^*\implies |\sigma\uuu p(n)|
\leq \epsilon\tag{3}
\]



\noindent

\noindent
\emph{A study of $\sigma_p[n^*]$}.
Keeping $n^*$ and $\epsilon$ fixed we apply (iii) for each $0\leq k\leq n^*$
and find an integer $p^*$ such that
\[
1\vvv \sum_{\nu=0}^{\nu=p} B_{k,\nu}\leq \frac{\epsilon}{n^*+1}
\quad\text {for all pairs }\quad p\geq p^*\,\colon\, 0\leq k\leq n^*
\]

\noindent
The   triangle inequality gives
\[
|\sigma_p(n^*)-s_{n^*}|\leq \frac{\epsilon}{n^*+1}\cdot \sum\uuu{k=0}^{k=n^*}\, |a\uuu k|
\quad\text {for  all  }\quad p\geq p^*\tag{4}
\]

\noindent
Since  $\sum\, a\uuu k$ converges the sequence
$\{a\uuu k\}$ is bounded, i.e. we have
a constant $M$ such that
$|a\uuu k|\leq M$ for all $k$.
Hence (4) gives
\[
|\sigma_p(n^*)-S|\leq \epsilon+\epsilon\cdot M
\quad\colon\quad p\geq p^*\tag{5}
\]
Together with (3) this entails that
\[
n\geq n^*\implies |\sum\uuu{k=0}^{n^*}\,  |c\uuu k\vvv s|\leq 
2\epsilon+ M\cdot \epsilon
\]
Since we can chose $\epsilon$ arbitrary small we conclude that 
$\sum c\uuu k$ converges and the limit is equal to $S$ which 
finishes the proof of Theorem 8.1.

\bigskip







\bigskip

\noindent
{\bf{8.2 A general case.}}
Now we  relax the condition that $\{b\uuu\nu\}$ are real and non-negative
but  impose extra conditions on $\phi$.
First we assume that $\phi(z)$ extends to a continuous function on
the closed disc, i.e. $\phi$ belongs to the disc\vvv algebra.
Moreover, we assume that 
$\phi(1)=1$ while $|\phi(z)|<1$ 
for all $z\in\bar D\setminus \{1\}$ which means that
$z=1$ is a peak point for $\phi$.
Consider   also  the function
$\theta\mapsto \phi(e^{i\theta})$ where $\theta$ is close to zero.
The final condition on $\phi$ is
that there exists some positive real number
$\beta$ and a constant $C$ such that
\[ 
|\phi(e^{i\theta})\vvv 1\vvv i\beta|\leq C\cdot \theta^2\tag{8.2.1}
\]
holds in some interval $\vvv \ell\leq \theta\geq\ell$.
This implies that for every integer $n\geq 2$
we get another constant $C\uuu n$ so that
\[ 
|\phi^n(e^{i\theta})\vvv 1\vvv in\beta|\leq C\uuu n\cdot \theta^2\tag{8.2.2}
\]
Hence the following integrals exist for all pairs
of integers $p\geq 0$ and $n\geq 1$:
\[
J(n,p)= \int\uuu{\vvv\ell}^\ell\,
\frac{\phi(e^{i\theta})^n\cdot (1\vvv \phi(e^{i\theta})}{
e^{ip\theta}\cdot (1\vvv e^{i\theta})}\cdot d\theta\tag{8.2.3}
\]
With these notations one has
\medskip

\noindent{\bf{8.2 Theorem.}}
\emph{Let $\phi$ satisfy the conditions above.
Then, if 
there exists a constant $C$ such that}
\[ 
\sum\uuu {k=0}^\infty\, |J(k,p)|\leq C\quad\text{for all}\quad p\geq 0\tag{*}
\] 
\emph{it follows that
the series (**) from the introduction
converges  and the   sum is equal to $\sum\, a\uuu k$.}
\bigskip







\noindent
{\emph {Proof}
With similar   notations as in  the previous proof 
we introduce the $\Omega$\vvv numbers by:
\[
\Omega\uuu{k,p}=\sum\uuu{\nu=0}^{\nu=k}\, B\uuu{k\nu}
\]
Repeating the proof of Theorem 8.1 the reader may
verify that
the series $\sum c\uuu k$ converges and has the limit $S$
if the following two conditions hold:
\[
\lim\uuu{N\to\infty}\, \Omega\uuu{N,p}=0
\quad \text{holds for every} \quad p\tag{i}
\]  
\[
\sum \uuu{k=0}^{\infty}\, 
\bigl|\Omega\uuu{k+1,p}\vvv \Omega\uuu{k,p}\bigr|\leq C
\quad\text{for  a constant}\quad C
\tag{ii}
\] 
where $C$ is
is independent of $p$.
Here (i) is clear since 
$\{g\uuu N(z)= \phi^N(z)\}$ converge uniformly to zero in
compact subsets of the unit disc and therefore
their Taylor coefficients  tend to zero with $N$.
To get   (ii)  we use residue calculus which gives:
\[
\Omega_{k+1,p}-\Omega_{k,p}=
\frac{1}{2\pi i}
\int_{|z|=1}\frac{\phi^k(z)}{z^{p+1}}\cdot \frac{1-\phi(z)}{1-z}\cdot dz\tag{iii}
\]
\medskip

\noindent
Let $\ell$ be a small positive number
and    $T_\ell$ denotes  the portion of the
unit circle where
$\ell \leq \theta\leq 2\pi\vvv \ell$. 
Since 1 is a peak \vvv point for $\phi$ there exists
some $\mu<1$ such that
\[ 
\max\uuu{z\in T\uuu\ell}\,|\phi(z)|\leq \mu
\]
This gives
\[
\frac{1}{2\pi}\cdot \bigl|\int_{z\in T\uuu\ell }\frac{\phi^k(z)}{z^{p+1}}\cdot \frac{1-\phi(z)}{1-z}\cdot dz
\bigl|\leq \mu^k\cdot \frac{2}{|e^{i\ell}\vvv 1}\bigr |\tag{iv}
\]
Since the geometric series $\sum\,\mu^k$ converges
it follows from (iii) and the construction of the $J$-integrals
in (3)
that (ii) above holds precisely when 
\[ 
\sum\uuu{k=0}^\infty\, |J\uuu \ell (k,p]|\leq C
\]
for a constant $C$ which is independent of $p$. This   finishes the
the proof of Theorem 8.2.

\bigskip

\noindent
{\bf{8.3. Oscillatory integrals.}}
Condition  (*) in Theorem 8.2.1  is   implicit. 
We shall therefore find
a sufficient condition in order that
the $J$\vvv integrals satisfy (*) which is  expressed by
local conditions on the 
$\phi$\vvv function close to
$z=1$. To begin with (8.2.1)
enable us to write
\[ 
\phi(e^{i\theta})= e^{i\beta \theta+\rho(\theta)}\tag{i}
\]
when  $\theta\simeq 0$  and
\[
\rho(\theta)= O(\theta^2)\tag{ii}
\]
The next result gives  the requested
convergence of the composed series
expressed  by an additional   condition on the $\rho$\vvv function 
in (i) above.

\bigskip

\noindent{\bf{8.4. Theorem.}}
\emph{Assume that $\rho(\theta)$ is a $C^2$-function on some interval 
$\vvv\ell <\theta<\ell$ and that the second derivative
$\rho''(0)$ is real and negative.
Then (*) in Theorem 8.2 holds.}
\bigskip


\noindent
{\bf{Remark.}}
The proof is left as  a (hard) exercise to the reader. If necessary, consult
Carleman's article [Car] for   a detailed proof.






\bigskip

\centerline{\bf 16. The series $\sum\, \bigl [a_1\cdots a_\nu\bigr ]^{\frac{1}{\nu}}$}
\bigskip

\noindent
{\bf{Introduction.}}
We shall prove a result from [Carleman:xx. Note V page 112-115].
Let $\{a_\nu\}$ be a sequence of positive real numbers
such that $\sum\, a_\nu<\infty$ and 
$e$ denotes Neper's constant. 

\medskip

\noindent
{\bf 9.1 Theorem.} \emph{Assume that the series $\sum\, a_\nu$  is 
convergent and let $S$ be the sum.
Then one has the strict inequality}
\[
\sum_{\nu=1}^\infty\, 
\bigl [a_1\cdots a_\nu\bigr ]^{\frac{1}{\nu}}<e\cdot S\tag{*}
\]



\noindent
{\bf Remark.}
The result is sharp in the sense that $e$ cannot be replaced by a smaller constant.
To see this we
consider a large positive integer $N$ and take the finite series
$\{a_\nu=\frac{1}{\nu}\quad\colon 1\leq \nu\leq N\}$.
Stirling's limit formula gives:
\[
\bigl [a_1\cdots a_\nu\bigr ]^{\frac{1}{\nu}}\simeq\frac {e}{\nu}\quad\colon\,\nu>>1
\] 
Since the harmonic series
$\sum\,\frac{1}{\nu}$ is divergent we conclude that
for every $\epsilon>0$ there exists some large integer $N$ such that
$\{a_\nu=\frac{1}{\nu}\}$ gives
\[
\sum_{\nu=1}^{\nu=N}\, 
\bigl [a_1\cdots a_\nu\bigr ]^{\frac{1}{\nu}} >
(e-\epsilon)\cdot \sum_{\nu=1}^{\nu=N}\, \frac{1}{\nu}
\]



\noindent
There remains to prove the strict upper bound (*)
when $\sum\, a_\nu$ is a convergent positive series.
To attain this we  first establish  inequalities for finite series.
Given a positive integer $m$ we consider the variational problem
\[
\max_{a_1,\ldots,a_m}\, 
\sum_{\nu=1}^{\nu=m}\, 
\bigl [a_1\cdots a_\nu\bigr ]^{\frac{1}{\nu}} \quad
\text{when}\quad a_1+\ldots+a_m=1\tag{1}
\]
\medskip

\noindent
Let $a^*_1,\ldots,a^*_m$ give a maximum and set
$a_\nu^*=e^{-x_\nu}$.
The Lagrange multiplier theorem gives a number
$\lambda^*(m)$ such that if
\[ 
y_\nu=\frac{x_\nu+\ldots+x_m}{\nu}
\]
then
\[
\lambda^*(m)\cdot e^{-x_\nu}=\frac{1}{\nu}\cdot e^{-y_\nu}+\ldots+
\frac{1}{m}\cdot e^{-y_m}\quad \colon\quad 1\leq\nu\leq m\tag{2}
\]
A summation over all $\nu$  gives
\[ 
\lambda^*(m)=e^{-y_1}+\ldots+e^{-y_m}=
\sum_{\nu=1}^{\nu=m}\, 
\bigl [a^*_1\cdots a^*_\nu\bigr ]^{\frac{1}{\nu}}
\]
Hence $\lambda^*(m)$ gives
the maximum for the variational problem which is
no surprise since $\lambda^*(m)$ is 
Lagrange's multiplier.
Now we shall
prove  the strict inequality
\[ 
\lambda^*(m)<e\tag{3}
\]
We prove (3) by  contradiction.
To begin with, subtracting the successive equalities in (2) we get
the following equations:
\[
\lambda^*(m)\cdot [e^{-x_\nu}-e^{-x_{\nu+1}}]=
\frac{1}{\nu} \cdot e^{-y_\nu}\quad
\colon\quad 1\leq\nu\leq m-1\tag{4}
\]
\[
m\cdot \lambda^*(m)=e^{x_m-y_m}\tag{5}
\]
Next, set
\[ 
\omega_\nu=\nu(1-\frac{a_{\nu+1}}{a_\nu})\colon\quad 1\leq\nu\leq m-1\tag{6}
\]
With these notations it is clear that (4) gives
\[
\lambda^*(m)\cdot\omega_\nu=
e^{x_\nu-y_\nu}\quad \colon\quad 1\leq\nu\leq m-1\tag{7}
\]
It is clear that (7) gives:
\[
\bigl(\lambda^*(m)\cdot\omega_\nu\bigr)^\nu=
e^{\nu(x_\nu-y_\nu)}=
\frac{a_1\cdots a_{\nu-1}}{a_\nu^{\nu-1}}\tag{8}
\]
By an induction over $\nu$ which is left to the reader it follows
the $\omega$-sequence satisfies the recurrence equations:
\medskip
\[
\omega_\nu^\nu=\frac{1}{\lambda^*(m)}\cdot
\bigl(
\frac{\omega_{\nu-1}}{1-\frac{\omega_{\nu-1}}{\nu-1}}\bigr)^{\nu-1}
\quad \colon\quad 1\leq\nu\leq m-1\tag{9}
\]
Notice that we also have
\[
\omega_1=\frac{1}{\lambda^*(m)}\tag{10}
\]


\noindent
{\bf{A special construction.}}
With $\lambda$ as a parameter
we define a sequence $\{\mu_\nu(\lambda)\}$
by the recursion formula:
\[ 
\mu_1(\lambda)=\frac{1}{\lambda}\quad\text{and}\quad
[\mu_\nu(\lambda)]^\nu=\frac{1}{\lambda}\cdot
\bigl[
\frac{\mu_{\nu-1}(\lambda)}{1-\frac{\mu_{\nu-1}(\lambda)}{\nu-1}}\bigr]^{\nu-1}
\quad \colon\quad \nu\geq 2\tag{**}
\]


\noindent
From (5) and (9) 
it is clear that 
$\lambda=\lambda^*(m)$ gives
the equality
\[
\mu_m(\lambda^*(m))=m\tag{***}
\]
Now we come to the key point during the whole proof.

\medskip

\noindent
{\bf{Lemma}}
\emph{If $\lambda\geq e$ then
the $\mu(\lambda)$ -sequence satisfies}
\[
\mu_\nu(\lambda)<\frac{\nu}{\nu+1}\quad \colon\quad \nu=1,2,\ldots
\]


\noindent
\emph{Proof.}
We use an induction over $\nu$. With $\lambda\geq e$ we have
$\frac{1}{\lambda}<\frac{1}{2}$ so the case $\nu=1$ is okay.
If $\nu\geq 1$ and the lemma  holds for $\nu-1$, then
the recursion formula (**) and the hypothesis $\lambda\geq e$ give:
\[
[\mu_\nu(\lambda)]^\nu=\frac{1}{\lambda}\cdot
\bigl[
\frac{\mu_{\nu-1}(\lambda)}{1-\frac{\mu_{\nu-1}(\lambda)}{\nu-1}}\bigr]^{\nu-1}<
\frac{1}{e}\cdot
\bigl[
\frac{\frac{\nu-1}{\nu}}{1-\frac{\nu-1}{\nu(\nu-1)}}\bigr]^{\nu-1}
\]
Notice that the last factor  is 1 and hence:
\[
[\mu_\nu(\lambda)]^\nu<e<\bigl(1+\frac{1}{\nu})^{-\nu}
\]
where the last inequality follows from the wellknown
limit  of Neper's constant.
Taking the $\nu$:th root we get
$\mu_\nu(\lambda)<\frac{\nu}{\nu+1}$ which finishes the induction.
\medskip

\noindent
{\bf{Conclusion.}}
If $\lambda^*(m)\geq e$ then  the lemma  above and the
equality (***)  would entail that
\[ 
m=\mu(\lambda^*(m))<\frac{m}{m+1}
\] 
This is impossible when $m$ is a positive integer and hence 
we must have proved the  strict inequality
$\lambda^*(m)<e$.


\medskip


\noindent
{\bf{The strict inequality for an infinite series.}}
It remains to prove that the strict inequality holds for
a convergent series with an infinite number of terms.
So assume that we have an equality
\[
\sum_{\nu=1}^\infty\, 
\bigl [a_1\cdots a_\nu\bigr ]^{\frac{1}{\nu}}=e\cdot \sum_{\nu=1}^\infty\, a_\nu\tag{i}
\]
Put as as above
\[ 
\omega_n=n(1-\frac{a_{n+1}}{a_n})\tag{ii}
\]
Since we already know that the left hand side  is at least equal to  the right hand side
one can apply  Lagrange multipliers and we leave it to the reader to verify that
the  equality (i) gives  the recursion formulas
\[
\omega^n_n=\frac{1}{e} \cdot \bigl[
\frac{\omega_{n-1}}{1-\frac{\omega_{n-1}}{n-1}}\bigr]^{n-1}\tag{iii}
\]
Repeating the proof of the Lemma  above it follows that
\[
 \omega_n<\frac{n}{n+1}\implies
\frac{a_{n+1}}{a_n}>\frac{n}{n+1}\tag{iv}
\]
where (ii) gives the implication.
So with
$N\geq 2$ one has:
\[ 
\frac{a_{N+1}}{a_1}>
\frac{1\cdots N}{1\cdots N(N+1)}=\frac{1}{N+1}
\]
Now $a_1>0$ and since the harmonic series $\sum\,\frac{1}{N}$ is 
divergent it would follows that
$\sum\, a_n$ is divergent.
This contradiction
shows that a strict inequality must hold
in Theorem 9.1.






\newpage



\centerline{\bf{16. Asymptotic  series.}}


\bigskip





\noindent
\emph{0. Introduction.}
A  sharp
version of the Phragmén-Lindelöf theorem is proved in 
Theorem A.1. 
Asymptotic series are studied in section B
where
earlier work by Poincaré and Borel  led Carleman to the  general 
construction in Theorem B.1. 
The   question of 
uniqueness is expressed via
Theorem B.5 whose proof relies upon
a  variational problem  in
Section C.



\bigskip

\centerline{\bf{A. The Phragmén-Lindelöf theorem.}}
\medskip

\noindent
Let $f(z)$ be an entire function.
To each $0\leq\phi\leq 2\pi$ we set
\[
\rho_f(\phi)=
\max_r\,|f(re^{i\phi})|\tag{*}
\]

\noindent
The text-book \emph{Le calcus des residues} by Ernst Lindelöf
contains examples of entire functions
$f$ where
$\rho_f(\phi)$ is finite for all $\phi$
with the exception 
$\phi=0$, i.e. only along  the positive real axis
the $\rho$-number fails to be  bounded.
An example is the entire function
\[ 
f(z)=
\frac{1}{z^2}\cdot \sum_{\nu=2}^\infty
\frac{z^\nu}{\bigl (\log\,\nu \bigr )^\nu}
\]
Here one verifies that that there exists a constant $k$ such that:
\[
|f(re^{i\phi})|\leq \text{exp}(e^{\frac{k}{|\phi|\cdot |2\pi-\phi|}}\,)\tag{**}
\]


\noindent
It turns out that the example above is essentially sharp. Namely, 
assume that
the $\rho$-number in (*) is finite for almost every
$\phi$. Then the $\rho_f$-function
cannot be too small, unless $f$ is reduced to
a constant. 
Before  Theorem A.1 is announced
we introduce
the non-negative function
\[ 
\omega(\phi)=\log^+\bigl[\,\log^+\rho_f(\phi)\,\bigr]\tag{***}
\]



\noindent
Since we have taken a two-fold logarithm 
$\omega(\phi)$ is considerably smaller  compared
to the $\rho$-function.
\medskip

\noindent
{\bf {A.1.Theorem.}}
\emph{For every non-constant entire function $f(z)$ one has}
\[
 \int_0^{2\pi}\,\omega(\phi)\cdot d\phi=+\infty
\]
\medskip

\noindent
\emph{Proof.} Assume that $f$ is not a constant.
Consider the maximum modulus function
\[
M(r)=\max_{|z|=r}\,|f(z)|
\]
By the ordinary Liouville theorem the $M$-function
increases to infinity. So we may assume that
$M(r)\geq 1$ when $r\geq r_*$ for some $r_*$.
Put
\[ v(r)=\log\, M(r)\quad\colon\quad
U(z)=\log\,|f(z)|\tag{i}
\]
Given $r\geq r_*$ we consider the domain
\[
\Omega_r=\{ U>\frac{v(r)}{2}\}\,\cap\, \{|z|<r\}\tag{ii}
\]
Next,  let $\zeta_r$ be some point on the circle
$|z|=r$ where
$|f(\zeta_r)|=M(r)$ where $\zeta_r$ always can be chosen
so that there exist
arbitrary small $\delta$
where $|f(\zeta_{r-\delta})|=M(r\vvv \delta)$
and $\lim_{\delta\to  0}\, \zeta_{r-\delta}=\zeta\uuu r$.



\noindent
Next,
in $\Omega$ we get the  connected component
$\Omega_*$
whose boundary contains
$\zeta_r$. Put
\[ \gamma=\partial\Omega_*\cap\,\{ |z|=r\}\tag{iii}
\]
Notice  that
\[ 
U(z)\leq\frac{v(r)}{2}\quad\colon\quad
z\in\partial \Omega_*\cap \{|z|<r\}\tag{iv}
\]
So if $W$ is the harmonic function in the disc $D_r$
with boundary values 1 on $\gamma$ and 0 on
$\{|z|= 1\}\setminus\gamma$ we have:
\[ 
U(z)-\frac{v(r)}{2}-
\frac{v(r)}{2}\cdot W(z)\leq 0\quad\colon\quad z\in\partial\Omega_*\tag{v}
\]


\noindent 
The maximum principle entails that (v) also holds in
$\Omega_*$. 
Hence there exist arbitrary small $\delta>0$ such that
\[
v(r-\delta)-\frac{v(r)}{2}-\frac{v(r)}{2}\cdot W(\zeta_{r-\delta})\leq 0\tag{vi}
\]


\noindent
Let $2 r\cdot\ell$ be the total 
length of the intervals which belong
to $\gamma$.
By the general inequality from XX we have
\[
W(\zeta_{r-\delta})\leq 
\frac{1}{2\pi}\int_{-\ell}^\ell\, \frac{r^2-(r-\delta)^2}
{r^2-2r(r-\delta)\text{cos}\,\theta+(r-\delta)^2}\tag{vii}
d\theta
\]
Let $h(r-\delta)$ denote the right hand side in (vii) which by (vi)
gives us  arbitrary small $\delta>0$ such that
\[
v(r-\delta)-\frac{v(r)}{2}-\frac{v(r)}{2}\cdot h(r-\delta)\leq 0\tag{viii}
\]
Rewriting this inequality we obtain
\[
\frac{v(r)-v(r-\delta)}{\delta}\geq
\frac{v(r)}{2}\cdot \frac{1-h(r-\delta)}{\delta}\tag{*}
\]
Next, from the definition of the $h$-function one has the limit formula

\[
\lim_{\delta\to 0}\frac{1-h(r-\delta)}{\delta}=
\frac{1}{2\pi}\cdot \frac{\text{cos}\,\ell}{\text{sin}\,\ell}\tag{ix}
\] 
Passing to the limit as $\delta\to 0$ in (vii) we get the differential inequality:
\[ 
v'(r)\geq 
\frac{v(r)}{2\pi r}\cdot 
\frac{\text{cos}\,\ell}{\text{sin}\,\ell}\tag{**}
\]


\noindent
Next, put
\[ \log\, r=s\quad\text{and}\quad 
 \log\,\frac{v(r)}{2}=g(s)
\]


\noindent
By derivation rules we see that (**) gives
\[
\frac{dg}{ds}\geq\frac{1}{2\pi}\cdot  
\frac{\text{cos}\,\ell}{\text{sin}\,\ell}\tag{***}
\]


\noindent
Next, identifying $\gamma$ with a subset of the periodic
interval $0\leq\phi\leq 2\pi$ it is clear that
the definition of the
$\omega$-function gives the inclusion

\[ 
\gamma\subset\{\omega(\phi)\geq g(s)\}\tag{x}
\]
So if $\lambda(s)$ is the Lebesgue measure of the
set 
$\{\omega(\phi)\geq g(s)\}$ then $\ell\leq\lambda(s)$
and  (***) gives
\[
\frac{dg}{ds}\geq\frac{1}{2\pi}\cdot  
\frac{\text{cos}\,\lambda(s)}{\text{sin}\,\lambda(s)}\tag{****}
\]


\noindent
Next, the inequality $\text{sin}(t)\geq \frac{2}{\pi}\cdot t$
gives a positive constant $k$ 
which is independent of $s$ such that
the following hold for sufficiently large $s$, i.e.
to ensure that
the corresponding $r$-value satisfies
$M(r)\geq 1$:
\[
\frac{dg}{ds}\geq \frac{k}{\lambda(s)}\tag{xi}
\]
Hence, starting from some sufficiently large
$s_0$ one has
\[ 
\int_{s_0}^s\,
\lambda(s)\cdot dg(s)\geq k(s-s_0)\tag{xii}
\]
\medskip

\noindent This inequality implies in particular  that
one has a divergent integral:
\[
\int_{s_0}^\infty\, 
\lambda(s)\cdot dg(s)=+\infty\tag{xiii}
\]
Finally,  the general equality for distribution functions 
from XXX gives:
\[
\int_0^{2\pi}\,\omega(\phi)\cdot d\phi=
\int_0^\infty\, 
\lambda(s)\cdot dg(s)\tag{xiiii}
\]
The last integral is $+\infty$ by (xiii) and  the requested
divergence  for the intergal of the $\omega$-function follows.

\bigskip

\noindent
{\bf Remark.}
At the end of the article [XXX]  Carleman  points
out  that the proof above  gives a sharp version of the Phragmén-
Lindelöf theorem. More precisely one has  the following:
Let $f(z)$ be analytic in a sector
\[ 
S_\alpha=\{ z= re^{i\phi}\quad\colon\quad -\alpha<\phi<\alpha\}
\]
Define $\omega(\phi)$ as above when
when $-\alpha<\phi<\phi$. With these notations one has:
\medskip

\noindent
{\bf {A.2. Theorem.}}
\emph{Let  $f$ be bounded on the 
half-lines $\text{arg}(z)=\alpha$ and
$\text{arg}(z)=-\alpha$ and assume also that}
\[
\int_{-\alpha}^\alpha\,\omega(\phi)\cdot d\phi<\infty
\]
\emph{Then $f(z)$ is bounded in the whole sector.}

\medskip

\noindent
{\bf {A.3. Exercise.}}
Deduce Theorem A.2 from the preceeding results.







\bigskip








\centerline{\bf B. Asymptotic series.}

\bigskip

\noindent
{\bf Introduction.}
The  notion of asymptotic series was expressed 
as follows by Poincaré:
\medskip

\noindent
\emph{Let $f(z)$ be  complex-valued function
defined in some
subset $E$ of ${\bf{C}}$ and $z_0$ is a boundary point.
We say that $f$ has an asymptotic
series expansion at $z_0$ if there exists a sequence of complex numbers
$c_0,c_1,\ldots$ such that $\lim_{z\to z_0}\, f(z)=c_0$ and for each
$n\geq 0$ one has:}
\[
\lim_{z\to z_0}\,
(z-z_0)^{-n-1}\,\bigl[ f(z)-(c_0+c_1+\ldots+c_n z^n)\bigr ]=c_{n+1}\tag{*}
\]


\noindent
\emph{where the limit is   taken as $z$ stay in 
$E$.}
\medskip

\noindent
It is obvious that if
$f$ has an asymptotic expansion at $z_0$ then
the sequence $\{c_n\}$ is unique.
Constructions of functions which admit asymptotic expansions
appear in   Emile Borel's  thesis
\emph{Sur quelques points de la théorie des fonctions} from 1895
and 
he  proved for example that for every 
sequence of real numbers
$\{c_n\}$ there exists a $C^\infty$-function $f(x)$ on the real line
whose Taylor expansion at $x=0$ is given
by
the sequence, i.e.
\[ 
\frac{f^{(n)}(0)}{n\,!}= c_n\quad\colon\quad n=0,1,\ldots
\]
Following
[Car: xx, page 29-31]
we prove a complex version of
Borel's result where
$D_+$ denotes  the open half-disc 
$\{\mathfrak{Re}(z)> 0\cap\{ |z|<1\}$.

\medskip

\noindent
{\bf B.1. Theorem.} \emph{To each sequence
$\{c_n\}$ of complex numbers there exists
a bounded analytic function $F(z)$ in $D_+$ which has an asymptotic
series expansion at $z=0$ given by $\{c_n\}$.}
\bigskip

\noindent
\emph{Proof.}
It suffices  to prove this when
$c_0=0$.
Let $a_1,a_2,\ldots$ be a sequence of positive real numbers
such that
$\sum\, a_\nu<\infty$.
Given $\{c_n\}$ we construct a sequence of 
functions $P_1(z),P_2(z),\ldots$ which are analytic in
the half plane
$\mathfrak{Re}(z)>0$ as follows: First
\[
P_1(z)=c_1z(1-\frac{z}{z+\epsilon_1})
\quad\colon\,
\epsilon_1=\frac{\alpha_1}{|c_1|}\implies
\tag{i}
\]
\[
|P_1(z)|=|c_1|\cdot \epsilon_1\cdot \frac{|z|}{|z+\epsilon_1}\leq
\alpha_1\quad\colon\quad\mathfrak{Re}(z)\geq 0\tag{ii}
\]
Now $P_1(z)$ has a series expansion at $z=0$:
\[ 
P_1(z)= \sum_{\nu=1}^\infty\, c_\nu^{(1)}\cdot z^\nu\tag{ii}
\]
Notice that the series converges in the disc
$|z|<\epsilon_1$. Set
\[ 
P_2(z)= \bigl[ c_2-c_2^{(1)}\bigr ]\cdot z^2\cdot \bigl(
1-\frac{z}{z+\epsilon_2}\bigr)\quad\colon\, |c_2-c_2^{(1)}|\cdot \epsilon_2\leq
a_2\tag{iii}
\]
With such a careful choice of a small positive $\epsilon_2$ we see that
\[
|P_2(z)|\leq a_2\cdot |z|\quad\colon\quad \mathfrak{Re}(z)\geq 0\tag{iii}
\]
Again we obtain a convergent series
at $z=0$:
\[
P_2(z)=P_1(z)= \sum_{\nu=2}^\infty\, c_\nu^{(2)}\cdot z^\nu\tag{iv}
\]
\medskip

\noindent
{\bf The inductive construction.}
Let $n\geq 3$ and suppose that
$P_1,\ldots,P_{n-1}$ have been constructed where we for each
$1\leq k\leq n-1$ have a series expansion
\[
P_k(z)= 
\sum_{\nu=k}^\infty\, c_\nu^{(k)}\cdot z^\nu\tag{v}
\]
Then we define
\[
P_n(z)=\bigl[ c_n-(c_n^{(1)}+\ldots+c_n^{(n-1)}\bigr]\cdot 
z^n\cdot \bigl(1-\frac{z}{z+\epsilon_n}\bigr)\quad\colon\quad
\bigl |\,c_n-(c_n^{(1)}+\ldots+c_n^{(n-1)}\,\bigr |\,\cdot \,\epsilon_n\leq\alpha_n
\]
\medskip

\noindent
So we obtain a new series at $z=0$:
\[ 
P_n(z)=\sum_{\nu=n}^\infty\, c_\nu^{(n)}\cdot z^\nu\tag{vi}
\]
Staying in the half-disc $D_+$, the inductive construction gives
\[ 
\max_{z\in D_+}\, |P_n(z)|\leq\alpha_n\quad\colon\quad n=1,2,\ldots
\]
Hence there exists  a bounded analytic function in $D_+$ defined by
\[ 
F(z)=P_1(z)+P_2(z)+\ldots
\]
At this stage we leave as an exercise to the reader to verify that
\[
\lim_{z\to 0}\,z^{-n-1}\cdot 
\bigl[\,  F(z)-(c_1z+\ldots+c_n z^n)\bigr ]\, = c_{n+1}
\]


\bigskip


\centerline {\bf B.2. Uniqueness of asymptotic expansions.}
\medskip

\noindent
There exist functions whose asymptotic series is identically zero.
Here is an  example:
\[ 
f(z)= e^{-\frac{1}{z^2}}
\]
If $z= re^{i\theta}$ with
$-\pi/8\leq\theta\leq \pi/8$ we see that
\[
|f(re^{i\theta})|= \text{exp}\,
(-\frac{\text{cos}\,2\theta}{r^2})
\leq\text{exp}
(-\frac{1}{\sqrt{2}\cdot r^2})
\]
It follows that the asymptotic series at $z=0$ is
identically zero.
Via a conformal map from the half-disc $D_+$ 
to the unit circle we are led to the
following problem: Let $f(z)$ be analytic in the open unit disc
$D$. Suppose that
\[ 
\lim_{z\to 1}\, \frac{f(z)}{(1-z)^n}=0
\quad\colon\quad n=1,2,\ldots\tag{*}
\]
We seek growth conditions on $f$ in order that
(*) implies that $f$ is identically zero.
An answer to this uniqueness problem
was proved by Carleman in [Car].
Namely. consider a sequence of real positive numbers
$A_1,A_2,\ldots$.
To each $n\geq 1$ we put
\[ 
I_n=\text{exp}\bigl(\, \frac{1}{\pi}\int_1^\infty\, \log\,
\bigr[\,\sum_{\nu=1}^{\nu=n}\,
\frac{r^{2\nu}}{A_\nu^2}\,\bigr]\, \cdot dr\,\bigr)\tag{**}
\]
\medskip

\noindent
{\bf B.3. Definition.} \emph{Denote by
$\mathfrak{B}$
the set of all sequences
$\{A_n\}$ such that 
$\{I_n\}$ is bounded, i.e. there exists some $K$ such that}
\[
 I_n\leq K\quad\colon\quad n=1,2\ldots
\]


\noindent
In [Car: page  7-52 ] the following 
existence result is proved:
\medskip

\noindent
{\bf B.4. Theorem.}
\emph{To each sequence $\{A_n\}\in\mathfrak{B}$
there exists an analytic function
$f(z)$ in $D$ which is not identically zero and satisfies:}
\[
\frac{|f(z)|}{|1-z|^n} \leq A_n \quad\colon\quad n=1,2,\ldots\tag{1}
\]
\emph{while (*) holds.}
\medskip

\noindent
{A converse result.}
In [loc.cit ] appears  the converse to the
result which ensures uniqueness of the asymoptotic expansion at $z=1$.

\medskip

\noindent
{\bf B.5. Theorem.}
\emph{Let $\{A_n\}$ be a sequence of positive numbers
such that
there exists an analytic
function $f(z)$ in $D$ which is not  reduced to a constant and
satisfies (*) and (1) in Theorem B.4. Then 
$\{ A_n\}\in\mathfrak{B}$.}
\bigskip

\noindent
{\bf{Remark.}}
The results above show that if
$\{A_n\}$ is a sequence for which
$\{I_n\}$ is unbounded then
the asymptotic expansion at $z=1$ is unique for
every analytic function $f(z)$ satisfying (1) in Theorem B.4.
The proofs  of the two results above rely upon
a varational
problem which
is presented below 
while the
deduction after of the two cited results above are left to the reader who  may find
details in  [Carleman].
\bigskip






\centerline{\bf{C. A variational problem.}}





\bigskip

\noindent
Let 
$n\geq 1$ and $a_0,a_1,\ldots,a_n$ some $n$-tuple of 
positive real numbers.
Denote by $\mathcal O(*)$  the family of analytic functions
$f(z)$ in the unit disc which extend to continuos functions on 
the closed disc
and in addition 
$f(0)=1$. Put
\[
I(f)=
\frac{1}{2\pi}\cdot \sum_{\nu=0}^{\nu=n}\, 
a_\nu^2\cdot \int_0^{2\pi}\, \frac{|f(e^{i\theta})|^2}{ |e^{i\theta}-1|^{2\nu}}
\cdot d\theta\quad\colon\quad I_*=\min_{f\in\mathcal O(*)}\,I(f)\tag{0.1}
\]
\medskip

\noindent
Above we have a variational problem. We shall prove
that
there exists a unique function in
$\mathcal O(*)$ which minimizes the functional.
To prove this
we shall rewrite the variational problem.
With $n$ fixed we have the
rational function
\[
\Omega(z)=\sum_{\nu=0}^{\nu=n}\, a_\nu^2\bigl[ (1-z)(1-\frac{1}{z})\bigr]^{n-\nu}\tag{0.2}
\]
It is clear that
$\Omega(z)$ has a pole of order $n$ at $z=0$ and can be written as
\[
Q(z)=
z^{-n}\cdot (-1)^n\cdot a_0^2\cdot \Omega^*(z)
\]
where $\Omega^*(z)$  is a polynomial of degree $2n$
and $\Omega^*(1)=1$.
Notice that  $(1-e^{i\theta})(1-e^{-i\theta})=|e^{i\theta}-1|^2$
hold for every $\theta$. This gives
\[
 \Omega(e^{i\theta})=a_0^2+
\sum_{\nu=1}^{\nu=n}\, a_\nu^2\cdot|e^{i\theta}-1|^{2n-2\nu}\tag{0.3}
\]
In particular $\Omega(z)$ takes real and positive
values on the unit circle.
\medskip

\noindent
{\bf{Exercise.}}
Show that (0.3) implies that
the polynomial $\Omega^*(z)$
has $n$-zeros $\rho_1,\ldots,\rho_n$ in
the  open disc while 
$1/\rho_1,\ldots,1/\rho_n$ are the zeros in
the exterior disc
$\{|z|>1\}$, and hence
\[ 
\Omega(z)=(-1)^n\cdot a_0^2\cdot z^{-n}\cdot
\prod (z-\rho_\nu)\cdot\prod\,
(z-\frac{1}{\rho_\nu})\tag{0.4}
\]
Next, (0.3) gives the equality
\[
I(f)= \frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |e^{i\theta}-1|^{2n}
\cdot |f(e^{i\theta})|^2\, d\theta\tag{0.5}
\]




\noindent
We  use (0.5)  to prove
\medskip

\noindent
{\bf C.1 Theorem.}\emph{
The variational problem has a unique solution minimizing
function $f_*$ given by}:
\[ 
f_*(z)=\frac{(1-z)^n}{\prod\, 1-\rho_\nu\cdot z)}\tag{i}
\]
Moreover, 
\[ 
I(f_*)=
\frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\text{Log}\, \bigl[ \sum_{\nu=0}^{\nu=n}\, a_\nu^2\cdot\frac{1}{
(2\cdot\text{sin}\,\frac{\theta}{2})^{2\nu}}\bigr ]\cdot d\theta\tag{ii}
\]
\medskip

\noindent
\emph{Proof} 
The choice if $f_*$ and (0.5) give
\[
I(f_*)= \frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot \prod\,|1-\rho_\nu e^{i\theta}|^{-2}
d\theta\tag{i}
\]
It is clear that $f_*$ is minimizing if
\[
I(f_*)<I(f_*+h)
\]
for every analytic function $h$ in $D$ such that
$h(0)=0$.
To prove this we notice that
(0.5) gives
\[
I(f_*+h)= I(f_*)+ I(h)+
 \frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |e^{i\theta}-1|^{-2n}
\cdot \mathfrak{Re}(f_*(e^{i\theta})\cdot \bar h(e^{i\theta})\, d\theta\tag{0.5}
\]
Since $I(h)>0$ when $h$ is not identically zero
we get (xx) it the last integral above is zero.
To orove this we use that
$\Omega(e^{i\theta})$ is real and hence the requested vanishing follows if
\[
 \int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |e^{i\theta}-1|^{-2n}
\cdot f_*(e^{i\theta})\cdot \bar h(e^{i\theta})\, d\theta=0
\]


\[
F(z)=\frac{f(z)}{(1-z)^n}\tag{i}
\]
Then (0.5) gives the equality:
\[ 
I(f)=\frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |F(e^{i\theta})|^2\cdot d\theta\tag{iii}
\]
Hence  the variational problem
is equivalent to seek the minimum of
\[ 
\min_{f\in\mathcal O(*)}\, \frac{1}{2\pi}\cdot\int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |F(e^{i\theta})|^2\cdot d\theta\tag{iv}
\]


\noindent
Now $f_*$ is a unique minimizing function in Theorem C.1
if we have proved the strict 
inequality
\[
 I(f_*)=\frac{1}{2\pi}\cdot\int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |F_*(e^{i\theta})|^2\cdot d\theta<
 \frac{1}{2\pi}\cdot\int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |F_*(e^{i\theta})+H(e^{i\theta})|^2\cdot d\theta
\tag{v}
\]
for every analytic function $h(z)$ in $D$ such that  $h(0)=0$.
Put
\[
I(h)= \frac{1}{2\pi}\cdot\int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot |H(e^{i\theta})|^2\cdot d\theta\tag{vi}
\]
Then  the right hand side in (v) becomes

\[
I(f_*)+ I(h)+
\frac{1}{2\pi}
\cdot\int_0^{2\pi}\,
\Omega(e^{i\theta})\cdot [\bar F_*(e^{i\theta})\cdot h(e^{i\theta})+ 
F_*(e^{i\theta})\cdot \bar h(e^{i\theta})]\, d\theta
\tag{vii}
\]
\medskip

\noindent
Since $I(h)>0$ whenever $h\neq 0$ the requested strict inequality
in (v)  follows if
we show that the last integral in (vii) is zero.
By (iii) the function $\Omega(e^{i\theta})$ is constant
so the requested vanishing follows if
\[
\mathfrak {Re}\, \frac{1}{2\pi}
\cdot\int_0^{2\pi}\,\bar F_*(e^{i\theta})\cdot h(e^{i\theta})d\theta=0\tag{viii}
\]
To prove (viii)
we notice that the construction of $f_*$ gives 
$F_*(z)=  \frac{1}{\prod\, 1-\rho_\nu\cdot z)}$.
Put
\[ 
k(z)= \frac{1}{\prod\, (z-\bar \rho_\nu)}
\implies k(z)= \bar F_*(z)\quad\colon |z|= 1\tag{ix}
\] 
\medskip

\noindent
Hence 
\[
\frac{1}{2\pi}
\cdot
\int_0^{2\pi}\,\bar F_*(e^{i\theta})\cdot h(e^{i\theta})d\theta=
\int_0^{2\pi}\,k(e^{i\theta})\cdot h(e^{i\theta})d\theta
\tag{x}
\]
The integral in (x)
vanishes since $h(0)=0$ and 
$k(z)h(z)$ is analytic in $D$.
In particular the real part is zero which gives
(viii) and finishes the proof that $f_*$ is minimizing.
\medskip


\noindent
{\bf{The equality (C.x.2)}}












\newpage


\centerline{\bf{§ 17. Representations of rotation invariant harmonic functions.}}

\bigskip

\noindent
The results in this section  appear in Carleman's article
\emph{Applications de la théorie des fonctions analytiques
à la resolutions de certaines équations fonctionelles} [Acad. Italia Volta 1940].
Let $(x,t,s)$ be the real coordinates in
${\bf{R}}^3$. 
Let $u(x,t,s)$ be real-valued and  harmonic.
We shall consider the subclass of harmonic 
 functions which are invariant under rotations of the
 $(t,s)$\vvv coordinates.
More precisely, suppose that $u$ is defined in
in an open set $\Omega$ given as the product of an interval 
$(-A,A)$
on the $x$\vvv axis and
a disc $\{t^2+s^2<R^2\}$. 
The invariance
means that the function
\[
\phi\mapsto u(x,r\cos\phi.r\sin\,\phi) 
 \] 
is constant for each $x$ and $0<r<R$.
Let $\square$ be the rectangle in the
$z$\vvv plane defined by 
\[ 
\{z=x+iy\,\colon\, 
- A<x<A,\colon\, - R< y<R\}
\]
\medskip


\noindent
Let $f(z)$ be analytic in
$\square$ assume that
$f(x)$ is real-valued when
$-A<x<A$.
Then we have

\medskip

\noindent
{\bf{17.1 Theorem.}}
\emph{Define $u$ in $\Omega$ by}
\[ 
u(x,t,s)= 
\frac{1}{\pi}\int\uuu 0^\pi\, f(x+i\sqrt{t^2+s^2}\cdot\cos\,\phi)\, d\phi
\]
\emph{Then  $u$ is  harmonic and rotation invariant in $\Omega$}
\medskip


\noindent
\emph{Proof.}
The existence of complex derivative of $f$ give
\[
\partial\uuu x^2(u)=
\frac{1}{\pi}\int\uuu 0^\pi\, f''(x+i\sqrt{t^2+s^2}\cdot\cos\,\phi)\, d\phi\tag{i}
\]
\[ 
\partial\uuu t(u)=
\frac{1}{\pi}\int\uuu 0^\pi\, i\cos\,\phi\cdot
\frac{t}{\sqrt{t^2+s^2}}\cdot
f'(x+i\sqrt{t^2+s^2}\cdot\cos\,\phi)\, d\phi\implies
\]
\[ 
\partial\uuu t^2(u)=
\frac{1}{\pi}\int\uuu 0^\pi\, [\vvv \cos^2\,\phi\cdot
\frac{t^2}{t^2+s^2}+i\cos\,\phi\cdot\frac{s^2}{(t^2+s^2)^{3/2}}\bigr]\cdot 
f''(x+i\sqrt{t^2+s^2}\cdot\cos\,\phi)\, d\phi\tag{ii}
\]
A similar expression is found for
$\partial\uuu s^2(u)$ and adding the result we find that
\[
\Delta(u)=
\frac{1}{\pi}\int\uuu 0^\pi\, \bigl(\sin^2\phi\cdot f''+
i\cos\phi\cdot \frac{1}{\sqrt{t^2+s^2}}\cdot f'\,\bigr )\, d\phi\tag{iii}
\]
where $1\vvv \cos^2\phi=\sin^2\phi$ was used.
Next, notice that
\[
\partial\uuu\phi(f'(x+i\sqrt{t^2+s^2}\cos\phi)=
\vvv i\sqrt{t^2+s^2}\cdot \sin\phi\cdot f''(x+\sqrt{t^2+s^2}\cos\phi)\tag{iv}
\]
\medskip


\noindent
By partial integration of the
first term in (iii), the reader can check that
(iv) entails that $\Delta(u)=0$.
Next, the integral equation in the theorem shows that
$u$ is rotation invariant and 
\[ 
u(x,0,0)= f(x)
\]
Since $f(x)$ was real-valued the reader can 
confirm that $u$ is real-valued in $\Omega$ and the proof is finished.
\medskip


\noindent
{\bf{17.2 A converse result.}}
Let $u$ be 
a rotation invariant harmonic function. Then there exists
an analytic function $f(z)$ in $\square$ such that
$u$ is represented as in Theorem 17.1
To prove this we  use that
harmonic functions are real-analytic
and define $f$ on the real $x$-interval $(-A,A)$ by
\[
f(x)= u(x,0,0)
\]
At this stage we leave as an exercise to the reader to confirm that
$f$ extends to an analytic funcituon in
$\square$ and that $u$ is represented via $f$ as in the theorem.
A hint is to apply the general result below.
\bigskip


\noindent
{\bf{17.3 Integrals expression solutions to elliptic equations.}}
Let $a(x,y),b(x,y),c(x,y)$ be real\vvv valued and
real\vvv analytic functions in a rectangle
\[
\square=\{z= x+iy\,\colon -A<x < A\,\colon\, 
\vvv B<y<B\}
\]
Denote by $\mathcal S$ the class of
real-valued functions
$u(x,y)$  which solve the elliptic equation
\[ 
\Delta(u)+ a\frac{\partial u}{\partial x}+
b\frac{\partial u}{\partial y}+c=0
\]
in $\square$.
\medskip

\noindent
{\bf{17.4 Theorem.}}
\emph{There exists a function $V(x,y,\zeta)$
where $\zeta$ is a new complex variable such that 
$V$ is complex analytic with
respect to $\zeta$, and the general solution $u$ is of the form}
\[
u(x,y)= A\cdot V(x,y,0)+
\mathfrak {Re}\, \int\uuu 0^{x+iy}\, V(x,y,\zeta)\cdot f(\zeta)\, d\zeta
\]
\emph{where $A$ is a real constant and $f$ an arbitray continous
complex analytic function.}
\medskip

\noindent
{\bf{17.5 Remark.}}
A special case of Theorem 17.4 appears when we regard
solutions to the elliptic equation 
\[
\Delta(u)-k^2\cdot u=0
\] 
where $k>0$ is a constant.
Here the general $u$-solution defined in some disc centered at the origin
takes the form
\[
u(x,y)= \mathfrak{Re}\, \int_0^z\, J_0(ik\sqrt{|z|^2-\bar z\cdot \zeta})\cdot f(\zeta)\, d\zeta
\]
where $z=x+iy$ and $J_0$  the usual Bessel function.


\newpage


\centerline {\bf{§ 18. Conformal maps of circular domains.}}

\medskip

\noindent
{\bf Introduction.}
In 1906 Koebe proved a
result about conformal mappings between
domains bordered by a finite set of circles.
Let $p\geq 2$
and denote by $\mathcal C^*(p)$ the family of connected
bounded  domains $\Omega$ in ${\bf{C}}$ for which
 $\partial\Omega$ is the union of $p$ many disjoint circles.
\medskip

\noindent
{\bf Theorem.} \emph{Let
$f\colon\Omega\to U$
be a conformal map between two domains in
$\mathcal C^*(p)$. Then $f(z)$ is a linear function, i.e.
$f(z)=Az+B$ for some constants $A$ and $B$.}
\medskip

\noindent
Koebe's  original proof  used reflections over the boundaries and
results related  to the uniformisation theorem.
A more direct  proof was given by Carleman in [Car] which we expose
below.  It teaches how to
compute certain winding numbers in  specific situations.
\medskip


\newpage




\centerline
{\bf{§ 19. On spectra of compact operators.}}
\bigskip

\noindent
Let $\mathcal H$ be a Hilbert space.
In §§ we proved that if $T$ is a compact operator on 
$\mathcal H$, then there exists the compact self-adjoint operator
$\sqrt{T^*T}$. Denote by
$\{\mu_n(T)\}$ its discrete spectrum
which  arranged so that sequence 
$\{\mu_n(T)\}$ is non-increasing, where eventual 
multiplicities are counted as usual.
\medskip

\noindent
{\bf{1.1 Definition.}} \emph{For each $p>0$ we denote by
$\mathcal C_p$ the class of compact operators on
$\mathcal H$ such that}
\[
\bigl(\sum_{n=1}^\infty \, \mu_n(T)^p\,\bigr) ^{\frac{1}{p}}<\infty
\]
\medskip

\noindent
Next, denote by $\text{sp}(T)$ the set of all vectors
$x\in\mathcal H$ for which there
exists some non-zero complex number
$\lambda$ and some integer $n\geq 1$ such that
\[
(\lambda E-T)^n(x)=0\tag{*}
\]
\medskip

\noindent
Next, for  every positive integer $N$ we have operator $T^N$
and get the image space
 $T^N(\mathcal H)$.
We shall find sufficient conditions in order that
\[
T^N\mathcal H\subset\text{sp}(T)\tag{**}
\] 
holds for some positive integer $N$. To achieve this we shall use
the resolvent operator
\[ 
R(\lambda)=(\lambda\cdot E-T)^{-1}
\]
which is defined outside the discrete spectrum of $T$.
Let $\gamma$ be a simple Jordan arc
which has the origin as one end-point while
$\gamma^*=\gamma\setminus\{0\}$ stays outside the spectrum of $T$.
Now  $R(\lambda)$ exists for every $\lambda\in \gamma^*$
and we can compute  operator norms which leads to:
\medskip

\noindent
{\bf{1.2 Definition.}}
\emph{A Jordan arc $\gamma$ as above is called $T$-escaping of order
$N$ if there exists a constant $C$ such that}
\[
||R(\lambda)||\leq C\cdot |\lambda|^{-N}\quad\colon\quad 
\lambda\in \gamma_*
\]
\medskip

\noindent
Next, let 
$\gamma_1,\ldots,\gamma_s$ be a finite family of Jordan arics as above
whose  intersections 
with a small  punctured disc $D^*(\delta)=\{0<|z|<\delta\}$
gives a disjoint famlily of curves
$\{\gamma^*_\nu\}$.
Then 
$D^*(\delta)$
is decomposed into  $s$ many pairwise disjoint
Jordan domains, each of which is bordered by a pair of
$\gamma^*$-curves.
Let  $\rho>0$ be some positive number.
We impose the geometric condition that every  Jordan
domain above is contained
in a sector where $\text{arg}(z)$ stays in an interval of
length
$<\rho$ as $z$ varies in the Jordan domain.
Denote by $\mathcal J(\rho)$ the class of all finite families of
Jordan curves for which
these sector conditions hold.
\medskip


\noindent
{\bf{1.3 Theorem.}}
\emph{Let $T$  be a  compact
operator of class $C_p$ for some $p>0$ and
suppose there exists
a family  $\{\gamma_\nu\}$  
which belongs to $\mathcal J(\pi/p)$
where  each $\gamma_\nu$ is $T$-escaping
order $N$. Then  one has the inclusion}

\[ 
T^N(\mathcal H)\subset \text{sp}(T)
\]
\bigskip


\noindent
{\bf{Remark.}}
This result is announced and proved in
[Dunford-Schwartz: Theorem XI.9.29 on page 1115].
The proof is bseed upon several  results. The first step which is fairly straightforward
reduces the proof to the case
when the compact operator $T$ is of Hilbert-Schmidt type.
We remark only that for this reduction one uses
the fact that $T$ belongs to $C_p$ for some $p>0$.
The major step is
to extend 
Carleman's inequality for matrices in
§ XX from Chapter XX to the case of Hilbert-Schmidt operators on
Hilbert spaces. After this
the proof is finished by standard applications of the
Phragmén-Lindelöf inequalities.

\medskip

\noindent
{\bf{Exampe and a question.}}
Let
$\mathcal H=L^2[0,1]$ and consider the operator
$T$  defined by
\[ 
Tu(x)=\int_0^1\,
\frac{k(x,y)u(y)}{|x-y|^\alpha}\,dy
\]
where $1/2<\alpha<1$
and $k(x,y)$ is a real-valued continuous function on
the closed unit square.
Then  $T$ is
compact and using the results from
§ X one finds a $p$-number which depend upon $\alpha$
such that
$T$ belongs to $C_p$.
It would be interesting to investigate
how one can produce integers $N$ to get the inclusion
in
Theorem 1.3.
In such an investigations one can   try 
specified $k$-functions and in partocular regard  the symmetric 
case when $k(x,y)= k(y,x)$. 









\newpage









\centerline{\bf{§ 20. Distribution of eigenvalues for a class of singular operators.}}
\bigskip


\noindent
Let $f(x,y)$ be a continuous function on the unit square
$0\leq x,y\leq1 $ which is symmetric, i.e.
$f(x,y)=f(y,x)$.
When $0<\alpha<1$
we set
\[
k(x,y)= 
\frac{f(x,y)}{|x-y|^\alpha}
\]
and get the linear operator
\[
K_\alpha(u)(x)=\int_0^1\, k(x,y)u(y)\, dy
\]
By the result in § xx 
$K_\alpha$ is a compact operator on the
Hilbert space
$L^2[0,1]$ In fact, by the result in § xx it is even a compact operator
and 
since $k$ is symmetric the eigenvalues are real and non-zero.
Let $\{\lambda_n^+\}$ be the positive eigenvalues arranged in a non-decreasing order.
Similarly $\{\lambda_n^-\}$ is the set of negative eigenvalues where
$\{-\lambda^-_n\}$ is non-decreasing. 
To the set of eigenvalues corrspond eigenfunctions
$\{\phi_n^+\}$ and $\phi_n^-\}$ where
\[ 
K_\alpha(\phi_n^+)=\lambda_n^+\cdot \phi_n^+
\]


\medskip

\noindent
{\bf{1. Theorem.}} \emph{If $f(x,x)>0$ hold on some open interval $x_0<x<x_1$
 it follows that}
 \[ 
 \sum_{n=1}^\infty\,\bigl(\frac{1}{\lambda_n^+}\bigr)^{\frac{1}{1-\alpha}}=
 +\infty
\]
\medskip

\noindent
During the proof
we use the following notation for real-valued functions $u$ in $L^2[0,1]$:
\[
\langle K_\alpha u,u\rangle=
\iint f(x,y)u(x)u(y)\, dxdy
\]
and for  a pair of real-valued $L^2$-functions $u,v$ we set
\[
\langle u,v\rangle=\int_0^1\, u(x)v(x)\, dx
\]
 
\medskip

\noindent
We shall need the following result from §§:
\bigskip

\noindent
{\bf{2. Proposition.}}
\emph{For each $u\in L^2[0,1]$ we have the equality}
\[
\langle Ku,u\rangle=
\sum\, \frac{1}{\lambda_n^+}\cdot
\langle u,\phi_n^+\rangle^2+
\sum\, \frac{1}{\lambda_n^-}\cdot
\langle u,\phi_n^-\rangle^2\tag{*}
\]
\medskip

\noindent
\emph{Proof of Theorem 1.}
Let $m$ be a positive integer. Since $\{\lambda_n^-\}$ are negative
(*) gives:
\[
\langle Ku,u\rangle\leq
\sum_{n=1}^m\, 
\frac{1}{\lambda_n^+}\cdot
\langle u,\phi_n^+\rangle^2+
\sum_{n=m+1}^\infty\, 
\frac{1}{\lambda_n^+}\cdot
\langle u,\phi_n^+\rangle^2
\]


\noindent
Since $\{\lambda_n^+\}$ is non-decreasing the last sum above is majorized by
\[
\frac{1}{\lambda_m^+}\cdot
\sum_{n=m+1}^\infty\, 
\langle u,\phi_n^+\rangle^2\leq \frac{1}{\lambda_{m+1}^+}\cdot \langle u,u\rangle
\]
where the last inequality follows from Bessel's inequality since
the eigenfunctions $\{\phi_n^+\}$ form an orthonormal family.
Hence the following inequality holds for every positive integer $m$:
\[
\langle Ku,u\rangle\leq
\sum_{n=1}^m\, 
\frac{1}{\lambda_n^+}\cdot
\langle u,\phi_n^+\rangle^2+\frac{\langle u,u\rangle}{\lambda_{m+1}^+}\tag{i}
\]
\medskip

\noindent
Let $\psi_1,\ldots,\psi_m$ be some
orthonormal $m$-tuple in $L^2[0,1]$.
We can apply (i) to each $\psi$-function and a summation over 
$1\leq k\leq m$ gives:

\[
\sum_{k=1}^{k=m}\, 
\langle K\psi_k,\psi_k\rangle\leq
\sum_{k=1}^{k=m}  \sum_{n=1}^{n=m}\, 
\frac{1}{\lambda_n^+}\cdot
\langle \psi_k,\phi_n^+\rangle^2+
\frac{m}{\lambda_{m+1}^+} \tag{ii}
\]
Another application of Bessel's inequality gives for each
$1\leq n\leq m$:

\[
\sum_{k=1}^{k=m}\,
 \langle \psi_k,\phi_n^+\rangle^2\leq \langle\phi_n^+,\phi_n^+\rangle=1
\] 
Hence (ii) entails that

\[
\sum_{k=1}^{k=m}\, 
\langle K\psi_k,\psi_k\rangle\leq
\sum_{n=1}^{n=m}\, \frac{1}{\lambda_n^+}+\frac{m}{\lambda_{m+1}^+}\tag{iii}
\]
\medskip

\noindent
\emph{A choice of $\psi$-functions.}
By assumption we find an interval $[x_0,x_1]$ where
$f(x,x)>0$. Set $d=x_1-x_0$ and when
$m$ is a  positive integer we 
define $\psi_1,\ldots,\psi_m$ where
\[
\psi_k(x)=\sqrt{\frac{m}{d}} \quad\text{when}\quad
x_0+(k-1)\frac{d}{m}<x<x_0+k\frac{d}{m}
\]
\medskip

\noindent
while $\psi_k=0$ outside the intervals above.
The  continuity of $f$ gives
some large integer $m_*$
and a positive constant $\delta$ such that
if $m\geq m_*$ then
$f(x,y)\geq \delta$ on each  small square
where 
$\psi_k(y)\cdot\psi_k(x)\neq 0$. Denote this small square by
$\square_k$ which gives  the inequality below 
for each $1\leq k\leq m$:
\[
\langle K\psi_k,\psi_k\rangle
\geq \delta\cdot\frac{m}{d} \cdot 
\iint_{\square_k} \frac{dxdy}{|x-y|^\alpha}
\]
An easy calculation shows that the double integral
over $\square_k$ becomes
\[
\frac{2}{(1-\alpha)(2-\alpha)}\cdot \bigl( \frac{d}{m}\bigr)^{2-\alpha}
\]
So with $A=\delta\cdot \frac{2}{(1-\alpha)(2-\alpha)}$ one has the inequality
\[
\sum_{k=1}^{k=m}\, 
\langle K\psi_k,\psi_k\rangle
\geq A\cdot \bigl( \frac{d}{m}\bigr)^{1-\alpha}\cdot m= Ad^{1-\alpha}\cdot m^\alpha
\tag{iv}\]
\medskip

\noindent
By  construction  $\psi_1,\dots,\psi_m$ is an orthonormal family
and hence (iii) holds which together with (iv)
gives the inequality below for every  $m\geq m_*$:
\[
Ad^{1-\alpha}\cdot m^\alpha\leq 
\sum_{n=1}^{n=m}\, \frac{1}{\lambda_n^+}+\frac{m}{\lambda_{m+1}^+}\tag{v}
\]


\noindent
At this stage we shall argue by a contradiction, i.e. we  prove that
(v) prevents that the positive  series in Theorem 1 converges.
Namely, suppose that
\[ 
\sum\, \bigl(\frac{1}{\lambda_n^+}\,\bigr)^{\frac{1}{1-\alpha}}<\infty
\]
Since the terms in this positive series decrease with $n$ it follows 
that
\[
\lim_{m\to \infty}\, 
m\cdot \bigl(\frac{1}{\lambda_m^+}\,\bigr)^{\frac{1}{1-\alpha}}=0
\]
So if $\epsilon>0$ we can find $m^*\geq m_*$ such that

\[
m\cdot \bigl(\frac{1}{\lambda_m^+}\,\bigr)^{\frac{1}{1-\alpha}}<\epsilon
\implies \frac{1}{\lambda_m^+}<\bigl(\frac{\epsilon}{m}\bigr)^{1-\alpha}
\]
Hence (v) gives the following when $m>m^*$:

\[
Ad^{1-\alpha}\cdot m^\alpha\leq
\sum_{n=1}^{n=m^*}\, \frac{1}{\lambda_n^+}+
\sum_{\nu=m^*+1}^{n=m}
(\frac{\epsilon}{\nu}\bigr)^{1-\alpha}+m\cdot (\frac{\epsilon}{m+1}\bigr)^{1-\alpha}
\]

\noindent
The middle sum above is majorized by 

\[
\epsilon^{1-\alpha}\cdot\int_{m^*}^m\, \frac{dx}{x^{1-\alpha}}
=\frac{\epsilon^{1-\alpha}}{\alpha}\cdot m^\alpha
\]
At the same time we notice that the last term is $\leq \epsilon^{1-\alpha}\cdot m^\alpha$
and after a division with $m^\alpha$ we  obtain
\[
Ad^{1-\alpha}\leq m^{-\alpha}\cdot 
\sum_{n=1}^{n=m^*}\, \frac{1}{\lambda_n^+}+\epsilon^{1-\alpha}(
\frac{1}{\alpha}+1)
\]
Above $A$ and $d$ are fixed positive constants 
while we can choose arbitary large $m$ and arbitrary small $\epsilon$. 
This gives a contradiction
and Theorem 1 is proved.







\newpage

\centerline{\bf{§ 21. An entire spectral function.}}




\bigskip


\noindent
{\bf{Introduction.}} Theorem 1 below is due to 
Carleman in the article
\emph{Sur le genre du dénominateur $D(\lambda)$
de Fredholm}. The proof uses some basic results about entire functions 
due to Poincaré, Lindelöf and Wiman and offers an instructive lesson
in analytic function theory.
Let $k(x,y)$ be a continuous function on the unit square
$\{0\leq x,y\leq 1\}$.
We do not assume that $k$ is symmetric, i.e. $k(x,y)\neq k(y,x)$
can hold.
To each $n$-tuple of points $\{s_\nu\}$ on
$[0,1]$ we assign the determinant function
\[ 
K(s_1 ,\ldots,s_n)
=\text{det}
\begin{pmatrix}
k(s\uuu 1,s_1)&\cdots&k(s_1,s_n)\\
\cdots &\cdots&\cdots \\
\cdots &\cdots&\cdots\\
k(s_n,s_1)&\cdots &k(s_n,s_n)\\
\end{pmatrix}
\]
Set
\[ 
c_n= \int_{\square_n}\,
K(s_1 ,\ldots,s_n)\cdot ds_1\cdots ds_n
\]

\medskip

\noindent
where the integral is taken over the $n$-dimensional unit cube.

\medskip

\noindent
{\bf{1. Theorem.}} \emph{Put}
\[ 
D(\lambda)=1+ \sum_{n=1}^ \infty\, \frac{(-1)^n}{n!}\cdot c_n\cdot \lambda^n
\]
\emph{Then $D$ is an entire function of the form}
\[ 
D(\lambda)= e^{a\lambda}\prod\,(1-\frac{\lambda}{\lambda_\nu})
\cdot e^{\frac{\lambda_\nu}{\lambda}}
\] 
\emph{where $a$ is some complex constant and}
\[ 
\sum\, \frac{1}{|\lambda_\nu|^2}<\infty
\]



\noindent
{\bf{Remark.}} 
Prior to Carleman's result in Theorem 1,
Schur proved that $D(\lambda)$ is an entire function
of the form
\[
D(\lambda)= e^{a\lambda+b\lambda^2}\prod\,(1-\frac{\lambda}{\lambda_\nu})
\cdot e^{\frac{\lambda_\nu}{\lambda}}
\]
for some second constant $b$.
The novelty in [Carleman] is that $b=0$ always holds.
Above we assumed that $k$ is a continuous kernel.
This condition was later relaxed in the article [§ xx. 1919]
which gives
Theorem 1 when 
$k(x,y)$  is a kernel of the Hilbert-Schmidt type, i.e. it suffices to assume that 
\[
\iint\, |k(x,y)|^2\, dxdy<\infty
\]

\newpage



\centerline{\bf{Proof of Theorem 1 }}

\medskip

\noindent
First we 
approximate $k$ by polynomials. If $\epsilon>0$ we find a 
polynomial $P(x,y)$ such that the maximum norm of $k-P$ over
the unit square is $<\epsilon$. Write
\[ 
k(x,y)= P(x,y)+B(x,y)
\] 
So now $|B(x,y)|<\epsilon$ for all $0\leq x,y\leq 1$.
To each pair $0\leq p\leq n$ we set

\[ 
B_p(s_1,\ldots,s_n)
=\text{det}
\begin{pmatrix}
P(s\uuu 1,s_1)&\cdots&k(s_1,s_n)\\
\cdots &\cdots&\cdots \\
P(s_p,s_1)&\cdot&P(s_p,s_n)\\
B(s_{p+1},s_1)&\cdots& B(s_{p+1},s_n)\\
\cdots &\cdots&\cdots\\
B(s_n,s_1)&\cdots &B(s_n,s_n)\\
\end{pmatrix}
\]
It is easily seen that
\[ 
c_n=
\sum_{p=0}^{p=n}\,
\binom {n}{p}\cdot  \int_{\square_n}\, B_p(s_1,\ldots,s_n)\cdot ds_1\cdots ds_n\tag{i}
\]
\medskip

\noindent
Next, let $N$ be the degree of the polynomial $P(x,y)$.
The reader can verify that
the first $p$ row vectors in the matrix which
defines
$B_p(s_1,\dots,s_n)$ are linearly independent as soon as $p>N$
which therefore gives $B_p=0$. So for every $n\geq N$ one has the equality
\[
c_n=\sum_{p=0}^{p=N}\,
\binom {n}{p}\cdot  \int_{\square_n}\, B_p(s_1,\ldots,s_n)\cdot ds_1\cdots ds_n\tag{ii}
\]
Next, if $M$ is the maximum norm of $k(x,y)$,
and $\epsilon<M$  the maximum norm of
$P$ is $\leq 2M$.  Hadamard's
determinant inequality in § xx gives
\[
|B_p(s_1,\ldots,s_n)|\leq (2M)^p\epsilon^{n-p}\cdot n^{\frac{n}{2}}\tag{iii}
\]
Next, when $n\geq p$ and $0\leq p\leq n$ we set

\[
c_n(p)=
\binom {n}{p}\cdot  \int_{\square_n}\, B_p(s_1,\ldots,s_n)\cdot ds_1\cdots ds_n
\]
Then (iii) gives:
\[ 
|c_n(p)|\leq\binom {n}{p}\cdot(2M)^p\epsilon^{n-p}\cdot n^{\frac{n}{2}}\tag{iv}
\]
Next, recall that
$\binom{n}{p}\leq \frac{n^p}{p !}$ and hence (iv) gives
\[ 
|c_n(p)|\leq \frac{(2M)^p}{p !}\cdot \epsilon^{n-p}\cdot n^{\frac{n}{2}+p}\tag{v}
\]
\medskip

\noindent
At this stage we return to the $D$-function. To each $0\leq p\leq N$
we set
\[ 
D_p(\lambda)=\sum_{n=p}^\infty\, \frac{-1)^n}{n !}\cdot c_n(p)\lambda^n
\]



\medskip

\noindent
{\bf{Subemma.}}
\emph{For each $p$  we have}
\[ 
\lim_{|\lambda|\to +\infty}\,
e^{-4\epsilon|\lambda|^2}\cdot D_p(\lambda)=0\tag{*}
\]

\medskip

\noindent
{\bf{Exercise.}} Prove (*). The hint is to 
use (v) above and Lindelöf's
asymptotic formula from § xx.
\medskip

\noindent
Next, we notice that
(ii) gives an equation
\[ 
D(\lambda)=q(\lambda)+ \sum_{p=0}^{p=N}\,D_p(\lambda)\tag{vi}
\] 
where $q(\lambda)$ is a polyonomial of degre $N-1$ at most.
This 
entails that the entire function
$D(\lambda)$ also satisfies (*) above.
Let $\{\lambda\uuu\nu\}$ be the zeros of $D(\lambda)$. Then (*) and 
a classic result due to Poincaré  gives  the entire function
\[ 
F(\lambda)=
\prod\,(1-\frac{\lambda}{\lambda_\nu})\cdot e^{\frac{\lambda}{\lambda_\nu}}
\quad\text{where}
\]
\[
\lim_{|\lambda|\to +\infty}\,
e^{-\delta|\lambda|^2}\cdot F(\lambda)=0
\quad\text{for all}\quad \delta>0\tag{**}
\]


\noindent
To profit upon (**) we use a device introduced by Lindelöf.
Let $\omega= e^{2\pi i/5}$ which  gives
the entire function 
\[ 
G(\zeta)= F(\zeta^5)F(\omega\zeta^5)\ldots F(\omega^4\zeta^5)\tag{vii}
\]
\medskip



\noindent
From (**) we see
that the entire function $G$ has order
$<1/2$. Then a result due to   Wiman in § xx  gives
an increasing  sequence 
$\{R_k\}$ which tends to $+\infty$  such that
\[
\min_\theta\, |G(R_ke^{i\theta})|\geq 1\tag{viii}
\]
hold for every $k$.
Taking $\lambda$-circles with $r_k^5=R_k$
and using Poincaré's limit  from (**) we see that (vii) and (viii)
entail that for every $\delta>0$ there exist some  $k_*$ such that
\[ 
k\geq k_*\implies
\max_\theta\, \frac{1}{|F(r_ke^{i\theta})}|\leq e^{\delta r_k^2}\tag{ix}
\]
Finally, we have the zero-free entire function
\[ 
H(\lambda)= \frac{D(\lambda)}{F(\lambda)}
\]
In (ix) we can  take $\delta=\epsilon$ which gives
\[
\limsup_{k\to +\infty}\, e^{-5\epsilon\cdot r_k^2}\cdot 
\max_\theta\, |H(r_ke^{i\theta})|=0
\]
\medskip

\noindent
Now Liouville's theorem entails that the entire function
$\log H(z)$ must be a linear polynomial and since
$D(0)=1$ we
conclude that
\[ 
D(\lambda)= e^{a\lambda}\cdot F(\lambda)
\] 
for a constant $a$ which finishes the proof of Theorem 1.






\newpage

\centerline{\bf{§ 22. Two problems in the calculus of variation.}}

\bigskip

\noindent
We shall consider two problems with a geometric content
which
are classic in the sense that they were alreadt treated by
Steiner and Weierstrass at an early stage.
\bigskip



\centerline{\bf{§ 0.1 An
isoperimetric inequality}}
\bigskip

\noindent
Recall that
a planar domain whose boundary
curve has  prescribed length
has a maximal   area when it it is a disc.  
It turns out that discs solve a more extensive class
of extremal problems.
Consider a function
$f(r)$ defined for
$r>0$ which is continuous and increasing with
$f(0)=0$. 
If $p$ and $q$ are two points in ${\bf{R}}^2$ their euclidian distance is denoted by
$|p-q|$.
When $U$ is a bounded open domain we set
 \[
J(U)=\iint_{U\times U}\, f(|p-q|)\cdot dA_p\cdot dA_q
 \]
where $dA_p$ and $dA_q$ denote   area measures.
Given a positive number $\mathcal A$ one seeks
to maximize the $J$-functional  in the
family of domains with  prescribed area  $\mathcal A$. 
The $J$-number is  unchanged under a
translation  or a rotation
of a  domain and the family of discs is
stable under these operations. So
the following result makes sense:
\medskip

\noindent
{\bf{1.Theorem.}}
\emph{The $J$-functional 
takes its maximum on discs $D$
of radius $r$ with $\pi r^2=\mathcal A$.
Moreover, for every domain $U$ with area $\mathcal A$
which is not a disc one has a strict inequality}
\[ 
J(U)<J(D)
\] 
\medskip

\noindent
When $f(r)$ is a strictly convex function 
Theorem 1  was established by Blaschke. 
For a general $f$-function which need not be convex the
theorem   was proved by Carleman in [Car]
using 
the symmetrisation process   by
W. Gros from  the article (Monatshefte math.physik 1917).
In § xx we explain why
Theorem 1 leads to another property of discs.

\medskip

\noindent
{\bf{2.Theorem.}}
\emph{Let $\Omega$ be a domain in the family $\mathcal D(C^1)$
and denote by $ds$ the arc\vvv length measure on its boundary.
Then, if the
function}

\[
 p\mapsto \int\uuu{\partial\Omega}\, f(|p\vvv q|)\cdot ds(q)
 \] 
\emph{is constant as $p$ varies in $\partial\Omega$ it follows that
$\Omega$ is a disc.}
 


\medskip

\noindent
{\bf{Remark.}} 
Theorem 1  can be extended to 
any dimension $n\geq 3$ using
successive symmetrisations of domains
taken in different directions converge to the unit
ball in ${\bf{R}}^n$. Here discs are replaced by
$n-1$-dimensional spheres.
\medskip




\bigskip

\centerline {\bf{2. A variational   inequality}}
\medskip

\noindent
We first establish some inequalties which will
be used
in § 3 to finish the proof of 
Theorem 1.
Let $M>0$  and on
the    vertical lines $\{x=0\}$ and $\{x=M\}$
we consider 
two subsets $G_*$ and $G^*$ which both consist of a finite union of closed intervals.
Let $\{[a_\nu,b_\nu]\}$ be the $G_*$-intervals taken in the $y$\vvv coordinates
and  
$\{[c_j,d_j]\}$ are the $G^*$-intervals.
Here $a_\nu<b_\nu<a_{\nu+1}$ holds, and similarly
the $G^*$-intervals are ordered with increasing $y$-coordinates.
The number of intervals of the two sets are arbitrary and 
need not be the same.
Given  $f(r) $ as in the Theorem 1 we set

\[ 
I(G_*,G^*)=
\sum_\nu\sum_j\, \int_{a_\nu}^{b_\nu}\int_{c_j}^{d_j}\,f(|y-y'|)\cdot dydy'
\]
Consider the variational problem where we seek to minimize these $I$-integrals
for  pairs $(G_*,G^*)$ as above under the
constraints:
  
\[
\sum\,(b_\nu-a_\nu)=\ell_*\quad\text{and}\quad  \sum\,(d_j-c_j)=\ell^*
\]
\medskip

\noindent
That is, the sum of the lengths of the intervals are prescribed on $G_*$ and $G^*$.

\medskip

\noindent
{\bf{2.1 Proposition.}} \emph
{For every  pair $(\ell_*,\ell^*)$ the $I$-integral is minimized when
both $G_*$ and $G^*$ 
consist of a single interval and the mid-points of
the two intervals have equal $y$-coordinate.}
\medskip

\noindent
{\bf{Proof.}} 
First we prove the
result when both $G_*=(a,b)$ and $G^*=(c,d)$ both are intervals.
We must prove that the $I$-integral is a minimum when
\[
\frac{a+b}{2}=\frac{c+d}{2}\tag{i}
\]
Suppose that inequality holds. Since the $I$-integral is symmetric with respect to the pair 
of intervals, we may assume that
\[
\frac{c+d}{2}=s+\frac{a+b}{2}\quad\text{where}\quad  s>0
\]
Now $I(G_*,G^*)$ is unchanged 
when we translate the two intervals, i.e. if we for some
number
$\xi$ take
$(a+\xi,b+\xi)$ and $(c+\xi,d+\xi)$.
By such a translation we can assume that $a=-b$
so  the mid-point of
$G_*$ becomes $y=0$ and we have:


\[
I=\int_{-b}^b\int _c^d\, f(\sqrt{M^2+(y-y')^2})\cdot dydy'
\]
Using  the variable substitutions
$u=y'-y$ and $v=y'+y$ we see that
\[
-b+c\leq u\leq d+b
\]
and obtain
\[
I=2b\int_{-b+c}^{d+b}\, f(\sqrt{M^2+v^2})\cdot dv
\]
With
\[ 
s=d-\frac{d+c}{2}= \frac{d-c}{2}
\]
we can write
\[ 
I=2b\cdot \int_{w-s}^{w+s} f(\sqrt{M^2+u^2})\cdot dv\quad\colon
w=b+\frac{d+c}{2}
\]
The last integral is a function of $s$, i.e. for every $s\geq 0$ we set

\[
\Phi(s)=2b\cdot \int_{w-s}^{w+s} f(\sqrt{M^2+u^2})\cdot dv\quad\colon
w=b+\frac{d+c}{2}
\]
The derivative of $s$ becomes

\[ 
\Phi'(s)= f(\sqrt{M^2+(w+s)^2})- 
 f(\sqrt{M^2+(w-s)^2})
 \] 
Since $f(r)$ was increasing the derivative is 
$>0$ when $s>0$.  Hence the minimum is achieved when $s=0$
which means that $G_*$ and $G^*$ have a common mid-point and
Proposition 2.1 is proved for the case of an interval pair.
\medskip


\noindent
\emph{The general case.}
If $G_*=\{(a_\nu,b_\nu)\}$ and $G^*=\{(c_k,d_k)\}$
we make an induction over the total number of intervals which appear in the 
two families.
Let 
\[
\xi^*=\frac{c^*+d^*}{2}
\]
be the largest mid-point from the $G^*$-family
which means that $k$ is maximal,
In the $G_*$-family
we also get the largest mid-point
is
\[
\eta^*= \frac{a^*+b^*}{2}
\]
If $\xi^*>\eta^*$ the previous 
case shows that the double sum representing $I$ decreases as long as
when the interval $(c^*,d^*)$ is lowered.
In this process two cases can occur:
First, suppose that
the lowered $(c^*,d^*)$-interval hits $(c_{k\vvv 1},d_{k\vvv 1})$ before
the mid-point equality appears. To be precise, this occurs if
\[
c^*-d_{k\vvv 1}<\xi^*-\eta^*
\]
In this case we replace $G^*$ by a union of intervals where
the number of intervals therefore has decreased by one and
we lower $(c^*,d^*)$ until
$\xi^*=\eta^*$.
After this we lower the two top-intervals at the same time
until
one of them hits
the second largest $G$-interval and in this way the total number of intervals is
decreased while the double sum for $I$ is not enlarged.
This gives the requested induction step and the proof of
Proposition 2.1 is finished.






 
 
 










\bigskip

\centerline {\bf{3. Proof of Theorem 1.}}
\medskip

\noindent
Consider a  domain $U$ 
defined by
\[ 
g_1(x)\leq y\leq g_2(x)\quad\colon\quad a\leq x\leq b\tag{1}
\]
where $g_1(a)=g_2(a)$ and $g_1(b)=g_2(b)$.
To $U$ we associate the symmetric domain $U^*$
defined by 
\[
- \frac{1}{2}\bigl[ g_2(x)-g_1(x)\bigr]\leq y\leq
 \frac{1}{2}\bigl[ g_2(x)-g_1(x)\bigr]\quad\colon\quad a\leq x\leq b\tag{2}
\]
\medskip


\noindent
Notice that $U$ and $U^*$ have the same area.
Set

\[ J=\iint_{U\times U}\,
f\bigl(\sqrt{(x-x')^2+(y-y')^2}\bigr)\cdot dxdx'dydy'
\]

\[ J^*=\iint_{U^*\times U^*}\,
f\bigl(\sqrt{(x-x')^2+(y-y')^2}\bigr)\cdot dxdx'dydy'
\]
\medskip

\noindent
{\bf{Lemma 3.1.}} \emph{One has the inequality}
$J\leq J^*$.
\medskip

\noindent 
\emph{Proof.} Set 
$h(x)=\frac{1}{2}[g_2(x)-g_1(x)]$
and 
introduce the  function
\medskip

\[ 
H^*(x,x')=\int_{y=-h(x)}^{h(x)}
\int_{y'=-h(x')}^{h(x')}
\,\rho\bigl(\sqrt{(x-x')^2+(y-y')^2}\bigr)\cdot dydy'
\]
We have also the function
\[
H(x,x')=\int_{y=g_1(x)}^{g_2(x)}
\int_{y'=g_1(x')}^{g_2(x')}
f\,\bigl(\sqrt{(x-x')^2+(y-y')^2}\bigr)\cdot dydy'
\]
It is clear that

\[ J=\int_a^b\int_a^b\, H(x,x')dxdx'\quad\text{and}\quad
J^*=\int_a^b\int_a^b\, H^*(x,x')dxdx'
\]

\noindent
Lemma 3.1 follows if we have proved the inequality 
\[
H(x,x')\leq H^*(x,x')\tag{*}
\]
for all pairs $x,x'$ in $[a,b]$.
But this follows via Fubini's theorem
when Proposition 2.1 applied in the special case where
$G_*$ and $G^*$ both consist of a single interval.

\bigskip

\noindent
{\bf{3.2 Variation of convex sets.}}
Let $\mathcal A$ be the prescribed area in Theorem 1 and consider
a convex domain $U$ whose area is $\mathcal A$.
By elementary geometry we see that after a translation and a rotation the convex
domain
$U$
can be represented as in(1)  above.
We construct 
$U_*$ as above and notice that
it is a new convex domain. Moreover, 
Proposition 2.1 gives  $J(U_*)\leq J(U)$.
In the next step
we perform a symmetrisation of $U_*$ 
along some other line which cuts $U_*$ to get 
a new domain
$U_{**}$ where we now have
$J(U_{**})\leq J(U_*)\leq J(U)$.
Finally we use the  geometric result
due to Steiner for  convex domains which
asserts   that when
symmetrisations as above are repeated infinitely often while 
the angles of the directions to the
$x$-axis  change with some
irrational multiple of $2\pi$, then
the resulting sequence of convex domains converge to a disc.
This  proves that the $J$-functional on a disc is $\leq J(U)$ for every convex domain.
 
\medskip


\noindent
{\bf{3.3 The non-convex case}}
Here we  use 
the symmetrisation process by
Gros.
Let $U$ be a domain. Its symmetrisation in the $x$-direction
is defined  as follows: To every $x$ we get the open
set
\[
\ell_U(x)=\{y\,\colon\,(x,y)\in U\}\tag{1}
\]
Let
$\{(a_\nu,b_\nu)\}$ be the  disjoint intervals of $\ell\uuu U(x)$
and put 
\[
 d(x)=\frac{1}{2}\cdot
 \sum\, (b_\nu-a_\nu)
\]
 
\noindent
We get  the domain $U^*$ which is symmetric with respect to the $x$-axis where
\[ 
\ell_{U^*}(x)=(-d(x),d(x))
\]
Notice that $U$ and $U^*$ have equal  area.
Proposition 2.1 applies and gives
the inequality
\[
J(U)\leq J(U^*)\tag{2}
\]
Now Theorem 1 follows when we start from a non-convex domain $U$.
Namely, by the  result proved in  [Gros], it holds
that after inifinitely many symmetrizations as above using
different directions, the sequence of
$U$-sets converge to a disc.










\bigskip





\centerline {\bf{§ 0.2 On minimal surfaces.}}
\medskip



\noindent 
We shall  consider 
an  isoperimetric problem with a fixed boundary curve. 
More involved situations
arise  when the  minimal surfaces are bordered by
closed Jordan curves which  are free to move on
prescribed manifolds. This leads to 
problems by Plateau and Douglas and for
an account about this general case we refer to Courant's article
\emph{The existence of minimal surfaces of given toplogical structure
under prescribed boundary conditions}. (Acta. Math. Vol 72 1940]) where the reader
also finds an extensive references to relevant literature.
\medskip

\noindent
From now on we discuss the restricted 
problem when a boundary curve is fixed in
${\bf{R}}^3$ with coordinates
$(x,y,z)$.
Consider a rectifiable   closed Jordan curve
$C$ and denote by $\mathcal S(C)$ the family of surfaces 
which are bordered by $C$.
A surface $M$ in this family is minimal if
it has smallest possible area.
To find such a minimal surface
corresponds to a problem in the calculus of variation and  was 
studied by Weierstrass in a series of articles
starting from \emph{Untersuchungen über die Flächen
deren mittlere Krümmung überall gleich null ist}  from 1866.
A revised version written by Weierstrass  himself appears in volume I of 
his collected work.
He proved
that
if $M$ is a minimal surface in $\mathcal S(C)$ then
its mean curvature vanishes identically. Moreover,
$M$ has no singular points and is simply connected.
More precisely, the exists a homeomorphic
parametrization
of $M$ above an open disc in the complex $u$-plane which can be
achieved via complex analytic functions, or as expressed by
Weierstrass in the introduction to [Wei]:
\medskip


\noindent
\emph{Ich habe mich mit der Theorie die Flächen, deren mittlere
Krümmung überall gleich null ist, besonders auf dem grunde eingehender beschäftigt, weil
sie, wie ich zeigen werde, auf das Innigste mit der Theorie der analytischen funktionen
einer komplexen Argumentz zusammenhhängt.}
Or shortly phrased: 
\emph{The theory about minimal surfaces
is closely linked to the theory of  analytic functions in one complex variable.}
\medskip


\noindent
{\bf{The isoperimetric inequality.}}
Using Weierstrass'  description of minimal surfaces 
the following was proved
by
Carleman in the article
\emph{Zur Theorie der Minimalflächen} in 1920:

\bigskip

\noindent
{\bf{Theorem.}}
\emph{For every rectifiable simple closed curve
$C$ the area $A$ of the minimal surface
in $\mathcal S(C)$ satisfies the inequality}
\[ 
A\leq \frac {\ell(C)^2}{4\pi}
\]
where $\ell(C)$ is the arc-length of $C$.
\medskip

\noindent
{\bf{Remark.}}
For historic reasons one may wonder why this result was not already
discovered by Weierstrass. The reason might be that certain facts
in analytic function theory was not yet enough developed. 
Carleaman's proof relies upon 
the Jensen-Blascke factorisation
of analytic functions which was not know prior to 1900.
Another obstacle was the discovery by Hermann Schwarz that
the minimal surface in the family $\mathcal S(C)$
is not
determined by vanishing mean curvarute alone. See
Volume II, page 264 and  151-167 in the collected work
of Hermann Schwarz for this "ugly phenomenon" which was one reason
why Weierstrass  paid much attention to existence problems in
the calculus of variation.
As remarked by Carleman at the end of his article, an
alternative (and simpler) proof was given
by Blaschke  after the publication of 
[Carleman]. However, this proof
is restricted to
a special class of minimal surfaces where the "ugly phenomena" do not occur
so here we rely upon Weierstrass' original parametristions which
lead
to a proof the the theorem above.
\medskip

\noindent
{\bf{The case when $C$ is piecewise linear}}.
Suppose that the boundary curve
consists of
$n$ many line segements $L_1,\ldots ,L_n$. Following
Weierstrass  it means that  one regards the  problem:
\emph{Es soll ein einfach zusamenhängenden Minimalflächenstück
$M$ analytish bestimmt werden, dessen vorgeschiebenen
begrenzung $C$
aus $n$ geradlinigen strecken  bestecht, welche eine einfache,
geschlossene, nicht verknotete Linie bilden.}
\medskip

\noindent
In  [Weierstrass] appears a  far reaching study of this problem. 
The main result shows that
$M$ is determined via
a  pair of analytic functions $G(u)$ and $H(u)$ defined in
the lower half-plane $\mathfrak{Im}u<0$
for which the three functions defined by
\[
\phi_1(u)=\text{det}\,
\begin{pmatrix} G(u)&H'(u)\\
G'(u)&H'(u)\end{pmatrix}
\]
\[
\phi_2(u)= \text{det}\,
\begin{pmatrix} G(u)&H'(u)\\
G''(u)&H''(u)\end{pmatrix}
\]
\[
\phi_3(u)= \text{det}\,
\begin{pmatrix} G'(u)&H'(u)\\
G''(u)&H''(u)\end{pmatrix}
\]
become rational functions of $u$.
Moreover, [ibid]  exhibits 
second order differential equations of the Fuchsian type 
satisfied by the rational $\phi$-functions  and the position of their
poles are described in terms of the 
geometric configuration
of $C$. It would lead us too far to
enter
the  material in [Weierstrass] so its rich contents is left
to the interested reader for further  studies.
\medskip


\noindent
{\bf{The planar case.}}
If $C$ is a simple closed curve in the complex $z$-plane
the isoperimetric inequality follows easily via analytic function theory.
Namely, let $M$ be the Jordan domain bordered by $C$.
By Riemann's theorem there exists 
a conformal mapping $\phi\colon\, D\to M$ and we have
\[ 
\ell(C)= 
\int_0^{2\pi}\ |\phi'(e^{i\theta})|\, d\theta
\quad \colon\quad
\text{area}(M)=
\iint_D\, |\phi'(z)|^2\, dxdy
\]
Hence the isoperimetric
inequality for planar domains boils down to show that
\[
4\pi\cdot \iint_D\, |\phi'(z)|^2\, dxdy\leq 
\bigl(\int_0^{2\pi}\ |\phi'(e^{i\theta})|\, d\theta\,\bigr)^2\tag{i}
\]
To prove (i) we use that
the derivative $\phi'(z)$ is zero-free
and hence it has a suingle-valued square root
$f=\sqrt{\phi}$.
We have a series expansion
\[ 
f(z)= a_1z+a_2z^2+\ldots
\]
The right hand side in (i) becomes
\[
4\pi^2\cdot \bigl(\int_0^{2\pi}\ |\sum\, a_\nu e^{i\nu\theta}|^2\, d\theta\,\bigr)^2
= 4\pi^2\cdot( \sum\, |a_\nu|^2)^2
\]
The left hand side becomes
\[
4\pi\cdot \iint_D\, (\sum\, |a_\nu z^\nu|)^4\, dxdy
\]
Set
\[ 
b_m= \sum_{\nu=1}^{\nu=m}\, a_\nu\cdot a_{m-\nu}
\quad\colon\, m\geq 2
\]
Then (xx) becomes
\[
4\pi\cdot \iint_D\,\sum\, |b_m z^m|)^2\, dxdy=
4\pi\sum\, |b_m|^2\cdot 2\pi\cdot \iint_D\, r^{2m+1}\,dr
=
8\pi^2\cdot \sum\, \frac{|b_m|^2}{2m+2}
\]
Hence (i) follows if
\[
\sum_{m=2}^\infty \, \frac{|b_m|^2}{m+1}\leq 
\sum_{\nu=1}^\infty\, |a_\nu|^2)^2\tag{ii}
\]
\medskip

\noindent
At this stage we leave it to the reader to verify
the planar isoperimetric
inequality in
Theorem 1 and that equality holds if and only 
$\phi(z)$ is such that
the complex derivative takes the form 
\[ 
\phi'(z)=\frac{a}{(1-qz)^2}
\] 
for a pair of constants $a,b$. This means that $\phi$ is
is a Möbius transform and hence $C$ must be a circle, i.e.
equality in Theorem 1 for a planar curve holds
if and only if $C$ borders a disc,








\bigskip

\centerline{\emph{B. Proof of Theorem 1.}}
\medskip




\noindent
The crucial step in the proof relies upon the following
result which is due to Weierstrass:
\medskip

\noindent
{\bf{B.1 Proposition.}}
\emph{Let $M$ be a minimal surface in $\mathcal S(C)$.
Then there exists an analytic function $F(u)$ in the open 
unit disc such that
points $(x,y,z)\in M$ are given by the equations:}
\[ 
x=\mathfrak{Re} \int\, (1-u^2) F(u)\,du
\quad\colon\quad
y=\mathfrak{Re}\int \, i(1+u^2)F(u)\,du\quad\colon\quad
z=\mathfrak{Re}\int \, 2F(u)\, du
\]
\medskip

\noindent
The proof of this result
occupies
five pages in [Weierstrass].
We remark that he employed
Riemann's mapping theoren for simply connected
domains
during the proof. Let us indicate some
details.
To begin with Weierstrass proved that there exists
a planar domain
$\Sigma$ with real coordinates
$(p,q)$ and a diffeomorphism
between
$M$ and $\Sigma$ which is conformal, i.e. 
$M$ is defined by the equations
\[ 
x=x(p,q)\quad\colon
y=y(p,q)\quad\colon z=z(p,q)\tag{i}
\]
where the 
vectors $(\frac{\partial x}{\partial p}, 
(\frac{\partial y}{\partial p}, (\frac{\partial x}{\partial p},)$
and
$(\frac{\partial x}{\partial q}, (\frac{\partial y}{\partial q}, (\frac{\partial z}{\partial q})$
are pairwise orthoginal unit vectors.
Moreover, when $M$ is minimal
the mean curvature of $M$ vanishes
which means that  the three functions in (1) are harmonic, i.e.
\[
\Delta(x)= \frac{\partial^2 x}{\partial p^2}+\frac{\partial ^2x}{\partial q^2}=0\tag{ii}
\]
and similarly for $y$ and $z$.
Next,
the harmonic functions above are real parts of analytic functions
which yields a triple $f,g,h$ in $\mathcal O(\Sigma)$
such that
\[ 
x= \mathfrak {Re}\, f(u)
\]
The orthogonality
of
the vectors ${\bf{v}}$ and ${\bf{w}}$ above entails via the
Cauchy Riemann equations that
\[
(f'(u))^2+(g'(u))^2+(h'(u))^2=0
\]


\medskip

\noindent
Starting from this, Weierstrass
used  sterographic projections and Riemann's conformal mapping theorem
to construct
an analytic function
$F(u)$ which gives the equations in Proposition B.1.
Admitting Weierstrass' result
the following hold:

\medskip

\noindent
{\bf{B.2 Propostion.}} \emph{
When the minimal surface $M$ is parametrized as in
Proposition B.1
one has the equations}
\[
\text{area}(M)=
\iint_D\, (1+|u|^2)^2\cdot |F(u)|^2\, d\xi d\eta\quad\colon\quad 
\ell(C)=2\cdot \int_0^{2\pi}\,  |F(e^{i\theta})|\, d\theta
\]
\medskip

\noindent
\emph{Proof.}
With $u=\alpha+i\beta$ this amounts to show that
\[ 
dx^2+dy^2+dz^2=
(1+|u|^2)|F(u)|^2\cdot (d\alpha^2+d\beta^2)\tag{i}
\]

\noindent
To prove  (i) we consider some point $u\in D$.
Set $F(u)= |F(u)|\cdot e^{i\theta}$
and $u= se^{i\alpha}$. With
$du=d\alpha$ real we have
\[
dx=\mathfrak{Re}(1-u^2)F(u))\cdot d\alpha=
|F(u)|\cdot  \bigl
(\cos\theta-|u|^2\cos\theta\cdot \cos 2\alpha
-|u|^2\sin\theta\cdot \sin 2\alpha\bigr)\cdot d\alpha
\]
Trigonometric formulas give
\[ 
(dx)^2=|F(u)|\cdot \bigl[\cos^2\theta+|u|^4\cos^2(2\alpha-\theta)-
2|u|^2\cos\theta\cdot \cos(2\alpha-\theta)\,\bigr]\cdot (d\alpha)^2\tag{i}
\]
\[
(dy)^2 =|F(u)|^2 \cdot  \bigl[\sin^2 \theta+|u|^4\sin^2(2\alpha-\theta)+
2|u|^2\sin\theta\cdot \sin(2\alpha-\theta)\bigr]\cdot d\alpha\tag{ii}
\]
\[ 
(dz)^2=4|F(u)|^2\cdot |u|^2\bigl(\cos^2(\theta-\alpha)]\cdot
(d\alpha)^2\tag{iii}
\]
\medskip

\noindent
Adding (i-ii) we get
\[
(dx)^2+(dy)^2= |F(u)|^2\cdot \bigl[1+|u|^4-
2\cdot|u|^2\cos(2\theta-2\alpha)\bigr]\cdot (d\alpha)^2
\]
Finally, the trigonometric formula
\[
4 \cos^2\phi=2-2\cos\,2\phi
\]
and (iii) entail that
\[
(dx)^2+(dy)^2+(dz)^2 = |F(u)|^2\cdot (1+|u|^2)^2\cdot (d\alpha)^2\tag{iv}
\]
\medskip

\noindent
The same infinitesmal equality as in (iv) 
is proved when
$u=id\beta$ for some small real $\beta$
and then we can read off 
Proposition B.2.





\bigskip



\centerline{ \emph{Final part of the proof}}
\medskip


\noindent
Put
$f_1(u) =F(u)u^2$ and
$f_2(u)=F(u)$. Proposition B.2 gives 
\[
\text{area}(M)=
\iint_D\,\bigl(\,|f_1(u)|^2+|f_2(u)|^2\,\bigr)\, d\xi d\eta+
2\cdot \iint_D\,|f_1(u)|\cdot |f_2(u)|\, d\xi d\eta\tag{i}
\]
Since $|f_1|=|f_2|= |F|$ holds on the unit circle we also get
\[
\ell(C)^2=
\bigl[ \int_0^{2\pi}\, |f_1(e^{i\theta})|\, d\theta\bigr ]^2+
\bigl[ \int_0^{2\pi}\, |f_2(e^{i\theta})|\, d\theta\bigr ]^2+
2\cdot  \int_0^{2\pi}\, |f_1(e^{i\theta})|\, d\theta\cdot
\int_0^{2\pi}\, |f_2(e^{i\theta})|\, d\theta\tag{ii}
\]
\medskip


\noindent
Using (i-ii) Carleman derived the isoperimetric  inequality
from the following:

\medskip

\noindent
{\bf {B.3 Lemma.}} \emph{For each pair of analytic functions $g,h$ in the unit disc
one has}
\[
\iint_D\,\bigl[g(u)|\cdot |h(u)|\, d\xi d\eta\leq
\frac{1}{4\pi}\cdot 
\int_0^{2\pi}\, |g(e^{i\theta})|\, d\theta\cdot 
\int_0^{2\pi}\, |h(e^{i\theta})|\, d\theta
\]
\medskip

\noindent
Let us first notice that  Lemma B.3 applied to the pairs $g=h=f_1$,
$g=h=f_2$ and the pair $g=f_1$ and $h=f_2$
together with (i-ii) give Theorem 1.
So there remains  to prove Lemma B.3.
We can write
\[ 
g=B_1\cdot g^*\quad\colon\quad h= B_2\cdot h^*
\]


\noindent
where $B_1,B_2$ are Blaschke products and the analytic functions
$g^*$ and $h^*$ are zero free in the unit disc.
Since
$|B_1|= |B_2|=1$ hold on the unit circle it suffices to prove
Lemma B.2 for the pair $g^*,h^*$,  i.e. we may assume that both $g$ and $h$
are zero-free.
Then they posses square roots so we
can find analytic functions $G,H$ in the unit disc where
\[
g=G^2\quad\colon\quad h=H^2
\]
Consider the Taylor series
\[
G(z)= \sum\, a_ku^k\quad\colon\quad H(z)= \sum\, b_ku^k
\]
Now $GH= \sum c_ku^k$
where
\[ 
c_k= a_0b_k+\ldots+a_kb_0\tag{i}
\]


\noindent
Using polar coordintes to perform double integrals it follows that

\[
\iint_D\,|G^2(u)|\cdot |H^2(u)|\, d\xi d\eta=
\pi\cdot \sum_{k=0}^\infty\, \frac{|c_k|^2}{k+1}
\]
At the same time one has
\[
\int_0^{2\pi}\, |G^2(e^{i\theta})|\, d\theta= 2\pi\cdot
\sum _{k=0}^\infty\, 
|a_k|^2
\]
with a similar formula for the integral of $H^2$.
Hence Lemma B.2 follows if we have proved the inequality
\[
\sum_{k=0}^\infty\, \frac{|c_k|^2}{k+1}\leq 
\sum _{k=0}^\infty\, 
|a_k|^2\cdot 
\sum _{k=0}^\infty\, 
|b_k|^2\tag{ii}
\]
To get (ii) we use (i) which for every $k$ gives:
\[
|c_k|^2\leq (|a_0||b_k|+\ldots+|a_k||b_0|)^2\leq
(k+1)\cdot (|a_0|^2|b_k|^2+\ldots+|a_k|^2|b_0|^2)
\]
Finally, a  summation over $k$ entails (ii) and Lemma B.3 is proved.






\newpage









\centerline{\bf {§ 23  Lindelöf functions.}}

\bigskip

\noindent
{\bf{Introduction.}}
For each real number $0<a\leq 1$
there exists the entire  function
\[ 
Ea_(z)=\sum_{n=0}^\infty\,\frac{z^n}{\Gamma(1+na)}
\]
Growth properties of the $E$-functions were investigated
in a series of articles by
Mittag-Leffler between 1900-1904 using 
integral formulas  for the entire function
$\frac{1}{\Gamma(z)}$.
This inspired
Phragmén
to study 
entire functions $f(z)$ such that
there are constants $C$ and $0<a<1$ with:
\[
\log|f(re^{i\theta})| \leq C\cdot (1+|r|)^a)\quad\colon
-\alpha<\theta<\alpha\tag{1}
\] 
for some $0<\alpha<\pi/2$ while
$f(z)|\leq C$ for all $z\in{\bf{C}}\setminus S$.
When this holds  we get the entire function
\[ 
g(z)=\int_0^\infty\, f(sz)\cdot e^{-s}\cdot ds
\]
If $z$ is outside the sector $S$ it is clear that
$|g(z)|$ is bounded by $C\cdot \int_0^\infty e^{-s}ds=C$.
When $z=re^{i\theta}$ is in the sector we 
still
get a  bound from (1) since $0<a<1$
and conclude that the entire function $g$ is bounded and hence a constant.
Since the Taylor coefficients of
$f$
are recaptured from $g$ it follows that
$f$ must be  constant.
More general  results of this kind were obtained in
the joint article [PL] by Phragmén and Lindelöf from 1908
and led to  the Phragmén-Lindelöf principle.
A continuation of [PL]
appears in  Lindelöf's  article
\emph{Remarques sur la croissance
de la fonction $\zeta(s)$}  (Bull. des scienes mathématiques 1908]
devoted to 
the growth of Riemann's $\zeta$-function along vertical lines 
in the strip $0<\mathfrak{Re}(z)<1$.
This  leads to the study of  various  indicator functions
attached to analytic functions
and we shall expose
material from Care,an's article
\emph{Sur la fonction $\mu(\sigma)$ de M. Lindelöf}
which was published in 1930
and attributed toi A. Wiman,. 
Here is the  set-up:
Consider a strip domain
in the complex $s$-plane:
\[
\Omega=\{ s=\sigma+it\quad
\colon t>0\quad\text{and}\quad 0\leq a<\sigma<b\}
\]

\medskip

\noindent
An analytic function
$f(z)$ in $\Omega$ is of
\emph{finite type} if
there exists some
integer $k$, a constant  $C$ and some $t_0>0$ such that
\[ 
|f(\sigma+it)|\leq C\cdot t^k\quad\text{hold for}\quad t\geq t_0
\] 
To every such $f$ we define the Lindelöf function
\[
\mu_f(\sigma)
=
\limsup_{t\to\infty}\,
\frac{\text{Log}\, |f(\sigma+it)|}{\text{Log}\, t}\tag{*}
\]
Lindelöf and Phragmén proved  that $\mu_f$ is a continuous and convex
function on $(a,b)$. No further restrictions
occur on the $\mu$-function because one has:
\bigskip

\noindent
{\bf{1. Theorem.}} \emph{For every convex and continuous function
$\mu(\sigma)$ defined in $[a,b]$
there exists an analytic function $f(z)$ without zeros in
$\Omega$ such that
$\mu_f=\mu$.}
\medskip

\noindent
{\bf{2. Exercise.}} Prove this result using the
$\Gamma$-function. First, to a pair of real numbers
$(\rho,\alpha)$ we set
\[
 f(s)=e^{-\frac{\pi i\cdot\rho s}{2}}\cdot\Gamma (\rho(s-a)+\frac{1}{2})\tag{i}
 \]
Use properties of the $\Gamma$-function to show that
$f$ has finite type in
$\Omega$ and its indicator function becomes 
a linear function:
\[ 
\mu_f(\sigma)= \rho\cdot (\sigma-a)
\]

\noindent
More generally one gets a function  $f$ where
$\mu_f$ is piecewise linear by:
\[ 
f= \sum_{k=1}^{k=m}\, c_ke^{-\frac{\pi i\cdot\rho_\nu s}{2}} \Gamma(\rho_k(s-a_k)+
\frac{1}{2})\tag{ii}
\]
where $\{c_k\}$, $\{\rho_k\}$ and $\{a_k\}$ are $m$-tuples of real numbers.
Finally, starting from
an arbitrary
convex curve we can 
choose  some dense and  enumerable set of enveloping tangents to
this curve. Then
an infinite series of the form above gives an analytic function
$f(s)$ such that
\[
 \sigma\mapsto\mu_f(\sigma)
\] 
yields an arbitrarily
given convex $\mu$-function on $(a,b)$.

\medskip


\centerline{\bf{1. A construction of   harmonic functions.}}
\medskip

\noindent
Let $U(x,y)$ be a bounded harmonic function in the strip domain
$\Omega$
and $V$  its harmonic conjugate. Set
\[
 f(s)=\text{exp}\,\bigl[\text{(log}(s)-\frac{\pi i}{2})(U(s)+iV(s))\bigr]\tag{*}
 \]


\noindent
It is easily see that
$f(z)$ has finite type in
$\Omega$.
With $s=\sigma+it$ we have
\[
|f(\sigma+it)|= 
\]
\[
\text{exp}(\frac{1}{2}\log(\sigma^2+t^2)\cdot U(\sigma+it)\cdot
\text{exp}(-(\frac{\pi}{2}- \text{arg}(\sigma+it))\cdot V(\sigma+it))
\]
It follows that 
\[ 
\frac{ \log\, |f(\sigma+it)|}{t}=
 \frac{\log\, \sqrt{\sigma^2+t^2}\cdot U(\sigma+it)]}{\log t}
+\frac {(\text{arg}(\sigma+it)-\frac{\pi i}{2})\cdot V(\sigma+it)}{t}
\]
 
 

\noindent{\bf{1.1 Exercise.}}
With $\sigma$ kept fixed one has
\[
\text{arg}(\sigma+it)=\tan\,\frac{t}{s}
\] 
which tends to $\pi/2$ as $t\to +\infty$.
Next,  $V(\sigma+it)$ is for large $t>0$
up to a constant the primitive of 
\[
\int\uuu 1^t\, \frac{\partial V}{\partial u}(\sigma+iu)\cdot du
\]
Here the partial derivative of $V$ is equal to the partial derivative
$\partial U/\partial\sigma(\sigma,u)$ taken along
$\mathfrak{Re}\, s=\sigma$.
Since $U$ is bounded in the strip domain
it follows from
Harnack's inequalities that
this partial derivative stays bounded when $1\leq u\leq t$
by a constant which is independent of $t$.
Putting this together the reader can verify that
\[ 
\lim_{t\to +\infty}\, 
\frac {(\text{arg}(\sigma+it)-\frac{\pi i}{2})\cdot 
V(\sigma+it)}{t}=0\tag{1.2}
\]

\bigskip

\noindent
From (1.2 )   we obtain the equality
\[
\mu\uuu f(\sigma)=\limsup_{t\to\infty}\, U(\sigma+it)\tag{*}
\]
This suggests a further study of 
growth properties of bounded harmonic functions in strip domains.


\bigskip


\centerline {\bf{2. The $M$ and the $m$-functions.}}

\medskip

\noindent
To a bounded harmonic function $U$ in
$\Omega$  we associate the maximum and the minimum
functions:
\[ 
M(\sigma)=\limsup_{t\to\infty}
\, U(\sigma+it)
\quad\text{and}\quad\liminf_{t\to\infty}
\,U(\sigma+it)
\]


\noindent
{\bf{2.1 Proposition.}}
\emph{$M(\sigma)$ is a convex function while
$m(\sigma)$ is concave.}
\medskip

\noindent
We prove the convexity of $M(\sigma)$. The concavity of $m$
follows when we replace $U$ by $\vvv U$.
Consider a pair $\alpha,\beta$ with $a<\alpha<\beta<b$.
Replacing $U$ by $U+ A+\cdot Bx$ for suitable constants
$A$ and $B$ we may assume that
$M(\alpha)=M(\beta)=0$
and the requested convexity follows if we can show that
\[ 
M(\sigma)\leq 0\quad\colon\quad \alpha<\sigma<\beta
\]
To see this we consider
rectangles 
\[
\mathcal R[T\uuu *,T^*]
=\{\sigma+it\quad \alpha \leq \sigma\leq \beta
\quad\text{and}\quad  T\uuu *\leq t\leq T^*\}
\]
Let $\epsilon>0$ and start with
a large $T\uuu *$ so that
\[
t\geq T\uuu *\implies
U(\alpha+it)\leq \epsilon\tag{i}
\] 
and similarly with $\alpha$ replaced by $\beta$.
Next, we have a constant $M$ such that
$|U|\uuu\Omega\leq M$.
If $z=\sigma+it$ is an interior point of the rectangle above
it follows by harmonic majorisation that

\[
U(\sigma+it)\leq \epsilon+ M\cdot \mathfrak m\uuu z(J\uuu *\cup J^*)
\]
where the last term  is the harmonic measure at $z$
which evaluates the harmonic function in
the rectangle at $z$ with boundary values zero on the two verical lines
of the rectangle which it is equal to 1 on the horizontal intervals 
$J^*=(\alpha,\beta)+iT^*$ and 
$J\uuu *=(\alpha,\beta)+iT\uuu *$
\medskip

\noindent
{\bf{Exercise.}}
Show (via the aid of figure that with $T^*=2T\uuu *$
one has
\[
\lim\uuu{T\uuu *\to +\infty}\,
\mathfrak m\uuu {\sigma+3i T\uuu */2}(J\uuu *\cup J^*)=0
\] 
where this limit is uniform when $\alpha\leq \sigma\leq \beta$.
Since $\epsilon>0$ is arbitrary in (i) the reader can  conclude that
$M(\sigma)\leq 0$ for every $\sigma\in(\alpha,\beta)$.
\bigskip

\noindent
{\bf{A special case.}}
Suppose that we have the equalities
\[
m(\alpha)=M(\alpha)\quad\text{and}\quad
m(\beta)=M(\beta)\tag{1}
\]
Using rectangles as above and harmonic majorization the
reader can verify that this implies that
\[
m(\sigma)=M(\sigma)\quad\colon\quad \alpha<\sigma<\beta
\]
Let us remark that
this result was originally proved by
Hardy and Littlewood in [H\vvv L].




\bigskip

\noindent
{\bf{The case when $M(\sigma)-m(\sigma)$ has
a tangential zero}}.
Put $\phi(\sigma)=M(\sigma)-m(\sigma)$ and suppose that this non\vvv 
negative
function in $(a,b)$
has a zero at some $a<\sigma\uuu 0<b$
whose graph has a tangent at $\sigma_0$.
This means that if:
\[ 
h(r)=\max_{-r\leq|\sigma\vvv \sigma\uuu 0|\leq r}\, \phi(\sigma)
\] 
then
\[
\lim_{r\to 0}\, \frac{h(r)}{r}=0\tag{*}
\]


\noindent
Under this hypothesis the following result is proved in
[Carleman].
\medskip


\noindent
{\bf{2.2 Theorem.}} \emph{When (*) holds we have}
\[ 
m(\sigma)=M(\sigma)\quad\colon\,
a<\sigma<b
\]

\medskip

\noindent
The subsequent proof from [Carleman]
was given
at 
a lecture by Carleman  in Copenhagen 1931 which
has the merit that a similar reasoning 
can be applied in dimension $\geq 3$.
Adding some linear function to $U$ we may assume that
$M(\sigma_0)=m(\sigma_0)=0$ which means that
\[
\limsup_{t\to\infty}\,
U(\sigma_0,t)=0\tag{1}
\]

\noindent
Next,
consider the function
\[ 
\phi\colon t\mapsto \partial U/\partial \sigma(\sigma_0,t)\tag{1}
\]
The assumption (*) and the result in XXX gives:
\[
\lim\uuu{t\to\infty}\,
\partial U/\partial \sigma(\sigma_0,t)=0\tag{2}
\]


\noindent
Next, consider some 
$a<\sigma<b$ and let $\epsilon>0$.
By the  result from XX there exist
finite tuples of constants $\{a_1,\ldots,a_N\}$ and
$\{b_1,\ldots,b_N\}$ and 
some $N$-tuple $\{\tau_\nu\}$ which
stays in a $[0,1]$ such that
\[
\bigl| U(\sigma,t)-\sum\, a_\nu\cdot U(\sigma_0, t_\nu+t)
-\sum\, b_\nu\cdot \partial U/\partial\sigma(\sigma_0, t_\nu+t)\bigr|<\epsilon\quad
\text{hold for all}
\quad t\geq 1\tag{5}
\]
Since $\epsilon$ is arbitrary it follows from (1\vvv 2)  
that
\[
\lim_{t\to\infty}\, U(\sigma,t)=0\tag{5}
\]
for every $a<\sigma<b$ which obviously gives
the requested equality
in
Theorem 2.2.



\bigskip

\noindent
\centerline {\bf{2.3. Integral  indicator funtions.}}
\medskip

\noindent
Let $f(s)$   be an analytic function of finite order
in the strip domain $\Omega$ and fix some $t_0>0$ which does not affect
the subsequent constructions.
For a 
pair  $(\sigma,p)$ where
$a<\sigma<b$ and $p>0$
we  associate the set of
of positive numbers $\chi$ such that the integral
\[ 
\int_{t_0}^\infty\, \frac{|f(\sigma+it)\bigl|^p}{t^\chi}\cdot dt<\infty\tag{*}
\]



\noindent
We get a critical smallest non-negative number  
$\chi_*(\sigma,p)$ such that (*) converges when
$\chi>\chi_*(\sigma,p)$.
In the case $p=1$ 
a  result due to Landau
asserts that 
$\chi(\sigma,1)$ determines the half-plane of the complex $z$-plane where
the function
\[ 
\gamma(z)=\int_{t_0}^\infty\, \frac{f(\sigma+it)}{t^z}\cdot dt
\] 
is  analytic and
$\sigma\mapsto \chi(\sigma,1)$
is a convex function on  $(a,b)$.
A more general  convexity
result holds when $p$  also varies.
\medskip

\noindent
{\bf{2.4 Theorem.}} \emph{Define the $\omega$-function by}:
\[ 
\omega(\sigma,\eta)= \eta\cdot \chi(\sigma,\frac{1}{\eta})\quad\colon
a<\sigma<b\quad\colon \eta>0
\]
\emph{Then $\omega$ is a continuous and convex function of the 
two variables $(\sigma,\eta)$
in the product set $(a,b)\times {\bf{R}}^+$.}
\medskip

\noindent
{\bf{2.5 Remark.}}
Theorem 2.4 is proved using 
Hölder inequalities and
factorisations of analytic functions which
reduces the proof to the case when
$f$ has no zeros.
The reader is invited to supply details of the proof or 
consult [Carleman].


\bigskip




\centerline{\bf {3.  Lindelöf estimates in the unit disc.}}

\bigskip

\noindent
Let $f(z)$ be analytic in the open unit disc given by a power series

\[ f(z)=\sum a_n\cdot z^n
\]
We assume that the sequence $\{a_n\}$ has temperate growth, i.e. there exists
some integer $N\geq 0$ and a constant $K$ such that
\[ 
|a_n|\leq K\cdot n^N\quad\colon\quad n=1,2,\ldots
\]
In addition we assume that the sequence
$\{a_n\}$ is not too small in the sense that
\[ 
\sum_{n=1}^\infty\, |a_n|^2\cdot n^{s}=+\infty\quad\colon
\quad\,\forall\, s>0\tag{*}
\]
Now there exists  the smallest number $s_*\geq 0$ such that
the Dirichlet series

\[ 
\sum_{n=1}^\infty\, |a_n|^2\cdot \frac{1}{n^s}<\infty,\quad
\text{for all}\,\, s>s_*
\]
\medskip

\noindent
To each
$0\leq\theta\leq 2\pi$ we set
\[ 
\chi(\theta)=\min_s\, \int_0^1\, \bigl|f(re^{i\theta})\bigr|\cdot(1-r)^{s-1}\cdot dr<\infty\tag{1}
\]
\[
\mu(\theta) =\text{Lim.sup}_{r\to 1}\,
\frac{\text{Log}\, |f(re^{i\theta})|}{ \text{Log}\,\frac{1}{1-r}}
\tag{2}
\]
\medskip

\noindent
We shall study the two functions $\chi$ and $\mu$.
The first result is left as an exercise.

\medskip


\noindent
{\bf {3.1. Theorem.}} \emph{The inequality}
\[
\chi(\theta)\leq\frac{s^*}{2}
\] 
\emph{holds almost everywhere, i.e. for all $0\leq\theta\leq 2\pi$ outside a null set on
$[0,2\pi]$.}

\medskip

\noindent
\emph{Hint.} Use the formula

\[ 
\frac{1}{2\pi}\cdot \int_=^{2\pi}\, |f(re^{i\theta})|^2\cdot d\theta=
\sum\, |a_n|^2
\]


\bigskip

\noindent 
For the $\mu$-function a corresponding result holds:



\medskip
\noindent
{\bf {3.2. Theorem.}} \emph{The inequality below holds almost everywhere.}
\[
\mu(\theta)\leq\frac{s^*}{2}
\] 


\noindent
\emph{Proof.}
Let $\epsilon>0$ and introduce the function
\[ 
\Phi(z)=\sum\, a_n\cdot \frac{\Gamma(n+1)}{\Gamma(n+1+\frac{s^*}{2}+\epsilon)}
\cdot z^n=\sum\, c_n\cdot z^n
\]


\noindent
It is clear that
the construction of
$s^*$ entails
\[ 
\sum\, |c_n|^2<\infty
\]


\noindent
Next, set $\Phi_0=\Phi$ and define inductively the sequence
$\Phi_0,\Phi_1,\ldots$ by
\[ \Phi_\nu(z)=
z^{\nu-1}\cdot \frac{d}{dz}\bigl[ z^\nu\cdot \Phi_{\nu-1}(z)\bigr)
\quad\colon\quad \nu=1,2,\ldots
\]


\noindent
{\bf 3.3 Exercise.} Show that for almost every
$0\leq\theta\leq2\pi$ there exists a constant
$K=K(\theta)$ such that
\[
|\Phi_\nu(re^{i\theta})|\leq K(\theta)\cdot \frac{1}{1-r)^\nu}\quad\colon
0<r<1
\]


\noindent
Next, with  $s^*$ and $\epsilon$ given we
define
the integers $\nu$ and $\rho$:
\medskip
\[ 
\nu=\bigl[\,\frac{s^*}{2}+\epsilon\,\bigr]+1\quad\colon\quad
\rho=\frac{s^*}{2}+\epsilon- \bigl[\,\frac{s^*}{2}+\epsilon\,\bigr]
\]
where the bracket term is the usual notation for the
smallest integer $\geq \frac{s^*}{2}+1$.
\medskip

\noindent
{\bf Exercise} Show that with
$\nu$ and $\rho$ chosen  as above one has
\[\Phi_\nu(z)=\sum\, a_n\cdot \frac{\Gamma(n+1+\nu)}{\Gamma(n+1+\rho-1)}
\cdot z^n
\]

\noindent
and use  this to show the inversion formula
\[ 
f(z)=\frac{1}{z^\nu\cdot\Gamma(1-\rho)}\cdot
\int_0^z\, (z-\zeta)^{-\rho}\dot \zeta^{\nu+\rho-1}\cdot
\Phi_\nu(\zeta)\cdot d\zeta\tag{*}
\]

\medskip

\noindent
{\bf 3.4 Exercise.} Deduce from the above that for almost every
$\theta$ there exists a constant $K(\theta)$ such that
\[
|f(re^{i\theta})|\leq K(\theta)\cdot\frac{1}{ (1-r)^{\nu+\rho-1}}\tag{**}
\]
\medskip

\noindent
{\bf Conclusion.}
From (**) and the construction of
$\nu$ and $\rho$ the reader can confirm
Theorem  3. 2.

\bigskip

\noindent
{\bf 3.5 Example.} Consider the function
\[ 
f(z)=\sum_{n=1}^\infty\, z^{n^2}
\]
Show that $s^*=\frac{1}{2}$ holds in  this case. Hence
Theorem  B.2 shows that for each $\epsilon>0$ one has 
\[
\max_r\, (1-r)^{\frac{1}{4}+\epsilon}\cdot |f(re^{i\theta}|<\infty\tag{E}
\]
for almost every $\theta$. 
\medskip

\noindent
{\bf 3.6 Exercise.}
Use the inequality above to show the following:
For a complex number
$x+iy$ with $y>0$ we set
\[
q= e^{\pi ix-\pi y}
\]
Define the function
\[
\Theta(x+iy)= 1+q+q^2+\ldots
\]
Show that when $\epsilon>0$
then there exists a constant $K=K(\epsilon,x)$ for almost all
$x$ such that
\[
y^{\frac{1}{4}+\epsilon}\cdot |\theta(x+iy)|\leq K\quad\colon\quad y>0
\]







\newpage

\centerline{\bf{The equation $\frac{\partial f}{\partial x}+i\frac{\partial f}{\partial y}= af-bf$}}
\bigskip







\noindent
Let $s$ and $b$ be complex-valued continous functions defined in a disc of radius $R$
centered at the origin  in  the complex $z$-plane where $z=x+iy$.
Let $f$ satisfy the equation above where we from the start
assume that $f$ is continuous and the equality holds in the sense of
distributions.
Assume also that
\[ 
\lim_{z\to 0}\, z^{-n}f(z)=0
\]
hold for every positive integer $n$.
We leave it to the reader to verify that this entails that the function
$f_n(z)=f(z)/z^n$ satisfies  the differential equation
\[
\frac{\partial f_n}{\partial x}+i\frac{\partial f_n}{\partial y}= af_n+b\cdot
\frac{\bar z^n}{z^n}\cdot \bar f(z)
\]
Multiplying thie equation with
$\frac{1}{z-\zeta}$, Cauchy's formula gives the equation
\[
f_n(\zeta)=\frac{1}{2\pi i}\int_{|z|=r}\,
\frac{f_n(z)}{z-\zeta}\, dz-
\frac{1}{2\pi }\iint_{|z|\leq r}\,\bigr[\,
af_n+b\cdot\frac{\bar z^n}{z^n}\cdot \bar f_n(z)]\, dxdy
\]
for each $0<r<R$. Recall that
\[
\frac{1}{2\pi }\iint_{|z|\leq r}\,
\frac{d\xi d\eta}{|z-\zeta|}| d\xi d\eta\
\leq 2r
\]
hold when  $|z|\leq r$.
Let $M$ majorise the maximum norms of $a$ and $b$ over the
disc of radius $r$. By the  triangle inequality we conclude that 
an integration over the
$\zeta$-disc of radius $r$ gives
\[
\iint_{|z|\leq r} |f_n(z)]\, dxdy\leq 
2r\cdot\int_{|z|=r}\,|f_n(z)|\, |dz|+
4Mr\iint_{|z|\leq r}\,|f_n(z)|\,dxdy
\]
With $r<1/4M$ we obtain
\[
\iint_{|z|\leq r} |\frac{f_n(z)}{z^n}|\, dxdy\leq \frac{2r}{1-4Mr }\cdot  \frac{1}{r^n }
\iint_{|z|\leq r}\,|f(z)|\,dxdy\tag{*}
\]
This inequality holds for each positive integer $n$.
If  $f(z_0)\neq 0$ for some
$|z_0|<r$ it is clear that there exists some $0<\rho<r $ and a positive constant $k$
such that the left hand side is
$\geq k/\rho^n$ for every $n$. Thus  contradicts  (*) when $n$ is large
and hence
$f$ must vanish identically in the disc
of radius $r$.






\newpage









\centerline{\bf{Appendix: Entire functions of exponential type}}.

\bigskip







\noindent
The class $\mathcal E$ of entire functions of exponential type is defined as follows:
\medskip

\noindent
{\bf{A.0 Definition.}} \emph{An entire function $f$ belongs to
$\mathcal E$ if and only if there exists constants
$A$ and $C$ such that}
\[
 |f(z)|\leq C\cdot e^{A|z|}\quad\colon\,\, z\in{\bf{C}}\tag{*}
\] 

\medskip

\noindent
The results in Sections A\vvv B are  due to Hadamard and Lindelöf.
The  class $\mathcal N$ which appears in Section 3
was introduced by Carleman
who used it to prove certain approximation theorems related to moment problems.
The main results
deal with
Tauberian theorems which is treated in section D and
based upon Chapter V in [Paley\vvv Wiener].
Let us present some  of the results to be proved in § D
while we refer to § A-B for
more elementary material about the class $\mathcal E$.
Consider a non\vvv decreasing sequence $\{\lambda\uuu\nu\}$
of positive real numbers such that the series
\[ 
\sum\, \lambda\uuu \nu^{\vvv 2}<\infty\tag{1}
\]
When this holds there exists the entire function
given by a product series:

\[ 
H(z)=\prod\, (1\vvv \frac{z^2}{\lambda_\nu^2})
\]
Notice that $H(z)$ is  positive on the imaginary
axis. We get  the function defined for real $y>0$:
\[
y\mapsto \frac{\log H(iy)}{y}=
\frac{1}{y}\, \sum \log\, (1+ \frac{y^2}{\lambda_\nu^2})
\]
At the same time we  consider the intergals
\[ 
J(R)=\int\uuu{\vvv R}^R\, \frac {\log |H(x)|\cdot dx}{x^2}
\]

\medskip
\noindent
{\bf{0.1 Theorem.}} \emph{The existence of a constant $A$ such that}
\[
\lim\uuu{y\to \infty}\, \frac{\log H(iy)}{y}= \pi A \tag{i}
\] 
\emph{and}
\[
\lim\uuu{R\to \infty} J(R)=\vvv \pi^2A\tag{ii}
\]
\emph{are completely equivalent}
\medskip

\noindent
{\bf{Remark.}}
Of special interest is the case when
the limit in (ii) is automatic via an integrability condition, i.e. when
\[
\int\uuu{\vvv\infty}^\infty\,\frac {\bigl|\log |H(x)|\,\bigr |\cdot dx}{x^2}\tag{*}
<\infty
\]
In this case the $J$\vvv integrals converge and as a consequence 
there is a limit in (i) for some $A\geq 0$.
It turns out that further conclusions can be made.
Namely, the convergence of (*) implies that
the
sequence $\{\lambda\uuu\nu\}$
has  regular growth in the sense that if $N(r)$ is the counting function
which for every $r>0$ counts the number of $\lambda\nu\leq r$, then
there exists the limit
\[ 
\lim\uuu{R\to\infty}\,
\frac{N(R)}{R}=A
\]
with $A$ determined via Theorem 0.1.
We shall prove this in §  D and remark that the integrability condition
(*) is related to the study of the Carleman class in
§ C.















\newpage



\centerline{\bf{Growth of entire functions.}}


\bigskip

\noindent
Each entire function  $f(z)$ can be written in the form
\[ 
f(z)=az^m\cdot f_*(z)
\] 
where $f_*$ is entire and $f_*(0)=1$.
The  case when $f(0)=1$ is therefore not so special and
several formulas below take a simpler form when this holds.





\medskip

\noindent
{\bf{A.1 The functions $T_f(R)$ and  $m_f(R)$}}.
They are defined for every $R>0$ by
\[ 
T_f(R)=\frac{1}{2\pi}\cdot   \int_0^{2\pi}\,
\log^+\,\bigl  |f(R(e^{i\theta})\bigr |\, d\theta\tag{i}
\]
\[
m_f(R)=\frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\log^+\,\frac{1}{\,\bigl  |f(R(e^{i\theta})\bigr |}
\, d\theta\tag{ii}
\]
\medskip

\noindent
{\bf{A.2 The maximum modulus function.}} It is defined by
\[ 
M_f(R)= \max_
{0\leq \theta\leq 2\pi}\, |f(Re^{i\theta})|
\]
\medskip

\noindent
{\bf{A.3  The counting function $N_f(R)$}}.
To each $R>0$ we count the number of zeros of
$f$ in the punctured disc $0<|z|<R$. This integer is denoted by
$N_f(R)$, where
multiple zeros are counted according to their
multiplicities.
Jensen's formula shows that if
$f(0)=1$ then
\[
\int_0^R\, \frac{N_f(s)}{s}\cdot ds
=\frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\log\,\bigl  |f(R(e^{i\theta})\bigr |\cdot d\theta=
T_f(R)-m_f(R)\tag{A.3.1}
\]
\medskip

\noindent
The left hand side is always 
$\geq 0$. So if $f(0)=1$ one has
\[ 
m_f(R)\leq T_f(R)\tag{A.3.2}
\]
Moreover, since $m_f(R)\geq 0$ we have
the inequality
\[
\int_0^R\, \frac{N_f(s)}{s}\cdot ds\leq T_f(R)\tag{A.3.3}
\]
Finally, since $N_f(R)$ is increasing we 
\[
\log 2\cdot N_f(R)\leq \int_R^{2R}\, \frac{N_f(s)}{s}\cdot ds
\leq T_f(2R)\implies
 N_f(R)\leq\frac{T_f(2R)}{\log 2}\tag{A.3.3}
 \]





\medskip

\noindent
{\bf{A.4 Harnack's inequality.}}
Since the  function $\log^+|f|$ is subharmonic one has 
\[
\log^+|f(re^{i\alpha})|\leq
\frac{1}{2\pi}\cdot \int_0^{2\pi}\,
\frac{R+r}{R-r}\cdot 
\log^+\,\bigl  |f(R(e^{i\theta})\bigr |\cdot d\theta\quad\colon 0< r<R
\tag{A.4.1}
\]


\noindent
It follows that
\[
M_f(r)\leq \frac{R+r}{R-r}\cdot T_f(R)\tag{A.4.2}
\]
With $R=2r$ we conclude that
\[
M_f(r)\leq 3\cdot T_f(2r)\quad\colon r>0\tag{A.4.3}
\]
The last inequality gives:
\medskip

\noindent
{\bf{A.5 Theorem.}}
\emph{An entire function $f$ belongs to $\mathcal E$ if and only if there
exists a constant $A$ such that the following holds
for every $R$}
\[ 
T_f(R)\leq A\cdot R
\]
\bigskip

\noindent
{\bf{A.6 A division theorem.}}
Let $f$ and $g$ be in $\mathcal E$ and assume that
$h=\frac{f}{g}$ is entire. Now
\[ 
\log^+|h|\leq \log^+|f|+\log^+|g|\tag{i}
\]
In the case when $g(0)=1$ we apply (**) in A.3 and conclude that
\[ 
T_h(R)\leq T_f(R)+T_g(R)
\]
Hence Theorem A.5 implies that
$h$ belongs to $\mathcal E$.
We leave it to the reader to verify that this conclusion holds
in general, i.e. without any assumption on
$g(0)$.




\bigskip



\medskip

\noindent {\bf{A.7 Hadamard products.}}
Let $\{\alpha_\nu\}$ be a sequence of complex numbers
arranged so that the absolute values are non-decreasing.
The counting function of the sequence is 
denoted by $N_{\alpha(\bullet)}(R)$. Suppose that the counting function
satisfies:
\[
N_{\alpha(\bullet)}(R)\leq A\cdot R\quad\text{for all}\quad R\geq 1\tag{*}
\]

\medskip

\noindent 
{\bf{A.8 Theorem}}
\emph{When (*) holds the infinite product}
\[
\prod\, (1-\frac{z}{\alpha_\nu})\cdot e^{\frac{z}{\alpha_\nu}}
\]
\emph{converges for every $z$ and gives an entire function to be denoted by
$H_{\alpha(\bullet)}$ and  called the Hadamard product of the
$\alpha$-sequence.}

\medskip

\noindent
{\bf{A.9 Exercise.}}
Prove this theorem and show 
that there exists a constant $C$ which is independent of $A$ such that
(*) entails that the Hadamard product satisfies the growth condition:
\[
\bigl|H_{\alpha(\bullet)}(z)\bigr| \leq
C\cdot e^{A\cdot |z|\cdot \log\,|z|}\quad
\text{for all}\quad |z|\geq e
\]
\medskip


\noindent{\bf{A.10 Lindelöf's condition.}}
For a sequence $\{\alpha\uuu\nu\}$ we define the Lindelöf function
\[ 
L(R)= \sum_{|\alpha_\nu|<R}\, \frac{1}{\alpha_\nu}
\]

\noindent
We say that $\{\alpha\uuu\nu\}$
is of Lindelöf type  if there there exists a constant $L^*$ such that
\[
\bigl|L(R)\bigr|\leq L^*\quad\text{hold  for all}\quad  R.
\tag{A.10.1}
\]




\bigskip

\noindent
{\bf{A.11 Theorem.}}
\emph{If $\alpha$-sequence is of the Lindelöf type
and satisfies (*) in (A.7),
then
there exists a constant $C$ such that the maximum modulos function of
$H\uuu {\alpha(\bullet)}$ satisfies}
\[
M_{H_{\alpha(\bullet)}}(R)\leq C\cdot e^{AR}
\]
\emph{and hence the entire function
$H\uuu {\alpha(\bullet)}(z)$
belongs to $\mathcal E$.}

\medskip

\noindent
{\bf{A.12 Exercise.}}
Prove this result.
A hint is to study the products
\[
\prod_{|\alpha_\nu|<2R}\,(1-\frac{z}{\alpha_\nu})e^{\frac{z}{\alpha_\nu}}
\quad\text{and}\quad 
\prod_{|\alpha_\nu|\geq 2R}\,(1-\frac{z}{\alpha\uuu\nu})e^{\frac{z}{\alpha_\nu}}
\] 
separately for every $R\geq 1$. Try also to find an upper bound for 
$C$ expressed by  $A$ and $L^*$.

\bigskip

\centerline {\bf{A converse result.}}
\bigskip

\noindent
{\bf{A.13 Theorem}}.
\emph{For each $f\in \mathcal E$ the set of zeros 
$\{\alpha_\nu\}$ is of the
Lindelöf type.}

\bigskip


\noindent
\emph{Proof.}
With $R>0$ we put
\[
g(z)=\frac{1}{z}-\frac{\bar z}{R^2}\tag{i}
\]
This is a is harmonic function in $\{0<|z|>R\}$ and 
$g=0$ on  $|z|=R$.
Let $f(z)$ be an entire function
with $f(0)=1$
and consider a pair $0<\epsilon<R$ where
$f$ has not zeros in
$|z|\leq\epsilon$.
Green's formula applied to $g$ and $\log\,|f|$
in the  annulus $\{\epsilon<|z|<R\}$ gives:
\[
\sum_{|\alpha_\nu|<R}\, \,\bigl[ \frac{1}{\alpha_\nu}-
\frac{\bar\alpha_\nu}{R^2}\bigr]
= \frac{1}{\pi\cdot R}\cdot \int_0^{2\pi}\,
\log\,|f(Re^{i\theta})|  \cdot e^{-i\theta}\cdot d\theta-f'(0)
\tag{ii}
\]
where the sum is taken over zeros of $f$ repeated with multiplicities in
the disc $\{|z|<R\}$.
Next, the triangle inequality gives
\[
\bigl|\sum_{|\alpha_\nu|<R}
\frac{\bar\alpha_\nu}{R^2}\bigr|\leq
\sum_{|\alpha_\nu|<R}\leq
\frac{|\alpha_\nu|}{R^2}\bigr|\leq
R^{-2}\cdot \int_0^R\, s\cdot dN(s)\leq  \frac{N(R)}{R}\tag{iii}
\]
We conclude that
\[
L(R)\leq \frac{N(R)}{R}+
\frac{1}{\pi\cdot R}\cdot \int_0^{2\pi}\,
\log^+\,|f(Re^{i\theta})| \,d\theta+|f'(0)|\tag{iii}
\]
From (A.3.3) the last sum is majorized by
\[
\frac{1}{R}\cdot [\frac{T_f(2R)}{\log 2}+2\cdot T_f(R)]+
|f'(0)|\tag{iv}
\]
In the case $f\in \mathcal E$
the sum in (iv) is bounded which proves Theorem A.13.



 
\bigskip


\centerline {\bf{B. The factorisation theorem for  $\mathcal E$}}

\bigskip

\noindent
Consider some 
$f\in\mathcal E$. 
If $f$ has a  zero at
the origin we can write
\[ 
f(z)= az^m\cdot f_*(z)\quad\text{where}\quad f_*(0)=1
\]
It is clear that $f_*$ again belongs to $\mathcal E$ which
essentially reduces the study of $\mathcal E$-functions
$f$ to the case when $f(0)=1$. 
Above we proved that the set of zeros satisfies Lindelöf's condition
and therefore the Hadamard product
\[ 
H_f(z)=\prod\,(1-\frac{z}{\alpha_\nu})\cdot e^{\frac{z}{\alpha_\nu}}
\] 
taken over all zeros of $f$ outside the origin belongs to $\mathcal E$.
Now the quotient $f/H\uuu f$ is entire and we shall prove:


\medskip




\noindent{\bf{B.1 Theorem}}
\emph{Let $f\in\mathcal E$ where $f(0)=1$. Then
there exists a complex number $b$ such that}
\[ 
f(z)=e^{bz}\cdot H_f(z)
\]


\noindent
\emph{Proof}.
The division
in
A.6 shows that the function
$G=\frac{f}{H_f}$
is entire and belongs to $\mathcal E$.
Here $G$ is zero\vvv free
which gives
the entire
function
$g=\log G$ and one has 
the inequality
\[ 
|g(z)|\leq 1+\log^+|G(z)|\leq 1+C|z|\tag{i}
\]
Since $G\in\mathcal E$, (i) implies that 
$|g|$ increases at most like a linear function so by Liouville's
theorem it is a polynomial of degree 1. 
Since $f(0)=1$  we have  $g(0)=0$ and hence $g(z)=bz$ for a complex number $b$
and  
Theorem B.1 follows.




\bigskip



\centerline{\bf\large C. The Carleman class $\mathcal N$}

\medskip

\noindent 
Let $f\in\mathcal E$. On the real $x$-axis we have the non-negative function
$\log^+|f(x)|$. If the integral
\[
\int_{-\infty}^\infty\, \frac{\log^+\,|f(x)| \cdot dx}{1+x^2}<\infty\tag{*}
\]



\noindent 
we say that $f$ belongs to the Carleman class 
denoted by $\mathcal N$. To study this class
the following integral formula
plays a crucial  role.

\medskip

\noindent 
{\bf C.1 Integral formula in a half-plane.}
Let $g(z)$ be analytic in the half plane $\mathfrak{Im}(z)>0$ which
extends continuously to the boundary $y=0$
and assume also that  $g(0)=1$. For each   pair $0<\ell<R$
we consider the domain
\[
\Omega_{\ell,R}=\{\ell^2<x^2+y^2<R^2\}\cap\,\{y>0\}
\]


\noindent
With $z=re^{i\theta}$
we have the harmonic function
\[
v(r,\theta)=(\frac{1}{r}-\frac{r}{R^2})\sin\,\theta=\frac{y}{x^2+y^2}-\frac{y}{R^2}\tag{C.1.1}
\]
Here $v=0$ on the upper half circle where $ |z|=R$ and $y>0$
and 
the outer normal derivative along the $x$-axis becomes
\[ 
\partial_n(v)=-\partial_y(v)=-\frac{1}{x^2}+\frac{1}{R^2}\quad\colon\,\quad x\neq 0\tag{C.1.2}
\]
Let $\{\alpha_\nu\}$ be the zeros of $g$ counted with multiplicites 
in the upper half-plane.
\medskip

\noindent
{\bf{C.2 Proposition.}} \emph{One has the equation}

\[ 
2\pi\cdot\sum\,\frac {\mathfrak{Im}\,\alpha\uuu\nu}{|\alpha_\nu|^2}\vvv
\frac{\mathfrak{Im}\, \alpha_\nu}{R^2}
=
\]
\[
\int_\ell^R\,\,\bigl(\frac{1}{R^2}-\frac{1}{x^2}\bigr)\cdot
\log\,|g(x)\cdot g(-x)|
\,dx
\vvv\frac{2}{R}\int_0^\pi\, \text{sin}(\theta)\cdot 
\log\,|g(Re^{i\theta})|\, d\theta+\chi(\ell)\tag{C.2.1}
\]
\emph{where $\chi(\ell)$ is a contribution from line integrals along
the half circle $|z|=\ell$ with $y>0$.}

\bigskip



\noindent
{\bf {C.3 Exercise}}
Prove  (C.3.1)
by 
Green's theorem.
Above the 
term $\chi(\ell)$ is independent of $R$ so (*)
can be used to study  the asymptotic behaviour as $R\to+\infty$.
\medskip

\noindent
{\bf{C.4 Relation  to the Jensen-Nevanlinna class.}}
The family of analytic functions $g(z)$ in the upper half\vvv plane
is identified with $\mathcal O(D)$
via 
a conformal map, i.e. every  $g$ gives  $g\uuu *\in \mathcal O(D)$
where
\[
g\uuu *(\frac{z\vvv i}{z+i})= g(z)\tag{C.4.1}
\] 
holds when $\mathfrak{Im}(z)>0$.
If  $g$ extends to a continuous function on
the real $x$\vvv axis the reader can verify 
the equality
\[
\int\uuu 0^{2\pi}\, \log^+|g\uuu *(e^{i\theta})|\, d\theta=
2\cdot \int_{-\infty}^\infty\, \frac{\log^+|g(x)| }{1+x^2}\, dx\tag{C.4.2}
\]
Hence the last integral is finite if and only if
$g\uuu *$ belongs to the Jensen\vvv Nevanlinna class
in the unit disc.
In §§ XX we proved that this entails that
\[
\int\uuu 0^{2\pi}\, \log^+\frac{1}{|g\uuu *(e^{i\theta})|}\, d\theta<\infty\tag{C.4.3}
\]
In particular we consider
an entire function $f$
which satisfies (*) above. Then (C.4.3)
implies that
\[
\int_{-\infty}^\infty\, \log^+\frac{1}{|f(x)|} \cdot 
\frac{dx}{1+x^2}\tag{C.4.4}
\]
Since the absolute value of
$\log\,|f(x)|$ is equal to the sum
\[
 \log^+\frac{1}{|f(x)|}+\log^+|f(x)|
\]
we conclude  that
(*) entails that the absolute value of
$\log\,|f(x)|$ is integrable with respect to
the density $\frac{1}{1+x^2}$.
Using this we can prove:



\bigskip

 \noindent {\bf C.5  Theorem} \emph{
 For each $f\in\mathcal N$ one has}
\[
\sum^*\,\mathfrak{Im}\frac{1}{\alpha_\nu}<\infty
\]
\emph{where the sum is taken over all zeros of $f$ 
which belong to the  upper half-plane.}
\bigskip


\noindent
\emph{Proof.}
Since $f\in\mathcal E$, we have sen in (iii) during the proof
of Theorem  A.13
that
there exists a constant $C$ which is independent
of $R$ such that 
\[ 
\bigl|
R^{\vvv 2}\sum\,|\alpha_\nu|\leq C\tag{i}
\]
where  the sum is taken over zeros in $\Omega\uuu{\ell,R}$.
Next, we have
\[
\sum\,\mathfrak{Im}\frac{1}{\alpha_\nu}=
-\sum\,\frac{\mathfrak{Im}\,\alpha_\nu}{|\alpha_\nu|^2}\tag{ii}
\]
where  the sum again is taken over zeros in $\Omega\uuu{\ell,R}$.
Now (C.2.1) gives
Theorem V.5 follows after a passage to the limit as $R\to+\infty$
when we apply  (C.2.1) with $g=f$
More precisely, it suffices to find
a constant $C$ such that

it suffices to establish an upper bound in the right hand side of
Proposition C.2 with $g=f$.
The integral taken over the half\vvv circle where $|z|=R$
is uniformly  bounded with respect to $R$
since $f\in \mathcal E$
and we have the inequality XX from A.XX.
There remains to
establish an upper bound for the integral on 
the $x$\vvv axis in (C.2.1).
Since $R^{\vvv 2}\vvv x^{\vvv 2}\leq 0$
during the integration it suffices to find a constant $C$ such that
\[
\int_\ell^R\,\,\bigl(\frac{1}{x^2}-\frac{1}{R^2}\bigr)\cdot
\log^+\frac{1}{\,|f(x)\cdot f(-x)|}
\cdot dx\leq C\quad\colon\,  R\geq 1\tag{iii}
\]
The reader may verify that such a constant $C$
exists from the result in (C.4).


















\bigskip



\centerline{\bf{D. A Tauberian Theorem}}


\bigskip

\noindent
Let $\Lambda$
be a non-decreasing and discrete sequence 
of positive real numbers  $\{t_\nu\}$
whose counting function satisfies
$\mathcal N_\Lambda(R)\leq C\cdot R$  for some constant.
We get the entire function
\[
f(z)=
\prod\,(1-\frac{z^2}{t_\nu^2})
\]
which by the results in § A belongs to $\mathcal E$.
If $R>0$ we set:
\[
 J_1(R)=\frac{\text{log}\, f(iR)}{R}
\quad\text{and}\quad 
J_2(R)=\int_{-R}^R\, \frac{\text{Log}\,| f(x)|}{x^2}\cdot dx\tag{*}
\]



\noindent
{\bf{D.1 Theorem.}}
\emph{There exists a limit }
\[ 
\lim\uuu {R\to\infty}\, \frac{N\uuu f(R)}{R}=2A
\]
\emph{if and only if at least one of the $J$\vvv functions has
a limit as $R\to\infty$. Moreover, when this holds
one has the equalities:}

\[
\lim_{R\to\infty} J_1(R)=\frac{\pi\cdot A}{2}\quad\text{and}\quad
\lim_{R\to\infty} J_2(R)=\vvv \frac{\pi^2\cdot A}{2}
\]
\bigskip

\noindent
The proof requires seveeral steps.
First 
we introduce the following:
\medskip


\noindent
{\bf{D.2 The $W$\vvv functions.}}
On the positive real $t$-line we define the following functions:
\[ 
W_0(t)=\frac{1}{t}\quad\colon \,\,t\geq 1\quad
\text{and}\quad W_0(t)=0\quad\text{when}\,\,\, t<1\tag{1}
\]
\[
W_1(t)=\frac{\log(1+t^2)}{t}\tag{2}
\]
\[
W_2(t)=
\int_0^t
\frac{\log\,|1-x^2|}{x^2}\cdot dx\tag{3}
\]

\noindent
Next, 
the
real   sequence
$\Lambda=\{t_\nu\}$   gives a discrete measure
on the positive real axis where one  assigns a unit point mass at
every $t_\nu$. If repetitions occur, i.e. if some
$t$-numbers are equal we
add these unit point-masses.
Let $\rho$ denote  the resulting  discrete measure. 
The constructions of the $J$\vvv functions obviously give:
\[
J_k(R)=
\int_0^\infty\,W_k\bigl(\frac{R}{t}\bigr)\cdot\frac{d\rho(t)}{t}
\quad\colon\, k=1,2\tag{4}
 \]
Moreover, the reader can verify that
\[ 
\frac{\mathcal N_\Lambda (R)}{R}=
2\cdot \int_0^\infty\, W_0(R/t)\cdot \frac{d\rho(t)}{t}\tag{5}
\]
\medskip

\noindent{\bf{D.3 Exercise.}}
Show that under the assumption that
the function $\frac{\mathcal N_\Lambda (R)}{R}$ is bounded, it follows
the three $\mathcal W$-functions belong to
the $\mathcal {BW}$-algebra defined by the measure $\rho$
as explained in § XXX.


\bigskip
\noindent
{\bf  D.4 Fourier transforms.} Recall that on $\{t>0\}$ we have the Haar
measure 
$\frac{dt}{t}$. 
We leave it to the reader to verify that all  the $W$-functions above  belong to $L^1({\bf{R}}^+)$, i.e. 
\[ 
\int_0^\infty\, \bigl|W_k(t)\bigr|\cdot \frac{dt}{t}<\infty\quad\colon
k=0,1,2
\tag{i}
\]
The Fourier
transforms  are defined by
\[ 
\widehat W_k(s)=
\int_0^\infty\,  W_k(t)\cdot t^{-(is+1)}\cdot dt\tag{ii}
\]
We shall prefer to use the functions with reversed sign on $s$, i.e. set
\[
\mathcal F\,W_k(s)=\int_0^\infty\,  W_k(t)\cdot t^{is-1}\cdot dt\tag{iii}
\]

\medskip

\noindent
{\bf{D.5 Proposition}} \emph{One has the formulas}
\[
\mathcal F\,W_0(s)=\frac{1}{1-is}\tag{i}
\]
\[
\mathcal F\,W_1(s)= 
\frac {\pi \cdot e^{\vvv \pi s/2}}{(1\vvv is)\cdot (1+e^{\vvv \pi s})}
\]
\[
\mathcal F\,W_2(s)=\frac{1}{is}\cdot\bigl[
\frac{i\pi}{1-is}+
\frac{2\pi}{(i+s)\cdot (e^{\pi s/2}+e^{-\pi s/2})}\,\bigr]\tag{iii}
\]


\bigskip

\noindent
\emph{Proof.}
Equation (i) is easily verified and left to the reader.
To prove (ii) we use a partial integration which gives
\[
\mathcal F\,W_1(s)=\frac{1}{is\vvv 1}\cdot
\int\uuu 0^\infty\,\frac{2\cdot t^{is}\cdot dt}{1+t^2}
\]
To compute this integral we employ residue calculus where
we shall use
the function
\[ 
\phi(z)=\frac{z^{is}}{1+z^2}
\]
We perform  line integrals over 
large half\vvv circles where $z=Re^{i\theta}$ and $0\leq \theta\leq \pi$.
A residue occurs at $z=i$. Notice also that if $t>0$ then
\[
 (\vvv t)^{is}= t^{is}\cdot e^{\vvv \pi s}
 \]
This gives
\[
 \mathcal FW\uuu 1(s)=
 \frac{1}{1\vvv is)\cdot (1+e^{\vvv \pi s})}
 \cdot
 \lim\uuu {R\to\infty}\, \int\uuu{\vvv R}^R\, \phi(t)\cdot dt
\]
Here $\phi$ has a simple pole at $z=1$
so by residue calculus the last integral becomes
\[
\vvv 2\pi i\cdot (i)^{is}\cdot  \frac{1}{2i}
 =\vvv \pi\cdot e^{\vvv \pi s/2}
\]
Taking the minus sign into the account we conclude that

\[
 \mathcal FW\uuu 1(s)=
 \frac {\pi \cdot e^{\vvv \pi s/2}}{(1\vvv is)\cdot (1+e^{\vvv \pi s})}
\]
 


\noindent
For (iii) a partial integration gives
\[
\mathcal F\,W_2(s)=\vvv \frac{1}{is}\cdot
\int\uuu 0^\infty\, \log|1\vvv t^2|\cdot t^{is\vvv 2}\cdot dt
\]
Here we computed the right hand side in
[Residue Calculus] which gives  (iii).
\bigskip




\centerline {\emph{ D.6  Proof of Theorem D.1}}
\medskip

\noindent
The formulas for the Fourier transforms in Proposition D.5  show that each
of them is $\neq 0$ on the  real $s$-line.
Hence we can apply the general result in XX
to the discrete measure $\rho$ since
the
$\mathcal W$-functions belong to the Beurling-Wiener 
algebra whose defintion and properties are
treated in my notes on the mathematics by Beurling.
This implies that if one of the three
limits in Theorem D.1   exists, so do the other.
To get the relation between the limit values we 
only have to evaluate the Fourier transform at $s=0$.
From Proposition D.5 we see that
\[
\mathcal FW_0(0)=1\quad\,\colon\quad 
F\mathcal W_1(0)=\frac{\pi}{2}
\]
Finally, (iii) in (D.4) and a computation which is left to the reader
gives
\[
F\mathcal W_2(0)=-\frac{\pi^2}{2}\tag{**}
\]

\noindent 
This gives the formulas
in
Theorem D.3 by the general result for $\mathcal{BW}$\vvv algebras in XXX.
\bigskip

\noindent{\bf {D.7 An application}}.
Using Theorem D.1 we can prove the following: 
\bigskip

\noindent
{\bf D.8  Theorem} \emph{For each $f\in\mathcal N$ there exists the limit:}
\[ 
\lim_{R\to\infty}\,\frac{N_f(R)}{R}
\]


\noindent 
\emph{Proof.}
The product $f(z)\cdot f(\vvv z)$ also 
belongs to $\mathcal N$ and for this even function
the counting function is twice that of $f$. So it suffices to prove
Theorem D.8  when $f$ is even.
We may also assume that $f(0)=1$ and since
$f\in\mathcal E$ it is given by a Hadamard product
\[
f(z)=\prod^*\, (1-\frac{z^2}{\alpha_\nu^2})\tag{1}
\]
where $\prod^*$ indicates the we  take the product of zeros whose
real part is $>0$ and if they are purely imaginary 
they are of the form $b\cdot i$ with $b>0$.
We can  replace the zeros by their absolute values and construct
\[
f_*(z)=\prod^*\, (1-\frac{z^2}{|\alpha_\nu|^2})\tag{2}
\]


\noindent
If $x$ is real we see that 
\[
|f_*[x)|\leq |f(x)|\tag{3}
\]
We conclude that if $f$ belongs to
$\mathcal N$ so does $f_*$.
At the same time their counting functions of zeros are equal.
This reduces the proof  to the special case when
$f$ is even and the zeros  are real and at this stage it is clear that
Theorem D.1 gives
existence of the limit  in Theorem D.8.


\medskip












\bigskip


\centerline{\bf{E. Application to measures with compact support.}}
\bigskip

\noindent
Le $\mu$ be a Riesz measure on the real $t$\vvv line with
compact support in an interval $[\vvv a,a]$ where
we assume that both end\vvv points belong to the support.
The measure is in general complex\vvv valued.
Now we get the entire function

\[
f(z)= \int\uuu{\vvv a}^a\, e^{\vvv izt}\cdot d\mu(t)
\]
Here $f$ restricts to a bounded function on the real $x$\vvv axis with
maximum norm $\leq ||\mu||$.
Hence $f$ belongs to $\mathcal N$ which means that
Theorem D.8 holds and the reader may now verify the following:
\medskip

\noindent
{\bf{E.1 Theorem.}}
\emph{One has the equality}
\[
\lim\uuu{R\to \infty}\,\frac{N\uuu f(R)}{R}=\frac{a}{\pi}
\]


\bigskip



















\centerline{\bf {F. Tauberian theorems with a remainder term}}
\medskip

\noindent
An extension of
Theorem D.1 which  contains remainder terms were
established by Beurling in 1936.
An example of Beurling's results  goes as follows:
Let
\[ 
f(z)=\prod\,(1\vvv \frac{z^2}{t\uuu\nu^2})
\]
be an even and entire function of exponential type with real zeros
as in section D. 

\medskip

\noindent
{\bf{F.1 Theorem.}}
\emph{Let $A>0$ and $0<a<1$ and assume that there 
exists a constant $C\uuu 0$ such that}
\[
\bigl|\vvv \frac{1}{\pi^2}\cdot \int\uuu 0^R\,
 \frac{\log |f(x)|}{x^2}\cdot dx\vvv A\,\bigr|\leq
 C\uuu 0\cdot R^{\vvv a}
 \]
\emph{hold for all $R\geq 1$.
Then there is another constant $C$ such that}
\[
\bigl|\, N\uuu f(R)\vvv R\bigr|\leq C\uuu 1\cdot R^{1\vvv a/2}
\]
\medskip

\noindent
{\bf{Remark.}}
Beurling's original manuscript which contains a proof of
Theorem F.1 as well as other 
results dealing with remainder terms    has remained
unpublished. It
was   resumed with details of proofs
in  a Master's Thesis at 
Stockholm University 
by F. Gülkan in 1994.
The interested reader should also consult articles by
Beurlings former Ph.d student
S. Lyttkens which prove various Tauberian theorems with
remainder terms. 




\newpage





















\centerline{\bf{7. Hadamard's radius theorem.}}

\bigskip

\noindent
The thesis \emph{Essais sur l'études des fonctions donnés par leur
dévelopment d Taylor} from 1894 by Hadamard
contains many interesting results.
Here we expose material from Section 2 in [ibid].
Consider a power series
\[
 f(z)=\sum\, c\uuu nz^n\tag{*}
\]
whose radius is a positive  number
$\rho$.
So $f$ is analytic in the open disc $\{|z|<\rho\}$
and has at least one singular point on the circle
$\{|z|=\rho\}$.
Hadamard found a condition in order that
these singularities consists of a finite set of poles only so that
$f$ extends to be meromorphic in some disc $\{|z|<\rho\uuu *\}$ with
$\rho\uuu * >\rho$. The condition is expressed via properties of
the  Hankel determinants. Let us recall their definition. 
Let $\{c\uuu 0,c\uuu 1,\ldots\}$
be a sequence of complex numbers.
For each  integer $p\geq 0$ and  every $n\geq 0$
we obtain the 
$(p+1)\times (p+1)$\vvv matrix:

\[
\mathcal C\uuu n^{(p)}=
\begin{pmatrix}
c\uuu{n}&c\uuu{n+1}&\ldots&c\uuu{n+p}\\
c\uuu{n+1}&c\uuu{n+2}&\ldots&c\uuu{n+p}\\
\ldots&\ldots&\ldots&\ldots\\
c\uuu{n+p}&c\uuu{n+p+1}&\ldots&c\uuu{n+2p}\\
\end{pmatrix}
\]

\medskip


\noindent
Let $\mathcal D\uuu n^{(p)}$ denote the determinant. One
refers to $\{\mathcal D\uuu n^{(p)}\}$
as the recursive Hankel determinants.
Kronecker proved that
the series (*) represents a rational function in the complex $z$-åplane whose poles are outside
the origin if and only if there
exists some positvie integer $p$ such that
$\mathcal D\uuu n^{(p)}=0$ hold for all $n$.
 We shall prove this in § xx.
 Hadamard established a remarkable extensionmof
 Kronecker's result which goes as follows.
 WEe are given the series in (*) and assume that
 it has a finite postive radius of convergence  which by a wellknown formula satisfies the equation
 \[
\frac{1}{\rho}=\limsup\uuu{n\to \infty}\, |c\uuu n|^{\frac{1}{n}}
\]
This entails that for every  $\epsilon>0$  there exists a constant $C\uuu\epsilon$ 
such that
\[ 
|c\uuu n|\leq C\cdot (\rho \vvv  \epsilon)^{\vvv n}\quad\text{
hold for every}\quad  n
\]
It follows trivially that
\[
|\mathcal D\uuu n^{(p)}|\leq (p+1) !\cdot C^{p+1}(\rho\vvv \epsilon)^{\vvv (p+1)n}
\]
Passing to limes superior where  high $n$:th roots are taken
we conclude that:
\[
\delta(p)= \limsup\uuu{n\to \infty}\, 
\bigl[\mathcal D\uuu n^{(p)}\bigr]^{\frac{1}{n}}\leq \rho^{\vvv (p+1)}\tag{1}
\]

\medskip


\noindent
Suppose   there exists some $p\geq 1$ 
where a strict inequality occurs:
\[
\delta(p)<\rho^{\vvv(p+1)}\tag{2}
\]
Let  $p$ be the smallest integer  for which  (2) which gives 
a number $\rho\uuu *>\rho$ such that
\[
\delta(p)=\rho\uuu *^{\vvv 1}\cdot
\rho ^{\vvv p}\tag{3}
\]


\medskip

\noindent
{\bf{Hadamard's Theorem.}} \emph{With $p$ and $\rho_*$ as in (3),
it follows that $f(z)$ extends to a meromorphic function in the disc
of radius $\rho\uuu *$ where the number of poles counted with multiplicity
is at most  $p$.}
\bigskip


\noindent
The proof requires several steps. 
We shall first expose some general formulas about determinants
while the proof of Hadamard's theorem starts in § xx.
But let us first describe an application of Hadamard's theorem.
Namely, if
\[
\lim_{p\to\infty }\,\delta(p)=0\tag{4}
\]
it follows that (*) extends to a meromprohic function inthe whole complex plane.
Let us now consider a complex-valued and continuous
function
$k(x,y)$ defined on
the unit square
$\{0\leq x,y\leq 1\}$. We do not assume that $k$ is symmetric,  i.e,
in general $k(x,y)\neq k(y,x)$.
 Let $f(x)$ be another  continuous function  on $[0,1]$.
Assume that the maximum norms of $k$ and $f$ both are $<1$.
By induction over $n$ starting with $f\uuu 0(x)= f(x)$
we get a sequence $\{f\uuu n\}$ where
\[
f\uuu n(x)=\int\uuu 0^1\, k(x,y)\cdot f\uuu{n\vvv 1}(y)\cdot dy
\quad \colon\quad n\geq 1
\]
The hypothesis entails that each $f\uuu n$ has maximum norm
$<1$ and hence there exists  a power series:
\[
u\uuu\lambda(x)= \sum\uuu{n=0}^\infty\, f\uuu n(x)\cdot \lambda^n
\] 
which converges for every  $|\lambda|<1$ and yields a continuous function
$u\uuu\lambda(x)$  on $[0,1]$.

\medskip

\noindent
{\bf{0.1 Theorem.}}
\emph{The function $\lambda\mapsto u\uuu\lambda(x)$ with values in the Banach space
$B=C^0[0,1]$ extends to a meromorphic $B$\vvv valued 
function in the whole
$\lambda$\vvv plane.}
\bigskip

\noindent
To prove this we consider  the recursive Hankel determinants for
each $0\leq x\leq 1$:


\[
\mathcal D_n^{(p)}(x)=
\det
\begin{pmatrix}
f_{n+1}(x)
&f_{n+2}(x)
&\ldots&\ldots
& f_{n+p}(x)\\
f_{n+2}(x)
&f_{n+3}(x)
&\ldots&\ldots
& f_{n+p+1}(x)\\

\ldots &\ldots &\ldots&\ldots \\
\ldots &\ldots&\ldots&\ldots\\
f_{n+p}(x)
&f_{n+p+1}(x)
&\ldots&\ldots
& f_{n+2p-1}(x)\\
\end{pmatrix}
\]
\medskip


\noindent
With these notations the following inequality holds:
\medskip


\noindent
{\bf{Proposition 0.2}} \emph{For every $p\geq 2$ and $0\leq x\leq 1$ one has}

\[
\bigl |\,  \mathcal D\uuu n^{(p)}(x))\,\bigr|\leq 
(p\, !)^{\vvv n}\cdot \bigl( p^{\frac{p}{2}}) ^n\cdot \frac{p^p}{p\,!}\tag{0.2.1}
\]
\medskip

\noindent
This result is due to Carleman and exposed in § xx.
The inequality (0.2.1)  entails that
\[ 
\limsup\uuu{n\to \infty}\, \bigl| \mathcal D\uuu n^{(p)}(x))\,\bigr |^{1/n}
\leq 
\frac{p^{p/2}}{p\,!}
\]
Next, Stirling's formula gives:
\[
\lim\uuu{p\to \infty}\bigl[\frac{p^{1/2}}{p\,!}\,\bigr]^{\vvv 1/p}=0
\]
Hence the special case of  Hadamard's theorem gives
Theorem 0.1





\newpage



\centerline {\bf{A.  The Sylvester-Franke theorem.}}
\medskip


\noindent
Let    $A$  be some
$n\times n$\vvv matrix with
elements $\{a\uuu{ik}\}$.
Put
\[
b\uuu{rs}=a\uuu {11}a\uuu {rs}\vvv a\uuu{r1}a\uuu{1s}
\quad\colon\quad 2\leq r,s\leq n
\]
These $b$\vvv numbers give an $(n\vvv 1)\times(n\vvv 1)$\vvv matrix
where $b\uuu{22}$ is put in position $(1,1)$ and so on.
The matrix is denoted by 
$\mathcal S^1(A)$ and called the first order
Sylvester matrix.
If $a\uuu{11}\neq 0$ one has
the equality
\[
a\uuu{11}^{n\vvv 2}\cdot \text{det}(A)=
\text{det}(\mathcal S^1(A))\tag{A.1.1}
\]
\medskip

\noindent
{\bf{Exercise.}} Prove this result or consult a text\vvv book
which
apart from "soft abstract notions"  
does not ignore to
treat  determinants. 
\medskip

\noindent
{\bf{A.1.2 Sylvester's equation.}}
For every
$1\leq h\leq n\vvv 1$ one constructs the
$(n\vvv h\times (n\vvv h)$\vvv matrix whose elements are

\[ b\uuu{rs}= \det\,
\begin{pmatrix}
a\uuu{11}&a\uuu{12}&\ldots &a\uuu{1h}& a\uuu{1s}\\
a\uuu{21}&a\uuu{22}&\ldots &a\uuu{2h}& a\uuu{2s}\\
\ldots&\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots&\ldots\\
a\uuu{h1}&a\uuu{h2}&\ldots &a\uuu{hh}& a\uuu{hs}\\
a\uuu{r1}&a\uuu{r2}&\ldots &a\uuu{rh}& a\uuu{rs}\\
\end{pmatrix}\quad\colon\quad h+1\leq r,s\leq n
\]
\medskip

\noindent
With these notation one has the Sylvester equation:

\[
\det
\begin{pmatrix}
b\uuu{h+1,h+1}&b\uuu{h+1,h+2}&\ldots &b\uuu{h+1,n}\\
b\uuu{h+2,h+1}&b\uuu{h+2,h+2}&\ldots &b\uuu{h+2,n}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
b\uuu{n,h+1}&b\uuu{n,h+2}&\ldots &b\uuu{n,n}\\
\end{pmatrix}=
\bigl[\,\det\begin{pmatrix}
a\uuu{11}&a\uuu{12}&\ldots &a\uuu{1h}\\
a\uuu{21}&a\uuu{22}&\ldots &a\uuu{2h}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
a\uuu{h1}&a\uuu{h2}&\ldots &a\uuu{hh}\\
\end{pmatrix}\,\bigr]^{n\vvv h\vvv 1}\cdot \det(A)\tag{*}
\]
\medskip


\noindent
For a proof of (*) we refer to original work by Sylvester or
[Kovalevski: page xx\vvv xx] which offers several different
proofs of (*).

\bigskip

\noindent
{\bf{A.1.3 The Sylvester\vvv Franke theorem.}}
Let  $n\geq 2$ and $A=\{a\uuu{ik}\}$ an
$n\times n$\vvv matrix.
Let $m<n$ and consider 
the family of minors of size $m$, i.e.
one picks $m$ columns and $m$ rows
which give  an $m\times m$\vvv matrix
whose determinant is called a minor of size $m$
of the given matrix $A$. The total number of
such minors is equal to
\[
N^2\quad\text{where}\quad N= \binom{n}{m}
\]
We have $N$ many strictly increasing sequences
$1\leq \gamma\uuu1<\ldots\gamma \uuu m\leq n$
where a $\gamma$\vvv sequence corresponds to preserved
columns when   a minor is constructed. Similarly we have
$N$ strictly increasing sequences which correspond to preserved rows.
With this in mind we get  for each pair $1\leq r,s\leq N$
a minor $\mathfrak{M}\uuu {rs}$
where the enumerated $r$:th $\gamma$\vvv  sequence preserve columns and similarly
$s$ corresponds to the enumerated sequence of rows.
Now we obtain the $N\times N$\vvv matrix

\[
\mathcal A\uuu m= \begin{pmatrix}
\mathfrak{M}\uuu{11}&\mathfrak{M}{12}&\ldots &\mathfrak{M}\uuu{1N}\\
\mathfrak{M}\uuu{21}&\mathfrak{M}{22}&\ldots &\mathfrak{M}\uuu{2N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
\mathfrak{M}\uuu{N1}&\mathfrak{M}{22}&\ldots &\mathfrak{M}\uuu{NN}\\
\end{pmatrix}
\]


\noindent
We refer to $\mathcal A\uuu m$ as the Franke\vvv Sylvester matrix of order
$m$. They  are defined for each $1\leq m\leq n\vvv 1$.

\medskip







\noindent
{\bf{A.1.4 Theorem.}}
\emph{For every $1\leq m<n$ one has
the equality}
\[
\mathcal A\uuu m= \text{det}(A)^{\binom{n\vvv 1}{m\vvv 1}}
\]


\medskip

\noindent
{\bf{Example.}} Consider the diagonal $3\times 3$\vvv matrix:

\[
A=\begin{pmatrix}
1&0&0\\
0&1&0\\
0&0&2\\
\end{pmatrix}
\]

\medskip

\noindent
With $m=2$
we have 9 minors of size 2 and the reader can recognize that
when they are arranged so that we begin to remove
the first column, respectively the first row, then 
the resulting $\mathfrak{M}$\vvv matrix becomes
\[
\begin{pmatrix}
2&0&0\\
0&2&0\\
0&0&1\\
\end{pmatrix}
\]
Its determinant is $4= 2^2$ which is in accordance with the general formula since
$n=3$ and $m=2$ give $\binom{n\vvv 1}{m\vvv 1}=2$.
For the proof of Theorem 0.A.1 the reader can consult 
[Kovalevski: page102\vvv 105].




\bigskip



\centerline {\bf{§ B. Hankel determinants.}}
\bigskip


\noindent
Let $\{c\uuu 0,c\uuu 1,\ldots\}$
be a sequence of complex numbers.
For each  integer $p\geq 0$ and  every $n\geq 0$
we obtain the 
$(p+1)\times (p+1)$\vvv matrix:


\[
\mathcal C\uuu n^{(p)}=
\begin{pmatrix}
c\uuu{n}&c\uuu{n+1}&\ldots&c\uuu{n+p}\\
c\uuu{n+1}&c\uuu{n+2}&\ldots&c\uuu{n+p}\\
\ldots&\ldots&\ldots&\ldots\\
c\uuu{n+p}&c\uuu{n+p+1}&\ldots&c\uuu{n+2p}\\
\end{pmatrix}
\]

\medskip


\noindent
Let $\mathcal D\uuu n^{(p)}$ denote the determinant. One
refers to $\{\mathcal D\uuu n^{(p)}\}$
 as the recursive Hankel determinants.
They  are used to establish   various properties of the given
$c$\vvv sequence.
To begin with we define  the rank   $r^*$ 
of $\{c_n\}$
as follows:
To every non\vvv negative integer $n$
one has the  infinite vector
\[ 
\xi\uuu n=(c\uuu n,c\uuu{n+1},\ldots)
\]
We say that $\{c\uuu n\}$ has finite rank if
there exists a number $r^*$ such that
$r^*$ many $\xi$\vvv vectors
are linearly independent and the rest are linear combinations of these.
\medskip

\noindent
{\bf{B.1 Rational series expansions.}}
The sequence $\{c\uuu n\}$ gives the formal power series
\[
f(x)=\sum\uuu{\nu=0}^\infty\, c\uuu\nu x^\nu \tag{B.1.1}
\]
If $n\geq 1$ we set
\[
\phi\uuu n(x)= x^{\vvv n}\cdot(
f(x)\vvv \sum\uuu{\nu=0}^{n\vvv 1} c\uuu\nu x^\nu)=
\sum\uuu{\nu=0}^\infty c\uuu{n+\nu} x^\nu
\]
It is clear
that $\{c\uuu \nu\}$ has finite rank if and only if  the sequence
$\{\phi\uuu\nu(x)\}$
generates a finite dimensional complex subspace of the vector space 
${\bf{C}}[[x]]$ whose elements are formal power series.
If this dimension is finite we find a positive integer
$p$ and a 
non\vvv zero $(p+1)$\vvv tuple $(a\uuu 0,\ldots,a\uuu p)$ of complex numbers
such that the power series
\[ 
a\uuu 0\cdot  \phi\uuu 0(x)+\ldots+a\uuu p\cdot \phi\uuu p(x)=0
\]
Multiplying this equation with $x^p$ it follows that
\[
(a\uuu p+a\uuu{p\vvv 1} x+\ldots+a\uuu o x^p)\cdot f(x)=q(x)
\]
where $q(x)$ is a polynomial.
Hence the finite rank entails that the power series (B.1.1) 
represents a rational function.
\medskip


\noindent
{\bf{Exercise.}}
Conversely, assume that
\[
\sum\, c\uuu\nu x^\nu= \frac{q(x)}{g(x)}
\] 
for some pair of polynomials. Show that $\{c\uuu n\}$ has finite rank.
The next result is also left as an exercise to the reader.

\medskip


\noindent
{\bf{B.2 Proposition.}}
\emph{A sequence $\{c\uuu n\}$ has a finite rank if and only if
there exists an integer $p$ such that}
\[
\mathcal D\uuu 0^{(p)}\neq 0\quad
\text{and}\quad D\uuu 0^{(q)}=0\quad \colon\quad q>p\tag{4}
\]
\emph{Moreover, one has the equality $p$ is equal to the rank of
$\{c_n\}$.}


\medskip

\noindent
{\bf{B.3 A specific example.}}
Suppose that the degree of $q$ is strictly less than that of $g$ in the Exercise above  
and that the rational function $\frac{q}{g}$
is expressed by a sum of simple 
fractions:
\[ 
\sum\, c\uuu\nu x^\nu= \sum\uuu{k=1}^{k=p}\, \frac{d\uuu k}{1\vvv \alpha\uuu k x}
\] 
where $\alpha\uuu 1,\ldots,\alpha\uuu p$ are distinct and every $d\uuu k\neq 0$.
Then we see that
\[ 
c\uuu n=\sum\uuu{k=1}^{k=p}\, d\uuu k\cdot \alpha\uuu k^n\quad 
\text{where we have put}\quad
\alpha\uuu k^0=1\quad\text{ so that}\quad
c\uuu 0=\sum\, d\uuu k
\]
\medskip



\noindent
{\bf{B.4 The reduced rank.}}
Assume that $\{c\uuu n\}$ has a finite rank $r^*$. To each $k\geq 0$ we denote by $r\uuu k$
the dimension of the vector space generated by
$\xi\uuu k,\xi\uuu{k+1},\ldots$.
It is clear that $\{r\uuu k\}$ decrease and we find a non\vvv negative integer
$r\uuu *$ such that $r\uuu k=r\uuu *$ for large $k$ and
refer to $r\uuu *$ as the reduced rank. By the construction
$r\uuu *\leq r^*$. The relation between $r^*$ and $r\uuu *$
is related to the representation
\[
 f(x)= \frac{q(x)}{g(x)}
\]
where $q$ and $g$ are polynomials without common factor.
We shall not pursue this discussion any further but refer to the literature.
See in particular
the exercises
in [Polya\vvv Szegö : Chapter VII:problems 17\vvv 34].




\bigskip

\noindent
{\bf{B.5 Hankel's formula for Laurent series.}}
Consider a rational function of the form
\[
R(z)= \frac{q(z)}{z^p\vvv [a\uuu 1z^{p\vvv 1}+\ldots
+a\uuu{p\vvv 1}z+ a\uuu p]}
\]
where the polynomial $q$ has degree $\leq p\vvv 1$.
At $\infty$ we have a Laurent series expansion

\[ 
R(z)= \frac{c\uuu 0}{z}+ 
\frac{c\uuu 1}{z^2}+\ldots
\]
Consider the $p\times p$\vvv matrix
\[
A=\begin{pmatrix}
0&0&&\ldots&0&a\uuu p\\
1&0&0&\ldots&0&a\uuu{p\vvv 1}\\
0&1&0&\ldots&\ldots&a\uuu{p\vvv 2}\\
\ldots&
\ldots&
\ldots&
\ldots&\ldots&\ldots
\\
0&0&0&\ldots&1&a\uuu 1\\
\end{pmatrix}
\]
\medskip

\noindent
{\bf{B.5.1 Theorem.}}
\emph{Let $\mathcal D\uuu n^{(p)}$ be the Hankel determinants of
$\{c_n\}$. Then 
the following  hold for every $n\geq 1$:}
\[
\mathcal D\uuu n^{(p)}=  \mathcal D^{(p)}\uuu 0\cdot
\bigl[\text{det}(\,A\bigr)\bigr ) ^n
\]
\medskip

\noindent
{\bf{Exercise. }} Prove this result.

\bigskip

\noindent

\noindent
{\bf{B.6 Kronecker's identity.}}
For all pairs
of positive integers $p$ and $n$ one has the equality:

\[
\mathcal D\uuu n^{(p+1)}\cdot
\mathcal D\uuu {n+2}^{(p-2)}=
\mathcal D\uuu n^{(p+1)}
\mathcal D\uuu {n+2}^{(p\vvv 1)}-
\bigl[\mathcal D\uuu {n+1}^{(p)}\,\bigr]^2\tag{B.6.1}
\]

\medskip


\noindent
\emph{Proof.}
The equality (B.6.1 ) is s special case of a determinant formula for symmetric matrices
which is due to Sylvester.  Namely,
let $N\geq 2$ and consider a symmetric matrix

\[
S=\begin{pmatrix}
s\uuu{11}&s\uuu{12}&\ldots &s\uuu{1N}\\
s\uuu{21}&s\uuu{22}&\ldots &s\uuu{2N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N1}&a\uuu{N2}&\ldots &s\uuu{NN}\\
\end{pmatrix}
\]
\medskip


\noindent
Now we consider  the
$(N-1)\times (N-1)$-matrices

\[
S_1= 
\begin{pmatrix}
s\uuu{22}&s\uuu{23}&\ldots &s\uuu{2N}\\
s\uuu{32}&s\uuu{33}&\ldots &s\uuu{3N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N2}&s\uuu{N3}&\ldots &s\uuu{NN}\\
\end{pmatrix}
\quad\colon\quad 
S_2= 
\begin{pmatrix}
s\uuu{12}&s\uuu{13}&\ldots &s\uuu{1N}\\
s\uuu{22}&s\uuu{23}&\ldots &s\uuu{2N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N-1,2}&s\uuu{N-1,3}&\ldots &s\uuu{N-1,N}\\
\end{pmatrix}
\]
\medskip
\[
S_3= 
\begin{pmatrix}
s\uuu{11}&s\uuu{12}&\ldots &s\uuu{1,N-1}\\
s\uuu{21}&s\uuu{22}&\ldots &s\uuu{2,N-1}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N-1,1}&s\uuu{N-1,2}&\ldots &s\uuu{N-1,N-1}\\
\end{pmatrix}
\]
\medskip

\noindent
We have also the $(N-2)\times (N-2)$-matrix
when extremal rows and columns are removed:

\[ S_*=\begin{pmatrix}
s\uuu{22}&s\uuu{23}&\ldots &s\uuu{2,N-1}\\
s\uuu{32}&s\uuu{33}&\ldots &s\uuu{3,N-1}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{2,N-1}&s\uuu{3,N-1}&\ldots &s\uuu{N-1,N-1}\\
\end{pmatrix}
\]
\medskip

\noindent
{\bf{B.7 Sylvester's identity.}}
\emph{One has the equation}
\[
\det(S)\cdot \det(S_*)=
\det S_1)\cdot \det S_3-\bigl(\det S_2\bigr)^2
\]
\medskip

\noindent{\bf{Exercise}}. Prove this result and deduce 
Kronecker's equation.

\bigskip




\centerline{\bf{C. Proof of Hadamard's theorem.}}







\medskip

\noindent
We are given the smallest integer $p$ in
Hadamard's theorem. A first step in the proof is:
\medskip

\noindent
{\bf{C.1  Lemma. }}\emph{When $p$ as above is minimal one has
the unrestricted limit formula:}
\[
\lim\uuu{n\to \infty}\, 
\bigl[\mathcal D\uuu n^{(p\vvv 1)}\bigr]^{\frac{1}{n}}=
\rho ^{\vvv p}\tag{*}
\]

\bigskip

TO BE GIVEN: Exercise power series+ Sylvesters equation.

\bigskip


\noindent
Lemma 7.2 entails that if $n$ is large
$\{\mathcal D\uuu n^{(p\vvv 1)}\}$
are  $\neq 0$. Hence
there exists some $n_*$ such that every  $n\geq n_*$
we find  a    unique $p$\vvv vector
$(A\uuu n^{(1)},\ldots, A\uuu n^{(p)})$
which solves the inhomogeneous system
\[
\sum\uuu{k=0}^{k=p\vvv 1}
\, c\uuu {n+k+j}\cdot A\uuu n^{(p\vvv k)}
=\vvv c\uuu {n+p+j}\quad\colon\quad 0\leq j\leq p\vvv 1
\]
Or expressed in matrix notation:
\[
\begin{pmatrix}
c\uuu{n}&c\uuu{n+1}&\ldots&c\uuu{n+p-1}\\
c\uuu{n+1}&c\uuu{n+2}&\ldots&c\uuu{n+p}\\
\ldots&\ldots&\ldots&\ldots\\
c\uuu{n+p-1}&c\uuu{n+p}&\ldots&c\uuu{n+2p-2}\\
\end{pmatrix}\,
\begin{pmatrix}A_n^{(p)}\\\ldots\\\ldots\\\ldots\\
A_n^{(1)}\end{pmatrix}=-
\begin{pmatrix}c_{n+p} \\\ldots\\\ldots\\\ldots\\
c_{n+2p-1}\end{pmatrix}\tag{*}
\]

\medskip


\noindent
{\bf{C.2  Exercise.}}
Put
\[
H\uuu n=
c\uuu{n+2p}+ A\uuu n^{(1)}\cdot  c\uuu{n+2p\vvv 1}+
\ldots+ A\uuu n^{[(p)} \cdot c\uuu{n+p}
\]
Show that the evaluation of  $\mathcal D\uuu n^{(p)}$ 
via an expansion of the last column gives the equality:
\[ 
H\uuu n=
\frac{\mathcal D\uuu n^{(p)}}{\mathcal D\uuu n^{(p\vvv 1)}}\tag{C.2.1}
\]
\medskip

\noindent

\noindent
Next,  the  limit formula   (3) above Theorem 7.1 together with
Lemma C.1 
give for every $\epsilon>0$
a constant $C\uuu\epsilon$ 
such that the following hold for all sufficiently large $n$:
\[ 
|H\uuu n|\leq C\uuu\epsilon \cdot 
\bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n\tag{i}
\]

\noindent
Next, 
put
\[ 
\delta\uuu n^{k}=A\uuu {n+1}^{(k)}\vvv A\uuu n^{(k)}
\quad\colon\quad 1\leq k\leq p\tag{ii}
\]

\medskip

\noindent
From the equation in  (*) applied with  $n$ and $n+1$ it is clear that
the $\delta$\vvv numbers satisfy the system
\[
\sum\uuu{k=0}^{k=p\vvv 1}
\, 
c\uuu {n+j+k+1}\cdot \delta \uuu n^{(p\vvv k)}=0
\quad\colon\quad 0\leq j\leq p\vvv 2
\]
\[
\sum\uuu{k=0}^{k=p\vvv 1}
\, 
c\uuu {n+p+k}\cdot \delta \uuu n^{(p\vvv k)}=
\vvv (c\uuu{n+2p}+ A\uuu n^{(1)}\cdot  c\uuu{n+2p\vvv 1}+
\ldots+ A\uuu n^{[(p)} \cdot c\uuu{n+p})
\tag{iii}
\]
\medskip



\noindent
here the $\delta$\vvv numbers in the linear system ( iii)
are found  via Cramer's rule. 
The minors of degree $p\vvv 1$ in the Hankel matrices 
$\mathcal C\uuu {n+1}^{(p\vvv 1)}$ have elements from
the given
$c$\vvv sequence and  
every such minor has an absolute value majorized by
\[
C\cdot (\rho\vvv \epsilon)^{\vvv (p\vvv 1)n}
\] 
where $C$ is a constant 
which is independent of $n$.
We conclude that the $\delta$\vvv numbers satisfy
\[
|\delta \uuu n^{(k)}|\leq |\mathcal D\uuu n^{(p\vvv 1)}|^{\vvv 1}\cdot 
C\cdot (\rho\vvv \epsilon)^{\vvv (p\vvv 1)n}\cdot |H\uuu n|\tag{iv}
\]


\noindent
Next, the  unrestricted limit in Lemma C.1
give  upper bounds for
 $|\mathcal D\uuu n^{(p\vvv 1)}|^{\vvv 1}$ so that  (C.2.1 ) and (iv) give:
 
\medskip
 
 \noindent
{\bf{C.3  Lemma}}
 \emph{To each $\epsilon>0$ there is a constant
 $C\uuu\epsilon$ such that}
 \[
|\delta \uuu n^{(k)}|\leq 
C\uuu\epsilon\cdot
 \bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n
 \quad\colon\quad 1\leq k\leq p
\]
\medskip


\noindent
{\bf{C.4  The polynomial $Q(z)$}}.
Lemma C.3   and (ii) entail that
the sequence $\{A\uuu n^{(k)}\,\colon\, n=1,2,\ldots\}$
converges for every $k$. Set
\[
A\uuu *^{(k)}=\lim_{n\to\infty}\, A\uuu n^{(k)}\,
\]
 Notice   that Lemma C.3  after summations of geometric series gives
a constant $C_1$ such that
\[
|A\uuu *^{(k)}\vvv A\uuu n^{(k)}|\leq C_1\cdot 
\bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n\tag{C.4.1}
\]
hold for every $1\leq k\leq p$ and every $n$.
\medskip

\noindent
Now we consider the sequence
\[
b\uuu n=
 c\uuu{n+p}+ A\uuu *^{(1)}\cdot c\uuu {n+p\vvv 1}+
\ldots A\uuu *^{(p)}\cdot c\uuu n\tag{C.4.2 }
 \]
Equation (*) applied to   $j=0$  gives
\[
b\uuu n= 
(A\uuu *^{(1)}\vvv A\uuu n ^{(1)})
\cdot c\uuu {n+p\vvv 1}+
\ldots +(A\uuu *^{(p)}\vvv A\uuu n^{(p)})\cdot c\uuu n\tag{C.4.3}
\]

\medskip

\noindent
Next, we have already seen that $|c\uuu n|\leq C\cdot(\rho\vvv \epsilon)^{\vvv n}$
hold for some constant $C$ which
together with (C.4.1)  gives:
\medskip

\noindent
{\bf{C.5  Lemma.}}
\emph{For every $\epsilon>0$ there exists a constant $C$ such that}
\[
|b\uuu n|\leq C\cdot \bigl(\frac{1+\epsilon}{\rho\uuu *}\bigr)^n
\]
\medskip

\noindent
Finally, consider the polynomial
\[
Q(z)=  1+ A\uuu *^{(1)}\cdot z+
\ldots A\uuu *^{(p)}\cdot z^p\tag{C.6}
\]

\noindent
Set $g(z)= Q(z)f(z)$ which has a power series
$\sum\, d_\nu z^\nu$
where 
\[
d_{n+p}=
c_n\cdot   A_*^{(p)}+\ldots
c_{n+p-1}A_*^{(1)} +c_{n+p}=b_n
\]
\medskip


\noindent
Above $p$ is fixed so Lemma 6.5 and the standard  spectral radius formula 
show that
$g(z)$ is analytic in the disc $|z|<\rho_*$. This
proves that $f$ extends and the poles are contained in
the zeros of the polynomial $Q$ which occur  in 
$\rho\leq |z|<\rho_*$.














\end{document}






\newpage



\centerline{ \bf{§ XX. Carleman's work in PDE-theory.}}


\bigskip


\noindent
{\bf{Introduction.}}
The material in § x-xx  stems from Carleman's lecture at
the Scandinavian Congress in Stockholm 1934.
To avoid  cumbersome technical points we shall
restrict the attention to second order elliptic operators
in dimension 2 or 3.
But it goes without saying that the subsequent results can be
extended after suitable changes of constants which appear
in the theorems.

\bigskip





\centerline {\bf{§ xx. Fundamental solutions to second order
Elliptic operators.}}
\bigskip


\noindent
{\bf{Introduction.}}
We shall expose material from Carleman's  
article \emph{xxx}.
Elliptic partial differential operators appear frequently and in order to solve 
inhomogeneous equations one often employs a fundamental  solution.
It  is therefore  of interest to contruct fundamental solutions with
"best possible regularity" conditions.
For PDE-operators with constant coefficients one 
employs Fouriers' inversion fourmula
and we  refer to Chapter X in vol.2 in Hörmander's text-book series on linear 
partial differential operators for a detailed account
about constructions of fundamental  solutions with optimal regularity
in the case of constant coefficients.
Passing to the case of variable coefficients one profits upon the constant case and
following Carleman we will show that
one can obtain fundamental  solutions to second order elliptic operators in
a canonical fashion.
In contrast to the csae of constant coefficients  the subsequent constructions do not 
use the Fourier transform. Insetad one finds fundemental 
solutions by solving integral equations of the Neumann-Fredholm type.
Let us  remark that one  does not need any concepts from distribution
theory since we will find
fundamental solutions are locally integrable and 
in such situations
the
notion of fundamental solutions were well understood at an early stage after pioneering work by
Weyl and Zeilon prior to 1925. In his article Carleman refers to
\emph{Grundlösungen} 
and their requested properties are derived via Green's formula.

\medskip


\noindent
{\bf{Remark.}}
For students interested in PDE-theory the material below offers 
an instructive lesson and  suggests further investigations.
We restrict the study to ${\bf{R}}^3$ and  remark only that
similar constructions can be performed when $n\geq 4$ starting from
Newton's potential 
$|x-\xi|^{-n+2}$. Here it would be  interesting to clarify the
precise estimates  when $n\geq 4$ and
establish similar inequalities as in the Main Theorem
One can also try to extend the whole condtructions to elliptic operators of
order $\geq 3$.
In the case of even order $2m$
the method would be to emply the canonical fundamental solutions for
elliptic operators of even order with constant coefficents which
were given by F. John. So here  replaces Newton's fundamental
solutions which appear in § 1 below by those of John and after 
it is tempting to perform  
similar constructions as those by 
Carleman. This appears to be a "profitable research problem" for 
ph.d-students.
Let us also remark that
one does not assume that the elliptic operators are symmetric, i.e.
both the constructions as well as estimates for the fundamental solutions do
not rely upon symmetry conditions.
Recall finally  that fundamental solutions are used to construct various Greens' functions
and here a priori estiamates are valuable 
We illustrate  this in § xx where we expose some further results by Carleman concerned with
asymptotic distributions of eigenvalues to elliptic boundary value problems
which we describe below.

\medskip


\noindent
{\bf{An asymptotic formula for the spectrum.}}
Let $n=3$ and consider a second order PDE-operator
\[
L=
\sum_{p=1}^{p=3}\sum_{q=1}^{q=3}\, a_{pq}(x)\cdot \frac{\partial ^2}{\partial x_p\partial x_q}+
\sum_{p=1}^{p=3}\, a_p(x)
\frac{\partial }{\partial x_p}+a_0(x)
\]
The $a$-functions are real-valued and
defined in a neighborhood of the closure of a bounded
domain
$\Omega$ in ${\bf{R}}^3$
with a $C^1$-boundary.
Here one has the symmetry $a_{pq}=a_{qp}$, and 
$\{a_{pq}\}$ are
of class $C^2$, $\{a_p\}$  of class $C^1$ and $a_0$ is continuous.
The elliptic property of
 $L$ means that
for
every $x\in\Omega$ the eigenvalues of the symmetric
matrix
$A(x)$ with elements $\{a_{pq}(x)\}$
are positive.
Under these conditions, a  result which goes back to work by 
Neumann and Poincaré,
gives
a positive constant
$\kappa_0$ such that
if $\kappa\geq \kappa_0$ then
the inhomogeneous equation
\[
L(u)-\kappa^2\cdot u=f\quad\colon f\in L^2(\Omega)
\]
has a unique solution $u$ which is a $C^2$-function 
in
$\Omega$ and  extends to the closure where it is zero on
$\partial\Omega$.
Moreover, there exists some $\kappa_0$
and for each $\kappa\geq \kappa_0$ a
Green's function
$G(x,y;\kappa)$ such that
\[
(L-\kappa^2)(\frac{1}{4\pi}\cdot \int_\Omega\, 
G(x,y;\kappa)\, f(y)\, dy )= -f(x)\quad\colon f\in L^2(\Omega)\tag{i}
\]
This  means  that the bounded linear operator on
$L^2(\Omega$ defined by
\[
f\mapsto 
-\frac{1}{4\pi}\cdot \int_\Omega\, 
G(x,y;\kappa)\, f(y)\, dy\tag{ii}
\]
is Neumann's resolvent
to the densely defined operator
$L-\kappa^2$ on the 
Hilbert space $L^2(\Omega)$. 
Next, one seeks pairs $(u_n,\lambda_n)$
where $u_n$ are $L2$-functions in $\Omega$ which 
extend to be zero on
$\partial\Omega$ and satisfy
\[ 
L(u_n)+\lambda_n\cdot u_n=0
\]
It turns out that the set of eigenvalues is discrete and
moreover their real parts tend to $+\infty$.
They are arranged with non-decreasing absolute values and in § xx we prove
that there exist positive constants
$C$ and $c$ such that
\[
|\mathfrak{Im}(\lambda_n)|\leq
C\cdot(\mathfrak{Re}(\lambda_n)+c)
\] 
hold for every $n$.
Next, the elliptic
hypothesis means that
the determinant function
\[
D(x)=\det(a_{p,q}(x))
\]
is positive in $\Omega$. With these notations one has


\medskip



\noindent
{\bf{ Theorem.}}
\emph{The following limit formula holds:}
\[
\lim_{n\to\infty}\, \frac{\mathfrak{Re}(\lambda_n)}{n^{\frac{2}{3}}}
=\frac{1}{6\pi^2}\cdot \int_\Omega\, 
\frac{1}{\sqrt{D(x)}}\, dx\tag{*}
\]
\medskip

\noindent
{\bf{Remark.}}
The formula above is due to Courant and Weyl  when
$P$ is symmetric and  extended to
non-symmetric operators during 
Carleman 's lectures at Institute Mittag-Leffler in  1935.
Weyl and Courant used calculus of variation
in the symmetric case 
while Carleman employed  different methods which
have the merit that the passage to the non-symmetric case
does not cause any  trouble. 
A crucial step during the  proof of the theorem above
is to
construct a fundamental solution $\Phi(x,\xi;\kappa)$
to the PDE-operators
$L-\kappa^2$ which done in § 1 while § 2 treats the asymptotic formula above.
As pointed out by
Carleman the methods in the  proof  
give similar asymptotic formulas 
in   other boundary value problems such as
those considered by Neumann where one imposes boundary value conditions on
outer normals.
As an example we consider an elliptic
operator
of the form
\[
L=\Delta+
\sum_{p=1}^{p=3}\, a_p(x)
\frac{\partial }{\partial x_p}+a_0(x)
\]
where $\Delta$ is the Laplace operator.
Given a positive real-valued continuous function
$\rho(x)$ on $\partial\Omega$
we obtain the Neumann-Poincaré operator
$\mathcal{NP}$ which sends each $u\in C^0(\partial\Omega)$ to
\[
\mathcal{NP}(u)=
\frac{\partial u^*}{\partial{\bf{n}}_i}-\rho\cdot u
\]
Here $u^*$ is the Dirichlet extension of $u$ to $\Omega$ which
is equal to $u$ on $\partial\Omega$ and satisfies $L(u)=0$ in
$\Omega$, while
$\frac{\partial u^*}{\partial{\bf{n}}_i}$ is the inner normal along the boundary.
In the special case when
$L=\Delta$ this  boundary value problem has unique solutions, i.e.
for every
$f\in C^0(\partial\Omega)$ there exists a unique $u$ such that
\[
\mathcal{NP}(u)=f
\]
This was proved
by Poincaré in 1897 for
domains in ${\bf{R}}^3$ whose boundaries are of class
$C^2$ and the extension to domains with a $C^1$-boundary
is also classic.
Passing to general operators $L$ as above which are not neccesarily symmetric
one encounters spectral problems, i.e. above
$\mathcal{NP}$ regared as a linear operator on the
Banach space $C^0(\partial\Omega)$ is densely defined and
one seeks its spectrum, i.e,  compex numbers
$\lambda$ for which there exists a non-zero
$u$ such that
\[
\mathcal{NP}(u)+\lambda\cdot u=0
\]
I do not
know if there exists
an  analytic formula for these eigenvalues. Notice that a new feauture is that
the $\rho$-function affects the spectrum.










\newpage 



\centerline{\bf{Fundamental solutions.}}
\bigskip

\noindent
In
${\bf{R}}^3$ with coordinates $x=(x_1,x_2,x_3)$ we consider 
 a second order PDE-operator
\[
L=
\sum_{p=1}^{p=3}\sum_{q=1}^{q=3}\, a_{pq}(x)\cdot \frac{\partial ^2}{\partial x_p\partial x_q}+
\sum_{p=1}^{p=3}\, a_p(x)
\frac{\partial }{\partial x_p}+a_0(x)
\]
where 
$a$-functions are real-valued and
one has the symmetry $a_{pq}=a_{qp}$.
To ensure existence of a globally defined fundamental solutions we
suppose the the following limit formulas hold
as $(x,y,z)\to \infty$:
\[
\lim a_\nu(x,y,z)=0 \colon 0\leq p\leq 3\quad\colon\,
\lim a_{pq}(x,y,z)= \text{Kronecker's delta function}
\]
Thus, $L$ approaches the Laplace operator as $(x,y,z)$ tends to
infinity. Moreover
$L$ is elliptic which means that
the eigenvalues of the symmetric
matrix with elements $\{a_{pq}(x)\}$
are positive for every $x$.
Recall the  notion of  fundamental solutions.
Consider
the adjoint
operator:
\[ 
L^*(x,\partial _x)=P-2\cdot \bigl(
\sum_{p=1}^{p=3}\, \bigl(\sum_{q=1}^{q=3}\, 
\frac{\partial a_{pq}}{\partial x_q}\bigr)\cdot \frac{\partial}{\partial x\uuu p}
-\sum_{p=1}^{p=3}\, \frac{\partial a_p}{\partial x_p}
+2\cdot \sum\sum\, \frac{\partial^2 a_{pq}}{\partial x_p\partial x_q}\tag{0.1}
\]
Partial integration gives  the equation  below for every pair of
$C^2$-functions $\phi,\psi $ in ${\bf{R}}^3$ with compact support:
\[
\int\, L(\phi)\cdot \psi\, dx=
\int\, \phi\cdot L^*(\psi)\, dx\tag{0.2}
\] 
where
the volume integrals are taken over
${\bf{R}}^3$.
A locally integrable function $\Phi(x)$ in ${\bf{R}}^3$
is  a fundamental solution to $L(x,\partial _x)$
if
\[
\psi(0)=\int\, \Phi\cdot L^*(\psi)\, dx\tag{0.3}
\] 
hold for every $C^2$-function  $\psi$ with compact support.
Next, to each 
positive number
$\kappa$ we  get  the PDE-operator $L-\kappa^2$ and a
function $x\mapsto \Phi(x;\kappa)$ is a fundamental solution to $L-\kappa^2$
if
\[
\psi(0)=\int\, \Phi(x:\kappa)\cdot (L^*-\kappa^2)(\psi(x))\, dx\tag{0.4}
\] 
hold for compactly supported $C^2$-functions $\psi$.
Next, the  origin can  replaced by a variable point $\xi$ in
${\bf{R}}^3$ and then one seeks
a function
$\Phi^*(x,\xi;\kappa)$ with the property that
\[
\psi(\xi)=\int\, \Phi(x,\xi;\kappa)\cdot (L^*(x,\partial_x)-\kappa^2)(\psi(x))\, dx\tag{*}
\] 
hold for all  $\xi\in{\bf{R}}^3$
and every $C^2$-function $\psi$ with compact support.
Keeping $\kappa$ fixed this means that  
$\Phi(x,\xi;\kappa)$ is a function of six variables  defined in 
${\bf{R}}^3\times {\bf{R}}^3$.
With these notations we announce the main result:


\bigskip

\noindent
{\bf{Main Theorem.}} \emph{There exists a  constant
$\kappa_*$ such that for every $\kappa\geq\kappa_*$ one can find a fundaemtal
solution
$\Phi(x,\xi;\kappa)$ which is locally integrable
in the 6-dimensional $(x,\xi)$-space.
Moreover,
there exist positive constants $C$ and $k$ and
for each $0<\gamma\leq 2$ a constant $C_\gamma$ such that}
\[
|\Phi(x,\xi;\kappa)|\leq
C\cdot \frac{e^{-k\kappa|x-\xi|}}{|x-\xi|}+
 \frac{C_\gamma}{(\kappa|x-\xi|)^{\gamma}}
\]
\emph{hold for all pairs $(x,\xi)$ in ${\bf{R}}^3$ and every
where the constants $k$ and $C$ do not depend upon $\kappa$.}

\bigskip



\centerline {\bf{1. The construction of $\Phi(x,\xi;\kappa)$.}}
\medskip



\noindent
The subsequent constructions 
are 
based upon a
classic formula due to Newton and  specific solutions to
integral equations
found by a convergent Neumann series.
When $L$ has
constant coefficients 
the construction of   fundamental solutions was (at least essentially)
given by
Newton in his famous
text-books from 1666 and goes as follows:
Consider a 
positive  and symmetric $3\times 3$-matrix
$A= \{a_{pq}\}$. Let
$\{b_{pq}\}$ be the elements of the inverse matrix which gives 
the quadratic form

\[ 
 B(x)= \sum_{p,q}\, b_{pq} a_px_q
\]
Put
\[
\alpha=\sqrt{\kappa^2+\frac{1}{2}\, \sum_{p,q}\, b_{pq} a_pa_q
-a_0}
\]
where $\kappa$ is chosen so large that
the term under the square-root is $>0$. Finally, put
\[
\Delta=\det(A)
\]
With these notations we get a function:
\[
H(x;\kappa)= \frac{1}{4\pi\cdot \sqrt{\Delta\cdot B(x)}}
\cdot e^{-\alpha \sqrt{B(x)}-
\frac{1}{2}\sum_{p,q}b_{pq} a_p\cdot x_q}\tag{1.1} 
\]


\medskip




\noindent
{\bf{Exercise.}} Verify by Stokes  formula
that $H(x;\kappa)$  yields  a fundamental solution
to the PDE-operator $L(\partial_x)-\kappa^2$.



\bigskip



\noindent
{\bf{1.2 The case with variable coefficients.}}
Now $L$ has variable coefficients.
For each $\xi\in{\bf{R}}^3$ the elements of the inverse matrix
to $\{a_{pq}(\xi)$
are denoted by $\{b_{pq}(\xi)\}$.
Choose $\kappa_0>0$ such that
\[
\kappa_0^2+\frac{1}{2}\, \sum_{p,q}\, b_{pq}(\xi) a_p(\xi)a_q(\xi)
-b(\xi)>0\quad\text{hold for all}\quad  \xi\in{\bf{R}}^3
\] 
and for every $\kappa\geq \kappa_0$ we set
\[
\alpha_\kappa(\xi)=
\sqrt{\kappa^2+\frac{1}{2}\, \sum_{p,q}\, b_{pq}(\xi) a_p(\xi)a_q(\xi)
-b(\xi)}\tag{i}
\]
Following Newton's construction in (1.1) we
put:
\[
H(x,\xi;\kappa)=\frac{1}{4\pi}\cdot
 \frac{\sqrt{\Delta(\xi)}^{-\frac{1}{2}}}{
\sqrt{ \sum_{p,q}\, b_{pq}(\xi)\cdot x_px_q}}
\cdot e^{-\alpha_\kappa(\xi) \sqrt{B(x)}-
\frac{1}{2}\sum_{p,q}b_{pq}(\xi) a_p(\xi)\cdot x_q} \tag{ii}
\]

\noindent
When $\xi$ is kept fixed this  function of
$x$ is real analytic  outside the origin and 
$x\to H(x,\xi;\kappa)$ is locally integrable
as a function of $x$ in a neighborhood of the origin.
We are going to construct  a fundamental solution
which takes the form
\[
\Phi(x,\xi;\kappa)=
H(x-\xi,\xi;\kappa)+\int_{{\bf{R}}^3}\, 
H(x-y,\xi;\kappa)\cdot\Psi(y,\xi;\kappa)\, dy\tag{iii}
\]
where the $\Psi$-function is the solution to an integral equation
which we construct in (1.5). But first we need another construction.

\medskip

\noindent
{\bf{1.3 The function $F(x,\xi;\kappa)$.}}
For every fixed $\xi$ we get  the  differential operator in the
$x$-space:
\[ 
L_*(x,\partial_x,\xi;\kappa)=
\]
\[\sum_{p=1}^{p=3}\sum_{q=1}^{q=3}\, (a\uuu{pq}(x)-
(a\uuu{pq}(\xi))\cdot 
\frac{\partial^2}{\partial x_p\partial x_q}+
\sum_{p=1}^{p=3}\,
(a_p(x)-a_p(\xi))\frac{\partial}{\partial x_p}+ (b(x)-b(\xi))
\]

\medskip

\noindent
Apply $L_*$ to the function
$x\mapsto H(x-\xi,\xi;\kappa)$
and put
\[ 
F(x,\xi;\kappa)=\frac{1}{4\pi}\cdot L_*(x,\partial_x,\xi;\kappa)(H(x-\xi,\xi,\kappa)) \tag{1.3.1}
\]

\medskip

\noindent
{\bf{1.4 Two  estimates.}}
The limit conditions  in (0.0)     give  positive constants
$C,C_1$ and $k$ such that the following hold when $\kappa\geq\kappa_0$:
\[
|H(x-\xi,\xi;\kappa)|\leq C\cdot \frac{e^{-k\kappa|x-\xi|}}{|x-\xi|}
\quad\colon\,
[F(x,\xi;\kappa)|\leq C_1\cdot 
\frac{e^{-k\kappa|x-\xi|}}{|x-\xi|^2}
\tag{1.4.1}
\]


\noindent
The verification of (1.4.1) is left as an exercise.



\bigskip





\noindent
{\bf{1.5 An integral equation.}}
We  seek
$\Psi(x,\xi;\kappa)$ which satisfies the equation:
\[ 
\Psi(x,\xi;\kappa)= \int_{{\bf{R}}^3}\,  F(x,y;\kappa)\cdot \Psi(y,\xi;\kappa)\,dy+F(x,\xi;\kappa)\tag{1.5.1}
\]
To solve (1.5.1 )
we construct the Neumann series of $F$.
Thus, starting with $F^{(1)}=F$ we set
\[
F^{(k)}(x,\xi;\kappa)=\int_{{\bf{R}}^3}\, F(x,y;\kappa)\cdot
F^{(k-1)}(y,\xi;\kappa)\, dy\quad\colon\quad k\geq 2\tag{1.5.2}
\]
Then (1.4.1 ) gives  the inequality
\[
|F^{(2)}(x,\xi;\kappa)|
\leq C_1^2\iiint
\frac{e^{-k\kappa|\xi-y|}}{|x-y|^2\cdot |\xi-y|^2}\cdot dy\tag{i}
\]


\noindent
To estimate (i) we  notice that the triple integral after
the substitution $y-\xi\to u$
becomes
\[
C_1^2\iiint
\frac{e^{-k\kappa|u|^2}}{|x-u-\xi|^2\cdot |u|^2}\cdot du\tag{ii}
\]


\noindent
In  (ii)  the volume integral can be integrated in polar
coordinates
and becomes
\[
C_1^2\cdot \int_0^\infty\int_{S^2}\, 
\frac{e^{-k\kappa r^2}}{|x-r\cdot w-\xi|^2}\cdot dwdr\tag{iii}
\]
where $S^2$ is the unit sphere and $dw$ the area measure on
$S^2$. It follows that
(iii) becomes
\[
2\pi C_1^2\cdot
\int_0^\infty\int_0^\pi\, 
\frac{e^{-k\kappa r}}{(x-\xi)^2+r^2-
2r\cdot |x-\xi|\cdot \sin\theta}\cdot d\theta dr=
\]
\[
\frac{2\pi C_1^2}{|x-\xi|}\cdot\int_0^\infty\, e^{-k\kappa |x-\xi|t}\cdot
\log\, |\frac{1+t}{1-t}|\cdot \frac{dt}{t}\tag{iv}
\]
where the last equality follows by a straightforward computation.

\medskip


\noindent
{\bf{1.6 Exercise.}}
Show that (iv) gives the estimate
\[
|F^{(2)}(x,\xi;\kappa)|\leq \frac{2\pi\cdot  C_1^2\cdot C_1^*}{\kappa\cdot |x-\xi|^2}
\]
where $C_1^*$ is a fixed positive constant
which is independent of $x$ and $\xi$ and 
show by an induction over $n$
that one has:
\[
|F^{(n)}(x,\xi;\kappa)|\leq\frac{C_1}{|x-\xi|^2}\cdot 
\bigl[\frac{2\pi C_1^2\cdot C_1^*}{\kappa}\bigr]^{n-1}
\quad\text{for every}\quad  n\geq 2\tag{*}
\]
\medskip

\noindent
{\bf{1.6 Conclusion.}}
Choose  $\kappa_0^*$ so large that
\[
2\pi C_1^2\cdot C_1^*<\kappa_0^*\tag{1.6.1}
\]
Then (*) implies that 
the Neumann series
\[
\sum_{n=1}^\infty F^{(n)}(x,\xi;\kappa)
\]
converges when 
$\kappa\geq \kappa_0^*$ 
and
gives the requested solution $\Psi(x,\xi;\kappa)$ in (1.5.1).
\bigskip


\noindent
{\bf{1.7 Exercise.}}
We  have found 
$\Psi$ which satisfies the integral equation in § 1.5.1.
Next, since the $H$-function in (ii) from § 1.2 is everywhere positive
the integral equation (iii)in § 1.2 has a unique solution
$\Phi(x,\xi;\kappa)$. Using Green's formula the reader can check that
$\Phi(x,\xi;\kappa)$ yields   a fundamental solution
of $L(x,\partial_x)-\kappa^2$.

\medskip


\noindent{\bf {1.8 Some estimates.}}
The  constructions above show that
the  functions
\[
x\mapsto \Phi(x,\xi;\kappa)\quad\text{and}\quad 
x\mapsto H(x-\xi,\xi;\kappa)
\]


\noindent
have the same  singularities at $x=\xi$.
Consider the difference
\[
Q(x,\xi;\kappa)=\Phi(x,\xi;\kappa)-
H(x-\xi,\xi;\kappa)\tag{1.8.1}
\]
\medskip


\noindent
{\bf{1.8.2 Exercise.}}
Use the previous constructions to show
that for every $0<\gamma\leq 2$
there is a constant $C_\gamma$
such that
\[
\bigl |Q(x,\xi;\kappa)\,\bigr|\leq \frac{C_\gamma}{(\kappa|x-\xi|)^{\gamma}}
\]
hold for every pair $(x,\xi)$ and every $\kappa\geq \kappa_0$.
Finally, the reader can apply 
the inequality for the
$H$-function in (1.4.1) to conclude the results in the Main Theorem.



\newpage

\centerline {\bf{§ 2. Green's functions.}}
\bigskip


\noindent
Let $\Omega$ be a bounded domain in
${\bf{R}}^3$, and $L$ an elliptic differential operator as in § xx.
Let $\kappa>0$ and suppose we have found a function
$G(x,y;\kappa)$ defined when $(x,y)\in \Omega\times\Omega$
with the property that
$G(x,y)=0$   if $x\in\partial\Omega$ and  $y\in\Omega$.
Moreover
\[
(L(x,\partial_x)-\kappa^2)(G(x,y;\kappa))=\delta(x-y)
\]
With $G$ as  kernel we get the integral operator
\[
\mathcal G(f)(x)=
\int_\Omega\, 
G(x,y;\kappa)\, f(y)\, dy 
\]
Then $\mathcal G(f)(x)=0$ on $\partial\Omega$
and the composed operator 
\[
(L(x,\partial_x)-\kappa^2)\circ \mathcal G=E
\]
To construct $G$ we use the fundamental solution
$\Phi(x,y;\kappa)$ from § xx which satisfies
\[
(L(x,\partial_x)-\kappa^2)(\Phi(x,y;\kappa))=\delta(x-y)
\]
Next, with $y\in\Omega$ kept fixed we have the 
continuous boundsry functon
\[
x\mapsto \Phi(x,y;\kappa)
\]
Solving the Dirchlet problem we find
$w(x)$ such that
$w(x)= \Phi(x,y;\kappa)$ on the boundary while
$ (L(x,\partial_x)-\kappa^2)(w)=0$ holds in $\Omega$.
Then we can take
\[
G(x,y;\kappa)=\Phi(x,y;\kappa)-w(x)
\]


\noindent
Using the estimates for the $\Phi$-function from § 1
we get
estimates for the $G$-function above.
We choose    a sufficiently large
$\kappa_0$ so  that 
$\Phi(x,\xi;\kappa_0)$ is a positive function of
$(x,\xi)$. Then the following hold:
\medskip


\noindent
{\bf{2.1 Theorem.}}
\emph{One has}
\[ 
G(x,\xi;\kappa_0)=
\frac{1}{\sqrt{\Delta(x)}\cdot\sqrt{\Phi(x,\xi;\kappa_0)}}
+R(x,\xi)
\]

\noindent
\emph{where the remainder function satisfies the following for all pairs
$(x,\xi)$ in $\Omega$:}
\[ 
|R(x,\xi)|\leq C\cdot |x-\xi|^{-\frac{1}{4}}
\]


\noindent
\emph{and the   constant $C$ only  depends on the  domain 
$\Omega$ and
the PDE-operator $L$.}
\medskip

\noindent
{\bf{Remark.}}
Above the negative power  of 
$|x-\xi|$ is  a fourth-root which means that  the remainder term $R$ 
is more regular  compared
to the first term which behaves like $|x-\xi|^{-1}$ on the diagonal $x=\xi$.

\bigskip

\noindent
{\bf{2.2 Exercise.}} Prove Theorem 2.1 
If necessary, consult [Carleman: page xx-xx9 for details.

\bigskip

\medskip

\noindent
\centerline {\bf{2.3. Almost reality of eigenvalues.}}
\medskip

\noindent
Consider the set of eigenvalues $\lambda$ for which there exists a function $u$
in $\Omega$ which is zero on
$\partial\Omega$ while
\[
L(u)+\lambda\cdot u=0
\]
holds in $\Omega$.


\medskip

\noindent
{\bf{2.3.1  Proposition.}}
\emph{There exist positive constants $C_*$ and $c_*$ such that
every eigenvalue  $\lambda$ above   satisfies}
\[
|\mathfrak{Im}\,\lambda|^2\leq C_*(\mathfrak{Re}\,\lambda)+c_*)
\]
\medskip

\noindent
\emph{Proof.}
Let $u$ be an eigenfunction where
$L(u)+\lambda\cdot u=0$.
Stokes theorem and the vanishing of $u|\partial\Omega$
give:
\[
0=\int_\Omega\, \bar u\cdot (L+\lambda)(u)\,dx
=-\int_\Omega \, \sum_{p,q}\, a_{pq}(x)\cdot \frac{\partial u}{\partial x_p}
\frac {\partial \bar u}{\partial x_q}\, dx+
\int_\Omega\, \bar u\cdot( \sum \, a_p(x)
\frac{\partial u}{\partial x_p}\,)\, dx+
\] 
\[
\int_\Omega\, |u(x)|^2\cdot b(x)\, dx+
\lambda\cdot \int\, |u(x)|^2\, dx
\]
\medskip


\noindent
Write $\lambda=\xi+i\eta$.
Separating real and imaginary parts we find the two equations:
\[
\xi\int\, |u|^2\, dx=
\int\, \sum_{p,q} a_{p,q}(x)\,\frac{\partial u}{\partial x_p}\cdot 
\frac{\partial \bar u}{\partial x_q}\, dx+
\int\, \bigl(\frac{1}{2}\cdot \sum\, \frac{\partial a_p}{\partial x_p}- b\,\bigr )
\cdot |u|^2\, dx\tag{i}
\]
\[
\eta\int\, |u|^2\, dx=\frac{1}{2i}\int \sum\, a_p\bigl(
u\frac{\partial \bar u}{\partial x_p}-
\bar u \frac{\partial u}{\partial x_p}\,\bigl )\, dx\tag{ii}
\]


\noindent
Set
\[ A= \int\, |u|^2\,dx\quad\colon\quad
B= \int\, |\nabla(u)|^2\,dx
\]
Since $L$ is elliptic there exists a positive constant $k$ such that
\[
\sum_{p,q} a_{p,q}(x)\,\frac{\partial u}{\partial x_p}>
k\cdot |\nabla(u)|^2
\]
From this we see that (i-ii) gives positive constants $c_1,c_2,c_3$ such that
\[
A\xi>c_1B-c_2B\quad\colon\quad A|\eta|<c_3\cdot \sqrt{AB}\tag{iii}
\]
\medskip

\noindent
Here (iii) implies that $\xi>-c_2$ and the reader can also confirm that
\[ 
B<\frac{A}{c-1}(\xi+c-2)\quad\colon\quad
A|\eta|< A\cdot c_2\cdot \sqrt{\frac{\xi+c_2}{c_1}}\quad\colon\quad
|\eta|< c_3\cdot \sqrt{\frac{\xi+c_2}{c_1}}\tag{iv}
\]


\noindent Finally it is obvious that (iv) above gives the requested
inequality in Proposition 2.3.1.

\bigskip

\centerline{\bf{2.4. Asymptotic  formula for eigenvalues}}
\bigskip


\noindent
Consider a function $f$ which satisfies
\[
\mathcal G(f)=-\frac{1}{\lambda}\cdot f
\]
for some non-zero complex number $\lambda$.
With $u=\mathcal G(f)$ it follows from (xx) that
\[
(L-\kappa^2)(u)=f=-\lambda\cdot u
\]
Hence
\[
L(u)+(\lambda-\kappa^2)u=0
\]
\medskip


\noindent
{\bf{About the proof of Theorem xx.}}
From  the above the asymptotic formula in Theorem xx 
can be derived from asymptotic properties of eigenvalues to
the integral operator $|mathcal G$.
Using Theorem 2.1 and the estimates for the fundsemtnal solution
$\Phi$ in § 1, one can proceed as in the
the next section where a Tauberian theorem is employed to
finish the proof of Theorem xx.
The  reader may try to supply details or  consult 
[Carleman: page xx-xx] for details.














\newpage














\newpage

\centerline{\bf{§ 3. A study of $\Delta(\phi)+\lambda\cdot \phi$.}}
\bigskip


\noindent
{\bf{Introduction.}}
We expose material from Carleman's article \emph{xxx}
whose contents were presented at the Scandinavian Congress in Stockholm 1934.
In
${\bf{R}}^2$ we 
consider a bounded Dirichlet regular domain
$\Omega$, i.e. every $f\in C^0(\partial\Omega)$
has a harmonic extension to $\Omega$.
A wellknown  
fact
established by
G. Neumann and H. Poincaré
during the years 1879-1895
gives the following: First there
exists the Greens' function
\[
G(p,q)= \log\,\frac{1}{|p-q|}+H(p,q)
\]
where $H(p,q)= H(q,p)$ is continuous in
the product set
$\overline{\Omega}\times\overline{\Omega}$ with the property that
the operator $\mathcal G$ defined on $L^2(\Omega)$ by
\[
f\mapsto \mathcal G_f(p)= \frac{1}{2\pi}\dot \iint\, G(p,q)f(q)\,dq
\]
satisfies
\[ 
\Delta\circ \mathcal G_f=-f\quad\colon f\in L^2(\Omega)
\]
Moreover,  $\mathcal G$ is a compact operator on
the Hilbert space $L^2(\Omega)$ and there 
exists a sequence $\{f_n\}$ in $L^2(\Omega$ such that
$\{\phi_n=\mathcal G_{f_n}\}$
is an orthonormal basis in $L^2(\Omega$ and
\[ 
\Delta(\phi_n)=-\lambda_n\cdot \phi_n\quad\colon\, n=1,2,\ldots
\] 
where
$0<\lambda_1\leq \lambda_2\leq \ldots\}$.
When  eigenspaces have  dimension $\geq 2$, the 
eigenvalues are repeated by their multiplicity.
\medskip

\noindent
{\bf{Main Theorem. }}\emph{For every Dirichlet regular domain
$\Omega$ and each $p\in\Omega$ one has the limit formula}
\[ 
\lim_{N\to\infty}\, \lambda_N^{-1}\cdot \sum_{n=1}^{n=N}\, \phi_n(p)^2= \frac{1}{4\pi}
\]
\medskip

\noindent
The strategy in the proof is to consider the function of a complex variable $s$
defined by
\[
\Phi(s)=\sum_{n=1}^\infty \frac{\phi_n(p)^2}{\lambda_n^s}
\]
and show that it
is a meromorphic function in the whole complex $s$-plane with
a simple pole at $s=1$ whose residue is $\frac{1}{4\pi}$.
More precisely we shall prove:
\medskip


\noindent
{\bf{0.1 Theorem.}}
\emph{There exists an entire function
$\Psi_p(s)$ such that}
\[
\Phi_p(s)=\Psi_p(s)+\frac{1}{4\pi(s-1)}
\]
\medskip

\noindent
Let us first remark that Theorem 0.1   gives ther main theorem 
by a result  due to Wiener in the article
\emph{Tauberian theorem} [Annals of Math.1932].
Wiener's theorem 
asserts that if $\{\lambda_n\}$ is a non-decreasing sequence of
positive numbers which tends to infinity and
$\{a_n\}$ are non-negative real numbers such that
there exists the limit
\[ 
\lim_{s\to 1}\,(s-1)\cdot \sum\, \frac{a_n}{\lambda_n^s}=A
\] 
then it follows that
\[
\lim_{n\to \infty}\,\lambda_n^{-1}\cdot
\sum_{k=1}^{k=n}\, a_k=A
\]
\medskip

\noindent
{\bf{Exercise.}}
Derive the main theorem from Wiener's result and Theorem 0.1.
\medskip

\noindent
{\bf{About Wiener's result.}}
It is a version of
an famous  Tauberian  theorem proved by
Hardy and Littlewood in 1913 which goes as follows:
\medskip

\noindent
{\bf{0.2 The Hardy-Littelwood theorem.}}
\emph{Let $\{a_n\}$ be a sequence of non-negative real numbers
such that}
\[ 
A=
\lim_{r\to 1}\, (1-r)\cdot \sum\,a_nr^n\tag{*}
\]
\emph{exists. Then  there also exists the limit}
\[
A=\lim_{N\to \infty}\, \frac{a_1+\ldots+a_N}{N}\tag{**}
\]
\medskip

\noindent
Notice that no growth condition is imposed on  the sequence 
$\{a_n\}$, i.e. the sole assumption
is the existing limit (*). The proof is quite demanding and does not follow by
"abstract nonsense"from functional analysis.
For the reader's convenience we include details of the proof in a 
separate appendix since
courses devoted to series rarely appear in contemporary
education.



\bigskip









\centerline{\bf{§ 1. Proof of Theorem 0.}}
\bigskip

\noindent
Let
$\Omega$ be a bounded and Dirichlet regular domain.
For ech fixed point  $p\in\Omega$
we 
get  the continuous function on
$\partial\Omega$ defined by
\[ 
q\mapsto  \log \frac{1}{|p-q|}
\]
We find the harmonic function
$u_p(q)$ in $\Omega$ such that
$u_p(q)=\log \frac{1}{|p-q|}\,\colon\, q\in\partial\Omega$.
Green's function is defined for pairs $p\neq q$ in
$\Omega\times\Omega$ 
by
\[ 
G(p,q)= \log\,\frac{1}{|p-q|}-u_p(q)\tag{1}
\]
Keeping
if $p\in\Omega$  fixed, the function
$q\mapsto G(p,q)$ extends to the 
closure of $\Omega$ where it vanishes if
$q\in\partial\Omega$.
If  $f\in L^2(\Omega$
we set
\[ 
\mathcal G_f(p)=\frac{1}{2\pi}\cdot \int_\Omega\, G(p,q)\cdot f(q)\, dq\tag{2}
\]
where $q=(x,y)$ so that $dq=dxdy$ when the double integral is evaluated.
From (1) we see that
\[
 \iint_{\Omega\times \Omega}\, |G(p,q)|^2\, dpdq<\infty
\]
Hence
$\mathcal G$ is of the Hilbert-Schmidt type and
therefore a compact operator on 
$L^2(\Omega)$.
Next,  recall that
$\frac{1}{2\pi}\cdot \log\sqrt{x^2+y^2}$ is
a fundamental solution to the Laplace operator.
From this the reader can   deduce the following:

\medskip

\noindent{\bf{1.1 Theorem.}}
\emph{For each $f\in L^2(\Omega)$
the Lapacian of $\mathcal G_f$
taken in the distribution sense belongs to
$L^2(\Omega)$ and one has the equality}
\[ 
\Delta(\mathcal G_f)=-f\tag{*}
\] 
\medskip


\noindent
The equation (*) means that
the composed operator
$\Delta\circ \mathcal G$ is minus the identity on
$L^2(\Omega)$.
We are  led
to introduce the 
linear operator $S$ on $L^2(\Omega)$ 
defined by $\Delta$, where  
$\mathcal D(S)$ is
the range of $\mathcal G$.
If $g\in C^2_0(\Omega)$, i.e. twice differentiable and with
compact support, it follows via Greens' formula that
\[
\frac{1}{2\pi}\cdot \int_\Omega\, G(p,q)\cdot \Delta(g)(q)\, dq=-g(p)
\]
In particular $C_0^2(\Omega)\subset\mathcal D(S)$
which  implies that
$S$ is densely defined and we  leave it to the reader to verify that
\[
\mathcal G(\Delta(f))=-f\quad\colon f\in\mathcal D(S)
\]


\medskip
\noindent
{\bf{Remark.}}
By Carl Neumann's classic construction of
resolvent operators from 1879, the result above   means that
$-\mathcal G$ is Neumann's inverse  of 
$S$. Since
$-\mathcal G$ is compact it follows by Neumann's formula for spectra that
$S$ has a discrete spectrum,and we recall the following wellknown fact which
goes back to work by Poincaré: 
\medskip

\noindent
{\bf{1.2 Proposition.}}\emph{
There exists an orthonormal basis $\{\phi_n\}$ in $L^2(\Omega)$
where each $\phi_n\in\mathcal D(S)$ is an eigenfunction, and
a non-decreasing sequence of positive real numbers
$\{\lambda_n\}$ such that}
\[ 
\Delta(\phi_n)+\lambda_n\cdot \phi_n=0\quad\colon n=1,2,\ldots\tag{1.2.1}
\]
\medskip

\noindent
{\bf{Remark. }} Above (1.2.1) means 
that
\[
\mathcal G(\phi_n)= \frac{1}{\lambda_n}\, \cdot \phi_n
\]
This, 
$\{\lambda_n^{-1}\}$
are  eigenvalues of the compact operator $\mathcal G$ whose sole cluster
point is $\lambda=0$.
As usual eigenvalues whose eigenspaces have
dimension $e>1$ are repeated $e$ times.



\medskip

\noindent
After these preliminaries we embark upon the proof
of Theorem 0.1. 
First, since $\mathcal G$ is a Hilbert-Schmidt operator a wellknown result due to Schur
gives
\[
\sum\, \lambda_n^{-2}<\infty \tag{i}
\]
This convergence entails that various constructions below are defined.
For each complex number $\lambda$ outside $\{\lambda_n\}$ we set
\[
G(p,q;\lambda)=
G(p,q)+
2\pi\lambda\cdot \sum_{n=1}^\infty\,
\frac{\phi_n(p)\phi_n(q)}{\lambda_n(\lambda-\lambda_n)}\tag{ii}
\]
This gives the integral operator
$\mathcal G_\lambda$ defined on $L^2(\Omega)$ by
 \[ 
 \mathcal G_\lambda(f)(p)
 =\frac{1}{2\pi}\cdot \iint_\Omega\, G(p,q;\lambda )\cdot f(q)\, dq\tag{iii}
\]

\medskip

\noindent
{\bf{A. Exercise.}} Use that the eigenfunctions $\{\phi_n\}$ is an orthonormal basis in
$L^2(\Omega)$ to show that
\[
(\Delta+\lambda)\cdot \mathcal G_\lambda=-E
\]


\noindent{\bf{B. The function $F(p,\lambda)$}}.
Set
\[ 
F(p,q,\lambda)= G(p,q;\lambda)- G(p,q)
\]
Keeping $p$ fixed we see that (ii) gives
\[
\lim_{q\to p}\, F(p,q,\lambda)=
2\pi\lambda\cdot \sum_{n=1}^\infty\,
\frac{\phi_n(p)^2}{\lambda_n(\lambda-\lambda_n)}\tag{B.1}
\]
Set
\[
F(p,\lambda)=
\lim_{q\to p}\, F(p,q,\lambda)
\]
From (i) and (B.1) it follows that it is a meromorphic function in
the complex $\lambda$-plane with at most simple poles
at $\{\lambda_n\}$.
\medskip

\noindent{\bf{C. Exercise.}}
Let $0<a<\lambda_1$. Show via residue calculus that
one has the equality below in a half-space
$\mathfrak{Re}\, s>2$:
\[ 
\Phi(s)=
\frac{1}{4\pi^2 \cdot i}\cdot \int_{a-i\infty}^{a+i\infty}\, 
F(p,\lambda)\cdot \lambda^{-s}\, d\lambda\tag{C.1}
\]
where the line integral  is taken on the vertical  line
$\mathfrak{Re}\,\lambda=a$.

\medskip

\noindent
{\bf{D. Change of contour integrals.}}
At this stage we employ a device which goes to
Riemann and
move the integration into the half-space
$\mathfrak{Re}(\lambda)<a$.
Consider  the curve $\gamma_+$
defined as the union of the
negative real interval $(-\infty,a]$ followed by
the upper
half-circle $\{\lambda= ae^{i\theta}\,\colon 0\leq\theta\leq \pi \}$
and the 
half-line $\{\lambda= a+it\,\colon t\geq 0\}$.
Cauchy's theorem entails that 
\[ 
\int_{\gamma_+}\, F(p,\lambda)\cdot \lambda^{-s}\, d\lambda=0
\]
We leave it to the reader to contruct the
similar
curve
$\gamma_-=\bar \gamma_+$. Using 
the vanishing of these line integrals and taking the branches of the 
multi-valued function
$\lambda^s$ into the account the reader should verify the following:

\medskip


\noindent
{\bf{E. Lemma.}}
\emph{One has the equality}
\[ 
\Phi(s)=\frac{a^{s-1}}{4\pi}\cdot \int_{-\pi}^\pi\,
F(ae^{i\theta})\cdot e^{(i(1-s)\theta}\,d\theta
+
\frac{\sin \pi s}{2\pi^2}\cdot \int_a^\infty\, F(p,-x)\cdot x^{-s}\,dx\tag{E.1}
\]
\medskip

\noindent
The first term in the sum of the right hand side of (E.1)
is obviously an entire function of $s$. So there remains to
prove that
\[
 s\mapsto  \frac{\sin \pi s}{2\pi^2}\cdot \
 \int_a^\infty\, F(p,-x)\cdot x^{-s}\,dx\tag{E.2}
\]
is meromorphic with
a single pole at $s=1$ whose residue is $\frac{1}{4\pi}$.
To attain this we  express $F(p,-x)$ when $x$ are real and positive in another way.
\medskip

\noindent
{\bf{F.  The $K$-function.}}
In the half-space $\mathfrak{Re}\,z>0$ there exists the analytic function
\[
K(z)= \int_1^\infty\, \frac{e^{-zt}}{\sqrt{t^2-1}}\,dt
\]
\medskip

\noindent
{\bf{Exercise.}}
Show that $K$ extends to a multi-valued analytic function outside
$\{z=0\}$ given by
\[
K(z)=-I_0(z)\cdot \log z+ I_1(z)\tag{F.1}
\] 
where $I_0$ and $I_1$ are entire functions
with series expansions
\[
I_0(z)=\sum_{m=0}^\infty\, \frac{2^{-2m}}{(m!)^2}\cdot
z^{2m}\tag{i}
\]
\[ 
I_1(z)= \sum_{m=0}^\infty\, \rho(m)\cdot
\frac{2^{-2m}} {(m!)^2} \cdot z^{2m}\quad
\colon \rho(m)=1+\frac{1}{2}+\ldots+\frac{1}{m}-\gamma\tag{ii}
\]
where $\gamma$ is the usual Euler constant.

\bigskip


\noindent
With  $p$ kept fixed and $\kappa>0$ 
we solve the Dirichlet problem and find
a  function $q\mapsto H(p,q;\kappa)$ which satisfies  the
equation
\[
 \Delta(H)-\kappa\cdot H=0\tag{F.2}
\] 
in $\Omega$ with boundary values
\[ 
H(p,q;\kappa)=K(\sqrt{\kappa}|p-q|)\quad\colon q\in \partial\Omega
\]


\noindent
{\bf{G. Exercise.}}
Verify the equation
\[ 
G(p,q;-\kappa)=K(\sqrt{\kappa}\cdot |p-q|)- H(q;\kappa)\quad\colon \kappa>0
\]



\noindent
Next,   the construction of $G(p,q)$ gives
\[
 F(p,-\kappa)=
 \lim_{q\to p}\,
 [K(\sqrt{\kappa}\cdot |p-q|)+\log\,|p-q|]+
 \lim_{q\to p}\,[u_p(q)+ H(p,q,\kappa)]\tag{G.1}
\]
The last term above has the  "nice limit" 
$u_p(p)+H(p,p,\kappa)$ and from  (F.1)  the reader can  verify the limit formula:
\[
 \lim_{q\to p}\,
 [K(\sqrt{\kappa}\cdot |p-q|)+\log\,|p-q|]=
 -\frac{1}{2}\cdot \log \kappa +\log 2-\gamma\tag{G.2}
\]
where $\gamma$ is  Euler's constant.

\bigskip

\noindent
{\bf{H. Final part of the proof.}}.
Set $A=  +\log 2-\gamma+u_p(p)$. Then (G.1) and (G.2)
give
\[
F(p,-\kappa)= -\frac{1}{2}\cdot \log \kappa +A+H(p,p;-\kappa)
\]
With $x=\kappa$ in (E.2 ) we  proceed  as follows.
To  begin with it is clear that
\[
s\mapsto A\cdot 
\frac{\sin \pi s}{2\pi^2}\cdot \int_a^\infty\,  x^{-s}\,dx
\]
is an entire function of $s$.
Next,  consider the function
\[ 
\rho(s)=
 -\frac{1}{2}\cdot 
\frac{\sin \pi s}{2\pi^2}\cdot \int_a^\infty\,  \log x\cdot x^{-s}\,dx
\]
Notice that the complex derivative
\[
\frac{d}{ds}\,  \int_a^\infty\,  x^{-s}\,dx=
- \int_a^\infty\,  \log x\cdot x^{-s}\,dx
\]

\medskip
\noindent
{\bf{H.1 Exercise.}}
Use the  above to show that
\[
\rho(s)-\frac{1}{4\pi(s-1)}
 \]
is an entire function.
\medskip


\noindent
From the above we see that Theorem 0.1  follows if we have proved
\medskip

\noindent
 {\bf{H.2 Lemma.}}
\emph{The following function  is entire}:
\[
s\mapsto \frac{\sin\,\pi s}{2\pi^2}\cdot
\int_a^\infty\, H(p,p,\kappa)\cdot  \kappa^{-s}\,d\kappa
\]
\medskip

\noindent
\emph{Proof.}
When $\kappa>0$
the equation (F.1) shows that $q\mapsto H(p,q;\kappa)$
is subharmonic  in $\Omega$ and the maximum principle gives
\[
0\leq  H(p,q;\kappa)\leq \max_{q\in\partial\Omega}\,K(\kappa|p-q|)\tag{i}
\]
With  $p\in\Omega$ fixed there is 
a positive number
$\delta$ such that
$|p-q|\geq\delta\,\colon q\in \partial\Omega$ which  
gives
positive constants
$B$ and  $\alpha$  such that
\[
H(p,p;\kappa)\leq e^{-\alpha\kappa}\quad\colon \kappa>0\tag{ii}
\]
The reader may now check that this
exponential decay gives Lemma H.2.

\newpage



\centerline{\bf {Appendix. Theorems by Abel, Tauber, Hardy and Littlewood}}
\bigskip


\noindent
{\bf Introduction.}
Consider a power series
$f(z)=\sum\, a_nz^n$ whose radius of convergence is one.
If $r<1$ and $0\leq\theta\leq 2\pi$
we are sure that the series
\[ 
f(re^{i\theta})= 
\sum\, a_nr^ne^{in\theta}
\]
is convergent. In fact, it is even absolutely convergent since
the assumption implies that
\[\sum\, |a_n|\cdot r^n<\infty\quad\text{for all}\quad r<1
\]
Passing to $r=1$ it is in general not true that the series
$\sum\, a_ne^{in\theta}$ is convergent. An example arises if we consider
the geometric series
\[ 
\frac{1}{1-z}= 1+z+z^2+\ldots
\] 
This leads to the following  problem where we without loss of
generality can take 
$\theta=0$.
Consider as above a
convergent power series and assume that there exists the limit
\[
\lim_{r\to 1}\, \sum\, a_nr^n\tag{*}
\]
When can we conclude that the series
$\sum\, a_n$ also is convergent and that
one has the equality
\[
 \sum\, a_n=
\lim_{r\to 1}\, \sum\, a_n r^n\tag{**}
\]
The first result in this direction was established by Abel in a work from 1823:
\medskip

\noindent
{\bf{A. Theorem}} \emph{Let $\{a_n\}$ be a sequence such that
$\frac{a_n}{n}\to 0$
as $n\to \infty$
and there exists}
\[
A=\lim_{r\to 1}\, \sum\, a_nr^n
\] 
\emph{Then  
$\sum\, a_n$ is convergent and the  sum is $A$.}

\medskip

\noindent
An extension of Abel's result was
established by  Tauber in 
1897. 
\medskip

\noindent
{\bf B. Theorem.}
\emph{Let $\{a_n\}$ be a sequence of real numbers such that
there exists the limit}
\[
A=\lim_{r\to 1}\, \sum\, a_nr^n
\]
Set
\[ 
\omega_n=a_1+2a_2+\ldots+na_n\quad\colon\, n\geq 1
\]
\emph{If $\lim_{n\to\infty}\,\omega_n=0$ it follows that
the series $\sum\, a_n$ is convergent and the sum is $A$.}


\bigskip

\noindent
{\bf C. Results by 
Hardy and Littlewood.}
In their joint article \emph{xxx} from 1913
the following extension of Abel's  result was proved by Hardy and Littlewood:

\medskip

\noindent
{\bf {C. Theorem.}}
\emph{Let $\{a_n\}$ be a sequence of real numbers such that there 
exists a constant $C$ so that
$\frac{a_n}{n}\leq C$ for all $n\geq 1$. Assume also that the
power series $\sum\, a_nz^n$ converges when
$|z|<1$. Then the same conclusion as in Abel's theorem holds.}
\medskip

\noindent
{\bf {Remark.}}
In addition to this they proved
a result about
positive series from the cited article which has independent interest.

\medskip

\noindent
{\bf {D. Theorem.}}
\emph{Assume that
each $a_n\geq 0$ and that there exists the limit:}
\[ 
A=
\lim_{r\to 1}\, (1-r)\cdot \sum\,a_nr^n\tag{*}
\]
\emph{Then  there exists the limit}
\[
A=\lim_{N\to \infty}\, \frac{a_1+\ldots+a_N}{N}\tag{**}
\]
\medskip

\medskip

\noindent
{\bf{Remark.}} The proofs of Abel's and Tauber's results are  easy
while C and D require more effort and rely upon 
results from calculus in one variable.
So before we enter the proofs of the  theorems above insert
some  preliminaries.
\newpage

\centerline{\bf{1. Results from calculus}}

\medskip

\noindent
Below $g(x)$ is a real-valued function defined on $(0,1)$ and
of class $C^2$ at least.
\medskip


\noindent
{\bf 1.1 Lemma } \emph{Assume that there exists a constant $C>0$ such that}
\[
g''(x)\leq C(1-x)^{-2}\quad\colon\, 0<x<1\quad\text{and}\quad
\lim_{x\to 1}\, g(x)=0
\] 
\emph{Then one  has the limit formula}:
\[
\lim_{x\to 1}\, (1-x)\cdot g'(x)=0
\]

\medskip

\noindent
{\bf 1.2 Lemma } \emph{Assume that the second order derivative
$g''(x)>0$.
Then the following implication holds for each $\alpha>0$:}

\[
\lim_{x\to 1}\, (1-x)^\alpha\cdot g(x)=1\implies
\lim_{x\to 1}\, (1-x)^{\alpha+1}\cdot g'(x)=\alpha
\]




\noindent
{\bf{Remark.}}
If $g(x)$ has higher order derivatives
which all are
$>0$ on $(0,1)$
we can iterate the conclusion in Lemma 1.2 where 
we take $\alpha$ to be positive integers.
More precisely, by an induction over
$\nu$ the reader may verify that if
\[
\lim_{x\to 1}\, (1-x)\cdot g(x)=1
\]
exists and  if 
$\{g^{(\nu)}(x)>0\}$ for all 
every $\nu\geq 2$ then 
\[
\lim_{x\to 1}\, (1-x)^{\nu+1}\cdot g^{(\nu)}(x)=\nu\,!
\quad\colon\, \nu\geq 2\tag{*}
\]



\bigskip

\noindent
Next, to each integer $\nu\geq 1$ we denote by $[\nu-\nu^{2/3}]$
the largest integer $\leq\,(\nu-\nu^{2/3}).$ Set
\[
J_*(\nu)=\sum_{n\leq [\nu-\nu^{2/3}]}\,
n^\nu e^{-\nu}
\quad\colon\quad J^*(\nu)=\sum_{n\geq [\nu+\nu^{2/3}]}\,
n^\nu e^{-\nu}
\]

\medskip

\noindent
{\bf 1.3 Lemma }
\emph{There exists a constant $C$
such that}
\[
\frac{J^*(\nu)+J_*(\nu)}{\nu\,!}\leq \delta(\nu)\quad\colon\quad
\delta(\nu)=C\cdot \text{exp}\, \bigl(-\frac{1}{2}\cdot \nu^{\frac{1}{{3}}}\bigr )
\quad\colon\,\nu=1,2,\ldots
\]

\medskip

\centerline{\emph{Proofs}}

\bigskip

\noindent
We prove only  Lemma 1.1 which is a bit tricky 
while the proofs of Lemma 1.2 and 1.3 are
left as  exercises to the reader.
Fix $0<\theta<1$. Let
$0<x<1$ and set
\[
x_1=x+(1-x)\theta
\]
The mean-value theorem in calculus gives
\[ 
g(x_1)-g(x)=\theta(1-x)g'(x)+\frac{\theta^2}{2}(1-x)^2\cdot g''(\xi)\quad
\text{for some}\quad \, x<\xi<x_1\tag{i}
\]
By the hypothesis
\[
g''(\xi)\leq C(1-\xi)^{-2}\leq C)1-x_1)^{-2}
\]
Hence (i) gives
\[
(1-x)g'(x)\geq
\frac{1}{\theta}(g(x_1)-g(x))-
C\cdot \frac{\theta}{2}\frac{(1-x)^2}{1-x_1)^2}=
\]
\[
\frac{1}{\theta}(g(x_1)-g(x))-
\frac{C\cdot \theta}{2(1-\theta)^2}
\]
Keeping $\theta$ fixed we have by assumption
\[
\lim_{x\to 1}\, g(x)=0
\]
Notice also that $x\to 1\implies x_1\to 1$. It follows that



\[
\liminf_{x\to 1}\,\,
(1-x)g'(x)\geq -\frac{C\cdot \theta}{2(1-\theta)^2}
\]
Above  $0<\theta<1$ is arbitrary, i.e. we can choose 
small $\theta>0$ and hence we have proved that
\[
\liminf_{x\to 1}\,
(1-x)g'(x)\geq 0\tag{*}
\]
\medskip

\noindent
Next we  prove the opposed inequality

\[
\limsup_{x\to 1}\,
(1-x)g'(x)\leq 0\tag{**}
\]
To get (**) we apply the mean value theorem in the form
\[
g(x_1)-g(x)=\theta(1-x)g'(x_1)-\frac{\theta^2}{2}(1-x)^2\cdot g''(\eta)\quad
\colon\, x<\eta<x_1\tag{ii}
\]
Since $(1-x_1)=\theta(1-x)(1-\theta)$ we get
\[ 
(1-x_1)g'(x_1)=\frac{1-\theta}{\theta}\cdot (g(x_1)-g(x))+
\frac{(1-\theta)\theta}{2}\cdot(1-x)^2g''(\eta)\tag{iii}
\]
Now $g''(\eta)\leq C(1-\eta)^{-2}\leq C(1-x_1)^{-2}$ so
the right hand side in (iii) is majorized by
\[
\frac{1-\theta}{\theta}\cdot (g(x_1)-g(x))+
C\cdot \frac{(1-\theta)\theta}{2}\cdot(1-x)^2(1-x_1)^2=
\]
 \[
\frac{1-\theta}{\theta}\cdot (g(x_1)-g(x))+
C\cdot \frac{\theta}{2(1-\theta}\tag{iv}
\]
Keeping $\theta$ fixed while $x\to 1$ we obtain:
\[
\liminf_{x\to 1}\, (1-x)g'(x)\leq 
C\cdot \frac{\theta}{2(1-\theta}
\]
Again we can choose arbitrary small $\theta$ and hence (**) 
holds which finishes the proof of 
Lemma 1.1.













\bigskip


\centerline{\bf{2. Proof of Abel's theorem.}}

\medskip

\noindent
Without loss of generality we can assume that
$a_0=0$ and set  $S_N=a_1+\ldots+a_N$.
Given $0<r<1$ we let $f(r)=\sum\, a_nr^n$. For every positive integer $N$
the triangle inequality gives:
\[
\bigl| S_N-f(r)\bigr|\leq
\sum_{n=1}^{n=N}\, |a_n|(1-r^n)+
\sum_{n\geq N+1}\, |a_n|r^n
\]
Set $\delta(N)=\max_{n\geq N}\,\frac{|a_n|}{n}$.
Since  $1-r^n)=(1-r)(1+\ldots+r^{n-1}\leq (1-r)n$
the last sum is majorised by
\[
(1-r)\cdot \sum_{n=1}^{n=N}\, n\cdot |a_n|
+
\delta(N+1)\cdot
 \sum_{n\geq N+1}\, \frac{r^n}{n}
\]
Next, the obvious inequality 
$\sum_{n\geq N+1}\, \frac{r^n}{n}\leq\frac{1}{N+1}\cdot \frac{1}{1-r}$
gives the new majorisation
\[
(1-r)\cdot \sum_{n=1}^{n=N}\, \frac{|a_n|}{n}
+\frac{\delta(N+1)}{N+1}\cdot  \frac{1}{1-r}\tag{1}
\]
This hold for all pairs $N$ and $r$.
To each $N\geq 2$ we take $r=1-\frac{1}{N}$
and hence the right hand side in (1)
is majorised by

\[
\frac{1}{N}\cdot \sum_{n=1}^{n=N}\, \frac{|a_n|}{n}
+\delta(N+1)\cdot \frac{N}{N+1}
\]
Here both terms tend to zero as $N\to\infty$. Indeed, Abel's condition 
$\frac{a_n}{n}\to 0$   implies that
$\frac{1}{N}\cdot \sum_{n=1}^{n=N}\, \frac{|a_n|}{n}$ 
tends to zero as $N\to \infty$. Hence
we have proved the limit formula:
\[ 
\lim_{N\to\infty}\,\bigl |s_N-f(1-\frac{1}{N})\bigr|=0\tag{*}
\]
Finally it is clear that (*)  gives Abel's result.

\bigskip

\centerline{\bf{3. Proof of Tauber's theorem.}}
\medskip

\noindent
We may assume that $a_0=0$. Notice that
\[
a_n=\frac{\omega_n-\omega_{n-1}}{n}\quad\colon\, n\geq 1
\]
It follows that
\[ 
f(r)=\sum\, \frac{\omega_n-\omega_{n-1}}{n}\cdot r^n
=\sum\,\omega_n\bigl(\frac{r^n}{n}-\frac{r^{n+1}}{n+1}\bigr )
\]
Using  the equality
$\frac{1}{n}=
\frac{1}{n+1}=
\frac{1}{n(n+1)}$ we can  rewrite the right hand side as follows:
\[
\sum\,\omega_n\bigl(\frac{r^n-r^{n+1}}{n+1}+\frac{r^n}{n(n+1)}\bigr )
\]
Set
\[ g_1(r)=\sum\,\omega_n\cdot\frac{r^n-r^{n+1}}{n+1}
=(1-r)\cdot \sum\, \frac{\omega_n}{n+1}\cdot r^n
\]
By the hypothesis 
$\lim_{n\to\infty}\,  \frac{\omega_n}{n+1}=0$ and then it is
clear that we get
\[
\lim_{r\to 1}\, g_1(r)=0
\]
Since we also have $f(r)\to 0$ as $r\to 1$ we conclude that
\[
\lim_{r\to 1} \sum\, \frac{\omega_n}{n(n+1)}\cdot r^n=0\tag{1}
\]
Next, with
$b_n= \frac{\omega_n}{n(n+1)}$ we have
$nb_n= \frac{\omega_n}{n+1}\to 0$.
Hence Abel's theorem applies so (1) gives  convergent series
\[
\sum\, \frac{\omega_n}{n(n+1)}=0\tag{2}
\]
If $N\geq 1$ we have the partial sum
\[
S_N=\sum_{n=1}^{n=N} 
\, \frac{\omega_n}{n(n+1)}=
\sum_{n=1}^{n=N}, \omega_n\cdot\bigl(\frac{1}{n}-\frac{1}{n+1}\bigr)
\]
The last term becomes
\[
\sum_{n=1}^{n=N}\,\frac{1}{n}(\omega_n-\omega_{n-1})-
\frac{\omega_N}{N+1}=
\sum_{n=1}^{n=N}\,a_n-\frac{\omega_N}{N+1}
\]
Again, since
$\frac{\omega_N}{N+1}\to 0$ as $N\to\infty$ we conclude that the convergent series
from (2) implies that the series
$\sum\, a_n$ also is converges and has sum equal to zero.
This finishes the proof of Tauber's result.
\bigskip

\centerline{\bf{4. Proof of Theorem D. }}
\medskip

\noindent
Set $f(x)=\sum\, a_nx^n$ which is defined when $0<x<1$.
Notice that 
\[
(1-x)f(x)=\sum\, s_nx^n\quad\text{where}\quad s_n=a_1+\ldots+a_n
\]
Set $g(x)= \sum\, s_nx^n$ which is defined when
$0<x<1$.
Since $s_n\geq 0$ for all $n$  all the higher order derivatives
\[
g^{(p)}(x)= \sum_{n=p}^\infty\, n(n-1)\cdots (n-p+1)a_nx^{n-p}>0
\]
when $0<x<1$.
The hypothesis that
$\lim_{x\to 1}\, g(x)=A$ and Lemma 1.1 and the inductive result in the
remark after Lemma 1.2 give:
\[
\lim_{x\to 1}\, (1-x)^{\nu+2}\cdot
\sum\, s_n\cdot n^\nu x^n=(\nu+1)!\quad\colon\,\nu\geq 1\tag{1}
\]
We shall use the substitution $e^{-t}=x$ where $t>0$.
Since $t\simeq 1-x$ when
$x\to 1$ we see that
(1) gives
\[
\lim_{t\to 0}\, t^{\nu+2}\cdot 
\sum\, s_n\cdot n^\nu e^{-nt}=(\nu+1)!\quad\colon\,\nu\geq 1\tag{2}
\]
Let us put
\[ J_*(\nu,t)=\frac{t^{\nu+2}}{(\nu+1)!}\cdot 
\sum_{n=1}^\infty\, s_n\cdot n^\nu e^{-nt}
\]
So for each fixed $\nu$ one has 
\[
\lim_{t\to 0}\, J_*(\nu,t)=1\tag{3}
\]

\medskip

\noindent
Next, for each pair $\nu\geq 2$ and $0<t<1$ we define the integer
\[ 
N=\bigl[\frac{\nu-\nu^{2/3}}{t}\bigr]\tag{*}
\]
Since the sequence $\{s_n\}$ is non-decreasing we get
\[
s_N\cdot\sum_{n\geq N}\, n^\nu e^{-nt}\leq
\sum_{n\geq N}\, s_n\cdot n^\nu e^{-nt}\leq\frac{(\nu+1)!\cdot J_*(\nu,t)}{t^{\nu+2}}
\tag{i}
\]
Next,  the construction of $N$ and Lemma 1.3 give:

\[
\sum_{n\geq N}\, n^\nu e^{-nt}\geq \frac{\nu !}{t^{\nu+1}}\cdot (1-\delta(\nu))\tag{ii}
\]
where the $\delta$ function is independent of $\nu$ and
tends to zero as $\nu\to\infty$. Hence (i-ii) give
\[
s_N\leq \frac{(\nu+1)}{t}\cdot \frac{1}{1-\delta(\nu)}\cdot
J_*(\nu,t)\tag{iii}
\]
Next, by the construction of $N$ one has
\[ 
N+1\geq \frac{\nu-\nu^{2/3}}{t}=\frac{\nu}{t}\cdot(1-\nu^{-1/3})
\]
It follows that (iii) gives
\[
\frac{s_N}{N+1}\leq 
\frac{\nu+1}{\nu}
\cdot\frac{1}{1-\nu^{-1/3}}\cdot\frac{1}{1-\delta(\nu)}\cdot 
J_*(\nu,t)\tag{iv}
\]
Since $\delta(\nu)\to 0$
it follows that for any $\epsilon>0$ there exists some
$\nu_*$ such that
\[
\frac{\nu_*+1}{\nu_*}
\cdot\frac{1}{1-\nu_*^{-1/3}}\cdot\frac{1}{1-\delta(\nu_*)}<1+\epsilon \tag{v}
\]
\medskip

\noindent
Keeping $\nu_*$ fixed we now consider pairs $t_n,N$ such that
(*) above hold with $\nu=\nu_*$.
Notice that
\[
 N\to+\infty\implies t_N\to 0\tag{vi}
\]

\medskip
\noindent
It follows from (iv) and (v) that we have:
\[
\frac{s_N}{N+1}<(1+\epsilon)\cdot J_*(\nu_*,t_N)\quad\colon\, N\geq 2\tag{vii}
\]
Now (vi) and the limit in (3) which applies with
$\nu_*$ while $t_N\to 0$
entail that
\[
\lim_{N\to \infty}\, J(\nu_*,t_N)=1
\]
We have also that
$\frac{N}{N+1}\to 1$ and since $\epsilon>0$ was arbitrary
we see that (vii) proves  the inequality
\[ 
\limsup_{N\to\infty}\, 
\frac{s_N}{N}\leq 1\tag{1}
\]
So Theorem 2 follows if we also prove that
\[
\liminf_{N\to\infty}\, 
\frac{s_N}{N}\geq 1\tag{2}
\]
The proof of (II) is similar where we now define the integers $N$ by:
\[ 
N=\bigl[\frac{\nu+\nu^{2/3}}{t}\bigr]
\]
Then we have
\[ 
S_N\cdot\sum_{n\leq N}\, n^\nu e^{-nt}\geq
\frac{(\nu+1)!\cdot J_*(\nu,t)}{t^{\nu+2}}-
\sum_{n> N}\,s_n\cdot n^\nu e^{-nt}
\]
Here the last term can be estimated above since the Lim.sup
inequality (I) gives a constant $C$ such that
$s_n\leq Cn$ for all $n$ and then
\[
\sum_{n> N}\,s_n\cdot n^\nu e^{-nt}
\leq C\cdot \sum_{n> N}\,n^{\nu+1} e^{-nt}
\leq C\cdot \delta^*(\nu)\cdot 
\frac{(\nu+1)!}{t^{\nu+2}}
\]
where Lemma 1.3  entails that
$\delta^*(\nu)\to 0$ as $\nu$ increases. At the same time Lemma 1.3 also gives
\[
\sum_{n\leq N}\, n^\nu \cdot e^{-nt}=
\frac{\nu !}{t^{\nu+1}}\cdot (1-\delta_*(\nu)
\] 
where $\delta(\nu_*)\to 0$. At this stage the reader can verify that (2) 
by  similar methods as in the proof of (I).


\bigskip
\centerline{\bf{5. Proof of Theorem C}}
\medskip

\noindent
Set $f(x)=\sum\, a_nx^n$. Notice that it suffices to prove
Theorem C when
the limit value
\[
\lim_{x\to 1}\, \sum\,a_nx^n=0
\]
Next,
the assumption that $a_n\leq\frac{c}{n}$ for a constant $c$ gives
\[
f''(x)=\sum\, n(n-1)a_nx^{n-2}\leq c\sum\, (n-1)x^{n-2}=\frac{c}{1-x)^2}
\]
The hypothesis $\lim_{x\to 1}\, f(x)=0$ and Lemma xx therefore gives
\[
\lim_{x\to 1}\, (1-x)f'(x)=0\tag{i}
\]
Next, notice the equality
\[
\sum_{n=1}^\infty\, \frac{na_n}{c} x^n=
\frac{x}{c}\cdot f'(x)\tag{ii}
\]
At the same time
$\sum_{n=1}^\infty\,x^n=\frac{x}{1-x}$
and hence (i-ii)  together give:

\[
\lim_{x\to 1}\, (1-x)\cdot\sum\, (1-\frac{na_n}{c} )\cdot x^n=1
\]
Here $1-\frac{na-n}{c}\geq 0$ so Theorem 2 gives
\[
\lim_{N\to \infty}\,
\frac{1}{N} \sum_{n=1}^{n=N}\, (1-\frac{na_n}{c})=1
\]
It follows that
\[
\lim_{N\to \infty}\,\frac{1}{N} \cdot \sum_{n=1}^{n=N}\, na_n=0
\]
This means precisely that the condition in Tauber's Theorem holds and hence 
$\sum\, a_n$ converges and has series sum
equal to 0 which finishes the proof of Theorem C.











\newpage









BRA


\bigskip


\centerline{\bf{A Non-Linear PDE-equation}}

\bigskip

\noindent
{\bf{Introduction.}}
In the  article
\emph{Über eine nichtlineare Randwertaufgabe bei der Gleichung $\Delta u=0$}
(Mathematisches Zeitschrift vol. 9 (1921),
Carleman considered
the following 
equation: Let
$\Omega$ be a bounded domain in ${\bf{R}}^3$
with $C^1$-boundary and
${\bf{R}}^+$ the non-negative real line where  $t$ is the coordinate.
Let $F(t,p)$
be a real-valued and continuous function
defined on  ${\bf{R}}^+\times\partial\Omega$.
Assume that 
\[
t\mapsto F(t,p)\tag{0.1}
\]
is strictly increasing  for every $p\in\partial\Omega$
and that $F(0,p)\geq 0$. Moreover,  
\[
\lim_{u\to\infty} F(t,p)=+\infty\tag{0.2}
\] 
holds uniformly with respect to $p$.
For a given point $q_*\in\Omega$ we seek a function $u(x)$
which is harmonic in $\Omega\setminus\{q_*\}$
and at $q_*$ it is locally $\frac{1}{|x-q_*|}$ plus a harmonic function.
Moreover, it is requested that
$u$
extends to a continuous function on
$\partial\Omega$ and that $u\geq 0$ in $\overline{\Omega}$.
Finally, along  the boundary
the  inner normal derivative $\partial u/\partial n$ satisfies the 
equation
\[
\frac{\partial u}{\partial n}(p)= F(u(p),p)\quad \colon p\in\partial\Omega\tag{*}
\]

\medskip

\noindent 
{\bf{Remark.}}
The case when $F(t,p)= kt^4$ for some positive constant $k$
means that we regard the Stefan-Boltzmann equation whose
physical 
interpretation 
ensures that
(*) has a unique non-negative solution $u$.


\medskip

\noindent {\bf {Theorem.}}
\emph{For each $F$  satisfying (0.1-0.2)
 the boundary value problem has a unique solution $u$.}
\medskip

\noindent
The strategy in the  proof is to consider
a family of boundary value problems where 
one for each
$0\leq h\leq 1$ seeks $u\uuu h$ to satisfy
\[
\frac{\partial u\uuu h}{\partial n}(p)=(1\vvv h)u\uuu h+ h\cdot  F(u\uuu h(p),p)\quad \colon p\in\partial\Omega\tag{*}
\]
and $u\uuu h$ has the same pole as $u$ above.
Let us begin  with
\medskip

\noindent
{\bf{0.1 The case $h=0$}}.
Here we seek $u_0$ so that
\[
\frac{\partial u_0}{\partial n}(p)=u_0\tag{i}
\]
If $G(p)$ is  the Greens' function with a pole at
$q_*$ we seek a harmonic
function $h$ in
$\Omega$ such that
\[ 
u_0=G-h\tag{ii}
\] 
Since $G(p)=0$ on  $\partial\Omega$, the equation (i) holds if
\[
\frac{\partial h}{\partial n}(p)=h(p)+
\frac{\partial G}{\partial n}(p)\quad\colon\, p\in \partial\Omega\tag{iii}
\]
This is a classic linear boundary value problem which
has a unique solution $h$. See § xx for further details.
\medskip


\noindent
{\bf{0.2 Properties of $u_0$.}}
The construction in (ii) entails
that  $u_0$ is superharmonic in $\Omega$ and therefore attains its
minimum on the boundary.
Say that
\[ 
u_0(p_*)=\min_{p\in\overline{\Omega}}\, u_0(p)
\]
It follows that
$\frac{\partial u_0}{\partial n}(p_*)\geq 0$
and the equation
(i) gives
\[
u_0(p_*)\geq 0
\]
Hnece our  unique  solution $u_0$ is non-negative.
We can say more. For consider the harmonic function
$h$ in (ii) which takes a maxium  at some $p^*\in\partial\Omega$.
Then
$\frac{\partial h}{\partial n}(p^*)\leq 0$ so that (iii) gives
\[
h(p^*)+\frac{\partial G}{\partial n}(p^*)\leq 0
\]
Hence
\[ 
\max_{p\in\partial\Omega}\, h(p)\leq
-\frac{\partial G}{\partial n}(p^*)
\]
which entails that
\[
\min_{p\in\partial \Omega}\, u(p)=
-\max_{p\in\partial\Omega}\, h(p)\geq
\frac{\partial G}{\partial n}(p^*)\tag{0.2.1}
\]
Here the function
\[
p\mapsto \frac{\partial G}{\partial n}(p)
\] 
is continuous and positive on
$\partial\Omega$ and if $\gamma_*$ is the minimum value we conclude that
\[
\min_{p\in\partial \Omega}\, u(p)\geq \gamma_*\tag{0.2.2}
\]
Next, let $h$ attain its minimum at some $p_*\in\partial\Omega$
which entails that
$\frac{\partial h}{\partial n}(p_*)\geq 0$ and then (iii) gives
\[
h(p_*)+\frac{\partial G}{\partial n}(p^*)\geq 0
\]
It follows that
\[
\max_{p\in\partial \Omega}\, u_0(p)=
\min_{p\in\partial \Omega}\, h(p)=-h(p_*)\leq 
\frac{\partial G}{\partial n}(p^*)\leq\gamma^*\tag{0.2.3}
\]
where
\[
\gamma^*=\max_{p\in\partial \Omega}\,
\frac{\partial G}{\partial n}(p)\tag{0.2.4}
\]
So the unique solution $u_0$ in (i) satisfies
\[
\gamma_*\leq u(p)\leq \gamma^*
\quad\colon p\in\partial\Omega\tag{0.2.5}
\]
where the  positive constants $\gamma_*$ and $\gamma^*$ depend on
the  point $q_*\in\Omega$ and the given domain $\Omega$.


\bigskip


\noindent
{\bf{The homotopy method.}}
To proceed from $h=0$ to $h=1$
the idea is to use a "homotopy argument"
which can be   handled via 
precise estimates of solutions to Neumann's linear
boundary value problem
which are presented in § B.
Thanks to this and some uniquness properties in § A below, 
the reduction to the case when
$F$ is real-analytic
is relatively easy. The ciucial steps during the  proof appear
in § C where we
carry out a  "homotoy method" to
get solutions in (*) as $h$ increases from zero to one.



\bigskip


\centerline {\bf{A.0. Proof of uniqueness.}}
\medskip

\noindent
Suppose that $u_1$ and $u_2$ are two solutions to the equation in the main theorem.
Notice that  $u_2-u_1$.
is harmonic in
$\Omega$.
If $u\uuu 1\neq u\uuu 2$ we may
without loss of generality we may assume that
the maximum of $u\uuu 2\vvv u\uuu 1$ is $>0$.
The maximum is attained at some $p\uuu *\in\partial\Omega$
and  the strict maximum principle for harmonic functions gives:
\[
u\uuu 2(x)\vvv u\uuu 1(x)<
u\uuu 2(p\uuu *)\vvv u\uuu 1(p\uuu *)\tag{i}
\] 
for all $x\in\Omega$.With $v=u\uuu 2\vvv u\uuu 1$
we have
\[
\frac{\partial v}{\partial n}(p)=F(u_2(p),p)-F(u_1(p),p)
\]
Here (0.1) entails that
$\frac{\partial v}{\partial n}(p\uuu *)>0$
and since we have an inner normal derivative this violates
(i) which proves the uniqueness.


\medskip



\centerline {\bf{A.1 Montonic properties.}}
\medskip


\noindent
Let $F_1$ and $F_2$ be two functions which both satisfy
(0.1) and (0.2) where  
\[ 
F_1(u,p)\leq F_2(u,p)
\]
hold for all $(u,p)\in{\bf{R}}^+\times\partial\Omega$.
If $u_1$, respectively $u_2$ solve (*) for $F_1$ and $F_2$
it follows that
$u_2(q)\leq u_1(q)$ for all $q\in\Omega$.
To see this we set $v=u_2-u_1$ which is harmonic in
$\Omega$.
If $p\in\partial\Omega$ we get
\[
\frac{\partial v}{\partial n}(p)=F_2(u_2(p),p)-F_1(u_1(p),p)\geq 0\tag{i}
\]
Suppose that the maximum of $v$ is $>0$ and let the maximum be attained at some 
point $p_*$. Since (i) is an inner normal it follows that we must have
$0=\frac{\partial v}{\partial n}(p)$ which would entail that

\[ 
F_2(u_2(p_*)p_*)>F_2(u_1(p_*),p_*)\geq F_1(u_1(p_*),p_*)\implies
\]
and this contradicts the strict inequality
$u\uuu 2(p\uuu *)>
u\uuu 1(p\uuu *)$
since we have an increasing function in (0.1).





\medskip


\noindent
{\bf{A.2. A bound for the maximum norm.}}
Let $G$ be the Green's function which has a pole
at $q_*$ while $G=0$ on $\partial\Omega$. Then
\[ 
p\mapsto
\frac{\partial G}{\partial n}(p)
\]
is a continuous and positive function on
$\partial\Omega$.
Set
\[
m_*=\min_{p\in\partial\Omega}\, \frac{\partial G}{\partial n}(p)
\quad\colon
m^*=\max_{p\in\partial\Omega}\, \frac{\partial G}{\partial n}(p)
\]
Next, let $0\leq h\leq 1$ and suppose that
$u_h$ is  a solution to (*). Put

\[
m(h)= \min_{p\in\partial\Omega} u_h(p)
\quad\colon
M(h)= \max_{p\in\partial\Omega} u_h(p)\tag{*}
\]
To estimate these numbers
we proceed as follows.
Choose
$p^*\in\partial\Omega$
such that
\[
 u_h(p^*)=M(h)\tag{1}
\]
Now the function 
\[
H=u-G-M(h)
\] 
is  harmonic function in
$\Omega$ and non-negative on the boundary.
Hence $H$ is positive in $\Omega$ and since $H(p^*)=0$
we have
\[ 
\frac{\partial H}{\partial n}(p^*)\leq 0\implies
\] 
which via the equation (*) give
\[
(1-h)M(h)+h\cdot F(M(h),p^*)\leq
\frac{\partial G}{\partial n}(p^*)\leq \gamma^*\tag{2}
\]
Next, the hypothesis on $F$ entails that
\[
t\mapsto (1-h)t+h\cdot F(t,p^*)\tag{3}
\]
is a strictly increasing function for each
fixed $0\leq h\leq 1$
and the hypothesis (0.2) together with the
inequality (2) above, give
a positive constant
$A^*$ which is independent of $h$ such that
\[
M(h)\leq A^*\quad\colon 0\leq h\leq 1\tag{3}
\]

\medskip


\noindent
Next, let $m(h)$ be the minimum of $u_h$ on $\partial\Omega$ and
this time we consider the harmonic function
\[
H=u-m(h)-G
\]
Here $H\geq 0$ on $\partial\Omega$
and if $u_h(p_*)=m(h)$ we have $H(p_*)=0$
$p_*$ is a minimum for $H$.
It follows that
\[ 
\frac{\partial H}{\partial n}(p_*)\geq 0\implies
F(u(p_*),p)=\frac{\partial u}{\partial n}(p_*)\geq 
\frac{\partial G}{\partial n}(p_*)
\]
So with
\[
\gamma_*=\min_{p\in\partial\Omega}\,\, \frac{\partial G}{\partial n}(p)
\]
one has the inequality
\[
F(m(h),p^*)\geq \gamma_*\tag{4}
\]
Above $\gamma^*$ is the constant from (xx) and the properties of $F$
give a positive constant $A_*$ such that
\[
m(h)\geq A_*
\]





\noindent
{\bf{Conclusion.}} Above $0<A_*<A^*$ are  constants which are independent of $h$.
Hence the maxima and the minima of
$u_h$ stay in a fixed interval $[A_*,A^*]$ as soon as 
$u_h$ exists.



\bigskip


\noindent
\centerline {\bf{B. The  linear equation.}}

\medskip


\noindent
Let $f(p)$ and $W(p)$
be a pair of continuous functions on the boundary
$\partial \Omega$ where  $W$ is positive, i.e. $W(p)>0$ for every
boundary point.
Set
\[
w_*=\min_p \, W(p)
\]
So by the assumption on  $W$ we have
$w_*>0$. 
The classical Neumann
theorem
asserts  that there exists a unique function $U$ which is harmonic in
$\Omega$, extends to a continuous function on
the closed domain and its inner normal  derivative satisfies:
\[ 
\partial U/\partial n(p)=
W(p)\cdot U(p)+f(p)\quad p\in\partial\Omega\tag{1}
\] 
For the unique   solution in (1)  some  estimates hold.
Namely, set 
\[
M^*=\max_p\, U(p)\quad\text{and}\quad
m_*=\min_p\, U(p)
\] 

\medskip

\noindent
Since $U$ is harmonic in $\Omega$ 
the  maximum and the minimum are both taken on the boundary.
If $U(p^*)= M^*$ for some $p^*\in\partial \Omega$
we have $\partial U/\partial n(p^*)\leq 0$ which together with
(1) entails that
\[
M^*\cdot W(p^*)+f(p^*)\leq 0\implies
M^*\leq  \frac{|f|_{\partial\Omega}}{w_*}
\]
where
$|f|_{\partial\Omega}$ is the maximum norm of $f$ on the boundary.
In the same way one verifies that
\[
m_U\geq -\frac{|f|_{\partial\Omega}}{w_*}
\]
Hence  the following inequality holds for the
 the maximum norm  $|U|_{\partial\Omega}$ :
\[
|U|_{\partial\Omega}\leq
\frac{|f|_{\partial\Omega}}{w_*}\tag{B.0}
\]
Notoice that
(B.0) and the equation (1)
entails that
Suppose that $W\in C^0(\partial\Omega)$ satisfies
\[ 
w_*\leq W(p)\leq w^*
\]
for a pair of positive constants.
If $|f|_{\partial\Omega}$ is the maximum norm of
$f$ it follows from (B.0) that
\[
\bigl|W(p)\cdot U(p)+f(p)\bigr|\leq (1+\frac{w^*}{w_*})\cdot
|f|_{\partial\Omega}
\]
Hence the equation (1) gives
\[ 
\max_{p\in\partial\Omega}\,|\frac{\partial U}{\partial n}(p)|
\leq (1+\frac{w^*}{w_*})\cdot |f|_{\partial\Omega}
\tag{B.1}
\]


\noindent
{\bf{B.2 An estimate for first order derivatives.}}
Let $p\in\partial \Omega$ and denote by $N$
the inner normal at $p$. Since $\partial\Omega$ is of class $C^1$
a sufficiently small line segment from $p$ along
$N$ stays in $\Omega$. So for small positive $\ell$ we have
points $q=p+\ell \cdot N$ in $\Omega$ and 
take the directional derivative of $U$ along $N_p$.
This gives  a function
\[
 \ell\mapsto \partial U/\partial N(p+\ell\cdot N)
\]
Since the boundary is $C^1$
these functions are defined on a fixed interval $0\leq\ell\leq \ell^*$ for all 
boundsry points $p$.
A classic result which appears in 
\emph{Der zweite 
Randwertaufgabe}  gives  a constant
$B$ such
that 
\[
\bigl|\partial U/\partial N(p+\ell\cdot N)\bigr|\leq B\cdot 
\max_{p\in\partial\Omega}\,|\frac{\partial U}{\partial n}(p)|
\]
hold for all
$p\in\partial\Omega$ and
$0\leq \ell\leq \ell^*$.

\bigskip


\centerline {\bf{C. Proof of Theorem when $t\mapsto F(t,p)$ is analytic.}} 

\medskip

\noindent
Assume that $t\mapsto F(t,p)$ is a real-analytic function on
the positive real axis for each $p\in\partial\Omega$
where local power series converge uniformly with respect to $p$.
In this situation we shall  prove
the
\emph{existence} of  a solution $u$ in the Theorem.
To attain this
we  proceed as follows.
To each real number $0\leq h\leq 1$ we seek a solution $u_h$ where
\[
 \frac{\partial u_h}{\partial n}(p)= h\cdot F(u_h,p)+(1-h)\cdot u_h(p)\tag{1}
\]
When  $h=0$ we found the solution $u_0$ in § xx.
Next, suppose that $0\leq h_0<1$ and that we have found the 
solution $u_{h_0}$ to (1).
By
the result in § B there exists
 a pair of positive constants $A_*<A^*$ such that
\[
 A_*\leq u_{h_0}(p)\leq A^*\tag{*}
 \]
 which are independent of $h_0$ and of $p$.
\medskip

\noindent
Set $u_0=u_{h_0}$
and
with $h=h_0+\alpha$ for some small $\alpha>0$
we shall find  $u_h$ by a series
\[
u_h= u_{h_0}+\sum_{\nu=1}^\infty\, \alpha^\nu\cdot u_\nu\tag{2}
 \]

 
\noindent
The pole at $q_*$  occurs already in $u_0$. So 
$u_1,u_2,\ldots$ is   a sequence of 
harmonic functions in  $\Omega$ and  there remains to find them
so that
$u_h$  solves (1). We will  show that this can
be achieved when $\alpha $ is sufficiently small.
Keeping $h_0$ fixed we set
\[
 u_0=u_{h_0}
\]
The analyticity of $F$ with respect to $t$ gives 
for every $p\in\partial\Omega$ a series expansion
\[
 F(u_0(p)+\alpha,p)=
F(u_0(p),p)+\sum_{k=1}^\infty\, c_k(p)\cdot \alpha^\nu
 \tag{3}
 \]


\noindent
where $\{c_k(p)\}$ are continuous functions on
 $\partial\Omega$.
Here (*) and  
the hypothesis on $F$ entail that
the radius of convergence has a uniform bound below, i.e.
there exists $\rho>0$ which is independent of $p\in\partial\Omega$
and a constant $K$ such that
\[
\sum_{k=1}^\infty\, |c_k(p)|\cdot \rho^k\leq K\tag{4}
\] 
Now
the equation (1) can be  solved 
via a system of equations where the  harmonic functions
$\{u_\nu\}$ are determined inductively
while $\alpha$-powers are identified.
The linear
$\alpha$-term gives  the equation
\[
\frac{\partial u_1}{\partial n}=F(u_0(p),p)-u_0(p)+
(1-h_0)u_1+h_0\cdot c_1(p)\cdot u_1(p)\tag{i}
\]
\medskip


\noindent
For $u_2$ we find that
\[
\frac{\partial u_2}{\partial n}=(1-h_0)u_2-u_1+h_0c_1(p)u_2+
c_1(p)u_1+c_2(p)u_1^2\tag{ii}
\]
\medskip

\noindent
In general we have
\[
\frac{\partial u_\nu}{\partial n}=(1-h_0+h_0\cdot c_1(p))\cdot u_\nu+
R_\nu(u_0,\ldots,u_{\nu-1},p)\quad\colon\, \nu\geq 1
\tag{iii}
\] 
where $\{R_\nu\}$ are polynomials in the preeceding $u$-functions
whose coefficients are
continuous functions obtained from
the
$c$-functions.
The function $c_1(p)$ is given by

\[ 
c_1(p)= \frac{\partial F}{\partial t}(u_0(p),p)
\]
which by  the hypothesis on $F$ is a
positive continuous function on $\partial\Omega$.
It follows that the function
\[ 
W(p)= (1-h_0)+h_0\cdot c_1(p)\tag{iv}
\] 
also is positive on $\partial\Omega$ and 
in the recursion above we have
\[
\frac{\partial u_\nu}{\partial n}=W(p)\cdot
u_\nu(p)+
R_\nu(u_0,\ldots,u_{\nu-1},p)\quad\colon\, \nu=1,2,\ldots
\tag{v}
\]

\medskip

\noindent
Above we encounter linear equations exactly as in (B.0) where the
the $f$-functions are  the $R$-polynomials.
Put

\[ 
w_*=\min_{p\in\partial\Omega}\, W(p)
\]
From § B.XX we get

\[
|u_\nu|_{\partial\Omega}\leq w_*^{-1}\cdot 
|R_\nu(u_0,\ldots,u_{\nu-1},p)|_{\partial\Omega}\tag{vi}
\]
\medskip

\noindent
Finally,   (vi) and a majorising  positive
series expressing maximum norms imply 
that if $\alpha$ is sufficiently small then the
series (2)  converges and gives the requested solution for
(1). Moreover,   $\alpha$ 
can be taken  \emph{independently} of $h_0$.
Together with the established
uniqueness of solutions $u_h$ whenever they exist, it follows
that we can move from $h=0$ until $h=1$ and arrive
at the requested solution 
in Theorem 1.

\medskip

\noindent
{\bf{Remark.}} 
The reader may consult page 106 in [Carleman]
where the existence of a uniform constant $\alpha>0$ for which the series
(2) converge for every $h$ is
demonstrated by an
explicit majorant series.





\newpage












\centerline{\bf{9. Neumann-Poincaré  boundary value problems}}

\bigskip

\noindent
{\bf{Introduction.}}
Several fundamental  results were
achieved by Carl  Neumann in the article
emph{xxx} from 1877 which in particular 
solved  boundary
valued problems where  double-layer potentials occur.
The results were carried out in dimension 3 which for
physical reasons is the most relevant part. Here we 
are content to expose 
Neumann's  theory in dimension two.
The crucial steategy is to use Neumann's
analytic series expansions which reduces 
the proof of existence to show
 that
certain poles are absent while
meromorphic extensions of  Neumann series are constructed.
We remark that Neumann's existence results were confined to convex
domains
where
certain majorizations become straighforward since this gives rise to
positive integral kernels. The
extension of Neumann's results to general domains was
achieved by Poincaré in the article \emph{xxx} from 1897
where some ingenoius new methods were introduced to overcome
the failure of positivity for the
non-symmetric kernel defining the double-layer potential.
\medskip

\noindent
The smoothness of boundaries
was  relaxed in later work.
Existence results for planar domains where
isolated corner points are allowed were 
established by Zarmela in 1904.
Further studies 
of Neumann's  problem for planar domains with non-regular boundary
appear 
in Carleman's thesis from 1916.
A novelty in this work is that solutions to the Neumann's
boundary value problem also are exhibited for functions which only 
are  integrable on the boundary.
This leads to new phenomena for the spectrum of
ïntegral operators, i.e the spectrum 
is not always  confined to discrete subsets of the
complex $\lambda$-plane.  It will take us too far to
go into  details, especially in the delicate analysis from Part 3 in
[ibid]. The interested reader can also consult  the expositary
article
\emph{xxxx} by Holmgen which describes how non-discrete spectral can occur 
for integral kernels associated to the Neumann problem
which in those days  was a  new phenomenon in operator theory.
Let us now expose the methods introduced by Neumann and Poincaré.

\bigskip

\noindent
{\bf{Preliminaries.}}
Let $\mathcal C$ be a closed Jordan curve of class $C^2$ whose 
arc-lengt measure is denoted by $\sigma$.
If  $g$ is a continuous function on
$\mathcal C$ the logarithmic  potential
\[
U_g(z)=
\frac{1}{\pi}\int_{\mathcal C}\, \log\,\frac{1}{|z-q|} \cdot g(q)\, d\sigma(q)
\]
yields a harmonic function
in open the complement of  $\mathcal C$. 
Since $\log\,|z|$ is locally integrable in
${\bf{C}}$ and  $U_g(z)$  the convolution of
this log-function and the compactly supported Riesz measure
$g\cdot \sigma$. By elementary measure theory
this implies
that $U_g$ extends to a continuous function.
In particular  the pair of harmonic functions in the 
inner respectively outer component of $\mathcal C$ are equal
on $\mathcal C$.
Moreover,  
the  Laplacian of $U_g$ taken in the distribution sense is equal to
the measure $g\cdot\sigma$.
Now we consider partial derivatives of $U$
and  study the inner normal derivative as $z$ approaches points
$p\in\mathcal C$ from the inside.
Let ${\bf{n}}_*$ denote the inner normal derivative
along $\mathcal C$ which gives
the function  on $\mathcal C$ defined by:
\[
p\mapsto \frac{\partial U_g}{\partial {\bf{n}}_*}(p)
\]
This function
is recaptured via an integral kernel
function $K(p,q)$ defined on
the product $\mathcal C\times\mathcal C$.
With  $p\neq q$
we consider the vector $p-q$ and  the unit vector
${\bf{n}}_*(q)$ and constructing  an inner product we
set
\[ 
K(p,q)=
\frac{\langle p-q,{\bf{n}}_*(q)}{|p-q|^2}\tag{*}
\]
\medskip


\noindent
Let  analyze the behaviour of $K$ close to a point on
the diagonal.
Working in local coordinates we can take $p=q=(0,0)$ and close 
the this boundary point 
the $C^2$-curve $\mathcal C$ is locally defined by a function
\[ 
y=f(x)
\] 
where $\phi(x)$ is a $C^1$-function and 
the $(x,y)$ belong to the bounded Jordan domain when
$y>f(x)$.
By drawing a figure the reader can verify that
\[
{\bf{n}}_*(x,f(x))\cdot d\sigma=(-f'(x), 1)\dot dx
\]
So with $p=(t,f(t))$ and $q=(x,f(x))$ we have

\[
K(p,q)\cdot d\sigma(q)=
\frac{f(t)-f(x)- f'(x)(t-x)}{(t-x)^2+(f(t)-f(x))^2}\cdot dx
\]
By hypothesis $f$ is of class $C^2$ which implies that
the right hand side stays bounded as $y$ and $x$ independently
of each other approach zero.
This eanble us to construct
integrals and  Green's formula yields:

\medskip

\noindent
{\bf{Theorem.}}
\emph{For each $p\in\mathcal C$ one has }

\[
\frac{\partial U_g}{\partial {\bf{n}}_*}(p)=
 g(p)+\int_{\mathcal C}\, K(p,q)\cdot g(q)\,d\sigma(q)
 \]
 \medskip
 
 \noindent
 {\bf{Exercise.}} Prove this equality.
A hint is by additivity it suffices to take $g$-functions with 
supports confined to small sub-intervals of $\mathcal C$ and profit upon
local coordinates and  parametrizations as above for 
$\mathcal C$ close to the support of $g$.


\bigskip


\centerline {\bf{1. Neumann's boundary value problem.}}
\bigskip

\noindent
Let $\Omega$ be a bounded domain
where $\partial\Omega$ consists of a finite set of closed Jordan
curves of class $C^2$. 
Let $h$ and $f$
be a pair of real-valued continuous functions on
$\partial\Omega$ where  $h$ is positive.
We seek a function $U$ which is harmonic in $\Omega$
and on the boundary satisfies
\[
\frac{\partial U}{\partial {\bf{n}}_*}(p)=
 h(p)U(p)+ f(p)
\]
\medskip

\noindent
{\bf{1.1 Theorem.}}
\emph{The boundary value problem
above has a unique solution $U$.}

\medskip

\noindent
The uniquenss amonuts to show that if $V$ is harmonic in $\Omega$ and
\[
\frac{\partial V}{\partial {\bf{n}}_*}(p)=
 h(p)V(p)
 \] 
 holds on $\partial\Omega$, then $V=0$.
Since 
$h$ is  positive 
this follows from  § XX: Chapter V.
\medskip

\noindent 
\emph{Proof of existence.}
For each $g\in C^0(\partial \Omega)$ we construct 
$U_g$
which by Theorem 0.1 solves the Neumann problem if
the $g$-function satisfies the integral equation
\[
g(p)+\int_{\mathcal C}\, K(p,q)\cdot g(q)\,d\sigma(q)=
h(p)\cdot \frac{1}{\pi}\cdot\int_{\partial\Omega}\, \log\,\frac{1}{|p-q|}\cdot g(q)\,d\sigma(q)
+f(p)\tag{1}
\]
With $h$ kept fixed we introduce the kernel
\[ 
K_h(p,q)=h(p)\cdot \frac{1}{\pi}\cdot\log\, \frac{1}{|p-q|}- K(p.q)
\]
and  (1) reduces to the equation
\[
g(p)-\int_{\partial\Omega}\,K_h(p,q) g(q)\,d\sigma(q)= f(p)\tag{2}
\]
\medskip
Next, introduce the linear operator on
the Banach space $C^0(\partial\Omega)$
defined by
\[ 
\mathcal K_h(f)=\int_{\partial\Omega}\,K_h(p,q) f(q)\,d\sigma(q)
\quad\colon\quad
f\in C^0(\partial\Omega)\tag{3}
\]
With this notation a $g$-function satisfies (2) if
\[
(E-\mathcal K_h)(g)=f\tag{4}
\] 
where $E$ is the identity operator on
$C^0(\partial\Omega)$.
Next, from the general result in §§ 
$\mathcal K_h$ is a compact linear operator and this entails by
another general result from § xx that each
$f\in C^0(\partial\Omega)$
yields a meromorphic function of the complex parameter
$\lambda$ given  by
\[ 
N_f(\lambda)=
f+\sum_{n=1}^\infty\, \lambda^n\cdot \mathcal K_h^n(f)
\]
If $\delta>0$ is so small that
$||\mathcal K_h||<\delta^{-1}$ it is clear that
\[
(E-\lambda \mathcal K_h)(N_f(\lambda)=f
\]
If $N_f(\lambda)$ has no pole at $\lambda=1$ it follows by analyticity that
\[
(E-\mathcal K_h)(N_f(1)=f
\] 
which means that $g=N_f(1)$
solves (4) and the existence part  follows.
So there remains only to show:
\medskip

\noindent
\emph {The absence of a pole at $\lambda=1$.}
Suppose that $N_f(\lambda)$ has a pole at $\lambda=1$
which entails that there is a positive integer $m$ such that 
\[ 
N_f(\lambda)=
\sum_{k=1} ^{k=m}\, \frac{a_k}{(1-\lambda)^k}+ b(\lambda)
\] 
hold when $|\lambda-1|$ is small where $a_m\neq 0$ in 
$C^0(\partial\Omega)$
and $b(\lambda$ is analytic in some disc centered at $\lambda=1$.
It follows that
\[
(1-\lambda)^m N_f(\lambda)=a_m+(1-\lambda)\beta(\lambda)
\] 
where 
$\beta(\lambda)$ again is an analytic $C^0(\partial\Omega)$-valued function
close to 1.
Apply $E-\mathcal K_h$ on both sides which gives
\[
(1-\lambda)^m (E- \mathcal K_h)(N_f(\lambda))
=(E-\mathcal K_h)(a_m)+(1-\lambda)
+(E-\mathcal K_h)(\beta(\lambda))
\]
Now  $\lambda=1$  gives
\[
(E-\mathcal K_h)(a_m)=0\implies
a_m=\mathcal K_h(a_m)
\]
This  contradicts  the uniqueness part which already has been proved.



\bigskip

\centerline{\bf{2. The case when
$\mathcal C$ has corner points.}}

\bigskip


\noindent
In the preceeding section we  found a unique solution to 
Neumann's boundary problem where
the inner normal derivative of $U$
along $\partial\Omega$ is a continuous function.
If corner points appear 
this will no longer be true. But 
stated in an appropriate way we can extend
Theorem 1.1.
Let us analyze the specific case when
the boundary curves are piecewise linear, i.e. each
closed Jordan curve in
$\partial\Omega$
is a simple polygon with a finite number of corner points.
Given one of these we begin to study the
$K$-function.
Let $\xi_1,\ldots,\xi_N$ be the corner points on
$\mathcal C$.
On the linear interval $\ell_i$ which joints two succescive
corner
points $\xi_i$ and $\xi_{i+1}$ we notice that
${\bf{n}}_*$ is constant and it is even true that
\[ 
K(p,q)=0\quad\colon\quad p,q\in \ell_i
\]
Indeed, this is obvious for if $p$ and $q$ both belong to$\ell_i$ then
the vector $p-q$ is parallell to $\ell_i$ and hence $\perp$ to
the normal of this line.
Next, keeping $q$ fixed on the open interval $\ell_i$
while $p$ varies on $\mathcal C\setminus \ell_i$
the behaviour of the function
\[ 
p\mapsto \langle p-q,{\bf{n}}_*(q)\rangle
\] 
is can be understood via a picture and it is
clear that (x) is a continuous function.
By a picture the reader should discover the different behaviour in the case
when $\mathcal C$ is convex or not.
For example, in the non-convex case it is in general not true 
that $\mathcal C\setminus \ell_i$
stays in the half-space bordered by the line passing $\ell_i$ and then
(*) can change sign, i.e. take both positive and negative values.
In the special case when
$\mathcal C$ is a convex polygon the reader should confirm that
(x) is a positive function of $p$ because we have taken the
\emph{inner} normal 
${\bf{n}}_*(q)$.
\medskip


\noindent
{\bf{2.1 Local behaviour at a corner point.}}
After a linear change of coordinates
we take a corner point $\xi_*$ placed at the origin
and one $\ell$-line is defined by
the equation $\{y=0\}$ to the left of $\xi_*$ where
$x<0$ while $y=Ax$ hold to the right for some $A\neq 0$.
If $A>0$ it means that
the angle $\alpha$ at the corner point is detemined by
\[ 
\alpha=\pi-\text{arctg}(A)
\]
If $A<0$ the inner angle is between 0 and $\pi/2$
which the reader should illustrate by a picture.
Next, consider
a pair of points $p=(-x,0)$ and $q=(t,At)$
where $x,t>0$. So $p$ and $q$ belong to opposite sides of the
corner point.
To be specific, suppose that $A>0$ which entails that
\[ 
{\bf{n}}_*(q)=\frac{(-A,1)}{\sqrt{1+A^2}}\implies
\]
\[
K(p,q)\cdot d\sigma(q)=  \frac{Ax+t}{(x+t)^2+A^2t^2}
\]
When $x$ and $t$ decrease to the origin the order of magnitude 
is
$\frac{1}{x+t}$ so the kernel function is unbounded
and the order of magnitude is $\frac{1}{x+t}$.
If $\ell_+$ denotes the boundsry interval to the right of the origin
where $q$ are placed we conclude that
\[
\int_{\ell_+}\, K(p,q)\cdot d\sigma(p)\simeq
\int_0^1\, \frac{dt}{x+t}\simeq \log\,\frac{1}{x}
\]
The last function is integrable with respect to $x$. This local computation shows
that the kernel function $K$ is not too large in 
the average. In particular
\[
\iint_{\mathcal C\times\mathcal C}\,
|K(p,q)|\cdot d\sigma(p)d\sigma(q)<\infty
\]
But
the
growth of $K$ near corner points prevail 
a finite $L^2$-integral, i.e. the reader may verify that
\[
\iint_{\mathcal C\times\mathcal C}\,
|K(p,q)|^2\cdot d\sigma(p)d\sigma(q)=+\infty
\]
\medskip


\noindent
{\bf{2.2 The integral operator $\mathcal K_h$}}.
Let $h$ be a positive continuous function on
$\partial\Omega$.
Now we define the kernel function $K_h(p,q)$ exactly as in
§ xx and obtain the corresponding
linear operator
\[ 
g\mapsto\int_{\partial\Omega}\, K_h(p,q)g(q)d\sigma(q)
\]
It has a natural domain of definition.
Namely,  introduce the space
$L^1_*$ which consists of functions on $g$
on $\partial\Omega$ for which
\[
\iint\, \log\frac {R}{|p-q|}\cdot |g(p)|\cdot d\sigma(q)d\sigma(p)<\infty\tag{*}
\] 
where  $R>0$ is so large that
$\frac{R}{|p-q|}>1$  hold for  pairs $p,q$ on $\partial\Omega$.
Return to the local situation in
(xx) and consider a $g$-function in  $L^1_*$. Locally 
we encounter an integral of the form
\[
\iint_{\square_+}\, \frac{1}{x+t}\cdot |g(t,At))|\, dt
\]
where $0\leq x,t\leq 1$ hold in
$\square_+$.
In this double integral we first perform integration with respect to $x$
which is finite since the inclusion $g\in L^1_*$ entails that
\[
\int_0^1\,\log\,\frac{1}{t}\cdot |g(t,At)|\, dt<\infty
\]


\noindent
From the above we obtain the following:

\medskip

\noindent
{\bf{2.3 Theorem.}}
\emph{The kernel function $K_h$ yields a continuous linear operator from
$L^1_*$ into $L^1(\partial\Omega)$, i.e. there exists a constant
$C$ such that}
\[
\int_{\partial \Omega} |\mathcal K_h(g)|\cdot d\sigma
\leq C\cdot 
\iint
_{\partial \Omega\times \partial \Omega} 
\, \log\frac {R}{|p-q|}\cdot |g(p)|\cdot d\sigma(q)d\sigma(p)
\]
\bigskip

\noindent
Armed with Theorem 2.3 
we can solve Neumann's boundary value problem for domains 
whose boundary curves are polygons.

\medskip
\noindent
{\bf{2.4 Theorem.}}
\emph{For each $f\in L^1(\partial\Omega$
there exists
a unique harmonic function $U$ in $\Omega$ such that}
\[
\frac{\partial U}{\partial {\bf{n}}_*}(p)=
 h(p)U(p)+ f(p)
\]
holds on $\partial \Omega$. Moreover, $U=U_g$ where
$g\in L^1_*$ solves the integral equation
\[
g-\mathcal K_h(g)=f
\]



\noindent
\emph{The uniquenss part.}
At corner points the inner normal of $U$ has no limit and
to establish the uniqueness part we use  instead
an integral formula:


\medskip

\noindent{\bf{2.5 Proposition.}}
\emph{For each $g\in L^1_*$ the potential function $U=U_g$ satisfies}

\[
\iint_\Omega\ [
(\frac{\partial U}{\partial x})^2
+(\frac{\partial U}{\partial y})^2]\, dxdy+
\int_{\partial\Omega}\, U\cdot 
\frac{\partial U}{\partial {\bf{n}}_*}\,
d\sigma=0
\]
\medskip


\noindent
{\bf{Exercise.}} Prove this result.

\medskip 

\noindent
The requested uniqueness follows. For if
$\frac{\partial U}{\partial {\bf{n}}_*}= h\cdot U$
holds on the boundary we get 

\[
0=\iint_\Omega\ [
(\frac{\partial U}{\partial x})^2
+(\frac{\partial U}{\partial y})^2]\, dxdy=\int_{\partial\Omega}\, 
h\cdot U^2\,
d\sigma\implies g=0
\] 
\medskip

\centerline
{\emph{2.6 Proof of existence.}}
\medskip

\noindent
It  is carried out by the same mehod as in
§ X. The crucial  point is  that
the kernel function $K_h$ is sufficiently well-behaved in order that
every $f\in L^1(\Omega)$
yields a meromorphic function $N_f(\lambda$
where $\mathcal K_h$-powers are applied to $f$ exactly as in XX.
\medskip


\noindent
{\bf{Exercise.}} Supply details which prove that
$N_f(\lambda)$ is meromorphic.
\medskip


\noindent
{\bf{Remark.}}
In [Carleman: Part 3] it is proved that
the unique solution $g$ to the integral equation
is represented in a canonical fashion using a certain orthonormal family of functions with 
respect to the $L^2$-function $\log\,\frac{1}{|p-q|}$ 
wtih respect to the product measure $\sigma\times\sigma$. Moreover, there exists
a representation formula expressed by convergent series for the inhomogenous
equation
\[ 
g+\lambda\cdot \mathcal K_h(g)=f
\] 
where poles of $N_f(\lambda)$ are taken into the account.

\newpage



\centerline{\bf \large A uniqueness theorem for 
an elliptic boundary value problem}}

\bigskip

\noindent
{\bf Introduction.}
We shall work in  ${\bf{R}}^2$ with  coordinates
$(x,y)$.
Let
$n=2m$ be an even positive integer and consider two $n\times n$-matrices
$\mathcal A=\{A_{pq}\}$ and $\mathcal B=\{B_{pq}\}$
whose elements are real-valued functions of $x$ and $y$
where
the $B$-functions are continuous and the
$A$-functions  of class $C^2$. 
Eigenvalues of the
$\mathcal A$-matrix 
when $(x,y)$-varies give an
$n$-tuple of  roots
$\lambda_1(x,y),\ldots,\lambda_n(x,y)$ which solve
\[
\text{det}\,\bigl(\lambda\cdot E_n-\mathcal A(x,y)\bigr)=0\tag{1}
\]



\noindent
Next, we have
a system of first order
PDE-equations whose solutions are 
vector valued functions $(f_1,\ldots,f_n)$
defined in a half-disc
\[
D_+(\rho)=\{ x^2+y^2<\rho^2\quad\colon\, x>0\}
\]
where the $f$-functions satisfy the system:
\[ 
\frac{\partial f_p}{\partial x}+
\sum_{q=1}^{q=n}\,
A_{pq}(x,y)\cdot
\frac {\partial f_p}{\partial y}+
\sum_{q=1}^{q=n}\,
B_{pq}(x,y)\cdot f_q(x,y)=0\tag{*}
\]


\noindent
together with the boundary conditions:
\[
f_p(0,y)=0\quad\text{for all}\quad 1\leq p\leq n\tag{**}
\]

\medskip


\noindent
If the $\lambda$-roots are non-real in (1)
we say that (*)  is an elliptic system. When this holds
one exocets that the vanishing Cauchy data in  (**) entails
that the   solution
$f$  is identically zero.
This uniqueness  was proved by
Erik Holmgren in the  article [Holmgren]
under the assumption that the $A$-functions and the
$B$-functions are real analytic.
The question remained if the uniqueness still holds under less
regularity on the coefficient functions. 
An affirmative answer was proved
by  Carleman in the article \emph{xxx}.
\bigskip 

\noindent
{\bf 1. Theorem.} \emph{Assume that the
$\lambda$-roots are all simple and non-real as 
$(x,y)$ varies in the open half-disc. Then every solution $f$ to (**) 
with vanishing Cauchy-data  is identically zero}.
\medskip

\noindent
The proof requires several steps and 
the methods which occur below
have inspired more recent work where   Carleman estimates 
are used to handle  boundary value problems
in PDE-theory.
\bigskip



\centerline {\bf {A. First part of the proof}}
\medskip

\noindent
The system  in (*) is equivalent to a system of
$m$-many equations where one  seeks
complex-valued functions
$g_1,\ldots,g_m$   satisfying:
\[ 
\frac{\partial g_p}{\partial x}+
\sum_{q=1}^{q=m}\,
\lambda_p(x,y)\cdot
\frac {\partial g_p}{\partial y}=
\]
\[
\sum_{q=1}^{q=m}\,
a_{pq}(x,y)\cdot g_q(x,y)+
b_{pq}(x,y)\cdot \bar g_q(x,y)=0\,\,\colon\,1\leq p\leq m\tag{**}
\]
Above $\{a\uuu{pq}\}$ and $\{b\uuu{pq}\}$
are complex\vvv valued,and by the elliptic hyptheis the
complex-valued $\lambda$-functions can be chosen so that
their  imaginary parts are  positive functions of $(x,y)$.
The  reduction  of the originalsystem to
to this complex family of equations
is left to the reader. From  now
on we study the system (**) and Theorem 1 amounts
to prove that
if the $g$-functions satisfy (**) 
in a half-disc
$D_+(\rho)$
and
\[
g_p(0,y)=0\quad\colon\quad 1\leq p\leq m
\]
then there exists some $0<\rho_*\leq \rho$ such that the $g$-functions
are identically zero in 
$D_+(\rho_*)$. To attain this we
introduce domains as follows:
For a pair  $\alpha>0$ and 
$\ell>0$ we put
\[ 
D_\ell(\alpha)=\{
x+y^2-\alpha x^2<\ell^2\}\cap\{ x>0\}\tag{1}
\]


\noindent
Notice that the boundary
\[ 
\partial D_\ell(\alpha)=\{0\}
\times[-\ell,\ell]\,\cup \,
\{x+y^2-\alpha x^2=\ell^2\}
\]




\noindent
Above $\alpha$ and $\ell$ are small so the the $g$-functions satisfy (**)
in $D_\ell(\alpha)$.
For  each  $t>0$
we define  the  $m$-tuple of functions
by
\[
\phi_p(x,y)= g_p(x,y)\cdot e^{-t(x+y^2-\alpha x^2)}\tag{2}
\]
Since the $g$-functions satisfy   (**)
one verifies easily that
the $\phi$-functions
satisfy the system
\[
\frac{\partial \phi_p}{\partial x}+
\frac {\partial}{\partial y}\bigl(\lambda_p\cdot\phi_p)+
t(1-2\alpha x+2y\lambda_p\bigl)\cdot\phi_p=H_p(\phi)\tag{3}
\]
where 
\[
H_p(\phi)=\sum_{q=1}^{q=n}\,
a_{pq}(x,y)\cdot \phi_q(x,y)+
b_{pq}(x,y)\cdot \bar \phi_q(x,y)=0\,\,\colon\,1\leq p\leq m
\]

\noindent
Next, we set
\[ 
\Phi(x,y)=\sum_{p=1}^{p=m}\, |\phi_p(x,y)|\tag{4}
\]


\noindent
The crucial step in the proof
of Theorem 1
is to establish the following inequality.
\medskip

\noindent
{\bf A.1 Proposition.} \emph{Provided that $\alpha$ from the start is sufficiently large
there exists some $0<\ell_*\leq\ell$ and a constant $C$
which is independent of $t$  such that}
\[
\iint_{D_{\ell_*}}\, \Phi(x,y)\cdot dxdy \leq
C\cdot \int_{T_{\ell_*}}\, \sum_{p=1}^{p=n}\,|\phi_p|\cdot
 |dy-\lambda_p\cdot dx|
\]
\medskip

\noindent
\emph{How to deduce  Theorem 1.}
Let us show why Proposition A.1 gives Teorem 1.
In addition to
$\ell_*$ we fix some
$0<\ell_{**}<\ell_*$.
In  (2) above we have used the function
\[
w(x,y)= e^{-t(x+y^2-\alpha x^2)}\implies
\]
\[ w(x,y)= e^{-t\ell_*^2}\quad\colon\quad \{x+y^2-\alpha x^2=\ell_*^2\}
\quad\colon\quad
w(x,y)\geq e^{-t\ell_{**}^2}\quad\colon\quad (x,y)\in D_{\ell_{**}}\tag{i}
\]

\medskip

\noindent
Next, we have
$|\phi_p|= |g_p|\cdot w$ for each $p$. Replacing the left hand side in Proposition
A.1 by the area integral over the smaller
domain
$D_{\ell_{**}}$
we obtain the inequality;
\[
\iint_{D_{\ell_{**}}}\,
\sum_{p=1}^{p=m}\,| g_p(x,y)|\cdot dxdy\leq
C\cdot  e^{t(\ell_{**}^2-\ell_*^2)}\cdot 
\int_{T_{\ell_*}}\, \sum_{p=1}^{p=n}\,|g_p|\cdot
 |dy-\lambda_p\cdot dx|\tag{ii}
\]
\medskip

\noindent
Here (ii)  holds for every $t>0$. When
$t\to+\infty$ we have 
$ e^{t(\ell_{**}^2-\ell_*^2)}\to 0$
and  conclude that
\[
\iint_{D_{\ell_{**}}}\,
\sum_{p=1}^{p=m}\,| g_p(x,y)|\cdot dxdy=0
\]

\noindent
This means  that the $g$-functions are all zero in
$D_{\ell_{**}}$ and Theorem 1 follows.


\bigskip

\centerline{\bf B. Proof of Proposition A.1}
\medskip

\noindent
The proof  relies upon the
construction of certain $\psi$-functions.
More precisely, when
$t>0$ and  a point $(x_*,y_*)\in D_\ell$ are given we shall construct
an $m$-tuple of $\psi$-functions satisfying
the following:

 \bigskip

\noindent
{\bf Condition 1.} Each
$\psi_p$ is defined in
the punctured domain
$D_\ell\setminus\{(x_*,y_*)\}$
where $\psi_p$ for a given $1\leq p\leq m$
satisfies the equation
\[
\frac{\partial\psi}{\partial x}+
\lambda_p\cdot\frac{\partial\psi}{\partial y}-
t(1-2\alpha x+2y\lambda_p)\psi_p=0\tag{i}
\]





\noindent
{\bf Condition 2}. For each $p$ the
singularity of $\psi_p$ at $(x_*,y_*)$
is such that the line integrals below have a limit:
\[
\lim_{\epsilon\to 0}\,
\int_{[z-z_*|=\epsilon}\,\psi_p\cdot (dx-\lambda_p\cdot dy)=2\pi\tag{ii}
\]


\noindent
{\bf Condition 3.} There exists a constant $K$
which is independent both of
$(x_*,y_*)$ and of $t$ such that
\[
|\psi_p(z)|\leq\frac{K}{|z-z_*|}\tag{iii}
\]
Notice that the $\psi$-functions depend on the parameter
$t$, i.e. they are found for each $t$ but the constant $K$ in (3) is independent of
$t$.
\bigskip

\centerline {\emph{ The deduction of Proposition A.1}}
\bigskip

\noindent
Before the $\psi$-functions are  constructed in Section C
we show how  they  give
Proposition A.1.
Consider a point  $z_*\in D_+(\ell)$.
We get the associated $\psi$-functions from § B
at this particular point.
Remove a small disc
$\gamma_\epsilon$ centered at $z_*$ and
consider some fixed
$1\leq p\leq m$.
Now $\phi_p$ satisfies the differential equation (3) from section A and 
$\psi_p$ satisfies (i) in Condition 1 above.
Stokes theorem gives:
\[
\int_{T_\ell}\phi_p\cdot\psi_p\cdot \bigl(dy-\lambda_p\cdot dx\bigr)
=\iint_{D_\ell\setminus\gamma_\epsilon}\,
H_p(\phi)\cdot \psi_p\cdot dxdy+
\int_{|z-z_*|=\epsilon}
\, \phi_p\cdot\psi_p\cdot \bigl(dy-\lambda_p\cdot dx\bigr)
\]
\medskip


\noindent
Passing to the limit as $\epsilon\to 0$, Condition 2 gives
\[
\phi_p(x_*,y_*)=\frac{1}{2\pi}
\int_{T_\ell}\phi_p\cdot\psi_p\cdot \bigl(dy-\lambda_p\cdot dx\bigr)
-\frac{1}{2\pi}\cdot \iint_{D_\ell}\,
H_p(\phi)\cdot \psi_p\cdot dxdy\tag{1}
\]


\noindent
Let $L$ be the maximum over $D_\ell$ of the 
coefficient functions  of $\phi$ and $\bar\phi$
which appear in  $H_p(\phi)$
from (3) i § A. We have also the constant $K$ from
Condition 3 for $\psi_p$. The
triangle inequality gives:


\[
\bigl|\phi_p(x_*,y_*)\bigr|\leq
\frac{K}{2\pi}
\int_{T_\ell}\frac{|\phi_p|\cdot |dy-\lambda_p\cdot dx|}{z-z_*|}
+\frac{LK}{\pi}\cdot \sum_{q=1}^{q=m}\,
\iint_{D_\ell}\,
\frac{|\phi_q|}{|z-z_*|}\cdot dxdy\tag{*}
\]
\medskip

\noindent
Next, we use the elementary  inequality

\[ \iint_\Omega\, \frac{dxdy}{\sqrt{x-a)^2+(y-b)^2}}
\leq 2\cdot\sqrt{\pi}\cdot \sqrt{\text{Area}(\Omega)}\tag{**}
\]
where $\Omega$ is an arbitrary  bounded domain
and $(a,b)\in\Omega$.
Apply (**)  with
$\Omega=D_\ell$ and set
$S=\text{area}(D_\ell)$.
Integrating both sides in (*) over $D_\ell$
for every
$p$ and taking the sum we get
\[
\iiint_{D_\ell}\, \Phi\cdot dxdy\leq
\]
\[
K\cdot\sqrt{\frac{S}{\pi}}\cdot \int_{T_\ell}\,
\sum_{p=1}^{p=m}\, |\phi_p|\cdot |dy-\lambda_p\cdot dx|
+2\pi m LK\cdot \sqrt{\frac{S}{\pi}}\iint_{D_\ell}\,
\Phi\cdot dxdy
\]
\medskip

\noindent
This inequality hold for all small $\ell$.  Choose
$\ell$ so small that
\[
2\pi m LK\cdot \sqrt{\frac{S}{\pi}}\leq\frac{1}{2}
\]
Then the inequality above gives
\[
\iiint_{D_\ell}\, \Phi\cdot dxdy\leq
2\cdot 
K\cdot\sqrt{\frac{S}{\pi}}\cdot \int_{T_\ell}\,
\sum_{p=1}^{p=m}\, |\phi_p|\cdot |dy-\lambda_p\cdot dx|\tag{***}
\]


\noindent
Finally, consider some relatively compact
domain
$\Delta$ in $D_\ell$. Then there exists
$0<\ell_*<\ell$ such that
\[
\Delta\subset D_{\ell_*}
\]
Now we notice that

\[ 
|\phi_p(z)|\geq e^{-t\ell_*^2}\cdot |u_p(z)|
\quad\colon\quad z\in \Delta\quad\colon\quad
|\phi_p(z)|\geq e^{-t\ell^2}\cdot |u_p(z)|
\quad\colon\quad z\in T_\ell
\]


\noindent
We conclude that
\[
e^{-t\ell_*^2}
\,\iiint_\Delta\, \sum_{p=1}^{p=m}\, |u_p(z)|\cdot dxdy\leq
e^{-t\ell^2}\cdot 2\cdot 
K\cdot\sqrt{\frac{S}{\pi}}\cdot \int_{T_\ell}\,
\sum_{p=1}^{p=m}\, |u_p|\cdot |dy-\lambda_p\cdot dx|\tag{****}
\]
\medskip

\noindent Here (****) hold for every $t>0$. Passing to the limit
as
$t\to+\infty$ it follows that

\[
\cdot \iiint_\Delta\, \sum_{p=1}^{p=m}\, |u_p(z)|\cdot dxdy\leq
\]
Since $\Delta$ was any relatively compact subset of
$D_\ell$, we conclude  that the $u$-functions are zero in
$D_\ell$ and Theorem 1   follows.







\bigskip

\centerline{\bf {C. Construction of the $\psi$-functions.}}

\bigskip


\noindent
Before we embark upon specific constructions
we investigate the whole family of solutions to
a first order differential operators  of the form
\[
Q=\partial_x+\lambda(x,y)\cdot\partial_y\tag{*}
\] 
where $\lambda(x,y)$ is a complex 
valued $C^2$-function whose
imaginary part is $>0$. 
Set
\[ 
\lambda(x,y)=\mu(x,y)+i\cdot\tau(x,y)\quad\colon\, \tau(x,y)>0
\]


\noindent
Now we look for
solutions 
$h(x,y)$ to the equation $Q(h)=0$.
With
$h(x,y)=\xi(x,y)+i\cdot\eta(x,y)$
where $\xi$ and $\eta$ are real-valued $C^2$-functions this gives
the differential system:
\[
\frac{\partial\xi}{\partial x}+\mu_p\cdot
\frac{\partial\xi}{\partial y}-
\tau_p\cdot \frac{\partial\eta}{\partial y}=0
\]
\[
\frac{\partial\eta}{\partial x}+\mu_p\cdot
\frac{\partial\eta}{\partial y}+
\tau_p\cdot \frac{\partial\xi}{\partial y}=0
\]

\medskip

\noindent
Suppose we have found one solution 
 $h=\xi+i\cdot\eta$ where the 
Jacobian 
$\xi_x\eta_y-\xi_y\eta_x$
is $\neq 0$ at the origin. 
Then $(x,y)\mapsto (\xi,\eta)$ is a local $C^2$-diffeomorphism.
With  $\zeta=\xi+i\eta$ 
we have the usual Cauchy\vvv Riemann operator.
\[ 
\frac{1}{2}(\frac{\partial}{\partial\xi}+
i\cdot \frac{\partial}{\partial\eta})
\]

\noindent
Let $g(\xi+i\eta)$ be  a holomorphic function
in the complex $\zeta$-space with $\zeta=\xi+i\eta$ and put
\[ 
g_*(x,y)=g(\xi(x,y)+i\eta(x,y))
\] 
Then one easily verifies that $Q(g\uuu*)=0$
and conversely, every solution
to this equation is expressed by 
a $g\vvv*$function derived from an
analytic function in the complex $\zeta$space.satisfies  $Q(g_*)$.
\medskip

\noindent
{\bf{Conclusion.}} \emph{If a non-degenerate solution $h=\xi+i\eta$ has been found
then the homogenous solutions to $Q$ is in a 1-1 correspondence to
analytic functions in the $\zeta$-variable.}
\medskip

\noindent
{\bf{Remark.}} The effect
of a coordinate transformation
as above is that
the $Q$-operator 
is transported to the
Cauchy-Riemann operator in
the complex $\zeta$-space where $\zeta=\xi+i\eta$.
Later we   employ such  $(\xi,\eta)$-transformations
to
construct  
solutions to an inhomogeneous equation of the form
\[ 
Q(\psi)=(t-\alpha x+2y\lambda(x,y))\cdot \psi(t,x,y)
\]
where $t$ is a positive parameter and the
$\psi$-functions 
will have certain specified properties.
Notice that it suffices to construct
the
$\psi$-functions separately, 
i.e. we no longer have to bother about
a differential system. With a fixed
$p$ fixed   $\lambda_p(x,y)=\mu_p+\tau_p$ and
from now on we may drop the index $p$ and explain how to obain
$\psi$-functions satisfying
the three conditions from § B.
So we consider
the first order differential operator
\[
Q=\frac{\partial}{\partial x}+(\mu(x,y)+i\tau(x,y))\cdot
\frac{\partial}{\partial y}\tag{1}
\]
where 
$\tau(x,y)>0$.
\bigskip



\noindent
{\bf C.1 A class of $(\xi,\eta)$-functions.}
Let $V(x,y)$ and $W(x,y)$
be two quadratic forms, i.e. both are homogeneous polynomials of
degree two. Given a point $(x_*,y_*)$ 
and with $z=x+iy$
we seek  a coordinate transformation $(x,y)\mapsto(\xi,\eta)$
of the form:

\[ 
\xi(z)= \tau_p(z_*)\cdot (x-x_*)+V(x-x_*,y-y_*)+\gamma_1(z)
\cdot|z-z_*|^2
\]
\medskip
\[ 
\eta(z)= (y-y_*)-\mu_p(z_*)\cdot (x-x_*)+W(x-x_*,y-y_*)+
\gamma_2(z)\cdot|z-z_*|^2
\]
\medskip

\noindent{\bf Lemma.}
\emph{There exists  a pair of quadratic forms
$V$ and $W$ whose coefficients depend on
$(x_*,y_*)$ and a pair of
$\gamma$-functions which both vanish at
$(x_*,y_*)$ up to order one such that the complex\vvv valued function
$\xi+i\eta$ solves the homogeneous equation $Q(\xi+i\eta)=0$.}
\medskip

\noindent
A solution above
gives
a change of variables
so that
$Q$ is expressed in new real coordinates
$(\xi,\eta)$ by the operator
\[
\frac{\partial}{\partial \xi}+i\cdot \frac{\partial}{\partial\eta}\tag{2}
\]
There exist many coordinate transforms
$(x,y)\to(\xi,\eta)$
which change $Q$ into (2).
This \emph{flexible choice} of coordinate transforms
is used to  construct  the required
$\psi$-functions. Notice  that
Condition (2) in § B is of a pointwise character, i.e. 
it suffices to find a $\psi$-function for a given point
$z_*=x_*+iy_*$. With this in mind
the required construction in § B boils down to perform
a suitable coordinate transformation
adapated to $z_*$,
and after use the existence of
a $\psi$-function which to begin with  is expressed in the
$(\xi,\eta)$-variables where  the $Q$-operator is replaced by
the Cauchy-Riemann operator. In this special case
the required $\psi$-function is easy to find, i.e. see 
the remark in § B.0.
So all that remains is to exhibit suitable coordinate transformations
which send $Q$ to the $\bar\partial$-operator. We leave it to the reader to
carry out such coordinate transformations. If
necessary, consult
Carleman's article where
a very detailed construction appears.


\bigskip



\newpage

\centerline{\bf{The Schrödinger equation.}}

\bigskip


\noindent
We work in ${\bf{R}}^3$ with the coordinates
$(x,y,z)$. Let $c(x,y,z)$ be a real-valued function in 
$L^2_{\text{loc}}({\bf{R}}^3$.
In order that the subsequent
formulas can be stated in a precise manner we also assume that
$c$is almost everywhere continuous which of course is a rather weak condition and
in any case satisfied in applications.
Next, let $\Delta$ be the Laplace operator and
define the operator $L$ by

\[ 
L(u)=\Delta(u)+c\cdot u\tag{*}
\]
Denote by $E_L({\bf{R}}^3)$
the set of functions $u$ such that both
$u$ and $L(u)$ belong to $L^2({\bf{R}}^3)$. Given a
pair $(f,\lambda)$ where
$f\in L^2({\bf{R}}^3$
and $\lambda$ is a complex number
we seek solutions $u\in E_L({\bf{R}}^3)$ such that

\[ 
L(u)+\lambda\cdot u=f\tag{**}
\]
\medskip

\noindent
{\bf{The case $\mathfrak{Im}(\lambda\neq 0$.}}
By
a classic result about solutions to the Neumann
boundary value problem  in
open balls in ${\bf{R}}^3$ one proves that
(1) has at least one solution $u$ whenever $\lambda$ is not real.
The remains to investigate the uniqueness, i.e, when one has the implication


\[
\mathfrak{Im}(\lambda\neq 0\quad\text{and}\quad 
L(u)+\lambda\cdot u=0\implies u=0\tag{***}
\]
\medskip


\noindent
This uniqueness property depends on the $c$-function.
A sufficient  condition is the following:


\medskip

\
\medskip

\noindent
{\bf{Theorem.}} \emph{Assume that there exists a constant $M$
and some $r_*>0$ such that}
\[ 
c(x,y,z)\leq M
\quad\text{when}\quad x^2+y^2+z^2\geq r_*^2
\]
Then (***) above holds.


\bigskip


\noindent
{\bf{The spectral $\theta$-function.}}
When (***)  holds it was proved in
[Carleman] that
classical solutions to the Neumanns boundary value problem in
open balls yield a $\theta$-function
which enable us to describe  solutions to 
(*) for real $\lambda$-values.
More precisely, there exists two increasing sequence of positive real numbers
$\{\lambda^*(\nu)\}$ and $\lambda_*(\nu)\}$
and two sequence of pairwise orthogonal functions
$\{\phi_\nu(p))\}$ and $\{\psi_\nu(p)\}$ in $L^({\bf{R}})^3$
where all these functions have $L^2$-norm equal to one such that
the following hold. First, set 


\[
\theta(p.q,\lambda)= \sum_{0<\lambda^*(\nu)\leq\lambda}\, \phi_\nu(p)\cdot\phi_\nu(q)
\quad\colon\quad \lambda>0
\]

\[
\theta(p.q,\lambda)= -\sum_{\lambda\leq \lambda_*(\nu)\leq<0}
\, \psi_\nu(p)\cdot\psi_\nu(q)
\quad\colon\quad \lambda<0
\]
such that the following hold:
\bigskip

\[
v(p)=\lim_{R\to \infty}\, \sum_{[\lambda_\nu<R}\, 
\theta(p,q,\lambda)\cdot v(q)\cdot dq\quad\text{for all}
\quad v\in L^2({\bf{R}}^3)\tag{1}
\]

\[
v\in E_L({\bf{R})^3}\quad\text{if and only if}\quad
xxxx\tag{2}
\]

\[
L(v)(p)=
\lim_{R\to \infty}\, \sum_{[\lambda_\nu<R}\, 
\lambda\cdot [
\int_{{\bf{R}}^3}
\theta(p,q,\lambda)\cdot v(q)\cdot dq]\cdot d\lambda\quad\text{for all}\quad
v\in E_L({\bf{R}}^3)\tag{3}
\]
Here the equaliy holds in $L^2$, i.e, in the sense of a Plancherel's limit.
\medskip


\noindent
{\bf{Remark.}}
Here the equaliy holds in $L^2$, i.e, in the sense of a Plancherel's limit.


\medskip

\noindent
{\bf{Construction of the $\phi$-functions. }}
For each finite $r$ we have the ball $B_r$ and consider the space $E_L(B_r)$ of 
functions 
$u$ in $B_r$ such that both $u$
and $L(u)$ also belong to $L^2(B_r)$.
By a classical result in the Fredholm theory that
exist discrete sequences of real numbers
$\{\lambda*(\nu)$ and $\lambda_*(\nu)$ as above
and two families of orthonormal functions
$\{\phi^{(r)}_\nu\}$ and $\{\psi^{(r)}_\nu\}$
satisfying (xx) 

and here a classical result shows that the real eigenvalues 
to the equation $L(u)+\lambda\cdot u=0$
xxx

\[ 
xxx
\]


\noindent
The proofs of the assertions above rely on a systematic use of Green's formula.
To begin with we recall how to
express solutions to an inhomogeneous
the Laplace equation by an integral formula.
\medskip


\noindent
{\bf{A. The equation $\Delta(u)=\phi$}}.
let $D$ be a domain in
${\bf{R}}^3$ and $\phi$
a function in $L^2(D)$.
Then a function $u$ for which both $u$ and $\Delta(u)$ belong to
$L^2(D)$ gives $\Delta(u)=\phi$ if and only if
the following hold for every $p\in D$ and every 
$\rho<\text{dist}(p,\partial D)$:

\[
u(p)=
\frac{1}{2\pi \rho^2}\cdot \int_{B_p(\rho)}\,
\frac{1}{|p-q|}\cdot u(q)\cdot dq+
\frac{1}{4\pi \rho^2}\cdot \int_{B_p(\rho)}\,
A(p,q)\cdot \phi(q)\cdot dq\tag{i}
\]
where we have put

\[ 
A(p,q)= \frac{2}{\rho}-\frac{1}{|p-q|}-\frac{|p-q|}{\rho^2}\tag{ii}
\]
\medskip

\noindent
{\bf{Exercise.}} Prove this result.The hint is to apply Green's formula
while $\phi$ is replaced by $\Delta(u)$ in the last integral.
\medskip

\noindent
{\bf{Remark.}}
Let us also recall
also that when $\Delta(u)$ is in $L^2$, then $u$ is automatically
a continuous function in $D$.
\medskip


\noindent
{\bf{The class $\mathfrak{Neu}(B_r)$}}.
Let $B_r$ be the open ball of radius $r$ centered at the origin.
The class of functions $u$  which are continuous on the closed ball
and whose interior normal derivative
$\frac{\partial u}{\partial{\bf{n}}}$ is continuous on the boundary
$S^2[r]$ is denoted by
$\mathfrak{Neu}(B_r)$. 
\medskip


\noindent
{\bf{The Neumann equation.}}
Let $c(x,y,z)$ be a function in $L^2({\bf{R}}$
and consider also a pair $a,H$ where
$a$ be a continuous function on
$S^2[r]$ and 
$H(p,q)$ a continuous hermitian function on
$S^2[r]\times S^2[r]$, i.e.  $H(q,p)=\bar H(p,q)$ hold for all pairs 
of point $p,q$ on
the sphere $S^2[r]$.
With these notations the following hold:


\bigskip


\noindent
{\bf{Theorem}} For each $f\in L^2(B_r)$ and every
non-real complex number $\lambda$ there exists a unique $u\in 
\mathfrak{Neu}(B_r)$
such that $u$ satisfies the two equations:


\[ 
L(u+\lambda\cdot u=f\quad\text{holds in}\quad B_r
\] 

\[
\partial u/\partial {\bf{n}}(p)=xx
\]
Moreover, one has the $L^2$-estimate

\[
\int_{B_r}\, |u|^2\cdot dxdydz\leq
\bigl|\frac{1}{\mathfrak{Im}(\lambda)}\bigr|\leq
\int_{B_r}\, |f|^2\cdot dxdydz
\]












\newpage




Classic result: $R>0$ we have unit ball $B_R$ and unit sphere $S_R$.
Let $\mathfrak{Neu}(R)$
set uf $u$ -functions where $\Delta(u)$ in $L^2$, continuous on closed ball
and limit of interior derivative as a continuous funtion.
Given $c\in L^2(B_R)$ define

\[
L(u)= \delta(u)+c\cdot u
\]
\medskip


\noindent
{\bf{Theorem}} For each pair $(a,H)$ in (*) there exists a unique
$u\in \mathfrak{Neu}(R)$ such that
\[ 
L(u+\lambda\cdot u=f\quad\text{holds in}\quad B_R
\] 
and $u$ saisfies th boundsry condition

\[
\partial u/\partial {\bf{n}}(p)=xx
\]

from that $L^2$-esteimate as well.

\bigskip

Do if for $R=m$ running over positive integers.
Catch up sequence with $L^2$-convergence bounded uniformly.
$u_m\to u_*$ weak sense and see tha $u_*$ is a solution to (*) on al over space.

Second point about eventual uniqueness. Class I type. Euquialent condition-
















In an article from 1920 Carleman constructed an "ugly  example" of a doubly
indexed sequence
$\{c_{pq}\}$ of real  numbers
satisfying (1) and the symmetry condition
$c_{pq}=c_{qp}$, and yet there exists a non-zero complex vector
$\{x_p=a_p+ib_p\}$ in $\ell^2$ such that
\[ 
S(x)= ix\tag{4}
\]
This should be compared with
the finite dimensional case where
the spectral theorem due to Cauchy and Weierstrass asserts that
if
$A$ is a real and symmetric $N\times N$-matrix for some
positive integer $N$, then there exists an orthogonal
$N\times N$-matrix $U$ such that
$UAU^*$ is a diagonal matrix with real elements.
Carleman  extended this finite dimensional result 
to infinite Hermitian matrices 
for which the densely defined linear operator $S$ has no eigenvectors with
eigenvalue $i$ or $-i$.
More precisely, one says that
the densely defined operator $S$ is of Class  I
if the equations
\[
S(z)= iz\quad\colon S(\zeta)= -i\zeta\tag{*}
 \] 
 do not have non-zero solutions with complex vectors
 $z$ or $\zeta$ in $\ell^2$.
 The major result in the cited monograph is as follows:
 \medskip
 
 
 \noindent
 {\bf{0.0.1 Theorem.}}
\emph{Each densely Hermitian operator $S$ of Class I has  a unique
adapted resolution of the identity.}
\medskip



\noindent 
{\bf{0.0.2 Resolutions of the identity.}}
In order to digest Theorem 0.0.1
we recall the notion of spectral resolutions.
To begin with, a resolution  of the identity on
$\ell^2$ consists of a 
family $\{E(\lambda)\}$
of self-adjoint projections, indexed by real numbers
$\lambda$  which satisfies  (A-C) below.

\medskip

\noindent
{\bf{A}}. Each $E(\lambda)$ 
is an orthogonal projection from
$\ell^2$ onto the range $E(\lambda)(\ell^2)$ and 
these operators commute pairwise, i.e.
\[
E(\lambda)\cdot E(\mu)=
E(\mu)\cdot E(\lambda)\tag{i}
\]
hold for pairs of real numbers. 

\noindent {\bf{B}}.
To each pair of real numbers
$a<b$ we set
\[ 
E_{a,b}= E(b)-E(a)
\]
Then
\[
E_{a,b}\cdot
E_{c,d}=0\tag{iii}
\] 
for each pair of disjoint interval
$[a,b]$ and $[b,c]$.

\medskip

\noindent {\bf{C}}.
For each $x\in\ell^2$  the real-valued function 
\[ 
\lambda\mapsto\langle E(\lambda)(x),x\rangle\tag{c}
\] 
is  a non-decreasing and 
right continuous function.
\medskip



\noindent{\bf{0.0.3 $S$-adapted resolutions.}}
Let $S$ be a densely defined and hermitian linear operator on
$\ell^2$.
A spectral resolution  $\{E(\lambda)\}$ of the identity
is $S$-adapted if the following  three conditions hold:
\medskip

\noindent
{\bf{A.1}} For each interval bounded $[a,b]$ the range of
$E_{a,b}$ from (B) above
is contained in $\mathcal D(S)$
 and 
\[
E_{a,b}(Sx)=S\circ E_{a,b}(x)
\quad\colon x\in\mathcal D(S)
\]
\medskip

\noindent
{\bf{B.1 }} By (C)  each  $x\in\ell^2$
gives the non-decreasing function
$\lambda\mapsto\langle E(\lambda)(x),x\rangle$ on the  real line.
Together with the right continuity in (c) there exist
Stieltjes' integrals
\[
\int_a^b\, \lambda\cdot \langle dE(\lambda)(x),x\rangle
\] 
for each bounded interval.
Carleman's  second condition for 
$\{E(\lambda)\}$  to be $S$-adapted is that
a vector $x$ belongs to $\mathcal D(S)$ if and only if
\[
\int_{-\infty}^\infty \, |\lambda|\cdot \langle dE(\lambda)(x),x\rangle<\infty\tag{b.1}
\] 


\noindent
{\bf{C.1}} The last  condition is that
\[
\langle Sx,y\rangle=
\int_{-\infty}^\infty \, \lambda\cdot \langle dE(\lambda)(x),y\rangle
\quad\colon x,y\in\mathcal D(S)\tag{c.1}
\]
where (b.1) and the Cauchy-Schwarz inequality
entail that the Stieltjes' integral in (c.1) is absolutely convergent.
\bigskip





\centerline{\bf{2. An example from PDE-theory.}}

\medskip


\noindent
{\bf{2.1. Propagation of sound}}.
With $(x,y,z)$ as space variables in
${\bf{R}}^3$ and a time variable $t$, the 
propagation of sound
in the infinite  open complement $U={\bf{R}}^3\setminus \overline{\Omega}$
of a bounded open subset $\Omega$ is governed by
 solutions $u(x,y,z,t)$ to the wave equation
 \[ 
 \frac{\partial^2 u}{\partial t^2}= \Delta u\tag{1}
 \] 
 where 
 $\Delta$ is the Laplace operator in $x,y,z$.
So here (1) holds when
$p=(x,y,z)\in U$
and $t\geq  0$. We  assume that
$\partial\Omega$ is of class $C^1$, i.e. given as  a union of pairwise disjoint
closed surfaces of class $C^1$ along which normal vectors are defined.
A boundary value problem
arises when we seek solutions 
such that
$p\mapsto u(p,t)$ belong to $L^2(U)$ for each $t$,
and the outer normal derivatives
taken along $\partial\Omega$ are zero,  i.e. for every $t$ 
\[
\frac{\partial u}{\partial n}(p,t)=0\quad\colon p\in \partial \Omega\tag{2}
\]
Initial conditions are expressed by  a pair of $C^2$-functions
$f_1x,y,z)$ and $f_2(x,y,z)$ defined in $U$ such that
$f_1,f_2$  together with
$\Delta(f_1$ and $\Delta(f_2)$ belong to $L^2(U)$,
and their outer normal derivatives along $\partial\Omega$ are zero.
So here
$u(p,0)= f_0(p)$ and $\frac{\partial u}{\partial t}(p,0)= f_1(p)$
hold for each $p\in U$.
\medskip

\noindent
That this  boundary value problem 
has a unique solution $u$ can be established via variational methods.
In the cited monograph, Carleman gave a proof using
the spectral function $\theta$ attached to a Class I operator
$A$ constructed via solutions to the Dirichlet problem
where no time variable appears.
A merit of thisproof is that
it confirms 
the physically expected result expressed by:
\[
\lim_{t\to \infty}\, (\frac{\partial u}{\partial x})^2(p,t)+
(\frac{\partial u}{\partial y})^2(p,t)+(\frac{\partial u}{\partial z})^2(p,t)=0\tag{*}
\]
with uniform convergence when $p$ stays in a relatively compact subset of
$U$.
More precisely, Carleman proved (*) by proving
that the  spectral function of $A$ 
is \emph{absolutely continuous} with respect to
the $\lambda$-parameter. 
In §§ we expose how Carelan derived this 
from  a
general result which goes as follows:

\medskip

\noindent
Let $\{a\leq s\leq b\}$ be a 
compact interval on the real $s$-line and
$s\mapsto G_s$ is  a function with values in the Hilbert space
$L^2(U)$ which  is 
continuous in the sense that 
\[
\lim_{s\to s_0}\, ||G_s-G_{s_0}||_2=0
\]
hold for each $s_0$, where we  introduced the $L^2$-norms.
The function has a finite total variation if 
there exists a constant $M$ such that
\[
\sum\, ||G_{s_{\nu+1}}-G_{s_\nu}||_2\leq M
\] 
hold for every partition $a=s_0<s_1<\ldots<s_M=b$.
When this holds one  construct Stieltjes integrals
and 
for every subinterval $[\alpha,\beta]$
there exists
the $L^2$-function in $U$ 
\[
\Phi_{[\alpha,\beta]}= \int_\alpha^\beta\, s\cdot \frac{dG_s}{ds}
\]
Impose the extra conditions that the normal deriviatives
$ \frac{\partial G_s}{\partial n}$ exist  and vanish 
$\partial\Omega$ for every $a\leq s\leq b$
and the following differential equation
holds for
every sub-interval $[\alpha,\beta]$ of $[a,b]$:
\[
\Delta(G_\beta-G_\alpha)+\Phi_{[\alpha,\beta]}=0
\] 
\medskip

\noindent
{\bf{Theorem.}}
\emph{The equations  above imply that
$s\mapsto G_s$ is absolutely continuous which means that 
whenever $\{\ell_1,\ldots,\ell_M\}$ a finite family of disjoint
intervals in $[a,b]$ where the sum of their lengths is $<\delta$,
then the sum of
the total variations over these intervals is
bounded by $\rho(\delta)$ where
$\rho$ is a function of $\delta$ which tends to zero as $\delta\to 0$.}

\newpage













\centerline{\bf{7. Hadamard's radius theorem.}}

\bigskip

\noindent
The thesis \emph{Essais sur l'études des fonctions donnés par leur
dévelopment d Taylor} from 1894 by Hadamard
contains many interesting results.
Here we expose material from Section 2 in [ibid].
Consider a power series
\[
 f(z)=\sum\, c\uuu nz^n\tag{*}
\]
whose radius is a positive  number
$\rho$.
So $f$ is analytic in the open disc $\{|z|<\rho\}$
and has at least one singular point on the circle
$\{|z|=\rho\}$.
Hadamard found a condition in order that
these singularities consists of a finite set of poles only so that
$f$ extends to be meromorphic in some disc $\{|z|<\rho\uuu *\}$ with
$\rho\uuu * >\rho$. The condition is expressed via properties of
the  Hankel determinants. Let us recall their definition. 
Let $\{c\uuu 0,c\uuu 1,\ldots\}$
be a sequence of complex numbers.
For each  integer $p\geq 0$ and  every $n\geq 0$
we obtain the 
$(p+1)\times (p+1)$\vvv matrix:

\[
\mathcal C\uuu n^{(p)}=
\begin{pmatrix}
c\uuu{n}&c\uuu{n+1}&\ldots&c\uuu{n+p}\\
c\uuu{n+1}&c\uuu{n+2}&\ldots&c\uuu{n+p}\\
\ldots&\ldots&\ldots&\ldots\\
c\uuu{n+p}&c\uuu{n+p+1}&\ldots&c\uuu{n+2p}\\
\end{pmatrix}
\]

\medskip


\noindent
Let $\mathcal D\uuu n^{(p)}$ denote the determinant. One
refers to $\{\mathcal D\uuu n^{(p)}\}$
as the recursive Hankel determinants.
Kronecker proved that
the series (*) represents a rational function in the complex $z$-åplane whose poles are outside
the origin if and only if there
exists some positvie integer $p$ such that
$\mathcal D\uuu n^{(p)}=0$ hold for all $n$.
 We shall prove this in § xx.
 Hadamard established a remarkable extensionmof
 Kronecker's result which goes as follows.
 WEe are given the series in (*) and assume that
 it has a finite postive radius of convergence  which by a wellknown formula satisfies the equation
 \[
\frac{1}{\rho}=\limsup\uuu{n\to \infty}\, |c\uuu n|^{\frac{1}{n}}
\]
This entails that for every  $\epsilon>0$  there exists a constant $C\uuu\epsilon$ 
such that
\[ 
|c\uuu n|\leq C\cdot (\rho \vvv  \epsilon)^{\vvv n}\quad\text{
hold for every}\quad  n
\]
It follows trivially that
\[
|\mathcal D\uuu n^{(p)}|\leq (p+1) !\cdot C^{p+1}(\rho\vvv \epsilon)^{\vvv (p+1)n}
\]
Passing to limes superior where  high $n$:th roots are taken
we conclude that:
\[
\delta(p)= \limsup\uuu{n\to \infty}\, 
\bigl[\mathcal D\uuu n^{(p)}\bigr]^{\frac{1}{n}}\leq \rho^{\vvv (p+1)}\tag{1}
\]

\medskip


\noindent
Suppose   there exists some $p\geq 1$ 
where a strict inequality occurs:
\[
\delta(p)<\rho^{\vvv(p+1)}\tag{2}
\]
Let  $p$ be the smallest integer  for which  (2) which gives 
a number $\rho\uuu *>\rho$ such that
\[
\delta(p)=\rho\uuu *^{\vvv 1}\cdot
\rho ^{\vvv p}\tag{3}
\]


\medskip

\noindent
{\bf{Hadamard's Theorem.}} \emph{With $p$ and $\rho_*$ as in (3),
it follows that $f(z)$ extends to a meromorphic function in the disc
of radius $\rho\uuu *$ where the number of poles counted with multiplicity
is at most  $p$.}
\bigskip


\noindent
The proof requires several steps. 
We shall first expose some general formulas about determinants
while the proof of Hadamard's theorem starts in § xx.
But let us first describe an application of Hadamard's theorem.
Namely, if
\[
\lim_{p\to\infty }\,\delta(p)=0\tag{4}
\]
it follows that (*) extends to a meromprohic function inthe whole complex plane.
Let us now consider a complex-valued and continuous
function
$k(x,y)$ defined on
the unit square
$\{0\leq x,y\leq 1\}$. We do not assume that $k$ is symmetric,  i.e,
in general $k(x,y)\neq k(y,x)$.
 Let $f(x)$ be another  continuous function  on $[0,1]$.
Assume that the maximum norms of $k$ and $f$ both are $<1$.
By induction over $n$ starting with $f\uuu 0(x)= f(x)$
we get a sequence $\{f\uuu n\}$ where
\[
f\uuu n(x)=\int\uuu 0^1\, k(x,y)\cdot f\uuu{n\vvv 1}(y)\cdot dy
\quad \colon\quad n\geq 1
\]
The hypothesis entails that each $f\uuu n$ has maximum norm
$<1$ and hence there exists  a power series:
\[
u\uuu\lambda(x)= \sum\uuu{n=0}^\infty\, f\uuu n(x)\cdot \lambda^n
\] 
which converges for every  $|\lambda|<1$ and yields a continuous function
$u\uuu\lambda(x)$  on $[0,1]$.

\medskip

\noindent
{\bf{0.1 Theorem.}}
\emph{The function $\lambda\mapsto u\uuu\lambda(x)$ with values in the Banach space
$B=C^0[0,1]$ extends to a meromorphic $B$\vvv valued 
function in the whole
$\lambda$\vvv plane.}
\bigskip

\noindent
To prove this we consider  the recursive Hankel determinants for
each $0\leq x\leq 1$:


\[
\mathcal D_n^{(p)}(x)=
\det
\begin{pmatrix}
f_{n+1}(x)
&f_{n+2}(x)
&\ldots&\ldots
& f_{n+p}(x)\\
f_{n+2}(x)
&f_{n+3}(x)
&\ldots&\ldots
& f_{n+p+1}(x)\\

\ldots &\ldots &\ldots&\ldots \\
\ldots &\ldots&\ldots&\ldots\\
f_{n+p}(x)
&f_{n+p+1}(x)
&\ldots&\ldots
& f_{n+2p-1}(x)\\
\end{pmatrix}
\]
\medskip


\noindent
With these notations the following inequality holds:
\medskip


\noindent
{\bf{Proposition 0.2}} \emph{For every $p\geq 2$ and $0\leq x\leq 1$ one has}

\[
\bigl |\,  \mathcal D\uuu n^{(p)}(x))\,\bigr|\leq 
(p\, !)^{\vvv n}\cdot \bigl( p^{\frac{p}{2}}) ^n\cdot \frac{p^p}{p\,!}\tag{0.2.1}
\]
\medskip

\noindent
This result is due to Carleman and exposed in § xx.
The inequality (0.2.1)  entails that
\[ 
\limsup\uuu{n\to \infty}\, \bigl| \mathcal D\uuu n^{(p)}(x))\,\bigr |^{1/n}
\leq 
\frac{p^{p/2}}{p\,!}
\]
Next, Stirling's formula gives:
\[
\lim\uuu{p\to \infty}\bigl[\frac{p^{1/2}}{p\,!}\,\bigr]^{\vvv 1/p}=0
\]
Hence the special case of  Hadamard's theorem gives
Theorem 0.1





\newpage



\centerline {\bf{A.  The Sylvester-Franke theorem.}}
\medskip


\noindent
Let    $A$  be some
$n\times n$\vvv matrix with
elements $\{a\uuu{ik}\}$.
Put
\[
b\uuu{rs}=a\uuu {11}a\uuu {rs}\vvv a\uuu{r1}a\uuu{1s}
\quad\colon\quad 2\leq r,s\leq n
\]
These $b$\vvv numbers give an $(n\vvv 1)\times(n\vvv 1)$\vvv matrix
where $b\uuu{22}$ is put in position $(1,1)$ and so on.
The matrix is denoted by 
$\mathcal S^1(A)$ and called the first order
Sylvester matrix.
If $a\uuu{11}\neq 0$ one has
the equality
\[
a\uuu{11}^{n\vvv 2}\cdot \text{det}(A)=
\text{det}(\mathcal S^1(A))\tag{A.1.1}
\]
\medskip

\noindent
{\bf{Exercise.}} Prove this result or consult a text\vvv book
which
apart from "soft abstract notions"  
does not ignore to
treat  determinants. 
\medskip

\noindent
{\bf{A.1.2 Sylvester's equation.}}
For every
$1\leq h\leq n\vvv 1$ one constructs the
$(n\vvv h\times (n\vvv h)$\vvv matrix whose elements are

\[ b\uuu{rs}= \det\,
\begin{pmatrix}
a\uuu{11}&a\uuu{12}&\ldots &a\uuu{1h}& a\uuu{1s}\\
a\uuu{21}&a\uuu{22}&\ldots &a\uuu{2h}& a\uuu{2s}\\
\ldots&\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots&\ldots\\
a\uuu{h1}&a\uuu{h2}&\ldots &a\uuu{hh}& a\uuu{hs}\\
a\uuu{r1}&a\uuu{r2}&\ldots &a\uuu{rh}& a\uuu{rs}\\
\end{pmatrix}\quad\colon\quad h+1\leq r,s\leq n
\]
\medskip

\noindent
With these notation one has the Sylvester equation:

\[
\det
\begin{pmatrix}
b\uuu{h+1,h+1}&b\uuu{h+1,h+2}&\ldots &b\uuu{h+1,n}\\
b\uuu{h+2,h+1}&b\uuu{h+2,h+2}&\ldots &b\uuu{h+2,n}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
b\uuu{n,h+1}&b\uuu{n,h+2}&\ldots &b\uuu{n,n}\\
\end{pmatrix}=
\bigl[\,\det\begin{pmatrix}
a\uuu{11}&a\uuu{12}&\ldots &a\uuu{1h}\\
a\uuu{21}&a\uuu{22}&\ldots &a\uuu{2h}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
a\uuu{h1}&a\uuu{h2}&\ldots &a\uuu{hh}\\
\end{pmatrix}\,\bigr]^{n\vvv h\vvv 1}\cdot \det(A)\tag{*}
\]
\medskip


\noindent
For a proof of (*) we refer to original work by Sylvester or
[Kovalevski: page xx\vvv xx] which offers several different
proofs of (*).

\bigskip

\noindent
{\bf{A.1.3 The Sylvester\vvv Franke theorem.}}
Let  $n\geq 2$ and $A=\{a\uuu{ik}\}$ an
$n\times n$\vvv matrix.
Let $m<n$ and consider 
the family of minors of size $m$, i.e.
one picks $m$ columns and $m$ rows
which give  an $m\times m$\vvv matrix
whose determinant is called a minor of size $m$
of the given matrix $A$. The total number of
such minors is equal to
\[
N^2\quad\text{where}\quad N= \binom{n}{m}
\]
We have $N$ many strictly increasing sequences
$1\leq \gamma\uuu1<\ldots\gamma \uuu m\leq n$
where a $\gamma$\vvv sequence corresponds to preserved
columns when   a minor is constructed. Similarly we have
$N$ strictly increasing sequences which correspond to preserved rows.
With this in mind we get  for each pair $1\leq r,s\leq N$
a minor $\mathfrak{M}\uuu {rs}$
where the enumerated $r$:th $\gamma$\vvv  sequence preserve columns and similarly
$s$ corresponds to the enumerated sequence of rows.
Now we obtain the $N\times N$\vvv matrix

\[
\mathcal A\uuu m= \begin{pmatrix}
\mathfrak{M}\uuu{11}&\mathfrak{M}{12}&\ldots &\mathfrak{M}\uuu{1N}\\
\mathfrak{M}\uuu{21}&\mathfrak{M}{22}&\ldots &\mathfrak{M}\uuu{2N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
\mathfrak{M}\uuu{N1}&\mathfrak{M}{22}&\ldots &\mathfrak{M}\uuu{NN}\\
\end{pmatrix}
\]


\noindent
We refer to $\mathcal A\uuu m$ as the Franke\vvv Sylvester matrix of order
$m$. They  are defined for each $1\leq m\leq n\vvv 1$.

\medskip







\noindent
{\bf{A.1.4 Theorem.}}
\emph{For every $1\leq m<n$ one has
the equality}
\[
\mathcal A\uuu m= \text{det}(A)^{\binom{n\vvv 1}{m\vvv 1}}
\]


\medskip

\noindent
{\bf{Example.}} Consider the diagonal $3\times 3$\vvv matrix:

\[
A=\begin{pmatrix}
1&0&0\\
0&1&0\\
0&0&2\\
\end{pmatrix}
\]

\medskip

\noindent
With $m=2$
we have 9 minors of size 2 and the reader can recognize that
when they are arranged so that we begin to remove
the first column, respectively the first row, then 
the resulting $\mathfrak{M}$\vvv matrix becomes
\[
\begin{pmatrix}
2&0&0\\
0&2&0\\
0&0&1\\
\end{pmatrix}
\]
Its determinant is $4= 2^2$ which is in accordance with the general formula since
$n=3$ and $m=2$ give $\binom{n\vvv 1}{m\vvv 1}=2$.
For the proof of Theorem 0.A.1 the reader can consult 
[Kovalevski: page102\vvv 105].




\bigskip



\centerline {\bf{§ B. Hankel determinants.}}
\bigskip


\noindent
Let $\{c\uuu 0,c\uuu 1,\ldots\}$
be a sequence of complex numbers.
For each  integer $p\geq 0$ and  every $n\geq 0$
we obtain the 
$(p+1)\times (p+1)$\vvv matrix:


\[
\mathcal C\uuu n^{(p)}=
\begin{pmatrix}
c\uuu{n}&c\uuu{n+1}&\ldots&c\uuu{n+p}\\
c\uuu{n+1}&c\uuu{n+2}&\ldots&c\uuu{n+p}\\
\ldots&\ldots&\ldots&\ldots\\
c\uuu{n+p}&c\uuu{n+p+1}&\ldots&c\uuu{n+2p}\\
\end{pmatrix}
\]

\medskip


\noindent
Let $\mathcal D\uuu n^{(p)}$ denote the determinant. One
refers to $\{\mathcal D\uuu n^{(p)}\}$
 as the recursive Hankel determinants.
They  are used to establish   various properties of the given
$c$\vvv sequence.
To begin with we define  the rank   $r^*$ 
of $\{c_n\}$
as follows:
To every non\vvv negative integer $n$
one has the  infinite vector
\[ 
\xi\uuu n=(c\uuu n,c\uuu{n+1},\ldots)
\]
We say that $\{c\uuu n\}$ has finite rank if
there exists a number $r^*$ such that
$r^*$ many $\xi$\vvv vectors
are linearly independent and the rest are linear combinations of these.
\medskip

\noindent
{\bf{B.1 Rational series expansions.}}
The sequence $\{c\uuu n\}$ gives the formal power series
\[
f(x)=\sum\uuu{\nu=0}^\infty\, c\uuu\nu x^\nu \tag{B.1.1}
\]
If $n\geq 1$ we set
\[
\phi\uuu n(x)= x^{\vvv n}\cdot(
f(x)\vvv \sum\uuu{\nu=0}^{n\vvv 1} c\uuu\nu x^\nu)=
\sum\uuu{\nu=0}^\infty c\uuu{n+\nu} x^\nu
\]
It is clear
that $\{c\uuu \nu\}$ has finite rank if and only if  the sequence
$\{\phi\uuu\nu(x)\}$
generates a finite dimensional complex subspace of the vector space 
${\bf{C}}[[x]]$ whose elements are formal power series.
If this dimension is finite we find a positive integer
$p$ and a 
non\vvv zero $(p+1)$\vvv tuple $(a\uuu 0,\ldots,a\uuu p)$ of complex numbers
such that the power series
\[ 
a\uuu 0\cdot  \phi\uuu 0(x)+\ldots+a\uuu p\cdot \phi\uuu p(x)=0
\]
Multiplying this equation with $x^p$ it follows that
\[
(a\uuu p+a\uuu{p\vvv 1} x+\ldots+a\uuu o x^p)\cdot f(x)=q(x)
\]
where $q(x)$ is a polynomial.
Hence the finite rank entails that the power series (B.1.1) 
represents a rational function.
\medskip


\noindent
{\bf{Exercise.}}
Conversely, assume that
\[
\sum\, c\uuu\nu x^\nu= \frac{q(x)}{g(x)}
\] 
for some pair of polynomials. Show that $\{c\uuu n\}$ has finite rank.
The next result is also left as an exercise to the reader.

\medskip


\noindent
{\bf{B.2 Proposition.}}
\emph{A sequence $\{c\uuu n\}$ has a finite rank if and only if
there exists an integer $p$ such that}
\[
\mathcal D\uuu 0^{(p)}\neq 0\quad
\text{and}\quad D\uuu 0^{(q)}=0\quad \colon\quad q>p\tag{4}
\]
\emph{Moreover, one has the equality $p$ is equal to the rank of
$\{c_n\}$.}


\medskip

\noindent
{\bf{B.3 A specific example.}}
Suppose that the degree of $q$ is strictly less than that of $g$ in the Exercise above  
and that the rational function $\frac{q}{g}$
is expressed by a sum of simple 
fractions:
\[ 
\sum\, c\uuu\nu x^\nu= \sum\uuu{k=1}^{k=p}\, \frac{d\uuu k}{1\vvv \alpha\uuu k x}
\] 
where $\alpha\uuu 1,\ldots,\alpha\uuu p$ are distinct and every $d\uuu k\neq 0$.
Then we see that
\[ 
c\uuu n=\sum\uuu{k=1}^{k=p}\, d\uuu k\cdot \alpha\uuu k^n\quad 
\text{where we have put}\quad
\alpha\uuu k^0=1\quad\text{ so that}\quad
c\uuu 0=\sum\, d\uuu k
\]
\medskip



\noindent
{\bf{B.4 The reduced rank.}}
Assume that $\{c\uuu n\}$ has a finite rank $r^*$. To each $k\geq 0$ we denote by $r\uuu k$
the dimension of the vector space generated by
$\xi\uuu k,\xi\uuu{k+1},\ldots$.
It is clear that $\{r\uuu k\}$ decrease and we find a non\vvv negative integer
$r\uuu *$ such that $r\uuu k=r\uuu *$ for large $k$ and
refer to $r\uuu *$ as the reduced rank. By the construction
$r\uuu *\leq r^*$. The relation between $r^*$ and $r\uuu *$
is related to the representation
\[
 f(x)= \frac{q(x)}{g(x)}
\]
where $q$ and $g$ are polynomials without common factor.
We shall not pursue this discussion any further but refer to the literature.
See in particular
the exercises
in [Polya\vvv Szegö : Chapter VII:problems 17\vvv 34].




\bigskip

\noindent
{\bf{B.5 Hankel's formula for Laurent series.}}
Consider a rational function of the form
\[
R(z)= \frac{q(z)}{z^p\vvv [a\uuu 1z^{p\vvv 1}+\ldots
+a\uuu{p\vvv 1}z+ a\uuu p]}
\]
where the polynomial $q$ has degree $\leq p\vvv 1$.
At $\infty$ we have a Laurent series expansion

\[ 
R(z)= \frac{c\uuu 0}{z}+ 
\frac{c\uuu 1}{z^2}+\ldots
\]
Consider the $p\times p$\vvv matrix
\[
A=\begin{pmatrix}
0&0&&\ldots&0&a\uuu p\\
1&0&0&\ldots&0&a\uuu{p\vvv 1}\\
0&1&0&\ldots&\ldots&a\uuu{p\vvv 2}\\
\ldots&
\ldots&
\ldots&
\ldots&\ldots&\ldots
\\
0&0&0&\ldots&1&a\uuu 1\\
\end{pmatrix}
\]
\medskip

\noindent
{\bf{B.5.1 Theorem.}}
\emph{Let $\mathcal D\uuu n^{(p)}$ be the Hankel determinants of
$\{c_n\}$. Then 
the following  hold for every $n\geq 1$:}
\[
\mathcal D\uuu n^{(p)}=  \mathcal D^{(p)}\uuu 0\cdot
\bigl[\text{det}(\,A\bigr)\bigr ) ^n
\]
\medskip

\noindent
{\bf{Exercise. }} Prove this result.

\bigskip

\noindent

\noindent
{\bf{B.6 Kronecker's identity.}}
For all pairs
of positive integers $p$ and $n$ one has the equality:

\[
\mathcal D\uuu n^{(p+1)}\cdot
\mathcal D\uuu {n+2}^{(p-2)}=
\mathcal D\uuu n^{(p+1)}
\mathcal D\uuu {n+2}^{(p\vvv 1)}-
\bigl[\mathcal D\uuu {n+1}^{(p)}\,\bigr]^2\tag{B.6.1}
\]

\medskip


\noindent
\emph{Proof.}
The equality (B.6.1 ) is s special case of a determinant formula for symmetric matrices
which is due to Sylvester.  Namely,
let $N\geq 2$ and consider a symmetric matrix

\[
S=\begin{pmatrix}
s\uuu{11}&s\uuu{12}&\ldots &s\uuu{1N}\\
s\uuu{21}&s\uuu{22}&\ldots &s\uuu{2N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N1}&a\uuu{N2}&\ldots &s\uuu{NN}\\
\end{pmatrix}
\]
\medskip


\noindent
Now we consider  the
$(N-1)\times (N-1)$-matrices

\[
S_1= 
\begin{pmatrix}
s\uuu{22}&s\uuu{23}&\ldots &s\uuu{2N}\\
s\uuu{32}&s\uuu{33}&\ldots &s\uuu{3N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N2}&s\uuu{N3}&\ldots &s\uuu{NN}\\
\end{pmatrix}
\quad\colon\quad 
S_2= 
\begin{pmatrix}
s\uuu{12}&s\uuu{13}&\ldots &s\uuu{1N}\\
s\uuu{22}&s\uuu{23}&\ldots &s\uuu{2N}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N-1,2}&s\uuu{N-1,3}&\ldots &s\uuu{N-1,N}\\
\end{pmatrix}
\]
\medskip
\[
S_3= 
\begin{pmatrix}
s\uuu{11}&s\uuu{12}&\ldots &s\uuu{1,N-1}\\
s\uuu{21}&s\uuu{22}&\ldots &s\uuu{2,N-1}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{N-1,1}&s\uuu{N-1,2}&\ldots &s\uuu{N-1,N-1}\\
\end{pmatrix}
\]
\medskip

\noindent
We have also the $(N-2)\times (N-2)$-matrix
when extremal rows and columns are removed:

\[ S_*=\begin{pmatrix}
s\uuu{22}&s\uuu{23}&\ldots &s\uuu{2,N-1}\\
s\uuu{32}&s\uuu{33}&\ldots &s\uuu{3,N-1}\\
\ldots&\ldots&\ldots&\ldots\\
\ldots&\ldots&\ldots&\ldots\\
s\uuu{2,N-1}&s\uuu{3,N-1}&\ldots &s\uuu{N-1,N-1}\\
\end{pmatrix}
\]
\medskip

\noindent
{\bf{B.7 Sylvester's identity.}}
\emph{One has the equation}
\[
\det(S)\cdot \det(S_*)=
\det S_1)\cdot \det S_3-\bigl(\det S_2\bigr)^2
\]
\medskip

\noindent{\bf{Exercise}}. Prove this result and deduce 
Kronecker's equation.

\bigskip




\centerline{\bf{C. Proof of Hadamard's theorem.}}







\medskip

\noindent
We are given the smallest integer $p$ in
Hadamard's theorem. 
\medskip

\noindent
{\bf{C.1  Lemma. }}\emph{When $p$ as above is minimal one has
the unrestricted limit formula:}
\[
\lim\uuu{n\to \infty}\, 
\bigl[\mathcal D\uuu n^{(p\vvv 1)}\bigr]^{\frac{1}{n}}=
\rho ^{\vvv p}\tag{*}
\]

\bigskip

TO BE GIVEN: Exercise power series+ Sylvesters equation.

\bigskip


\noindent
Lemma C.1 entails that if $n$ is large
$\{\mathcal D\uuu n^{(p\vvv 1)}\}$
are  $\neq 0$. Hence
there exists some $n_*$ such that every  $n\geq n_*$
gives   a    unique $p$\vvv vector
$(A\uuu n^{(1)},\ldots, A\uuu n^{(p)})$
which solves the inhomogeneous system
\[
\sum\uuu{k=0}^{k=p\vvv 1}
\, c\uuu {n+k+j}\cdot A\uuu n^{(p\vvv k)}
=\vvv c\uuu {n+p+j}\quad\colon\quad 0\leq j\leq p\vvv 1
\]
Or expressed in matrix notation:
\[
\begin{pmatrix}
c\uuu{n}&c\uuu{n+1}&\ldots&c\uuu{n+p-1}\\
c\uuu{n+1}&c\uuu{n+2}&\ldots&c\uuu{n+p}\\
\ldots&\ldots&\ldots&\ldots\\
c\uuu{n+p-1}&c\uuu{n+p}&\ldots&c\uuu{n+2p-2}\\
\end{pmatrix}\,
\begin{pmatrix}A_n^{(p)}\\\ldots\\\ldots\\\ldots\\
A_n^{(1)}\end{pmatrix}=-
\begin{pmatrix}c_{n+p} \\\ldots\\\ldots\\\ldots\\
c_{n+2p-1}\end{pmatrix}\tag{*}
\]

\medskip


\noindent
{\bf{C.2  Exercise.}}
Put
\[
H\uuu n=
c\uuu{n+2p}+ A\uuu n^{(1)}\cdot  c\uuu{n+2p\vvv 1}+
\ldots+ A\uuu n^{(p)} \cdot c\uuu{n+p}
\]




Show that the evaluation of  $\mathcal D\uuu n^{(p)}$ 
via an expansion of the last column gives the equality:
\[ 
H\uuu n=
\frac{\mathcal D\uuu n^{(p)}}{\mathcal D\uuu n^{(p\vvv 1)}}\tag{C.2.1}
\]
\medskip

\noindent

\noindent
Next,  the  limit formula   (3) above Theorem 7.1 together with
Lemma C.1 
give for every $\epsilon>0$
a constant $C\uuu\epsilon$ 
such that the following hold for all sufficiently large $n$:
\[ 
|H\uuu n|\leq C\uuu\epsilon \cdot 
\bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n\tag{i}
\]

\noindent
Next, 
put
\[ 
\delta\uuu n^{k}=A\uuu {n+1}^{(k)}\vvv A\uuu n^{(k)}
\quad\colon\quad 1\leq k\leq p\tag{ii}
\]

\medskip

\noindent
From the equation in  (*) applied with  $n$ and $n+1$ it is clear that
the $\delta$\vvv numbers satisfy the system
\[
\sum\uuu{k=0}^{k=p\vvv 1}
\, 
c\uuu {n+j+k+1}\cdot \delta \uuu n^{(p\vvv k)}=0
\quad\colon\quad 0\leq j\leq p\vvv 2
\]
\[
\sum\uuu{k=0}^{k=p\vvv 1}
\, 
c\uuu {n+p+k}\cdot \delta \uuu n^{(p\vvv k)}=
\vvv (c\uuu{n+2p}+ A\uuu n^{(1)}\cdot  c\uuu{n+2p\vvv 1}+
\ldots+ A\uuu n^{(p)} \cdot c\uuu{n+p})
\tag{iii}
\]
\medskip



\noindent
The $\delta$\vvv numbers in the linear system ( iii)
are found  via Cramer's rule. 
The minors of degree $p\vvv 1$ in the Hankel matrices 
$\mathcal C\uuu {n+1}^{(p\vvv 1)}$ have elements from
the given
$c$\vvv sequence and  
every such minor has an absolute value majorized by
\[
C\cdot (\rho\vvv \epsilon)^{\vvv (p\vvv 1)n}
\] 
where $C$ is a constant 
which is independent of $n$.
We conclude that the $\delta$\vvv numbers satisfy
\[
|\delta \uuu n^{(k)}|\leq |\mathcal D\uuu n^{(p\vvv 1)}|^{\vvv 1}\cdot 
C\cdot (\rho\vvv \epsilon)^{\vvv (p\vvv 1)n}\cdot |H\uuu n|\tag{iv}
\]


Show that the evaluation of  $\mathcal D\uuu n^{(p)}$ 
via an expansion of the last column gives the equality:
\[ 
H\uuu n=
\frac{\mathcal D\uuu n^{(p)}}{\mathcal D\uuu n^{(p\vvv 1)}}\tag{C.2.1}
\]
\medskip

\noindent

\noindent
Next,  the  limit formula   (3) above Theorem 7.1 together with
Lemma C.1 
give for every $\epsilon>0$
a constant $C\uuu\epsilon$ 
such that the following hold for all sufficiently large $n$:
\[ 
|H\uuu n|\leq C\uuu\epsilon \cdot 
\bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n\tag{i}
\]


\noindent
Next, the  unrestricted limit in Lemma C.1
give  upper bounds for
 $|\mathcal D\uuu n^{(p\vvv 1)}|^{\vvv 1}$ so that  (C.2.1 ) and (iv) give:
 
\medskip
 
 \noindent
{\bf{C.3  Lemma}}
 \emph{To each $\epsilon>0$ there is a constant
 $C\uuu\epsilon$ such that}
 \[
|\delta \uuu n^{(k)}|\leq 
C\uuu\epsilon\cdot
 \bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n
 \quad\colon\quad 1\leq k\leq p
\]
\medskip


\noindent
{\bf{C.4  The polynomial $Q(z)$}}.
Lemma C.3   and (ii) entail that
the sequence $\{A\uuu n^{(k)}\,\colon\, n=1,2,\ldots\}$
converges for every $k$. Set
\[
A\uuu *^{(k)}=\lim_{n\to\infty}\, A\uuu n^{(k)}\,
\]
and notice     that Lemma C.3  after summations of geometric series gives
a constant $C_1$ such that
\[
|A\uuu *^{(k)}\vvv A\uuu n^{(k)}|\leq C_1\cdot 
\bigl(\frac{\rho+\epsilon}{\rho\uuu *\vvv \epsilon}\bigr)^n\tag{C.4.1}
\]
hold for every $1\leq k\leq p$ and every $n$.
\medskip

\noindent
Now we consider the sequence
\[
b\uuu n=
 c\uuu{n+p}+ A\uuu *^{(1)}\cdot c\uuu {n+p\vvv 1}+
\ldots A\uuu *^{(p)}\cdot c\uuu n\tag{C.4.2 }
 \]
Equation (*) applied to   $j=0$  gives
\[
b\uuu n= 
(A\uuu *^{(1)}\vvv A\uuu n ^{(1)})
\cdot c\uuu {n+p\vvv 1}+
\ldots +(A\uuu *^{(p)}\vvv A\uuu n^{(p)})\cdot c\uuu n\tag{C.4.3}
\]

\medskip

\noindent
We have already seen that $|c\uuu n|\leq C\cdot(\rho\vvv \epsilon)^{\vvv n}$
hold for some constant $C$ which
together with (C.4.1)  gives:
\medskip

\noindent
{\bf{C.5  Lemma.}}
\emph{For every $\epsilon>0$ there exists a constant $C$ such that}
\[
|b\uuu n|\leq C\cdot \bigl(\frac{1+\epsilon}{\rho\uuu *}\bigr)^n
\]
\medskip

\noindent
Finally, consider the polynomial
\[
Q(z)=  1+ A\uuu *^{(1)}\cdot z+
\ldots A\uuu *^{(p)}\cdot z^p\tag{C.6}
\]

\noindent
Set $g(z)= Q(z)f(z)$ which has a power series
$\sum\, d_\nu z^\nu$
where 
\[
d_{n+p}=
c_n\cdot   A_*^{(p)}+\ldots
c_{n+p-1}A_*^{(1)} +c_{n+p}=b_n
\]
\medskip


\noindent
Above $p$ is fixed so Lemma 6.5 and the standard  spectral radius formula 
show that
$g(z)$ is analytic in the disc $|z|<\rho_*$. This
proves that $f$ extends and the poles are contained in
the zeros of the polynomial $Q$ which occur  in 
$\rho\leq |z|<\rho_*$.












\end{document}










